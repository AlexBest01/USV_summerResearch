[2022-01-03 12:09:29,315][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': 'tb_logs', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 3, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1400000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1400000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 288, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 96, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': True, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 0.1, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'checkpoint_activations': False}, 'task': {'_name': 'audio_pretraining', 'data': '/local/scratch/bestalex/cut_10s_mixed_usv/maternal_calls', 'labels': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 250000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'tpu': False, 'text_compression_level': 'none'}, 'criterion': {'_name': 'wav2vec', 'infonce': True, 'loss_weights': [0.1, 10.0], 'log_keys': ['prob_perplexity', 'code_perplexity', 'temp']}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2022-01-03 12:09:29,814][fairseq_cli.train][INFO] - Wav2Vec2Model(
  (feature_extractor): ConvFeatureExtractionModel(
    (conv_layers): ModuleList(
      (0): Sequential(
        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
        (3): GELU()
      )
      (1): Sequential(
        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU()
      )
      (2): Sequential(
        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU()
      )
      (3): Sequential(
        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU()
      )
      (4): Sequential(
        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU()
      )
      (5): Sequential(
        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU()
      )
      (6): Sequential(
        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU()
      )
    )
  )
  (post_extract_proj): Linear(in_features=512, out_features=288, bias=True)
  (dropout_input): Dropout(p=0.1, inplace=False)
  (dropout_features): Dropout(p=0.1, inplace=False)
  (quantizer): GumbelVectorQuantizer(
    (weight_proj): Linear(in_features=512, out_features=640, bias=True)
  )
  (project_q): Linear(in_features=96, out_features=96, bias=True)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(288, 288, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
      (1): SamePad()
      (2): GELU()
    )
    (layers): ModuleList(
      (0): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=288, out_features=288, bias=True)
          (v_proj): Linear(in_features=288, out_features=288, bias=True)
          (q_proj): Linear(in_features=288, out_features=288, bias=True)
          (out_proj): Linear(in_features=288, out_features=288, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=288, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=288, bias=True)
        (final_layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (final_proj): Linear(in_features=288, out_features=96, bias=True)
)
[2022-01-03 12:09:29,816][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2022-01-03 12:09:29,816][fairseq_cli.train][INFO] - model: Wav2Vec2Model
[2022-01-03 12:09:29,816][fairseq_cli.train][INFO] - criterion: Wav2vecCriterion
[2022-01-03 12:09:29,818][fairseq_cli.train][INFO] - num. shared model params: 30,693,088 (num. trained: 30,693,088)
[2022-01-03 12:09:29,818][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2022-01-03 12:09:29,821][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 2, skipped 0 samples
[2022-01-03 12:09:42,590][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.1.0.bias
[2022-01-03 12:09:42,590][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.2.0.bias
[2022-01-03 12:09:42,590][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.3.0.bias
[2022-01-03 12:09:42,590][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.4.0.bias
[2022-01-03 12:09:42,590][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.5.0.bias
[2022-01-03 12:09:42,590][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.6.0.bias
[2022-01-03 12:09:42,591][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2022-01-03 12:09:42,591][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 15.740 GB ; name = NVIDIA RTX A4000                        
[2022-01-03 12:09:42,591][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2022-01-03 12:09:42,591][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2022-01-03 12:09:42,591][fairseq_cli.train][INFO] - max tokens per device = 1400000 and max sentences per device = None
[2022-01-03 12:09:42,593][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2022-01-03 12:09:42,593][fairseq.trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2022-01-03 12:09:42,593][fairseq.trainer][INFO] - loading train data for epoch 1
[2022-01-03 12:09:42,594][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 198, skipped 0 samples
[2022-01-03 12:09:42,824][fairseq.trainer][INFO] - NOTE: your device may support faster training with --fp16 or --amp
[2022-01-03 12:09:42,842][fairseq.trainer][INFO] - begin training epoch 1
[2022-01-03 12:09:42,842][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:09:56,685][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:09:57,116][valid][INFO] - {"epoch": 1, "valid_loss": "8.984", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "137.874", "valid_code_perplexity": "133.926", "valid_temp": "2", "valid_loss_0": "6.751", "valid_loss_1": "0.113", "valid_loss_2": "2.119", "valid_accuracy": "0.00916", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "40"}
[2022-01-03 12:09:57,119][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 40 updates
[2022-01-03 12:09:57,119][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:10:00,943][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:10:08,285][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 40 updates, score 8.984) (writing took 11.165889294818044 seconds)
[2022-01-03 12:10:08,285][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2022-01-03 12:10:08,301][train][INFO] - {"epoch": 1, "train_loss": "9.663", "train_ntokens": "1791", "train_nsentences": "4.95", "train_prob_perplexity": "186.272", "train_code_perplexity": "182.778", "train_temp": "2", "train_loss_0": "6.788", "train_loss_1": "0.102", "train_loss_2": "2.773", "train_accuracy": "0.01114", "train_wps": "2862", "train_ups": "1.6", "train_wpb": "1791", "train_bsz": "5", "train_num_updates": "40", "train_lr": "6.25e-07", "train_gnorm": "2.405", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "26"}
[2022-01-03 12:10:08,386][fairseq.trainer][INFO] - begin training epoch 2
[2022-01-03 12:10:08,387][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:10:21,959][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:10:22,355][valid][INFO] - {"epoch": 2, "valid_loss": "8.802", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "180.317", "valid_code_perplexity": "176.077", "valid_temp": "1.999", "valid_loss_0": "6.701", "valid_loss_1": "0.104", "valid_loss_2": "1.997", "valid_accuracy": "0.01282", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "80", "valid_best_loss": "8.802"}
[2022-01-03 12:10:22,357][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 80 updates
[2022-01-03 12:10:22,358][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:10:26,428][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:10:33,363][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 80 updates, score 8.802) (writing took 11.005273586139083 seconds)
[2022-01-03 12:10:33,363][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2022-01-03 12:10:33,377][train][INFO] - {"epoch": 2, "train_loss": "9.11", "train_ntokens": "1800.5", "train_nsentences": "4.95", "train_prob_perplexity": "209.228", "train_code_perplexity": "205.382", "train_temp": "1.999", "train_loss_0": "6.74", "train_loss_1": "0.097", "train_loss_2": "2.273", "train_accuracy": "0.01161", "train_wps": "2873.6", "train_ups": "1.6", "train_wpb": "1800.5", "train_bsz": "5", "train_num_updates": "80", "train_lr": "1.25e-06", "train_gnorm": "1.787", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "51"}
[2022-01-03 12:10:33,420][fairseq.trainer][INFO] - begin training epoch 3
[2022-01-03 12:10:33,420][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:10:47,068][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:10:47,459][valid][INFO] - {"epoch": 3, "valid_loss": "7.613", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "208.126", "valid_code_perplexity": "202.411", "valid_temp": "1.999", "valid_loss_0": "6.695", "valid_loss_1": "0.097", "valid_loss_2": "0.821", "valid_accuracy": "0.01053", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "120", "valid_best_loss": "7.613"}
[2022-01-03 12:10:47,462][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 120 updates
[2022-01-03 12:10:47,463][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:10:51,368][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:10:58,519][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 3 @ 120 updates, score 7.613) (writing took 11.0567125082016 seconds)
[2022-01-03 12:10:58,520][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2022-01-03 12:10:58,533][train][INFO] - {"epoch": 3, "train_loss": "8.383", "train_ntokens": "1781.33", "train_nsentences": "4.95", "train_prob_perplexity": "244.308", "train_code_perplexity": "239.838", "train_temp": "1.999", "train_loss_0": "6.712", "train_loss_1": "0.089", "train_loss_2": "1.582", "train_accuracy": "0.01186", "train_wps": "2833.9", "train_ups": "1.59", "train_wpb": "1781.3", "train_bsz": "5", "train_num_updates": "120", "train_lr": "1.875e-06", "train_gnorm": "1.267", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "76"}
[2022-01-03 12:10:58,620][fairseq.trainer][INFO] - begin training epoch 4
[2022-01-03 12:10:58,621][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:11:12,347][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:11:12,765][valid][INFO] - {"epoch": 4, "valid_loss": "7.673", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "272.475", "valid_code_perplexity": "261.887", "valid_temp": "1.998", "valid_loss_0": "6.661", "valid_loss_1": "0.083", "valid_loss_2": "0.929", "valid_accuracy": "0.01776", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "160", "valid_best_loss": "7.613"}
[2022-01-03 12:11:12,770][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 160 updates
[2022-01-03 12:11:12,772][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:11:16,700][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:11:16,718][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 4 @ 160 updates, score 7.673) (writing took 3.9480280308052897 seconds)
[2022-01-03 12:11:16,719][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2022-01-03 12:11:16,731][train][INFO] - {"epoch": 4, "train_loss": "7.8", "train_ntokens": "1795.38", "train_nsentences": "4.95", "train_prob_perplexity": "290.399", "train_code_perplexity": "285.019", "train_temp": "1.999", "train_loss_0": "6.692", "train_loss_1": "0.079", "train_loss_2": "1.029", "train_accuracy": "0.01239", "train_wps": "3948.9", "train_ups": "2.2", "train_wpb": "1795.4", "train_bsz": "5", "train_num_updates": "160", "train_lr": "2.5e-06", "train_gnorm": "0.843", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "94"}
[2022-01-03 12:11:16,808][fairseq.trainer][INFO] - begin training epoch 5
[2022-01-03 12:11:16,809][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:11:30,583][train_inner][INFO] - {"epoch": 5, "update": 5.0, "loss": "8.475", "ntokens": "1792.93", "nsentences": "4.95", "prob_perplexity": "254.624", "code_perplexity": "250.048", "temp": "1.999", "loss_0": "6.722", "loss_1": "0.087", "loss_2": "1.666", "accuracy": "0.0119", "wps": "3344.4", "ups": "1.87", "wpb": "1792.9", "bsz": "5", "num_updates": "200", "lr": "3.125e-06", "gnorm": "1.376", "clip": "0", "train_wall": "66", "gb_free": "6", "wall": "108"}
[2022-01-03 12:11:30,584][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:11:30,994][valid][INFO] - {"epoch": 5, "valid_loss": "7.055", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "304.251", "valid_code_perplexity": "290.94", "valid_temp": "1.998", "valid_loss_0": "6.666", "valid_loss_1": "0.076", "valid_loss_2": "0.313", "valid_accuracy": "0.01667", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "200", "valid_best_loss": "7.055"}
[2022-01-03 12:11:30,998][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 200 updates
[2022-01-03 12:11:30,999][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:11:34,856][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:11:42,121][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 5 @ 200 updates, score 7.055) (writing took 11.123343884013593 seconds)
[2022-01-03 12:11:42,121][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2022-01-03 12:11:42,136][train][INFO] - {"epoch": 5, "train_loss": "7.421", "train_ntokens": "1796.45", "train_nsentences": "4.95", "train_prob_perplexity": "342.916", "train_code_perplexity": "337.226", "train_temp": "1.998", "train_loss_0": "6.678", "train_loss_1": "0.067", "train_loss_2": "0.676", "train_accuracy": "0.01251", "train_wps": "2830.2", "train_ups": "1.58", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "200", "train_lr": "3.125e-06", "train_gnorm": "0.58", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "120"}
[2022-01-03 12:11:42,221][fairseq.trainer][INFO] - begin training epoch 6
[2022-01-03 12:11:42,222][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:11:55,927][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:11:56,339][valid][INFO] - {"epoch": 6, "valid_loss": "6.934", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "339.823", "valid_code_perplexity": "322.718", "valid_temp": "1.998", "valid_loss_0": "6.665", "valid_loss_1": "0.068", "valid_loss_2": "0.202", "valid_accuracy": "0.01404", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "240", "valid_best_loss": "6.934"}
[2022-01-03 12:11:56,342][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 240 updates
[2022-01-03 12:11:56,343][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:12:00,261][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:12:07,599][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 6 @ 240 updates, score 6.934) (writing took 11.256714664399624 seconds)
[2022-01-03 12:12:07,600][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2022-01-03 12:12:07,615][train][INFO] - {"epoch": 6, "train_loss": "7.153", "train_ntokens": "1796.38", "train_nsentences": "4.95", "train_prob_perplexity": "390.843", "train_code_perplexity": "384.254", "train_temp": "1.998", "train_loss_0": "6.674", "train_loss_1": "0.056", "train_loss_2": "0.423", "train_accuracy": "0.01124", "train_wps": "2821.9", "train_ups": "1.57", "train_wpb": "1796.4", "train_bsz": "5", "train_num_updates": "240", "train_lr": "3.75e-06", "train_gnorm": "0.423", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "145"}
[2022-01-03 12:12:07,686][fairseq.trainer][INFO] - begin training epoch 7
[2022-01-03 12:12:07,687][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:12:21,380][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:12:21,786][valid][INFO] - {"epoch": 7, "valid_loss": "6.867", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "381.272", "valid_code_perplexity": "363.672", "valid_temp": "1.997", "valid_loss_0": "6.662", "valid_loss_1": "0.058", "valid_loss_2": "0.146", "valid_accuracy": "0.00964", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "280", "valid_best_loss": "6.867"}
[2022-01-03 12:12:21,788][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 280 updates
[2022-01-03 12:12:21,789][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:12:25,742][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:12:33,004][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 7 @ 280 updates, score 6.867) (writing took 11.215639588423073 seconds)
[2022-01-03 12:12:33,005][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2022-01-03 12:12:33,017][train][INFO] - {"epoch": 7, "train_loss": "7.013", "train_ntokens": "1789.45", "train_nsentences": "4.95", "train_prob_perplexity": "433.78", "train_code_perplexity": "426.907", "train_temp": "1.997", "train_loss_0": "6.669", "train_loss_1": "0.046", "train_loss_2": "0.297", "train_accuracy": "0.0114", "train_wps": "2819.2", "train_ups": "1.58", "train_wpb": "1789.5", "train_bsz": "5", "train_num_updates": "280", "train_lr": "4.375e-06", "train_gnorm": "0.339", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "170"}
[2022-01-03 12:12:33,070][fairseq.trainer][INFO] - begin training epoch 8
[2022-01-03 12:12:33,070][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:12:46,778][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:12:47,164][valid][INFO] - {"epoch": 8, "valid_loss": "6.807", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "407.361", "valid_code_perplexity": "394.109", "valid_temp": "1.997", "valid_loss_0": "6.653", "valid_loss_1": "0.052", "valid_loss_2": "0.101", "valid_accuracy": "0.01459", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "320", "valid_best_loss": "6.807"}
[2022-01-03 12:12:47,167][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 320 updates
[2022-01-03 12:12:47,167][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:12:51,085][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:12:57,607][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 8 @ 320 updates, score 6.807) (writing took 10.440459526143968 seconds)
[2022-01-03 12:12:57,607][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2022-01-03 12:12:57,621][train][INFO] - {"epoch": 8, "train_loss": "6.913", "train_ntokens": "1807.8", "train_nsentences": "4.95", "train_prob_perplexity": "467.075", "train_code_perplexity": "459.872", "train_temp": "1.997", "train_loss_0": "6.664", "train_loss_1": "0.039", "train_loss_2": "0.21", "train_accuracy": "0.01157", "train_wps": "2940.7", "train_ups": "1.63", "train_wpb": "1807.8", "train_bsz": "5", "train_num_updates": "320", "train_lr": "5e-06", "train_gnorm": "0.272", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "195"}
[2022-01-03 12:12:57,711][fairseq.trainer][INFO] - begin training epoch 9
[2022-01-03 12:12:57,712][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:13:11,481][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:13:11,894][valid][INFO] - {"epoch": 9, "valid_loss": "6.833", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "407.073", "valid_code_perplexity": "389.002", "valid_temp": "1.996", "valid_loss_0": "6.653", "valid_loss_1": "0.053", "valid_loss_2": "0.127", "valid_accuracy": "0.01535", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "360", "valid_best_loss": "6.807"}
[2022-01-03 12:13:11,897][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 360 updates
[2022-01-03 12:13:11,898][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:13:15,854][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:13:15,875][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 9 @ 360 updates, score 6.833) (writing took 3.978321397677064 seconds)
[2022-01-03 12:13:15,876][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2022-01-03 12:13:15,889][train][INFO] - {"epoch": 9, "train_loss": "6.855", "train_ntokens": "1789.55", "train_nsentences": "4.95", "train_prob_perplexity": "493.59", "train_code_perplexity": "486.186", "train_temp": "1.997", "train_loss_0": "6.66", "train_loss_1": "0.033", "train_loss_2": "0.162", "train_accuracy": "0.01183", "train_wps": "3921.2", "train_ups": "2.19", "train_wpb": "1789.5", "train_bsz": "5", "train_num_updates": "360", "train_lr": "5.625e-06", "train_gnorm": "0.24", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "213"}
[2022-01-03 12:13:15,975][fairseq.trainer][INFO] - begin training epoch 10
[2022-01-03 12:13:15,976][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:13:29,729][train_inner][INFO] - {"epoch": 10, "update": 10.0, "loss": "6.948", "ntokens": "1789.06", "nsentences": "4.95", "prob_perplexity": "458.786", "code_perplexity": "451.611", "temp": "1.997", "loss_0": "6.664", "loss_1": "0.041", "loss_2": "0.243", "accuracy": "0.0117", "wps": "3003.4", "ups": "1.68", "wpb": "1789.1", "bsz": "5", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.303", "clip": "0", "train_wall": "66", "gb_free": "5.5", "wall": "227"}
[2022-01-03 12:13:29,730][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:13:30,167][valid][INFO] - {"epoch": 10, "valid_loss": "6.753", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "423.046", "valid_code_perplexity": "406.033", "valid_temp": "1.996", "valid_loss_0": "6.645", "valid_loss_1": "0.049", "valid_loss_2": "0.06", "valid_accuracy": "0.01263", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "400", "valid_best_loss": "6.753"}
[2022-01-03 12:13:30,171][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 400 updates
[2022-01-03 12:13:30,172][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:13:34,132][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:13:42,026][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 10 @ 400 updates, score 6.753) (writing took 11.854361236095428 seconds)
[2022-01-03 12:13:42,026][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2022-01-03 12:13:42,040][train][INFO] - {"epoch": 10, "train_loss": "6.803", "train_ntokens": "1762.12", "train_nsentences": "4.95", "train_prob_perplexity": "508.64", "train_code_perplexity": "500.836", "train_temp": "1.996", "train_loss_0": "6.655", "train_loss_1": "0.03", "train_loss_2": "0.118", "train_accuracy": "0.01244", "train_wps": "2696.7", "train_ups": "1.53", "train_wpb": "1762.1", "train_bsz": "5", "train_num_updates": "400", "train_lr": "6.25e-06", "train_gnorm": "0.24", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "239"}
[2022-01-03 12:13:42,129][fairseq.trainer][INFO] - begin training epoch 11
[2022-01-03 12:13:42,130][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:13:55,963][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:13:56,390][valid][INFO] - {"epoch": 11, "valid_loss": "6.504", "valid_ntokens": "810", "valid_nsentences": "2", "valid_prob_perplexity": "266.045", "valid_code_perplexity": "255.113", "valid_temp": "1.996", "valid_loss_0": "6.33", "valid_loss_1": "0.084", "valid_loss_2": "0.089", "valid_accuracy": "0.02963", "valid_wps": "0", "valid_wpb": "810", "valid_bsz": "2", "valid_num_updates": "440", "valid_best_loss": "6.504"}
[2022-01-03 12:13:56,393][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 11 @ 440 updates
[2022-01-03 12:13:56,394][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:14:00,293][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:14:07,925][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 11 @ 440 updates, score 6.504) (writing took 11.532138973474503 seconds)
[2022-01-03 12:14:07,926][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2022-01-03 12:14:07,938][train][INFO] - {"epoch": 11, "train_loss": "6.705", "train_ntokens": "1765.88", "train_nsentences": "4.95", "train_prob_perplexity": "455.784", "train_code_perplexity": "448.232", "train_temp": "1.996", "train_loss_0": "6.559", "train_loss_1": "0.041", "train_loss_2": "0.104", "train_accuracy": "0.02012", "train_wps": "2728.7", "train_ups": "1.55", "train_wpb": "1765.9", "train_bsz": "5", "train_num_updates": "440", "train_lr": "6.875e-06", "train_gnorm": "0.49", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "265"}
[2022-01-03 12:14:08,018][fairseq.trainer][INFO] - begin training epoch 12
[2022-01-03 12:14:08,019][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:14:21,841][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:14:22,383][valid][INFO] - {"epoch": 12, "valid_loss": "6.063", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "71.471", "valid_code_perplexity": "69.457", "valid_temp": "1.995", "valid_loss_0": "5.842", "valid_loss_1": "0.128", "valid_loss_2": "0.093", "valid_accuracy": "0.10336", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "480", "valid_best_loss": "6.063"}
[2022-01-03 12:14:22,387][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 12 @ 480 updates
[2022-01-03 12:14:22,388][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:14:26,174][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:14:33,146][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 12 @ 480 updates, score 6.063) (writing took 10.758905579335988 seconds)
[2022-01-03 12:14:33,147][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2022-01-03 12:14:33,163][train][INFO] - {"epoch": 12, "train_loss": "6.341", "train_ntokens": "1789.25", "train_nsentences": "4.95", "train_prob_perplexity": "143.281", "train_code_perplexity": "140.593", "train_temp": "1.995", "train_loss_0": "6.12", "train_loss_1": "0.112", "train_loss_2": "0.109", "train_accuracy": "0.06894", "train_wps": "2839", "train_ups": "1.59", "train_wpb": "1789.2", "train_bsz": "5", "train_num_updates": "480", "train_lr": "7.5e-06", "train_gnorm": "1.006", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "291"}
[2022-01-03 12:14:33,253][fairseq.trainer][INFO] - begin training epoch 13
[2022-01-03 12:14:33,255][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:14:47,220][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:14:47,747][valid][INFO] - {"epoch": 13, "valid_loss": "6.023", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "80.287", "valid_code_perplexity": "76.861", "valid_temp": "1.995", "valid_loss_0": "5.815", "valid_loss_1": "0.126", "valid_loss_2": "0.081", "valid_accuracy": "0.14973", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "520", "valid_best_loss": "6.023"}
[2022-01-03 12:14:47,751][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 13 @ 520 updates
[2022-01-03 12:14:47,752][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:14:51,442][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:14:58,461][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 13 @ 520 updates, score 6.023) (writing took 10.710239935666323 seconds)
[2022-01-03 12:14:58,462][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2022-01-03 12:14:58,477][train][INFO] - {"epoch": 13, "train_loss": "6.14", "train_ntokens": "1780.4", "train_nsentences": "4.95", "train_prob_perplexity": "87.815", "train_code_perplexity": "85.833", "train_temp": "1.995", "train_loss_0": "5.918", "train_loss_1": "0.124", "train_loss_2": "0.098", "train_accuracy": "0.13161", "train_wps": "2815", "train_ups": "1.58", "train_wpb": "1780.4", "train_bsz": "5", "train_num_updates": "520", "train_lr": "8.125e-06", "train_gnorm": "0.986", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "316"}
[2022-01-03 12:14:58,568][fairseq.trainer][INFO] - begin training epoch 14
[2022-01-03 12:14:58,568][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:15:12,436][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:15:12,829][valid][INFO] - {"epoch": 14, "valid_loss": "6.08", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "71.537", "valid_code_perplexity": "69.676", "valid_temp": "1.994", "valid_loss_0": "5.869", "valid_loss_1": "0.128", "valid_loss_2": "0.082", "valid_accuracy": "0.17553", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "560", "valid_best_loss": "6.023"}
[2022-01-03 12:15:12,832][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 14 @ 560 updates
[2022-01-03 12:15:12,833][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:15:16,735][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:15:16,757][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 14 @ 560 updates, score 6.08) (writing took 3.924427875317633 seconds)
[2022-01-03 12:15:16,757][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2022-01-03 12:15:16,772][train][INFO] - {"epoch": 14, "train_loss": "6.018", "train_ntokens": "1791.42", "train_nsentences": "4.95", "train_prob_perplexity": "81.038", "train_code_perplexity": "79.512", "train_temp": "1.995", "train_loss_0": "5.806", "train_loss_1": "0.126", "train_loss_2": "0.086", "train_accuracy": "0.17086", "train_wps": "3919.8", "train_ups": "2.19", "train_wpb": "1791.4", "train_bsz": "5", "train_num_updates": "560", "train_lr": "8.75e-06", "train_gnorm": "1.125", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "334"}
[2022-01-03 12:15:16,854][fairseq.trainer][INFO] - begin training epoch 15
[2022-01-03 12:15:16,854][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:15:30,649][train_inner][INFO] - {"epoch": 15, "update": 15.0, "loss": "6.219", "ntokens": "1782.52", "nsentences": "4.95", "prob_perplexity": "167.381", "code_perplexity": "164.352", "temp": "1.995", "loss_0": "6.017", "loss_1": "0.107", "loss_2": "0.095", "accuracy": "0.11915", "wps": "2948.6", "ups": "1.65", "wpb": "1782.5", "bsz": "5", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.943", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "348"}
[2022-01-03 12:15:30,650][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:15:31,065][valid][INFO] - {"epoch": 15, "valid_loss": "5.781", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "56.252", "valid_code_perplexity": "54.808", "valid_temp": "1.994", "valid_loss_0": "5.57", "valid_loss_1": "0.132", "valid_loss_2": "0.079", "valid_accuracy": "0.23521", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "600", "valid_best_loss": "5.781"}
[2022-01-03 12:15:31,068][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 600 updates
[2022-01-03 12:15:31,069][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:15:34,961][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:15:43,015][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 15 @ 600 updates, score 5.781) (writing took 11.946867699734867 seconds)
[2022-01-03 12:15:43,016][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2022-01-03 12:15:43,029][train][INFO] - {"epoch": 15, "train_loss": "5.896", "train_ntokens": "1785.65", "train_nsentences": "4.95", "train_prob_perplexity": "68.987", "train_code_perplexity": "67.587", "train_temp": "1.994", "train_loss_0": "5.688", "train_loss_1": "0.129", "train_loss_2": "0.08", "train_accuracy": "0.20308", "train_wps": "2721.6", "train_ups": "1.52", "train_wpb": "1785.7", "train_bsz": "5", "train_num_updates": "600", "train_lr": "9.375e-06", "train_gnorm": "1.108", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "360"}
[2022-01-03 12:15:43,091][fairseq.trainer][INFO] - begin training epoch 16
[2022-01-03 12:15:43,092][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:15:56,915][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:15:57,328][valid][INFO] - {"epoch": 16, "valid_loss": "5.223", "valid_ntokens": "674", "valid_nsentences": "2", "valid_prob_perplexity": "29.367", "valid_code_perplexity": "28.127", "valid_temp": "1.994", "valid_loss_0": "5.011", "valid_loss_1": "0.138", "valid_loss_2": "0.075", "valid_accuracy": "0.35163", "valid_wps": "0", "valid_wpb": "674", "valid_bsz": "2", "valid_num_updates": "640", "valid_best_loss": "5.223"}
[2022-01-03 12:15:57,330][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 16 @ 640 updates
[2022-01-03 12:15:57,331][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:16:01,379][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:16:08,690][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 16 @ 640 updates, score 5.223) (writing took 11.359295930713415 seconds)
[2022-01-03 12:16:08,690][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2022-01-03 12:16:08,704][train][INFO] - {"epoch": 16, "train_loss": "5.72", "train_ntokens": "1795.1", "train_nsentences": "4.95", "train_prob_perplexity": "52.811", "train_code_perplexity": "51.697", "train_temp": "1.994", "train_loss_0": "5.503", "train_loss_1": "0.132", "train_loss_2": "0.085", "train_accuracy": "0.24191", "train_wps": "2798.1", "train_ups": "1.56", "train_wpb": "1795.1", "train_bsz": "5", "train_num_updates": "640", "train_lr": "1e-05", "train_gnorm": "1.433", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.7", "train_wall": "386"}
[2022-01-03 12:16:08,769][fairseq.trainer][INFO] - begin training epoch 17
[2022-01-03 12:16:08,770][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:16:22,592][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:16:22,980][valid][INFO] - {"epoch": 17, "valid_loss": "5.14", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "27.962", "valid_code_perplexity": "27.116", "valid_temp": "1.993", "valid_loss_0": "4.932", "valid_loss_1": "0.138", "valid_loss_2": "0.07", "valid_accuracy": "0.33613", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "680", "valid_best_loss": "5.14"}
[2022-01-03 12:16:22,983][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 17 @ 680 updates
[2022-01-03 12:16:22,984][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:16:26,871][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:16:33,957][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 17 @ 680 updates, score 5.14) (writing took 10.973456295207143 seconds)
[2022-01-03 12:16:33,957][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2022-01-03 12:16:33,971][train][INFO] - {"epoch": 17, "train_loss": "5.565", "train_ntokens": "1797.5", "train_nsentences": "4.95", "train_prob_perplexity": "40.783", "train_code_perplexity": "39.944", "train_temp": "1.993", "train_loss_0": "5.352", "train_loss_1": "0.135", "train_loss_2": "0.078", "train_accuracy": "0.26951", "train_wps": "2847.2", "train_ups": "1.58", "train_wpb": "1797.5", "train_bsz": "5", "train_num_updates": "680", "train_lr": "1.0625e-05", "train_gnorm": "1.439", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "411"}
[2022-01-03 12:16:34,053][fairseq.trainer][INFO] - begin training epoch 18
[2022-01-03 12:16:34,054][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:16:47,815][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:16:48,282][valid][INFO] - {"epoch": 18, "valid_loss": "5.399", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "29.289", "valid_code_perplexity": "28.474", "valid_temp": "1.993", "valid_loss_0": "5.189", "valid_loss_1": "0.138", "valid_loss_2": "0.073", "valid_accuracy": "0.2772", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "720", "valid_best_loss": "5.14"}
[2022-01-03 12:16:48,283][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 18 @ 720 updates
[2022-01-03 12:16:48,284][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:16:52,177][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:16:52,197][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 18 @ 720 updates, score 5.399) (writing took 3.913869297131896 seconds)
[2022-01-03 12:16:52,198][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2022-01-03 12:16:52,212][train][INFO] - {"epoch": 18, "train_loss": "5.576", "train_ntokens": "1789.5", "train_nsentences": "4.95", "train_prob_perplexity": "39.499", "train_code_perplexity": "38.771", "train_temp": "1.993", "train_loss_0": "5.362", "train_loss_1": "0.135", "train_loss_2": "0.079", "train_accuracy": "0.2488", "train_wps": "3927.2", "train_ups": "2.19", "train_wpb": "1789.5", "train_bsz": "5", "train_num_updates": "720", "train_lr": "1.125e-05", "train_gnorm": "1.441", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "430"}
[2022-01-03 12:16:52,268][fairseq.trainer][INFO] - begin training epoch 19
[2022-01-03 12:16:52,269][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:17:06,064][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:17:06,462][valid][INFO] - {"epoch": 19, "valid_loss": "5.236", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "24.058", "valid_code_perplexity": "23.561", "valid_temp": "1.992", "valid_loss_0": "5.026", "valid_loss_1": "0.139", "valid_loss_2": "0.071", "valid_accuracy": "0.29258", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "760", "valid_best_loss": "5.14"}
[2022-01-03 12:17:06,465][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 19 @ 760 updates
[2022-01-03 12:17:06,465][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:17:11,010][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:17:11,037][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 19 @ 760 updates, score 5.236) (writing took 4.571874549612403 seconds)
[2022-01-03 12:17:11,037][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2022-01-03 12:17:11,055][train][INFO] - {"epoch": 19, "train_loss": "5.461", "train_ntokens": "1790.45", "train_nsentences": "4.95", "train_prob_perplexity": "34.105", "train_code_perplexity": "33.496", "train_temp": "1.993", "train_loss_0": "5.247", "train_loss_1": "0.137", "train_loss_2": "0.077", "train_accuracy": "0.26615", "train_wps": "3804.4", "train_ups": "2.12", "train_wpb": "1790.5", "train_bsz": "5", "train_num_updates": "760", "train_lr": "1.1875e-05", "train_gnorm": "1.455", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "448"}
[2022-01-03 12:17:11,142][fairseq.trainer][INFO] - begin training epoch 20
[2022-01-03 12:17:11,143][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:17:25,287][train_inner][INFO] - {"epoch": 20, "update": 20.0, "loss": "5.551", "ntokens": "1792.29", "nsentences": "4.95", "prob_perplexity": "39.779", "code_perplexity": "39.024", "temp": "1.993", "loss_0": "5.337", "loss_1": "0.135", "loss_2": "0.079", "accuracy": "0.25507", "wps": "3127.2", "ups": "1.74", "wpb": "1792.3", "bsz": "5", "num_updates": "800", "lr": "1.25e-05", "gnorm": "1.475", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "463"}
[2022-01-03 12:17:25,288][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:17:25,693][valid][INFO] - {"epoch": 20, "valid_loss": "5.028", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "21.374", "valid_code_perplexity": "21.107", "valid_temp": "1.992", "valid_loss_0": "4.82", "valid_loss_1": "0.139", "valid_loss_2": "0.069", "valid_accuracy": "0.31154", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "800", "valid_best_loss": "5.028"}
[2022-01-03 12:17:25,696][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 800 updates
[2022-01-03 12:17:25,697][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:17:29,600][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:17:36,382][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 20 @ 800 updates, score 5.028) (writing took 10.685505830682814 seconds)
[2022-01-03 12:17:36,383][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2022-01-03 12:17:36,396][train][INFO] - {"epoch": 20, "train_loss": "5.433", "train_ntokens": "1788.88", "train_nsentences": "4.95", "train_prob_perplexity": "31.7", "train_code_perplexity": "31.213", "train_temp": "1.992", "train_loss_0": "5.22", "train_loss_1": "0.137", "train_loss_2": "0.076", "train_accuracy": "0.24894", "train_wps": "2825.2", "train_ups": "1.58", "train_wpb": "1788.9", "train_bsz": "5", "train_num_updates": "800", "train_lr": "1.25e-05", "train_gnorm": "1.606", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "474"}
[2022-01-03 12:17:36,436][fairseq.trainer][INFO] - begin training epoch 21
[2022-01-03 12:17:36,437][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:17:50,266][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:17:50,721][valid][INFO] - {"epoch": 21, "valid_loss": "5.272", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "20.996", "valid_code_perplexity": "20.89", "valid_temp": "1.992", "valid_loss_0": "5.061", "valid_loss_1": "0.14", "valid_loss_2": "0.071", "valid_accuracy": "0.23967", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "840", "valid_best_loss": "5.028"}
[2022-01-03 12:17:50,724][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 21 @ 840 updates
[2022-01-03 12:17:50,725][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:17:54,761][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:17:54,784][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 21 @ 840 updates, score 5.272) (writing took 4.059405024163425 seconds)
[2022-01-03 12:17:54,784][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2022-01-03 12:17:54,797][train][INFO] - {"epoch": 21, "train_loss": "5.423", "train_ntokens": "1799.75", "train_nsentences": "4.95", "train_prob_perplexity": "29.751", "train_code_perplexity": "29.324", "train_temp": "1.992", "train_loss_0": "5.212", "train_loss_1": "0.138", "train_loss_2": "0.074", "train_accuracy": "0.23663", "train_wps": "3914.9", "train_ups": "2.18", "train_wpb": "1799.8", "train_bsz": "5", "train_num_updates": "840", "train_lr": "1.3125e-05", "train_gnorm": "1.407", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "492"}
[2022-01-03 12:17:54,879][fairseq.trainer][INFO] - begin training epoch 22
[2022-01-03 12:17:54,879][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:18:08,659][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:18:09,070][valid][INFO] - {"epoch": 22, "valid_loss": "5.222", "valid_ntokens": "654", "valid_nsentences": "2", "valid_prob_perplexity": "23.113", "valid_code_perplexity": "22.702", "valid_temp": "1.991", "valid_loss_0": "5.014", "valid_loss_1": "0.139", "valid_loss_2": "0.068", "valid_accuracy": "0.26453", "valid_wps": "0", "valid_wpb": "654", "valid_bsz": "2", "valid_num_updates": "880", "valid_best_loss": "5.028"}
[2022-01-03 12:18:09,073][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 22 @ 880 updates
[2022-01-03 12:18:09,074][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:18:13,075][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:18:13,100][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 22 @ 880 updates, score 5.222) (writing took 4.02681636903435 seconds)
[2022-01-03 12:18:13,101][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2022-01-03 12:18:13,114][train][INFO] - {"epoch": 22, "train_loss": "5.332", "train_ntokens": "1798.65", "train_nsentences": "4.95", "train_prob_perplexity": "26.769", "train_code_perplexity": "26.419", "train_temp": "1.991", "train_loss_0": "5.122", "train_loss_1": "0.138", "train_loss_2": "0.072", "train_accuracy": "0.24742", "train_wps": "3930.8", "train_ups": "2.19", "train_wpb": "1798.7", "train_bsz": "5", "train_num_updates": "880", "train_lr": "1.375e-05", "train_gnorm": "1.606", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "511"}
[2022-01-03 12:18:13,168][fairseq.trainer][INFO] - begin training epoch 23
[2022-01-03 12:18:13,169][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:18:27,114][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:18:27,524][valid][INFO] - {"epoch": 23, "valid_loss": "5.084", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "20.722", "valid_code_perplexity": "20.701", "valid_temp": "1.991", "valid_loss_0": "4.876", "valid_loss_1": "0.14", "valid_loss_2": "0.069", "valid_accuracy": "0.2532", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "920", "valid_best_loss": "5.028"}
[2022-01-03 12:18:27,528][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 23 @ 920 updates
[2022-01-03 12:18:27,529][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:18:31,285][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:18:31,306][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 23 @ 920 updates, score 5.084) (writing took 3.7776382947340608 seconds)
[2022-01-03 12:18:31,306][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2022-01-03 12:18:31,319][train][INFO] - {"epoch": 23, "train_loss": "5.303", "train_ntokens": "1779.4", "train_nsentences": "4.95", "train_prob_perplexity": "26.004", "train_code_perplexity": "25.744", "train_temp": "1.991", "train_loss_0": "5.095", "train_loss_1": "0.138", "train_loss_2": "0.07", "train_accuracy": "0.24163", "train_wps": "3912.4", "train_ups": "2.2", "train_wpb": "1779.4", "train_bsz": "5", "train_num_updates": "920", "train_lr": "1.4375e-05", "train_gnorm": "1.491", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "529"}
[2022-01-03 12:18:31,377][fairseq.trainer][INFO] - begin training epoch 24
[2022-01-03 12:18:31,378][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:18:45,227][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:18:45,636][valid][INFO] - {"epoch": 24, "valid_loss": "5.344", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "29.79", "valid_code_perplexity": "29.521", "valid_temp": "1.99", "valid_loss_0": "5.148", "valid_loss_1": "0.138", "valid_loss_2": "0.058", "valid_accuracy": "0.22", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "960", "valid_best_loss": "5.028"}
[2022-01-03 12:18:45,641][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 24 @ 960 updates
[2022-01-03 12:18:45,642][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:18:49,568][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:18:49,594][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 24 @ 960 updates, score 5.344) (writing took 3.9527677055448294 seconds)
[2022-01-03 12:18:49,594][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2022-01-03 12:18:49,607][train][INFO] - {"epoch": 24, "train_loss": "5.247", "train_ntokens": "1798.3", "train_nsentences": "4.95", "train_prob_perplexity": "25.375", "train_code_perplexity": "25.099", "train_temp": "1.991", "train_loss_0": "5.039", "train_loss_1": "0.139", "train_loss_2": "0.07", "train_accuracy": "0.24786", "train_wps": "3936", "train_ups": "2.19", "train_wpb": "1798.3", "train_bsz": "5", "train_num_updates": "960", "train_lr": "1.5e-05", "train_gnorm": "1.528", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "547"}
[2022-01-03 12:18:49,692][fairseq.trainer][INFO] - begin training epoch 25
[2022-01-03 12:18:49,693][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:19:03,665][train_inner][INFO] - {"epoch": 25, "update": 25.0, "loss": "5.306", "ntokens": "1792.13", "nsentences": "4.95", "prob_perplexity": "26.532", "code_perplexity": "26.218", "temp": "1.991", "loss_0": "5.097", "loss_1": "0.138", "loss_2": "0.07", "accuracy": "0.24412", "wps": "3643.8", "ups": "2.03", "wpb": "1792.1", "bsz": "5", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "1.492", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "561"}
[2022-01-03 12:19:03,666][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:19:04,119][valid][INFO] - {"epoch": 25, "valid_loss": "5.212", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "20.709", "valid_code_perplexity": "20.486", "valid_temp": "1.99", "valid_loss_0": "5.006", "valid_loss_1": "0.14", "valid_loss_2": "0.066", "valid_accuracy": "0.25325", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "1000", "valid_best_loss": "5.028"}
[2022-01-03 12:19:04,122][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 1000 updates
[2022-01-03 12:19:04,123][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:19:07,766][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:19:07,789][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 25 @ 1000 updates, score 5.212) (writing took 3.6673945635557175 seconds)
[2022-01-03 12:19:07,790][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2022-01-03 12:19:07,803][train][INFO] - {"epoch": 25, "train_loss": "5.222", "train_ntokens": "1784.58", "train_nsentences": "4.95", "train_prob_perplexity": "24.759", "train_code_perplexity": "24.502", "train_temp": "1.99", "train_loss_0": "5.017", "train_loss_1": "0.139", "train_loss_2": "0.066", "train_accuracy": "0.24708", "train_wps": "3925.9", "train_ups": "2.2", "train_wpb": "1784.6", "train_bsz": "5", "train_num_updates": "1000", "train_lr": "1.5625e-05", "train_gnorm": "1.428", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "565"}
[2022-01-03 12:19:07,875][fairseq.trainer][INFO] - begin training epoch 26
[2022-01-03 12:19:07,876][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:19:21,966][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:19:22,422][valid][INFO] - {"epoch": 26, "valid_loss": "4.99", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "19.709", "valid_code_perplexity": "19.606", "valid_temp": "1.99", "valid_loss_0": "4.786", "valid_loss_1": "0.14", "valid_loss_2": "0.065", "valid_accuracy": "0.2493", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "1040", "valid_best_loss": "4.99"}
[2022-01-03 12:19:22,424][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 26 @ 1040 updates
[2022-01-03 12:19:22,425][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:19:26,478][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:19:33,582][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 26 @ 1040 updates, score 4.99) (writing took 11.157088834792376 seconds)
[2022-01-03 12:19:33,582][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2022-01-03 12:19:33,595][train][INFO] - {"epoch": 26, "train_loss": "5.238", "train_ntokens": "1785.9", "train_nsentences": "4.95", "train_prob_perplexity": "24.842", "train_code_perplexity": "24.601", "train_temp": "1.99", "train_loss_0": "5.034", "train_loss_1": "0.139", "train_loss_2": "0.065", "train_accuracy": "0.23959", "train_wps": "2771.1", "train_ups": "1.55", "train_wpb": "1785.9", "train_bsz": "5", "train_num_updates": "1040", "train_lr": "1.625e-05", "train_gnorm": "1.445", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "591"}
[2022-01-03 12:19:33,680][fairseq.trainer][INFO] - begin training epoch 27
[2022-01-03 12:19:33,681][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:19:47,476][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:19:47,874][valid][INFO] - {"epoch": 27, "valid_loss": "5.318", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "26.347", "valid_code_perplexity": "26.176", "valid_temp": "1.989", "valid_loss_0": "5.12", "valid_loss_1": "0.138", "valid_loss_2": "0.06", "valid_accuracy": "0.21489", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "1080", "valid_best_loss": "4.99"}
[2022-01-03 12:19:47,878][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 27 @ 1080 updates
[2022-01-03 12:19:47,878][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:19:51,796][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:19:51,818][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 27 @ 1080 updates, score 5.318) (writing took 3.940784049220383 seconds)
[2022-01-03 12:19:51,819][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2022-01-03 12:19:51,835][train][INFO] - {"epoch": 27, "train_loss": "5.179", "train_ntokens": "1783.83", "train_nsentences": "4.95", "train_prob_perplexity": "25.31", "train_code_perplexity": "25.096", "train_temp": "1.989", "train_loss_0": "4.975", "train_loss_1": "0.139", "train_loss_2": "0.065", "train_accuracy": "0.23954", "train_wps": "3915.3", "train_ups": "2.19", "train_wpb": "1783.8", "train_bsz": "5", "train_num_updates": "1080", "train_lr": "1.6875e-05", "train_gnorm": "1.608", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "609"}
[2022-01-03 12:19:51,905][fairseq.trainer][INFO] - begin training epoch 28
[2022-01-03 12:19:51,906][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:20:05,759][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:20:06,163][valid][INFO] - {"epoch": 28, "valid_loss": "5.189", "valid_ntokens": "802", "valid_nsentences": "2", "valid_prob_perplexity": "22.888", "valid_code_perplexity": "22.729", "valid_temp": "1.989", "valid_loss_0": "4.991", "valid_loss_1": "0.139", "valid_loss_2": "0.059", "valid_accuracy": "0.21072", "valid_wps": "0", "valid_wpb": "802", "valid_bsz": "2", "valid_num_updates": "1120", "valid_best_loss": "4.99"}
[2022-01-03 12:20:06,166][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 28 @ 1120 updates
[2022-01-03 12:20:06,167][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:20:10,058][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:20:10,080][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 28 @ 1120 updates, score 5.189) (writing took 3.914071445353329 seconds)
[2022-01-03 12:20:10,081][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2022-01-03 12:20:10,093][train][INFO] - {"epoch": 28, "train_loss": "5.17", "train_ntokens": "1797.78", "train_nsentences": "4.95", "train_prob_perplexity": "25.437", "train_code_perplexity": "25.204", "train_temp": "1.989", "train_loss_0": "4.969", "train_loss_1": "0.139", "train_loss_2": "0.062", "train_accuracy": "0.2377", "train_wps": "3941.3", "train_ups": "2.19", "train_wpb": "1797.8", "train_bsz": "5", "train_num_updates": "1120", "train_lr": "1.75e-05", "train_gnorm": "1.446", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "627"}
[2022-01-03 12:20:10,171][fairseq.trainer][INFO] - begin training epoch 29
[2022-01-03 12:20:10,172][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:20:24,102][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:20:24,520][valid][INFO] - {"epoch": 29, "valid_loss": "5.241", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "24.445", "valid_code_perplexity": "24.332", "valid_temp": "1.988", "valid_loss_0": "5.044", "valid_loss_1": "0.139", "valid_loss_2": "0.058", "valid_accuracy": "0.2046", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "1160", "valid_best_loss": "4.99"}
[2022-01-03 12:20:24,523][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 29 @ 1160 updates
[2022-01-03 12:20:24,524][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:20:28,261][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:20:28,288][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 29 @ 1160 updates, score 5.241) (writing took 3.7649217024445534 seconds)
[2022-01-03 12:20:28,289][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2022-01-03 12:20:28,302][train][INFO] - {"epoch": 29, "train_loss": "5.146", "train_ntokens": "1787.55", "train_nsentences": "4.95", "train_prob_perplexity": "25.328", "train_code_perplexity": "25.133", "train_temp": "1.989", "train_loss_0": "4.947", "train_loss_1": "0.139", "train_loss_2": "0.061", "train_accuracy": "0.23286", "train_wps": "3929.6", "train_ups": "2.2", "train_wpb": "1787.5", "train_bsz": "5", "train_num_updates": "1160", "train_lr": "1.8125e-05", "train_gnorm": "1.574", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "646"}
[2022-01-03 12:20:28,386][fairseq.trainer][INFO] - begin training epoch 30
[2022-01-03 12:20:28,387][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:20:42,456][train_inner][INFO] - {"epoch": 30, "update": 30.0, "loss": "5.173", "ntokens": "1790.39", "nsentences": "4.95", "prob_perplexity": "25.158", "code_perplexity": "24.949", "temp": "1.989", "loss_0": "4.972", "loss_1": "0.139", "loss_2": "0.063", "accuracy": "0.23662", "wps": "3625.1", "ups": "2.02", "wpb": "1790.4", "bsz": "5", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "1.518", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "660"}
[2022-01-03 12:20:42,457][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:20:42,864][valid][INFO] - {"epoch": 30, "valid_loss": "5.226", "valid_ntokens": "814", "valid_nsentences": "2", "valid_prob_perplexity": "24.126", "valid_code_perplexity": "23.936", "valid_temp": "1.988", "valid_loss_0": "5.03", "valid_loss_1": "0.139", "valid_loss_2": "0.057", "valid_accuracy": "0.22604", "valid_wps": "0", "valid_wpb": "814", "valid_bsz": "2", "valid_num_updates": "1200", "valid_best_loss": "4.99"}
[2022-01-03 12:20:42,866][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 1200 updates
[2022-01-03 12:20:42,867][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:20:46,969][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:20:46,993][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 30 @ 1200 updates, score 5.226) (writing took 4.126975619234145 seconds)
[2022-01-03 12:20:46,994][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2022-01-03 12:20:47,008][train][INFO] - {"epoch": 30, "train_loss": "5.134", "train_ntokens": "1796.9", "train_nsentences": "4.95", "train_prob_perplexity": "24.871", "train_code_perplexity": "24.713", "train_temp": "1.988", "train_loss_0": "4.936", "train_loss_1": "0.139", "train_loss_2": "0.059", "train_accuracy": "0.23344", "train_wps": "3845.3", "train_ups": "2.14", "train_wpb": "1796.9", "train_bsz": "5", "train_num_updates": "1200", "train_lr": "1.875e-05", "train_gnorm": "1.518", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "664"}
[2022-01-03 12:20:47,077][fairseq.trainer][INFO] - begin training epoch 31
[2022-01-03 12:20:47,078][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:21:01,058][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:21:01,471][valid][INFO] - {"epoch": 31, "valid_loss": "4.906", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "22.413", "valid_code_perplexity": "22.355", "valid_temp": "1.988", "valid_loss_0": "4.709", "valid_loss_1": "0.139", "valid_loss_2": "0.058", "valid_accuracy": "0.25603", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "1240", "valid_best_loss": "4.906"}
[2022-01-03 12:21:01,474][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 31 @ 1240 updates
[2022-01-03 12:21:01,475][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:21:05,405][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:21:11,944][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 31 @ 1240 updates, score 4.906) (writing took 10.47006441000849 seconds)
[2022-01-03 12:21:11,945][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2022-01-03 12:21:11,959][train][INFO] - {"epoch": 31, "train_loss": "5.069", "train_ntokens": "1792.53", "train_nsentences": "4.95", "train_prob_perplexity": "24.974", "train_code_perplexity": "24.809", "train_temp": "1.988", "train_loss_0": "4.872", "train_loss_1": "0.139", "train_loss_2": "0.059", "train_accuracy": "0.24101", "train_wps": "2875.3", "train_ups": "1.6", "train_wpb": "1792.5", "train_bsz": "5", "train_num_updates": "1240", "train_lr": "1.9375e-05", "train_gnorm": "1.573", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "689"}
[2022-01-03 12:21:12,042][fairseq.trainer][INFO] - begin training epoch 32
[2022-01-03 12:21:12,043][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:21:25,954][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:21:26,371][valid][INFO] - {"epoch": 32, "valid_loss": "4.718", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "21.791", "valid_code_perplexity": "21.764", "valid_temp": "1.987", "valid_loss_0": "4.523", "valid_loss_1": "0.139", "valid_loss_2": "0.055", "valid_accuracy": "0.2964", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "1280", "valid_best_loss": "4.718"}
[2022-01-03 12:21:26,373][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 32 @ 1280 updates
[2022-01-03 12:21:26,374][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:21:30,324][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:21:37,469][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 32 @ 1280 updates, score 4.718) (writing took 11.095720877870917 seconds)
[2022-01-03 12:21:37,469][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2022-01-03 12:21:37,483][train][INFO] - {"epoch": 32, "train_loss": "5.121", "train_ntokens": "1781.88", "train_nsentences": "4.95", "train_prob_perplexity": "25.56", "train_code_perplexity": "25.4", "train_temp": "1.987", "train_loss_0": "4.925", "train_loss_1": "0.139", "train_loss_2": "0.057", "train_accuracy": "0.23059", "train_wps": "2793.9", "train_ups": "1.57", "train_wpb": "1781.9", "train_bsz": "5", "train_num_updates": "1280", "train_lr": "2e-05", "train_gnorm": "1.781", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "715"}
[2022-01-03 12:21:37,553][fairseq.trainer][INFO] - begin training epoch 33
[2022-01-03 12:21:37,554][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:21:51,293][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:21:51,703][valid][INFO] - {"epoch": 33, "valid_loss": "4.952", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "21.955", "valid_code_perplexity": "21.936", "valid_temp": "1.987", "valid_loss_0": "4.755", "valid_loss_1": "0.139", "valid_loss_2": "0.057", "valid_accuracy": "0.24138", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "1320", "valid_best_loss": "4.718"}
[2022-01-03 12:21:51,705][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 33 @ 1320 updates
[2022-01-03 12:21:51,706][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:21:55,637][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:21:55,658][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 33 @ 1320 updates, score 4.952) (writing took 3.9531445438042283 seconds)
[2022-01-03 12:21:55,659][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2022-01-03 12:21:55,671][train][INFO] - {"epoch": 33, "train_loss": "5.057", "train_ntokens": "1787.38", "train_nsentences": "4.95", "train_prob_perplexity": "25.51", "train_code_perplexity": "25.347", "train_temp": "1.987", "train_loss_0": "4.862", "train_loss_1": "0.139", "train_loss_2": "0.056", "train_accuracy": "0.2382", "train_wps": "3933.5", "train_ups": "2.2", "train_wpb": "1787.4", "train_bsz": "5", "train_num_updates": "1320", "train_lr": "2.0625e-05", "train_gnorm": "1.578", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "733"}
[2022-01-03 12:21:55,739][fairseq.trainer][INFO] - begin training epoch 34
[2022-01-03 12:21:55,740][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:22:09,697][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:22:10,116][valid][INFO] - {"epoch": 34, "valid_loss": "4.713", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "22.304", "valid_code_perplexity": "22.303", "valid_temp": "1.986", "valid_loss_0": "4.523", "valid_loss_1": "0.139", "valid_loss_2": "0.051", "valid_accuracy": "0.26396", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "1360", "valid_best_loss": "4.713"}
[2022-01-03 12:22:10,119][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 34 @ 1360 updates
[2022-01-03 12:22:10,120][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:22:13,855][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:22:21,436][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 34 @ 1360 updates, score 4.713) (writing took 11.317587059922516 seconds)
[2022-01-03 12:22:21,437][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2022-01-03 12:22:21,451][train][INFO] - {"epoch": 34, "train_loss": "5.047", "train_ntokens": "1784.83", "train_nsentences": "4.95", "train_prob_perplexity": "24.933", "train_code_perplexity": "24.811", "train_temp": "1.987", "train_loss_0": "4.852", "train_loss_1": "0.139", "train_loss_2": "0.056", "train_accuracy": "0.24263", "train_wps": "2770.9", "train_ups": "1.55", "train_wpb": "1784.8", "train_bsz": "5", "train_num_updates": "1360", "train_lr": "2.125e-05", "train_gnorm": "1.7", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "759"}
[2022-01-03 12:22:21,519][fairseq.trainer][INFO] - begin training epoch 35
[2022-01-03 12:22:21,519][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:22:35,335][train_inner][INFO] - {"epoch": 35, "update": 35.0, "loss": "5.061", "ntokens": "1789.94", "nsentences": "4.95", "prob_perplexity": "25.274", "code_perplexity": "25.129", "temp": "1.987", "loss_0": "4.866", "loss_1": "0.139", "loss_2": "0.057", "accuracy": "0.23825", "wps": "3171.8", "ups": "1.77", "wpb": "1789.9", "bsz": "5", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "1.639", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "773"}
[2022-01-03 12:22:35,336][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:22:35,763][valid][INFO] - {"epoch": 35, "valid_loss": "4.718", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "22.135", "valid_code_perplexity": "22.128", "valid_temp": "1.986", "valid_loss_0": "4.527", "valid_loss_1": "0.139", "valid_loss_2": "0.052", "valid_accuracy": "0.27481", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "1400", "valid_best_loss": "4.713"}
[2022-01-03 12:22:35,766][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 1400 updates
[2022-01-03 12:22:35,767][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:22:39,694][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:22:39,715][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 35 @ 1400 updates, score 4.718) (writing took 3.9487719191238284 seconds)
[2022-01-03 12:22:39,715][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2022-01-03 12:22:39,729][train][INFO] - {"epoch": 35, "train_loss": "5.014", "train_ntokens": "1803.12", "train_nsentences": "4.95", "train_prob_perplexity": "25.393", "train_code_perplexity": "25.275", "train_temp": "1.986", "train_loss_0": "4.821", "train_loss_1": "0.139", "train_loss_2": "0.055", "train_accuracy": "0.23881", "train_wps": "3948.8", "train_ups": "2.19", "train_wpb": "1803.1", "train_bsz": "5", "train_num_updates": "1400", "train_lr": "2.1875e-05", "train_gnorm": "1.563", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "777"}
[2022-01-03 12:22:39,793][fairseq.trainer][INFO] - begin training epoch 36
[2022-01-03 12:22:39,794][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:22:53,573][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:22:53,990][valid][INFO] - {"epoch": 36, "valid_loss": "5.161", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "29.96", "valid_code_perplexity": "29.75", "valid_temp": "1.986", "valid_loss_0": "4.978", "valid_loss_1": "0.138", "valid_loss_2": "0.046", "valid_accuracy": "0.21526", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "1440", "valid_best_loss": "4.713"}
[2022-01-03 12:22:53,994][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 36 @ 1440 updates
[2022-01-03 12:22:53,995][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:22:57,916][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:22:57,939][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 36 @ 1440 updates, score 5.161) (writing took 3.9451144272461534 seconds)
[2022-01-03 12:22:57,940][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2022-01-03 12:22:57,953][train][INFO] - {"epoch": 36, "train_loss": "5.036", "train_ntokens": "1794.2", "train_nsentences": "4.95", "train_prob_perplexity": "26.63", "train_code_perplexity": "26.465", "train_temp": "1.986", "train_loss_0": "4.845", "train_loss_1": "0.138", "train_loss_2": "0.053", "train_accuracy": "0.23267", "train_wps": "3940.9", "train_ups": "2.2", "train_wpb": "1794.2", "train_bsz": "5", "train_num_updates": "1440", "train_lr": "2.25e-05", "train_gnorm": "1.787", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "795"}
[2022-01-03 12:22:58,024][fairseq.trainer][INFO] - begin training epoch 37
[2022-01-03 12:22:58,025][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:23:11,980][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:23:12,386][valid][INFO] - {"epoch": 37, "valid_loss": "4.999", "valid_ntokens": "804", "valid_nsentences": "2", "valid_prob_perplexity": "24.552", "valid_code_perplexity": "24.562", "valid_temp": "1.985", "valid_loss_0": "4.807", "valid_loss_1": "0.139", "valid_loss_2": "0.054", "valid_accuracy": "0.22139", "valid_wps": "0", "valid_wpb": "804", "valid_bsz": "2", "valid_num_updates": "1480", "valid_best_loss": "4.713"}
[2022-01-03 12:23:12,389][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 37 @ 1480 updates
[2022-01-03 12:23:12,390][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:23:16,115][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:23:16,138][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 37 @ 1480 updates, score 4.999) (writing took 3.7490976145491004 seconds)
[2022-01-03 12:23:16,139][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2022-01-03 12:23:16,151][train][INFO] - {"epoch": 37, "train_loss": "4.991", "train_ntokens": "1786.08", "train_nsentences": "4.95", "train_prob_perplexity": "26.517", "train_code_perplexity": "26.378", "train_temp": "1.985", "train_loss_0": "4.8", "train_loss_1": "0.138", "train_loss_2": "0.053", "train_accuracy": "0.23486", "train_wps": "3928.5", "train_ups": "2.2", "train_wpb": "1786.1", "train_bsz": "5", "train_num_updates": "1480", "train_lr": "2.3125e-05", "train_gnorm": "1.768", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "814"}
[2022-01-03 12:23:16,226][fairseq.trainer][INFO] - begin training epoch 38
[2022-01-03 12:23:16,227][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:23:30,271][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:23:30,682][valid][INFO] - {"epoch": 38, "valid_loss": "5.143", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "24.903", "valid_code_perplexity": "24.907", "valid_temp": "1.985", "valid_loss_0": "4.949", "valid_loss_1": "0.139", "valid_loss_2": "0.055", "valid_accuracy": "0.20779", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "1520", "valid_best_loss": "4.713"}
[2022-01-03 12:23:30,685][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 38 @ 1520 updates
[2022-01-03 12:23:30,686][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:23:34,374][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:23:34,393][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 38 @ 1520 updates, score 5.143) (writing took 3.7083807457238436 seconds)
[2022-01-03 12:23:34,394][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2022-01-03 12:23:34,407][train][INFO] - {"epoch": 38, "train_loss": "4.93", "train_ntokens": "1794.55", "train_nsentences": "4.95", "train_prob_perplexity": "27.862", "train_code_perplexity": "27.729", "train_temp": "1.985", "train_loss_0": "4.739", "train_loss_1": "0.138", "train_loss_2": "0.053", "train_accuracy": "0.23922", "train_wps": "3934.7", "train_ups": "2.19", "train_wpb": "1794.5", "train_bsz": "5", "train_num_updates": "1520", "train_lr": "2.375e-05", "train_gnorm": "1.694", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "832"}
[2022-01-03 12:23:34,489][fairseq.trainer][INFO] - begin training epoch 39
[2022-01-03 12:23:34,490][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:23:48,464][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:23:48,875][valid][INFO] - {"epoch": 39, "valid_loss": "4.811", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "25.798", "valid_code_perplexity": "25.813", "valid_temp": "1.984", "valid_loss_0": "4.62", "valid_loss_1": "0.138", "valid_loss_2": "0.052", "valid_accuracy": "0.24863", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "1560", "valid_best_loss": "4.713"}
[2022-01-03 12:23:48,879][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 39 @ 1560 updates
[2022-01-03 12:23:48,880][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:23:52,598][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:23:52,620][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 39 @ 1560 updates, score 4.811) (writing took 3.741051067598164 seconds)
[2022-01-03 12:23:52,621][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2022-01-03 12:23:52,633][train][INFO] - {"epoch": 39, "train_loss": "4.976", "train_ntokens": "1794.08", "train_nsentences": "4.95", "train_prob_perplexity": "27.744", "train_code_perplexity": "27.631", "train_temp": "1.985", "train_loss_0": "4.784", "train_loss_1": "0.138", "train_loss_2": "0.054", "train_accuracy": "0.23647", "train_wps": "3940.1", "train_ups": "2.2", "train_wpb": "1794.1", "train_bsz": "5", "train_num_updates": "1560", "train_lr": "2.4375e-05", "train_gnorm": "1.636", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "850"}
[2022-01-03 12:23:52,713][fairseq.trainer][INFO] - begin training epoch 40
[2022-01-03 12:23:52,715][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:24:06,630][train_inner][INFO] - {"epoch": 40, "update": 40.0, "loss": "4.982", "ntokens": "1792.62", "nsentences": "4.95", "prob_perplexity": "27.339", "code_perplexity": "27.207", "temp": "1.985", "loss_0": "4.791", "loss_1": "0.138", "loss_2": "0.053", "accuracy": "0.23482", "wps": "3927.7", "ups": "2.19", "wpb": "1792.6", "bsz": "5", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "1.721", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "864"}
[2022-01-03 12:24:06,630][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:24:07,041][valid][INFO] - {"epoch": 40, "valid_loss": "5.013", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "27.839", "valid_code_perplexity": "27.673", "valid_temp": "1.984", "valid_loss_0": "4.83", "valid_loss_1": "0.138", "valid_loss_2": "0.046", "valid_accuracy": "0.20413", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "1600", "valid_best_loss": "4.713"}
[2022-01-03 12:24:07,044][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 1600 updates
[2022-01-03 12:24:07,044][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:24:10,847][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:24:10,874][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 40 @ 1600 updates, score 5.013) (writing took 3.829921428114176 seconds)
[2022-01-03 12:24:10,874][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2022-01-03 12:24:10,889][train][INFO] - {"epoch": 40, "train_loss": "4.978", "train_ntokens": "1794.22", "train_nsentences": "4.95", "train_prob_perplexity": "27.942", "train_code_perplexity": "27.831", "train_temp": "1.984", "train_loss_0": "4.789", "train_loss_1": "0.138", "train_loss_2": "0.051", "train_accuracy": "0.23088", "train_wps": "3934.5", "train_ups": "2.19", "train_wpb": "1794.2", "train_bsz": "5", "train_num_updates": "1600", "train_lr": "2.5e-05", "train_gnorm": "1.719", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "868"}
[2022-01-03 12:24:10,951][fairseq.trainer][INFO] - begin training epoch 41
[2022-01-03 12:24:10,952][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:24:24,958][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:24:25,368][valid][INFO] - {"epoch": 41, "valid_loss": "4.856", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "29.123", "valid_code_perplexity": "28.886", "valid_temp": "1.984", "valid_loss_0": "4.679", "valid_loss_1": "0.138", "valid_loss_2": "0.04", "valid_accuracy": "0.24495", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "1640", "valid_best_loss": "4.713"}
[2022-01-03 12:24:25,371][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 41 @ 1640 updates
[2022-01-03 12:24:25,372][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:24:29,065][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:24:29,080][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 41 @ 1640 updates, score 4.856) (writing took 3.7087717317044735 seconds)
[2022-01-03 12:24:29,080][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2022-01-03 12:24:29,093][train][INFO] - {"epoch": 41, "train_loss": "4.897", "train_ntokens": "1779.58", "train_nsentences": "4.95", "train_prob_perplexity": "28.9", "train_code_perplexity": "28.788", "train_temp": "1.984", "train_loss_0": "4.71", "train_loss_1": "0.138", "train_loss_2": "0.049", "train_accuracy": "0.24083", "train_wps": "3913.1", "train_ups": "2.2", "train_wpb": "1779.6", "train_bsz": "5", "train_num_updates": "1640", "train_lr": "2.5625e-05", "train_gnorm": "1.743", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "886"}
[2022-01-03 12:24:29,145][fairseq.trainer][INFO] - begin training epoch 42
[2022-01-03 12:24:29,145][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:24:43,060][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:24:43,509][valid][INFO] - {"epoch": 42, "valid_loss": "4.757", "valid_ntokens": "692", "valid_nsentences": "2", "valid_prob_perplexity": "26.392", "valid_code_perplexity": "26.396", "valid_temp": "1.983", "valid_loss_0": "4.57", "valid_loss_1": "0.138", "valid_loss_2": "0.049", "valid_accuracy": "0.23844", "valid_wps": "0", "valid_wpb": "692", "valid_bsz": "2", "valid_num_updates": "1680", "valid_best_loss": "4.713"}
[2022-01-03 12:24:43,511][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 42 @ 1680 updates
[2022-01-03 12:24:43,512][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:24:47,418][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:24:47,442][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 42 @ 1680 updates, score 4.757) (writing took 3.9309169901534915 seconds)
[2022-01-03 12:24:47,443][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2022-01-03 12:24:47,455][train][INFO] - {"epoch": 42, "train_loss": "4.902", "train_ntokens": "1803.55", "train_nsentences": "4.95", "train_prob_perplexity": "28.696", "train_code_perplexity": "28.591", "train_temp": "1.983", "train_loss_0": "4.715", "train_loss_1": "0.138", "train_loss_2": "0.049", "train_accuracy": "0.2371", "train_wps": "3931.5", "train_ups": "2.18", "train_wpb": "1803.5", "train_bsz": "5", "train_num_updates": "1680", "train_lr": "2.625e-05", "train_gnorm": "1.575", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "905"}
[2022-01-03 12:24:47,537][fairseq.trainer][INFO] - begin training epoch 43
[2022-01-03 12:24:47,538][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:25:01,571][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:25:02,054][valid][INFO] - {"epoch": 43, "valid_loss": "4.868", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "28.233", "valid_code_perplexity": "28.108", "valid_temp": "1.983", "valid_loss_0": "4.682", "valid_loss_1": "0.138", "valid_loss_2": "0.048", "valid_accuracy": "0.2619", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "1720", "valid_best_loss": "4.713"}
[2022-01-03 12:25:02,056][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 43 @ 1720 updates
[2022-01-03 12:25:02,057][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:25:05,972][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:25:05,995][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 43 @ 1720 updates, score 4.868) (writing took 3.9381304820999503 seconds)
[2022-01-03 12:25:05,995][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2022-01-03 12:25:06,008][train][INFO] - {"epoch": 43, "train_loss": "4.897", "train_ntokens": "1802.55", "train_nsentences": "4.95", "train_prob_perplexity": "29.346", "train_code_perplexity": "29.23", "train_temp": "1.983", "train_loss_0": "4.711", "train_loss_1": "0.138", "train_loss_2": "0.049", "train_accuracy": "0.23698", "train_wps": "3889.1", "train_ups": "2.16", "train_wpb": "1802.5", "train_bsz": "5", "train_num_updates": "1720", "train_lr": "2.6875e-05", "train_gnorm": "1.916", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "923"}
[2022-01-03 12:25:06,063][fairseq.trainer][INFO] - begin training epoch 44
[2022-01-03 12:25:06,064][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:25:20,165][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:25:20,564][valid][INFO] - {"epoch": 44, "valid_loss": "4.921", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "27.841", "valid_code_perplexity": "27.665", "valid_temp": "1.982", "valid_loss_0": "4.736", "valid_loss_1": "0.138", "valid_loss_2": "0.047", "valid_accuracy": "0.20531", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "1760", "valid_best_loss": "4.713"}
[2022-01-03 12:25:20,569][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 44 @ 1760 updates
[2022-01-03 12:25:20,570][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:25:24,485][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:25:24,509][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 44 @ 1760 updates, score 4.921) (writing took 3.9407473793253303 seconds)
[2022-01-03 12:25:24,510][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2022-01-03 12:25:24,523][train][INFO] - {"epoch": 44, "train_loss": "4.895", "train_ntokens": "1798.25", "train_nsentences": "4.95", "train_prob_perplexity": "28.611", "train_code_perplexity": "28.512", "train_temp": "1.983", "train_loss_0": "4.708", "train_loss_1": "0.138", "train_loss_2": "0.049", "train_accuracy": "0.23702", "train_wps": "3887.6", "train_ups": "2.16", "train_wpb": "1798.2", "train_bsz": "5", "train_num_updates": "1760", "train_lr": "2.75e-05", "train_gnorm": "1.671", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "942"}
[2022-01-03 12:25:24,579][fairseq.trainer][INFO] - begin training epoch 45
[2022-01-03 12:25:24,579][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:25:38,537][train_inner][INFO] - {"epoch": 45, "update": 45.0, "loss": "4.897", "ntokens": "1794.39", "nsentences": "4.95", "prob_perplexity": "28.996", "code_perplexity": "28.889", "temp": "1.983", "loss_0": "4.711", "loss_1": "0.138", "loss_2": "0.049", "accuracy": "0.23736", "wps": "3905.3", "ups": "2.18", "wpb": "1794.4", "bsz": "5", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "1.73", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "956"}
[2022-01-03 12:25:38,538][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:25:38,943][valid][INFO] - {"epoch": 45, "valid_loss": "4.687", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "27.155", "valid_code_perplexity": "26.937", "valid_temp": "1.982", "valid_loss_0": "4.505", "valid_loss_1": "0.138", "valid_loss_2": "0.044", "valid_accuracy": "0.23895", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "1800", "valid_best_loss": "4.687"}
[2022-01-03 12:25:38,947][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 1800 updates
[2022-01-03 12:25:38,948][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:25:42,744][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:25:49,737][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 45 @ 1800 updates, score 4.687) (writing took 10.78920198790729 seconds)
[2022-01-03 12:25:49,737][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2022-01-03 12:25:49,750][train][INFO] - {"epoch": 45, "train_loss": "4.896", "train_ntokens": "1788.03", "train_nsentences": "4.95", "train_prob_perplexity": "29.428", "train_code_perplexity": "29.322", "train_temp": "1.982", "train_loss_0": "4.711", "train_loss_1": "0.138", "train_loss_2": "0.047", "train_accuracy": "0.23491", "train_wps": "2836.5", "train_ups": "1.59", "train_wpb": "1788", "train_bsz": "5", "train_num_updates": "1800", "train_lr": "2.8125e-05", "train_gnorm": "1.744", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "967"}
[2022-01-03 12:25:49,822][fairseq.trainer][INFO] - begin training epoch 46
[2022-01-03 12:25:49,823][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:26:03,683][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:26:04,086][valid][INFO] - {"epoch": 46, "valid_loss": "5.218", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "28.263", "valid_code_perplexity": "28.148", "valid_temp": "1.982", "valid_loss_0": "5.032", "valid_loss_1": "0.138", "valid_loss_2": "0.049", "valid_accuracy": "0.21059", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "1840", "valid_best_loss": "4.687"}
[2022-01-03 12:26:04,090][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 46 @ 1840 updates
[2022-01-03 12:26:04,091][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:26:08,001][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:26:08,023][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 46 @ 1840 updates, score 5.218) (writing took 3.9329922748729587 seconds)
[2022-01-03 12:26:08,024][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2022-01-03 12:26:08,037][train][INFO] - {"epoch": 46, "train_loss": "4.843", "train_ntokens": "1775.97", "train_nsentences": "4.95", "train_prob_perplexity": "29.014", "train_code_perplexity": "28.91", "train_temp": "1.982", "train_loss_0": "4.656", "train_loss_1": "0.138", "train_loss_2": "0.049", "train_accuracy": "0.24641", "train_wps": "3887.5", "train_ups": "2.19", "train_wpb": "1776", "train_bsz": "5", "train_num_updates": "1840", "train_lr": "2.875e-05", "train_gnorm": "1.997", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "985"}
[2022-01-03 12:26:08,096][fairseq.trainer][INFO] - begin training epoch 47
[2022-01-03 12:26:08,097][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:26:22,010][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:26:22,440][valid][INFO] - {"epoch": 47, "valid_loss": "4.594", "valid_ntokens": "812", "valid_nsentences": "2", "valid_prob_perplexity": "27.758", "valid_code_perplexity": "27.656", "valid_temp": "1.981", "valid_loss_0": "4.408", "valid_loss_1": "0.138", "valid_loss_2": "0.048", "valid_accuracy": "0.26355", "valid_wps": "0", "valid_wpb": "812", "valid_bsz": "2", "valid_num_updates": "1880", "valid_best_loss": "4.594"}
[2022-01-03 12:26:22,447][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 47 @ 1880 updates
[2022-01-03 12:26:22,449][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:26:26,200][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:26:34,347][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 47 @ 1880 updates, score 4.594) (writing took 11.899723088368773 seconds)
[2022-01-03 12:26:34,347][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2022-01-03 12:26:34,361][train][INFO] - {"epoch": 47, "train_loss": "4.877", "train_ntokens": "1818.8", "train_nsentences": "4.95", "train_prob_perplexity": "29.236", "train_code_perplexity": "29.151", "train_temp": "1.981", "train_loss_0": "4.692", "train_loss_1": "0.138", "train_loss_2": "0.048", "train_accuracy": "0.23484", "train_wps": "2765.2", "train_ups": "1.52", "train_wpb": "1818.8", "train_bsz": "5", "train_num_updates": "1880", "train_lr": "2.9375e-05", "train_gnorm": "1.803", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1012"}
[2022-01-03 12:26:34,440][fairseq.trainer][INFO] - begin training epoch 48
[2022-01-03 12:26:34,441][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:26:48,248][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:26:48,645][valid][INFO] - {"epoch": 48, "valid_loss": "4.896", "valid_ntokens": "702", "valid_nsentences": "2", "valid_prob_perplexity": "28.31", "valid_code_perplexity": "28.199", "valid_temp": "1.981", "valid_loss_0": "4.708", "valid_loss_1": "0.138", "valid_loss_2": "0.05", "valid_accuracy": "0.22222", "valid_wps": "0", "valid_wpb": "702", "valid_bsz": "2", "valid_num_updates": "1920", "valid_best_loss": "4.594"}
[2022-01-03 12:26:48,648][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 48 @ 1920 updates
[2022-01-03 12:26:48,649][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:26:52,567][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:26:52,590][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 48 @ 1920 updates, score 4.896) (writing took 3.941478645429015 seconds)
[2022-01-03 12:26:52,590][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2022-01-03 12:26:52,603][train][INFO] - {"epoch": 48, "train_loss": "4.837", "train_ntokens": "1779.33", "train_nsentences": "4.95", "train_prob_perplexity": "29.401", "train_code_perplexity": "29.33", "train_temp": "1.981", "train_loss_0": "4.652", "train_loss_1": "0.138", "train_loss_2": "0.047", "train_accuracy": "0.23881", "train_wps": "3904.4", "train_ups": "2.19", "train_wpb": "1779.3", "train_bsz": "5", "train_num_updates": "1920", "train_lr": "3e-05", "train_gnorm": "1.626", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1030"}
[2022-01-03 12:26:52,678][fairseq.trainer][INFO] - begin training epoch 49
[2022-01-03 12:26:52,679][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:27:06,476][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:27:06,946][valid][INFO] - {"epoch": 49, "valid_loss": "4.934", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "28.52", "valid_code_perplexity": "28.37", "valid_temp": "1.981", "valid_loss_0": "4.75", "valid_loss_1": "0.138", "valid_loss_2": "0.046", "valid_accuracy": "0.2036", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "1960", "valid_best_loss": "4.594"}
[2022-01-03 12:27:06,949][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 49 @ 1960 updates
[2022-01-03 12:27:06,949][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:27:10,884][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:27:10,911][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 49 @ 1960 updates, score 4.934) (writing took 3.9624761855229735 seconds)
[2022-01-03 12:27:10,912][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2022-01-03 12:27:10,925][train][INFO] - {"epoch": 49, "train_loss": "4.832", "train_ntokens": "1794.53", "train_nsentences": "4.95", "train_prob_perplexity": "30.014", "train_code_perplexity": "29.931", "train_temp": "1.981", "train_loss_0": "4.649", "train_loss_1": "0.138", "train_loss_2": "0.045", "train_accuracy": "0.23598", "train_wps": "3920.6", "train_ups": "2.18", "train_wpb": "1794.5", "train_bsz": "5", "train_num_updates": "1960", "train_lr": "3.0625e-05", "train_gnorm": "1.728", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "1048"}
[2022-01-03 12:27:10,981][fairseq.trainer][INFO] - begin training epoch 50
[2022-01-03 12:27:10,982][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:27:24,944][train_inner][INFO] - {"epoch": 50, "update": 50.0, "loss": "4.84", "ntokens": "1792.03", "nsentences": "4.95", "prob_perplexity": "29.537", "code_perplexity": "29.452", "temp": "1.981", "loss_0": "4.656", "loss_1": "0.138", "loss_2": "0.046", "accuracy": "0.23891", "wps": "3368.6", "ups": "1.88", "wpb": "1792", "bsz": "5", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.772", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "1062"}
[2022-01-03 12:27:24,945][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:27:25,337][valid][INFO] - {"epoch": 50, "valid_loss": "5.094", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "32.296", "valid_code_perplexity": "32.096", "valid_temp": "1.98", "valid_loss_0": "4.919", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.2118", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "2000", "valid_best_loss": "4.594"}
[2022-01-03 12:27:25,340][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 2000 updates
[2022-01-03 12:27:25,341][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:27:29,075][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:27:29,099][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 50 @ 2000 updates, score 5.094) (writing took 3.758954642340541 seconds)
[2022-01-03 12:27:29,099][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2022-01-03 12:27:29,112][train][INFO] - {"epoch": 50, "train_loss": "4.809", "train_ntokens": "1791.53", "train_nsentences": "4.95", "train_prob_perplexity": "30.021", "train_code_perplexity": "29.94", "train_temp": "1.98", "train_loss_0": "4.629", "train_loss_1": "0.137", "train_loss_2": "0.043", "train_accuracy": "0.23864", "train_wps": "3943.1", "train_ups": "2.2", "train_wpb": "1791.5", "train_bsz": "5", "train_num_updates": "2000", "train_lr": "3.125e-05", "train_gnorm": "1.705", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1067"}
[2022-01-03 12:27:29,191][fairseq.trainer][INFO] - begin training epoch 51
[2022-01-03 12:27:29,191][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:27:43,107][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:27:43,586][valid][INFO] - {"epoch": 51, "valid_loss": "4.861", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "28.438", "valid_code_perplexity": "28.324", "valid_temp": "1.98", "valid_loss_0": "4.686", "valid_loss_1": "0.138", "valid_loss_2": "0.037", "valid_accuracy": "0.26374", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "2040", "valid_best_loss": "4.594"}
[2022-01-03 12:27:43,588][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 51 @ 2040 updates
[2022-01-03 12:27:43,588][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:27:47,317][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:27:47,343][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 51 @ 2040 updates, score 4.861) (writing took 3.755406462587416 seconds)
[2022-01-03 12:27:47,344][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2022-01-03 12:27:47,357][train][INFO] - {"epoch": 51, "train_loss": "4.859", "train_ntokens": "1786.9", "train_nsentences": "4.95", "train_prob_perplexity": "30.213", "train_code_perplexity": "30.152", "train_temp": "1.98", "train_loss_0": "4.677", "train_loss_1": "0.137", "train_loss_2": "0.045", "train_accuracy": "0.23408", "train_wps": "3920.5", "train_ups": "2.19", "train_wpb": "1786.9", "train_bsz": "5", "train_num_updates": "2040", "train_lr": "3.1875e-05", "train_gnorm": "2.163", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1085"}
[2022-01-03 12:27:47,435][fairseq.trainer][INFO] - begin training epoch 52
[2022-01-03 12:27:47,436][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:28:01,447][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:28:01,844][valid][INFO] - {"epoch": 52, "valid_loss": "4.87", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "28.725", "valid_code_perplexity": "28.708", "valid_temp": "1.979", "valid_loss_0": "4.69", "valid_loss_1": "0.138", "valid_loss_2": "0.042", "valid_accuracy": "0.2395", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "2080", "valid_best_loss": "4.594"}
[2022-01-03 12:28:01,847][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 52 @ 2080 updates
[2022-01-03 12:28:01,848][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:28:05,584][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:28:05,607][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 52 @ 2080 updates, score 4.87) (writing took 3.760217315517366 seconds)
[2022-01-03 12:28:05,608][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2022-01-03 12:28:05,621][train][INFO] - {"epoch": 52, "train_loss": "4.799", "train_ntokens": "1789.92", "train_nsentences": "4.95", "train_prob_perplexity": "29.725", "train_code_perplexity": "29.67", "train_temp": "1.98", "train_loss_0": "4.615", "train_loss_1": "0.138", "train_loss_2": "0.046", "train_accuracy": "0.2418", "train_wps": "3922.8", "train_ups": "2.19", "train_wpb": "1789.9", "train_bsz": "5", "train_num_updates": "2080", "train_lr": "3.25e-05", "train_gnorm": "1.627", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1103"}
[2022-01-03 12:28:05,697][fairseq.trainer][INFO] - begin training epoch 53
[2022-01-03 12:28:05,698][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:28:19,556][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:28:19,957][valid][INFO] - {"epoch": 53, "valid_loss": "4.713", "valid_ntokens": "704", "valid_nsentences": "2", "valid_prob_perplexity": "29.911", "valid_code_perplexity": "29.909", "valid_temp": "1.979", "valid_loss_0": "4.54", "valid_loss_1": "0.138", "valid_loss_2": "0.036", "valid_accuracy": "0.22869", "valid_wps": "0", "valid_wpb": "704", "valid_bsz": "2", "valid_num_updates": "2120", "valid_best_loss": "4.594"}
[2022-01-03 12:28:19,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 53 @ 2120 updates
[2022-01-03 12:28:19,961][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:28:23,920][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:28:23,945][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 53 @ 2120 updates, score 4.713) (writing took 3.9854290522634983 seconds)
[2022-01-03 12:28:23,946][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2022-01-03 12:28:23,958][train][INFO] - {"epoch": 53, "train_loss": "4.784", "train_ntokens": "1804", "train_nsentences": "4.95", "train_prob_perplexity": "29.96", "train_code_perplexity": "29.907", "train_temp": "1.979", "train_loss_0": "4.603", "train_loss_1": "0.138", "train_loss_2": "0.044", "train_accuracy": "0.24127", "train_wps": "3937.9", "train_ups": "2.18", "train_wpb": "1804", "train_bsz": "5", "train_num_updates": "2120", "train_lr": "3.3125e-05", "train_gnorm": "1.609", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1121"}
[2022-01-03 12:28:24,017][fairseq.trainer][INFO] - begin training epoch 54
[2022-01-03 12:28:24,017][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:28:38,011][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:28:38,423][valid][INFO] - {"epoch": 54, "valid_loss": "4.489", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "28.477", "valid_code_perplexity": "28.477", "valid_temp": "1.979", "valid_loss_0": "4.31", "valid_loss_1": "0.138", "valid_loss_2": "0.041", "valid_accuracy": "0.27669", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "2160", "valid_best_loss": "4.489"}
[2022-01-03 12:28:38,426][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 54 @ 2160 updates
[2022-01-03 12:28:38,427][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:28:42,194][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:28:49,527][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 54 @ 2160 updates, score 4.489) (writing took 11.101082797162235 seconds)
[2022-01-03 12:28:49,528][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2022-01-03 12:28:49,541][train][INFO] - {"epoch": 54, "train_loss": "4.784", "train_ntokens": "1805.62", "train_nsentences": "4.95", "train_prob_perplexity": "30.482", "train_code_perplexity": "30.394", "train_temp": "1.979", "train_loss_0": "4.602", "train_loss_1": "0.137", "train_loss_2": "0.044", "train_accuracy": "0.24118", "train_wps": "2824.7", "train_ups": "1.56", "train_wpb": "1805.6", "train_bsz": "5", "train_num_updates": "2160", "train_lr": "3.375e-05", "train_gnorm": "1.745", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "1147"}
[2022-01-03 12:28:49,608][fairseq.trainer][INFO] - begin training epoch 55
[2022-01-03 12:28:49,609][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:29:03,454][train_inner][INFO] - {"epoch": 55, "update": 55.0, "loss": "4.808", "ntokens": "1791.7", "nsentences": "4.95", "prob_perplexity": "30.175", "code_perplexity": "30.11", "temp": "1.979", "loss_0": "4.626", "loss_1": "0.137", "loss_2": "0.045", "accuracy": "0.23941", "wps": "3638.1", "ups": "2.03", "wpb": "1791.7", "bsz": "5", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.804", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "1161"}
[2022-01-03 12:29:03,455][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:29:03,873][valid][INFO] - {"epoch": 55, "valid_loss": "4.735", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "28.944", "valid_code_perplexity": "28.927", "valid_temp": "1.978", "valid_loss_0": "4.554", "valid_loss_1": "0.138", "valid_loss_2": "0.044", "valid_accuracy": "0.2231", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "2200", "valid_best_loss": "4.489"}
[2022-01-03 12:29:03,876][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 2200 updates
[2022-01-03 12:29:03,876][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:29:07,814][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:29:07,836][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 55 @ 2200 updates, score 4.735) (writing took 3.960039908066392 seconds)
[2022-01-03 12:29:07,836][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2022-01-03 12:29:07,849][train][INFO] - {"epoch": 55, "train_loss": "4.814", "train_ntokens": "1772.08", "train_nsentences": "4.95", "train_prob_perplexity": "30.497", "train_code_perplexity": "30.427", "train_temp": "1.978", "train_loss_0": "4.634", "train_loss_1": "0.137", "train_loss_2": "0.043", "train_accuracy": "0.2387", "train_wps": "3874.3", "train_ups": "2.19", "train_wpb": "1772.1", "train_bsz": "5", "train_num_updates": "2200", "train_lr": "3.4375e-05", "train_gnorm": "1.874", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1165"}
[2022-01-03 12:29:07,924][fairseq.trainer][INFO] - begin training epoch 56
[2022-01-03 12:29:07,925][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:29:21,759][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:29:22,183][valid][INFO] - {"epoch": 56, "valid_loss": "4.972", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "29.303", "valid_code_perplexity": "29.264", "valid_temp": "1.978", "valid_loss_0": "4.79", "valid_loss_1": "0.138", "valid_loss_2": "0.044", "valid_accuracy": "0.21208", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "2240", "valid_best_loss": "4.489"}
[2022-01-03 12:29:22,186][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 56 @ 2240 updates
[2022-01-03 12:29:22,187][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:29:26,093][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:29:26,120][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 56 @ 2240 updates, score 4.972) (writing took 3.9332341104745865 seconds)
[2022-01-03 12:29:26,120][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2022-01-03 12:29:26,133][train][INFO] - {"epoch": 56, "train_loss": "4.779", "train_ntokens": "1805.28", "train_nsentences": "4.95", "train_prob_perplexity": "29.933", "train_code_perplexity": "29.888", "train_temp": "1.978", "train_loss_0": "4.595", "train_loss_1": "0.138", "train_loss_2": "0.046", "train_accuracy": "0.23755", "train_wps": "3952.1", "train_ups": "2.19", "train_wpb": "1805.3", "train_bsz": "5", "train_num_updates": "2240", "train_lr": "3.5e-05", "train_gnorm": "1.801", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1184"}
[2022-01-03 12:29:26,211][fairseq.trainer][INFO] - begin training epoch 57
[2022-01-03 12:29:26,212][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:29:40,003][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:29:40,418][valid][INFO] - {"epoch": 57, "valid_loss": "4.59", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "28.824", "valid_code_perplexity": "28.82", "valid_temp": "1.977", "valid_loss_0": "4.407", "valid_loss_1": "0.138", "valid_loss_2": "0.045", "valid_accuracy": "0.24384", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "2280", "valid_best_loss": "4.489"}
[2022-01-03 12:29:40,421][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 57 @ 2280 updates
[2022-01-03 12:29:40,422][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:29:44,384][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:29:44,410][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 57 @ 2280 updates, score 4.59) (writing took 3.9890758879482746 seconds)
[2022-01-03 12:29:44,411][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2022-01-03 12:29:44,424][train][INFO] - {"epoch": 57, "train_loss": "4.779", "train_ntokens": "1782.75", "train_nsentences": "4.95", "train_prob_perplexity": "29.999", "train_code_perplexity": "29.951", "train_temp": "1.978", "train_loss_0": "4.598", "train_loss_1": "0.138", "train_loss_2": "0.044", "train_accuracy": "0.24051", "train_wps": "3901.4", "train_ups": "2.19", "train_wpb": "1782.8", "train_bsz": "5", "train_num_updates": "2280", "train_lr": "3.5625e-05", "train_gnorm": "1.604", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "1202"}
[2022-01-03 12:29:44,518][fairseq.trainer][INFO] - begin training epoch 58
[2022-01-03 12:29:44,518][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:29:58,396][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:29:58,831][valid][INFO] - {"epoch": 58, "valid_loss": "4.71", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "29.132", "valid_code_perplexity": "29.1", "valid_temp": "1.977", "valid_loss_0": "4.533", "valid_loss_1": "0.138", "valid_loss_2": "0.04", "valid_accuracy": "0.25065", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "2320", "valid_best_loss": "4.489"}
[2022-01-03 12:29:58,833][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 58 @ 2320 updates
[2022-01-03 12:29:58,833][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:30:02,625][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:30:02,651][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 58 @ 2320 updates, score 4.71) (writing took 3.8181834323331714 seconds)
[2022-01-03 12:30:02,651][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2022-01-03 12:30:02,664][train][INFO] - {"epoch": 58, "train_loss": "4.761", "train_ntokens": "1787.72", "train_nsentences": "4.95", "train_prob_perplexity": "30.134", "train_code_perplexity": "30.076", "train_temp": "1.977", "train_loss_0": "4.581", "train_loss_1": "0.137", "train_loss_2": "0.042", "train_accuracy": "0.24137", "train_wps": "3923.2", "train_ups": "2.19", "train_wpb": "1787.7", "train_bsz": "5", "train_num_updates": "2320", "train_lr": "3.625e-05", "train_gnorm": "1.663", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1220"}
[2022-01-03 12:30:02,736][fairseq.trainer][INFO] - begin training epoch 59
[2022-01-03 12:30:02,737][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:30:16,637][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:30:17,130][valid][INFO] - {"epoch": 59, "valid_loss": "4.515", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "28.009", "valid_code_perplexity": "28.012", "valid_temp": "1.977", "valid_loss_0": "4.338", "valid_loss_1": "0.138", "valid_loss_2": "0.039", "valid_accuracy": "0.27023", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "2360", "valid_best_loss": "4.489"}
[2022-01-03 12:30:17,132][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 59 @ 2360 updates
[2022-01-03 12:30:17,132][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:30:20,881][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:30:20,903][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 59 @ 2360 updates, score 4.515) (writing took 3.771164978854358 seconds)
[2022-01-03 12:30:20,904][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2022-01-03 12:30:20,919][train][INFO] - {"epoch": 59, "train_loss": "4.764", "train_ntokens": "1789.03", "train_nsentences": "4.95", "train_prob_perplexity": "29.79", "train_code_perplexity": "29.742", "train_temp": "1.977", "train_loss_0": "4.586", "train_loss_1": "0.138", "train_loss_2": "0.041", "train_accuracy": "0.24343", "train_wps": "3923.4", "train_ups": "2.19", "train_wpb": "1789", "train_bsz": "5", "train_num_updates": "2360", "train_lr": "3.6875e-05", "train_gnorm": "2.179", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "1238"}
[2022-01-03 12:30:21,000][fairseq.trainer][INFO] - begin training epoch 60
[2022-01-03 12:30:21,001][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:30:34,822][train_inner][INFO] - {"epoch": 60, "update": 60.0, "loss": "4.769", "ntokens": "1795.46", "nsentences": "4.95", "prob_perplexity": "29.951", "code_perplexity": "29.904", "temp": "1.977", "loss_0": "4.588", "loss_1": "0.138", "loss_2": "0.043", "accuracy": "0.24083", "wps": "3930.8", "ups": "2.19", "wpb": "1795.5", "bsz": "5", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.793", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "1252"}
[2022-01-03 12:30:34,823][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:30:35,220][valid][INFO] - {"epoch": 60, "valid_loss": "4.526", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "28.403", "valid_code_perplexity": "28.334", "valid_temp": "1.976", "valid_loss_0": "4.346", "valid_loss_1": "0.138", "valid_loss_2": "0.042", "valid_accuracy": "0.27892", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "2400", "valid_best_loss": "4.489"}
[2022-01-03 12:30:35,223][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 2400 updates
[2022-01-03 12:30:35,224][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:30:39,253][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:30:39,279][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 60 @ 2400 updates, score 4.526) (writing took 4.05642656609416 seconds)
[2022-01-03 12:30:39,280][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2022-01-03 12:30:39,292][train][INFO] - {"epoch": 60, "train_loss": "4.76", "train_ntokens": "1812.55", "train_nsentences": "4.95", "train_prob_perplexity": "29.897", "train_code_perplexity": "29.864", "train_temp": "1.976", "train_loss_0": "4.58", "train_loss_1": "0.138", "train_loss_2": "0.042", "train_accuracy": "0.2413", "train_wps": "3948.9", "train_ups": "2.18", "train_wpb": "1812.5", "train_bsz": "5", "train_num_updates": "2400", "train_lr": "3.75e-05", "train_gnorm": "1.718", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "1257"}
[2022-01-03 12:30:39,358][fairseq.trainer][INFO] - begin training epoch 61
[2022-01-03 12:30:39,359][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:30:53,168][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:30:53,584][valid][INFO] - {"epoch": 61, "valid_loss": "4.859", "valid_ntokens": "800", "valid_nsentences": "2", "valid_prob_perplexity": "28.356", "valid_code_perplexity": "28.323", "valid_temp": "1.976", "valid_loss_0": "4.678", "valid_loss_1": "0.138", "valid_loss_2": "0.043", "valid_accuracy": "0.23", "valid_wps": "0", "valid_wpb": "800", "valid_bsz": "2", "valid_num_updates": "2440", "valid_best_loss": "4.489"}
[2022-01-03 12:30:53,587][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 61 @ 2440 updates
[2022-01-03 12:30:53,588][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:30:57,552][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:30:57,581][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 61 @ 2440 updates, score 4.859) (writing took 3.994198373518884 seconds)
[2022-01-03 12:30:57,582][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2022-01-03 12:30:57,595][train][INFO] - {"epoch": 61, "train_loss": "4.699", "train_ntokens": "1777.83", "train_nsentences": "4.95", "train_prob_perplexity": "30.022", "train_code_perplexity": "29.984", "train_temp": "1.976", "train_loss_0": "4.52", "train_loss_1": "0.137", "train_loss_2": "0.042", "train_accuracy": "0.25153", "train_wps": "3888.2", "train_ups": "2.19", "train_wpb": "1777.8", "train_bsz": "5", "train_num_updates": "2440", "train_lr": "3.8125e-05", "train_gnorm": "1.707", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1275"}
[2022-01-03 12:30:57,680][fairseq.trainer][INFO] - begin training epoch 62
[2022-01-03 12:30:57,681][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:31:11,778][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:31:12,174][valid][INFO] - {"epoch": 62, "valid_loss": "4.854", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "29.726", "valid_code_perplexity": "29.76", "valid_temp": "1.975", "valid_loss_0": "4.676", "valid_loss_1": "0.138", "valid_loss_2": "0.041", "valid_accuracy": "0.21954", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "2480", "valid_best_loss": "4.489"}
[2022-01-03 12:31:12,177][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 62 @ 2480 updates
[2022-01-03 12:31:12,178][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:31:15,813][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:31:15,841][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 62 @ 2480 updates, score 4.854) (writing took 3.6636251555755734 seconds)
[2022-01-03 12:31:15,841][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2022-01-03 12:31:15,855][train][INFO] - {"epoch": 62, "train_loss": "4.691", "train_ntokens": "1793.7", "train_nsentences": "4.95", "train_prob_perplexity": "30.308", "train_code_perplexity": "30.257", "train_temp": "1.976", "train_loss_0": "4.513", "train_loss_1": "0.137", "train_loss_2": "0.041", "train_accuracy": "0.25387", "train_wps": "3932.1", "train_ups": "2.19", "train_wpb": "1793.7", "train_bsz": "5", "train_num_updates": "2480", "train_lr": "3.875e-05", "train_gnorm": "1.779", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1293"}
[2022-01-03 12:31:15,926][fairseq.trainer][INFO] - begin training epoch 63
[2022-01-03 12:31:15,927][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:31:29,878][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:31:30,273][valid][INFO] - {"epoch": 63, "valid_loss": "4.617", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "29.617", "valid_code_perplexity": "29.633", "valid_temp": "1.975", "valid_loss_0": "4.441", "valid_loss_1": "0.138", "valid_loss_2": "0.039", "valid_accuracy": "0.25741", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "2520", "valid_best_loss": "4.489"}
[2022-01-03 12:31:30,276][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 63 @ 2520 updates
[2022-01-03 12:31:30,277][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:31:34,006][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:31:34,034][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 63 @ 2520 updates, score 4.617) (writing took 3.7578873289749026 seconds)
[2022-01-03 12:31:34,035][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2022-01-03 12:31:34,049][train][INFO] - {"epoch": 63, "train_loss": "4.726", "train_ntokens": "1791.42", "train_nsentences": "4.95", "train_prob_perplexity": "30.519", "train_code_perplexity": "30.463", "train_temp": "1.975", "train_loss_0": "4.548", "train_loss_1": "0.137", "train_loss_2": "0.041", "train_accuracy": "0.24127", "train_wps": "3941.5", "train_ups": "2.2", "train_wpb": "1791.4", "train_bsz": "5", "train_num_updates": "2520", "train_lr": "3.9375e-05", "train_gnorm": "1.742", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1311"}
[2022-01-03 12:31:34,130][fairseq.trainer][INFO] - begin training epoch 64
[2022-01-03 12:31:34,131][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:31:48,108][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:31:48,596][valid][INFO] - {"epoch": 64, "valid_loss": "4.637", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "29.611", "valid_code_perplexity": "29.551", "valid_temp": "1.975", "valid_loss_0": "4.462", "valid_loss_1": "0.138", "valid_loss_2": "0.038", "valid_accuracy": "0.25691", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "2560", "valid_best_loss": "4.489"}
[2022-01-03 12:31:48,598][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 64 @ 2560 updates
[2022-01-03 12:31:48,599][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:31:52,246][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:31:52,274][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 64 @ 2560 updates, score 4.637) (writing took 3.6759712547063828 seconds)
[2022-01-03 12:31:52,274][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2022-01-03 12:31:52,287][train][INFO] - {"epoch": 64, "train_loss": "4.706", "train_ntokens": "1786.2", "train_nsentences": "4.95", "train_prob_perplexity": "30.594", "train_code_perplexity": "30.54", "train_temp": "1.975", "train_loss_0": "4.529", "train_loss_1": "0.137", "train_loss_2": "0.04", "train_accuracy": "0.2459", "train_wps": "3920.2", "train_ups": "2.19", "train_wpb": "1786.2", "train_bsz": "5", "train_num_updates": "2560", "train_lr": "4e-05", "train_gnorm": "1.851", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1330"}
[2022-01-03 12:31:52,358][fairseq.trainer][INFO] - begin training epoch 65
[2022-01-03 12:31:52,359][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:32:06,327][train_inner][INFO] - {"epoch": 65, "update": 65.0, "loss": "4.704", "ntokens": "1790.14", "nsentences": "4.95", "prob_perplexity": "30.36", "code_perplexity": "30.31", "temp": "1.975", "loss_0": "4.527", "loss_1": "0.137", "loss_2": "0.041", "accuracy": "0.24771", "wps": "3913.2", "ups": "2.19", "wpb": "1790.1", "bsz": "5", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.752", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "1344"}
[2022-01-03 12:32:06,328][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:32:06,824][valid][INFO] - {"epoch": 65, "valid_loss": "4.973", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "30.069", "valid_code_perplexity": "29.926", "valid_temp": "1.974", "valid_loss_0": "4.801", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.20076", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "2600", "valid_best_loss": "4.489"}
[2022-01-03 12:32:06,826][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 2600 updates
[2022-01-03 12:32:06,827][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:32:10,472][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:32:10,501][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 65 @ 2600 updates, score 4.973) (writing took 3.6746322428807616 seconds)
[2022-01-03 12:32:10,501][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2022-01-03 12:32:10,514][train][INFO] - {"epoch": 65, "train_loss": "4.7", "train_ntokens": "1801.58", "train_nsentences": "4.95", "train_prob_perplexity": "30.356", "train_code_perplexity": "30.308", "train_temp": "1.974", "train_loss_0": "4.523", "train_loss_1": "0.137", "train_loss_2": "0.04", "train_accuracy": "0.24601", "train_wps": "3956.5", "train_ups": "2.2", "train_wpb": "1801.6", "train_bsz": "5", "train_num_updates": "2600", "train_lr": "4.0625e-05", "train_gnorm": "1.68", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1348"}
[2022-01-03 12:32:10,563][fairseq.trainer][INFO] - begin training epoch 66
[2022-01-03 12:32:10,564][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:32:24,420][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:32:24,907][valid][INFO] - {"epoch": 66, "valid_loss": "4.728", "valid_ntokens": "706", "valid_nsentences": "2", "valid_prob_perplexity": "28.584", "valid_code_perplexity": "28.476", "valid_temp": "1.974", "valid_loss_0": "4.552", "valid_loss_1": "0.138", "valid_loss_2": "0.038", "valid_accuracy": "0.25496", "valid_wps": "0", "valid_wpb": "706", "valid_bsz": "2", "valid_num_updates": "2640", "valid_best_loss": "4.489"}
[2022-01-03 12:32:24,909][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 66 @ 2640 updates
[2022-01-03 12:32:24,910][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:32:28,811][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:32:28,839][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 66 @ 2640 updates, score 4.728) (writing took 3.9297041669487953 seconds)
[2022-01-03 12:32:28,839][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2022-01-03 12:32:28,852][train][INFO] - {"epoch": 66, "train_loss": "4.728", "train_ntokens": "1782.33", "train_nsentences": "4.95", "train_prob_perplexity": "30.891", "train_code_perplexity": "30.843", "train_temp": "1.974", "train_loss_0": "4.551", "train_loss_1": "0.137", "train_loss_2": "0.039", "train_accuracy": "0.24747", "train_wps": "3890.4", "train_ups": "2.18", "train_wpb": "1782.3", "train_bsz": "5", "train_num_updates": "2640", "train_lr": "4.125e-05", "train_gnorm": "1.833", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "1366"}
[2022-01-03 12:32:28,933][fairseq.trainer][INFO] - begin training epoch 67
[2022-01-03 12:32:28,934][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:32:42,981][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:32:43,391][valid][INFO] - {"epoch": 67, "valid_loss": "4.303", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "28.315", "valid_code_perplexity": "28.193", "valid_temp": "1.973", "valid_loss_0": "4.128", "valid_loss_1": "0.138", "valid_loss_2": "0.037", "valid_accuracy": "0.29921", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "2680", "valid_best_loss": "4.303"}
[2022-01-03 12:32:43,393][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 67 @ 2680 updates
[2022-01-03 12:32:43,394][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:32:47,041][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:32:53,966][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 67 @ 2680 updates, score 4.303) (writing took 10.57230884116143 seconds)
[2022-01-03 12:32:53,967][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2022-01-03 12:32:53,981][train][INFO] - {"epoch": 67, "train_loss": "4.65", "train_ntokens": "1807.1", "train_nsentences": "4.95", "train_prob_perplexity": "30.412", "train_code_perplexity": "30.357", "train_temp": "1.974", "train_loss_0": "4.472", "train_loss_1": "0.137", "train_loss_2": "0.04", "train_accuracy": "0.25418", "train_wps": "2878.1", "train_ups": "1.59", "train_wpb": "1807.1", "train_bsz": "5", "train_num_updates": "2680", "train_lr": "4.1875e-05", "train_gnorm": "1.784", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.4", "train_wall": "1391"}
[2022-01-03 12:32:54,047][fairseq.trainer][INFO] - begin training epoch 68
[2022-01-03 12:32:54,047][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:33:07,936][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:33:08,342][valid][INFO] - {"epoch": 68, "valid_loss": "4.979", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "28.962", "valid_code_perplexity": "28.964", "valid_temp": "1.973", "valid_loss_0": "4.803", "valid_loss_1": "0.138", "valid_loss_2": "0.039", "valid_accuracy": "0.21108", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "2720", "valid_best_loss": "4.303"}
[2022-01-03 12:33:08,346][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 68 @ 2720 updates
[2022-01-03 12:33:08,346][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:33:12,251][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:33:12,271][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 68 @ 2720 updates, score 4.979) (writing took 3.9259473672136664 seconds)
[2022-01-03 12:33:12,272][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2022-01-03 12:33:12,285][train][INFO] - {"epoch": 68, "train_loss": "4.654", "train_ntokens": "1785.53", "train_nsentences": "4.95", "train_prob_perplexity": "30.456", "train_code_perplexity": "30.408", "train_temp": "1.973", "train_loss_0": "4.477", "train_loss_1": "0.137", "train_loss_2": "0.04", "train_accuracy": "0.25324", "train_wps": "3904.8", "train_ups": "2.19", "train_wpb": "1785.5", "train_bsz": "5", "train_num_updates": "2720", "train_lr": "4.25e-05", "train_gnorm": "1.861", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1410"}
[2022-01-03 12:33:12,356][fairseq.trainer][INFO] - begin training epoch 69
[2022-01-03 12:33:12,357][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:33:26,406][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:33:26,826][valid][INFO] - {"epoch": 69, "valid_loss": "4.499", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "29.068", "valid_code_perplexity": "28.987", "valid_temp": "1.973", "valid_loss_0": "4.324", "valid_loss_1": "0.138", "valid_loss_2": "0.037", "valid_accuracy": "0.26786", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "2760", "valid_best_loss": "4.303"}
[2022-01-03 12:33:26,829][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 69 @ 2760 updates
[2022-01-03 12:33:26,829][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:33:30,497][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:33:30,526][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 69 @ 2760 updates, score 4.499) (writing took 3.6968333330005407 seconds)
[2022-01-03 12:33:30,526][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2022-01-03 12:33:30,539][train][INFO] - {"epoch": 69, "train_loss": "4.66", "train_ntokens": "1793.33", "train_nsentences": "4.95", "train_prob_perplexity": "31.18", "train_code_perplexity": "31.142", "train_temp": "1.973", "train_loss_0": "4.485", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.25068", "train_wps": "3932.4", "train_ups": "2.19", "train_wpb": "1793.3", "train_bsz": "5", "train_num_updates": "2760", "train_lr": "4.3125e-05", "train_gnorm": "1.728", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1428"}
[2022-01-03 12:33:30,623][fairseq.trainer][INFO] - begin training epoch 70
[2022-01-03 12:33:30,624][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:33:44,511][train_inner][INFO] - {"epoch": 70, "update": 70.0, "loss": "4.662", "ntokens": "1794.16", "nsentences": "4.95", "prob_perplexity": "30.863", "code_perplexity": "30.817", "temp": "1.973", "loss_0": "4.486", "loss_1": "0.137", "loss_2": "0.039", "accuracy": "0.25215", "wps": "3655.2", "ups": "2.04", "wpb": "1794.2", "bsz": "5", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.784", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "1442"}
[2022-01-03 12:33:44,512][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:33:44,935][valid][INFO] - {"epoch": 70, "valid_loss": "4.868", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "31.413", "valid_code_perplexity": "31.374", "valid_temp": "1.972", "valid_loss_0": "4.692", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.24339", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "2800", "valid_best_loss": "4.303"}
[2022-01-03 12:33:44,939][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 2800 updates
[2022-01-03 12:33:44,940][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:33:48,709][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:33:48,735][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 70 @ 2800 updates, score 4.868) (writing took 3.7967060450464487 seconds)
[2022-01-03 12:33:48,736][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2022-01-03 12:33:48,749][train][INFO] - {"epoch": 70, "train_loss": "4.619", "train_ntokens": "1802.55", "train_nsentences": "4.95", "train_prob_perplexity": "31.375", "train_code_perplexity": "31.334", "train_temp": "1.972", "train_loss_0": "4.444", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.25512", "train_wps": "3962.3", "train_ups": "2.2", "train_wpb": "1802.5", "train_bsz": "5", "train_num_updates": "2800", "train_lr": "4.375e-05", "train_gnorm": "1.716", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1446"}
[2022-01-03 12:33:48,824][fairseq.trainer][INFO] - begin training epoch 71
[2022-01-03 12:33:48,825][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:34:02,701][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:34:03,102][valid][INFO] - {"epoch": 71, "valid_loss": "4.915", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "30.69", "valid_code_perplexity": "30.614", "valid_temp": "1.972", "valid_loss_0": "4.739", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.21728", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "2840", "valid_best_loss": "4.303"}
[2022-01-03 12:34:03,105][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 71 @ 2840 updates
[2022-01-03 12:34:03,106][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:34:06,941][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:34:06,969][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 71 @ 2840 updates, score 4.915) (writing took 3.8641966385766864 seconds)
[2022-01-03 12:34:06,970][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2022-01-03 12:34:06,983][train][INFO] - {"epoch": 71, "train_loss": "4.629", "train_ntokens": "1780", "train_nsentences": "4.95", "train_prob_perplexity": "31.224", "train_code_perplexity": "31.171", "train_temp": "1.972", "train_loss_0": "4.453", "train_loss_1": "0.137", "train_loss_2": "0.039", "train_accuracy": "0.25733", "train_wps": "3907.6", "train_ups": "2.2", "train_wpb": "1780", "train_bsz": "5", "train_num_updates": "2840", "train_lr": "4.4375e-05", "train_gnorm": "1.855", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "1464"}
[2022-01-03 12:34:07,059][fairseq.trainer][INFO] - begin training epoch 72
[2022-01-03 12:34:07,060][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:34:21,016][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:34:21,522][valid][INFO] - {"epoch": 72, "valid_loss": "4.254", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "29.548", "valid_code_perplexity": "29.5", "valid_temp": "1.971", "valid_loss_0": "4.078", "valid_loss_1": "0.138", "valid_loss_2": "0.038", "valid_accuracy": "0.3", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "2880", "valid_best_loss": "4.254"}
[2022-01-03 12:34:21,524][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 72 @ 2880 updates
[2022-01-03 12:34:21,525][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:34:25,185][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:34:32,416][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 72 @ 2880 updates, score 4.254) (writing took 10.891501920297742 seconds)
[2022-01-03 12:34:32,416][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2022-01-03 12:34:32,431][train][INFO] - {"epoch": 72, "train_loss": "4.591", "train_ntokens": "1815.5", "train_nsentences": "4.95", "train_prob_perplexity": "30.961", "train_code_perplexity": "30.922", "train_temp": "1.972", "train_loss_0": "4.413", "train_loss_1": "0.137", "train_loss_2": "0.04", "train_accuracy": "0.26114", "train_wps": "2855.3", "train_ups": "1.57", "train_wpb": "1815.5", "train_bsz": "5", "train_num_updates": "2880", "train_lr": "4.5e-05", "train_gnorm": "1.676", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1490"}
[2022-01-03 12:34:32,521][fairseq.trainer][INFO] - begin training epoch 73
[2022-01-03 12:34:32,522][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:34:46,383][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:34:46,789][valid][INFO] - {"epoch": 73, "valid_loss": "4.724", "valid_ntokens": "678", "valid_nsentences": "2", "valid_prob_perplexity": "30.294", "valid_code_perplexity": "30.336", "valid_temp": "1.971", "valid_loss_0": "4.548", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.26991", "valid_wps": "0", "valid_wpb": "678", "valid_bsz": "2", "valid_num_updates": "2920", "valid_best_loss": "4.254"}
[2022-01-03 12:34:46,793][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 73 @ 2920 updates
[2022-01-03 12:34:46,794][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:34:50,690][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:34:50,711][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 73 @ 2920 updates, score 4.724) (writing took 3.917738763615489 seconds)
[2022-01-03 12:34:50,711][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2022-01-03 12:34:50,724][train][INFO] - {"epoch": 73, "train_loss": "4.594", "train_ntokens": "1772.22", "train_nsentences": "4.95", "train_prob_perplexity": "30.964", "train_code_perplexity": "30.924", "train_temp": "1.971", "train_loss_0": "4.416", "train_loss_1": "0.137", "train_loss_2": "0.041", "train_accuracy": "0.26159", "train_wps": "3877.9", "train_ups": "2.19", "train_wpb": "1772.2", "train_bsz": "5", "train_num_updates": "2920", "train_lr": "4.5625e-05", "train_gnorm": "1.751", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1508"}
[2022-01-03 12:34:50,804][fairseq.trainer][INFO] - begin training epoch 74
[2022-01-03 12:34:50,805][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:35:04,705][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:35:05,207][valid][INFO] - {"epoch": 74, "valid_loss": "4.353", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "29.288", "valid_code_perplexity": "29.177", "valid_temp": "1.971", "valid_loss_0": "4.176", "valid_loss_1": "0.138", "valid_loss_2": "0.039", "valid_accuracy": "0.28375", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "2960", "valid_best_loss": "4.254"}
[2022-01-03 12:35:05,209][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 74 @ 2960 updates
[2022-01-03 12:35:05,209][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:35:08,902][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:35:08,929][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 74 @ 2960 updates, score 4.353) (writing took 3.7200989071279764 seconds)
[2022-01-03 12:35:08,929][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2022-01-03 12:35:08,942][train][INFO] - {"epoch": 74, "train_loss": "4.557", "train_ntokens": "1783.62", "train_nsentences": "4.95", "train_prob_perplexity": "30.965", "train_code_perplexity": "30.926", "train_temp": "1.971", "train_loss_0": "4.381", "train_loss_1": "0.137", "train_loss_2": "0.039", "train_accuracy": "0.26379", "train_wps": "3918.9", "train_ups": "2.2", "train_wpb": "1783.6", "train_bsz": "5", "train_num_updates": "2960", "train_lr": "4.625e-05", "train_gnorm": "1.727", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1526"}
[2022-01-03 12:35:08,992][fairseq.trainer][INFO] - begin training epoch 75
[2022-01-03 12:35:08,993][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:35:22,798][train_inner][INFO] - {"epoch": 75, "update": 75.0, "loss": "4.594", "ntokens": "1789.79", "nsentences": "4.95", "prob_perplexity": "31.044", "code_perplexity": "31", "temp": "1.971", "loss_0": "4.418", "loss_1": "0.137", "loss_2": "0.04", "accuracy": "0.25996", "wps": "3642.4", "ups": "2.04", "wpb": "1789.8", "bsz": "5", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.759", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "1540"}
[2022-01-03 12:35:22,799][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:35:23,213][valid][INFO] - {"epoch": 75, "valid_loss": "4.529", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "28.593", "valid_code_perplexity": "28.626", "valid_temp": "1.97", "valid_loss_0": "4.357", "valid_loss_1": "0.138", "valid_loss_2": "0.034", "valid_accuracy": "0.25749", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "3000", "valid_best_loss": "4.254"}
[2022-01-03 12:35:23,216][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 75 @ 3000 updates
[2022-01-03 12:35:23,216][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:35:27,158][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:35:27,184][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 75 @ 3000 updates, score 4.529) (writing took 3.9687789399176836 seconds)
[2022-01-03 12:35:27,185][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2022-01-03 12:35:27,197][train][INFO] - {"epoch": 75, "train_loss": "4.601", "train_ntokens": "1797.58", "train_nsentences": "4.95", "train_prob_perplexity": "31.106", "train_code_perplexity": "31.055", "train_temp": "1.97", "train_loss_0": "4.426", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.25597", "train_wps": "3941.4", "train_ups": "2.19", "train_wpb": "1797.6", "train_bsz": "5", "train_num_updates": "3000", "train_lr": "4.6875e-05", "train_gnorm": "1.788", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1545"}
[2022-01-03 12:35:27,256][fairseq.trainer][INFO] - begin training epoch 76
[2022-01-03 12:35:27,257][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:35:41,309][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:35:41,713][valid][INFO] - {"epoch": 76, "valid_loss": "4.768", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "30.103", "valid_code_perplexity": "30.029", "valid_temp": "1.97", "valid_loss_0": "4.59", "valid_loss_1": "0.137", "valid_loss_2": "0.04", "valid_accuracy": "0.256", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "3040", "valid_best_loss": "4.254"}
[2022-01-03 12:35:41,716][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 76 @ 3040 updates
[2022-01-03 12:35:41,717][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:35:45,382][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:35:45,409][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 76 @ 3040 updates, score 4.768) (writing took 3.69247533287853 seconds)
[2022-01-03 12:35:45,409][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2022-01-03 12:35:45,422][train][INFO] - {"epoch": 76, "train_loss": "4.583", "train_ntokens": "1793.05", "train_nsentences": "4.95", "train_prob_perplexity": "31.34", "train_code_perplexity": "31.297", "train_temp": "1.97", "train_loss_0": "4.406", "train_loss_1": "0.137", "train_loss_2": "0.04", "train_accuracy": "0.26088", "train_wps": "3938.2", "train_ups": "2.2", "train_wpb": "1793", "train_bsz": "5", "train_num_updates": "3040", "train_lr": "4.75e-05", "train_gnorm": "1.756", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1563"}
[2022-01-03 12:35:45,503][fairseq.trainer][INFO] - begin training epoch 77
[2022-01-03 12:35:45,504][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:35:59,370][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:35:59,784][valid][INFO] - {"epoch": 77, "valid_loss": "4.595", "valid_ntokens": "790", "valid_nsentences": "2", "valid_prob_perplexity": "31.356", "valid_code_perplexity": "31.22", "valid_temp": "1.969", "valid_loss_0": "4.425", "valid_loss_1": "0.137", "valid_loss_2": "0.033", "valid_accuracy": "0.25063", "valid_wps": "0", "valid_wpb": "790", "valid_bsz": "2", "valid_num_updates": "3080", "valid_best_loss": "4.254"}
[2022-01-03 12:35:59,787][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 77 @ 3080 updates
[2022-01-03 12:35:59,788][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:36:03,588][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:36:03,615][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 77 @ 3080 updates, score 4.595) (writing took 3.8277798471972346 seconds)
[2022-01-03 12:36:03,615][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2022-01-03 12:36:03,628][train][INFO] - {"epoch": 77, "train_loss": "4.575", "train_ntokens": "1815.55", "train_nsentences": "4.95", "train_prob_perplexity": "31.649", "train_code_perplexity": "31.614", "train_temp": "1.97", "train_loss_0": "4.4", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.26073", "train_wps": "3991.8", "train_ups": "2.2", "train_wpb": "1815.5", "train_bsz": "5", "train_num_updates": "3080", "train_lr": "4.8125e-05", "train_gnorm": "1.763", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1581"}
[2022-01-03 12:36:03,703][fairseq.trainer][INFO] - begin training epoch 78
[2022-01-03 12:36:03,704][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:36:17,635][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:36:18,143][valid][INFO] - {"epoch": 78, "valid_loss": "4.7", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "30.577", "valid_code_perplexity": "30.574", "valid_temp": "1.969", "valid_loss_0": "4.524", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.23496", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "3120", "valid_best_loss": "4.254"}
[2022-01-03 12:36:18,145][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 78 @ 3120 updates
[2022-01-03 12:36:18,145][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:36:21,814][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:36:21,842][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 78 @ 3120 updates, score 4.7) (writing took 3.6971926698461175 seconds)
[2022-01-03 12:36:21,842][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2022-01-03 12:36:21,855][train][INFO] - {"epoch": 78, "train_loss": "4.578", "train_ntokens": "1802.58", "train_nsentences": "4.95", "train_prob_perplexity": "31.741", "train_code_perplexity": "31.71", "train_temp": "1.969", "train_loss_0": "4.403", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.25916", "train_wps": "3958.7", "train_ups": "2.2", "train_wpb": "1802.6", "train_bsz": "5", "train_num_updates": "3120", "train_lr": "4.875e-05", "train_gnorm": "1.733", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1599"}
[2022-01-03 12:36:21,931][fairseq.trainer][INFO] - begin training epoch 79
[2022-01-03 12:36:21,932][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:36:35,811][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:36:36,293][valid][INFO] - {"epoch": 79, "valid_loss": "4.469", "valid_ntokens": "816", "valid_nsentences": "2", "valid_prob_perplexity": "28.855", "valid_code_perplexity": "28.831", "valid_temp": "1.969", "valid_loss_0": "4.297", "valid_loss_1": "0.138", "valid_loss_2": "0.035", "valid_accuracy": "0.25613", "valid_wps": "0", "valid_wpb": "816", "valid_bsz": "2", "valid_num_updates": "3160", "valid_best_loss": "4.254"}
[2022-01-03 12:36:36,294][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 79 @ 3160 updates
[2022-01-03 12:36:36,295][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:36:40,077][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:36:40,106][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 79 @ 3160 updates, score 4.469) (writing took 3.8113799784332514 seconds)
[2022-01-03 12:36:40,106][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2022-01-03 12:36:40,119][train][INFO] - {"epoch": 79, "train_loss": "4.529", "train_ntokens": "1798.83", "train_nsentences": "4.95", "train_prob_perplexity": "31.806", "train_code_perplexity": "31.771", "train_temp": "1.969", "train_loss_0": "4.355", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.2636", "train_wps": "3942.4", "train_ups": "2.19", "train_wpb": "1798.8", "train_bsz": "5", "train_num_updates": "3160", "train_lr": "4.9375e-05", "train_gnorm": "1.692", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "1618"}
[2022-01-03 12:36:40,189][fairseq.trainer][INFO] - begin training epoch 80
[2022-01-03 12:36:40,189][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:36:54,160][train_inner][INFO] - {"epoch": 80, "update": 80.0, "loss": "4.557", "ntokens": "1800.94", "nsentences": "4.95", "prob_perplexity": "31.397", "code_perplexity": "31.361", "temp": "1.969", "loss_0": "4.381", "loss_1": "0.137", "loss_2": "0.038", "accuracy": "0.26263", "wps": "3943", "ups": "2.19", "wpb": "1800.9", "bsz": "5", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.767", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "1632"}
[2022-01-03 12:36:54,161][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:36:54,605][valid][INFO] - {"epoch": 80, "valid_loss": "4.648", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "30.002", "valid_code_perplexity": "29.821", "valid_temp": "1.968", "valid_loss_0": "4.47", "valid_loss_1": "0.138", "valid_loss_2": "0.04", "valid_accuracy": "0.23464", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "3200", "valid_best_loss": "4.254"}
[2022-01-03 12:36:54,608][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 3200 updates
[2022-01-03 12:36:54,609][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:36:58,329][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:36:58,342][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 80 @ 3200 updates, score 4.648) (writing took 3.7341425959020853 seconds)
[2022-01-03 12:36:58,343][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2022-01-03 12:36:58,356][train][INFO] - {"epoch": 80, "train_loss": "4.518", "train_ntokens": "1794.72", "train_nsentences": "4.95", "train_prob_perplexity": "30.45", "train_code_perplexity": "30.416", "train_temp": "1.968", "train_loss_0": "4.342", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.26882", "train_wps": "3939.4", "train_ups": "2.19", "train_wpb": "1794.7", "train_bsz": "5", "train_num_updates": "3200", "train_lr": "5e-05", "train_gnorm": "1.889", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "1636"}
[2022-01-03 12:36:58,409][fairseq.trainer][INFO] - begin training epoch 81
[2022-01-03 12:36:58,410][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:37:12,407][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:37:12,864][valid][INFO] - {"epoch": 81, "valid_loss": "4.211", "valid_ntokens": "686", "valid_nsentences": "2", "valid_prob_perplexity": "31.33", "valid_code_perplexity": "31.226", "valid_temp": "1.968", "valid_loss_0": "4.037", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.28571", "valid_wps": "0", "valid_wpb": "686", "valid_bsz": "2", "valid_num_updates": "3240", "valid_best_loss": "4.211"}
[2022-01-03 12:37:12,867][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 81 @ 3240 updates
[2022-01-03 12:37:12,868][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:37:16,561][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:37:23,219][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 81 @ 3240 updates, score 4.211) (writing took 10.352396071888506 seconds)
[2022-01-03 12:37:23,220][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2022-01-03 12:37:23,233][train][INFO] - {"epoch": 81, "train_loss": "4.578", "train_ntokens": "1779.9", "train_nsentences": "4.95", "train_prob_perplexity": "31.467", "train_code_perplexity": "31.432", "train_temp": "1.968", "train_loss_0": "4.402", "train_loss_1": "0.137", "train_loss_2": "0.039", "train_accuracy": "0.25841", "train_wps": "2863.4", "train_ups": "1.61", "train_wpb": "1779.9", "train_bsz": "5", "train_num_updates": "3240", "train_lr": "5.0625e-05", "train_gnorm": "1.869", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1661"}
[2022-01-03 12:37:23,272][fairseq.trainer][INFO] - begin training epoch 82
[2022-01-03 12:37:23,272][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:37:37,166][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:37:37,602][valid][INFO] - {"epoch": 82, "valid_loss": "4.868", "valid_ntokens": "666", "valid_nsentences": "2", "valid_prob_perplexity": "30.566", "valid_code_perplexity": "30.573", "valid_temp": "1.967", "valid_loss_0": "4.692", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.23874", "valid_wps": "0", "valid_wpb": "666", "valid_bsz": "2", "valid_num_updates": "3280", "valid_best_loss": "4.211"}
[2022-01-03 12:37:37,605][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 82 @ 3280 updates
[2022-01-03 12:37:37,605][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:37:41,542][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:37:41,559][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 82 @ 3280 updates, score 4.868) (writing took 3.9542487701401114 seconds)
[2022-01-03 12:37:41,559][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2022-01-03 12:37:41,572][train][INFO] - {"epoch": 82, "train_loss": "4.518", "train_ntokens": "1781.53", "train_nsentences": "4.95", "train_prob_perplexity": "31.714", "train_code_perplexity": "31.689", "train_temp": "1.968", "train_loss_0": "4.343", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.26546", "train_wps": "3888.4", "train_ups": "2.18", "train_wpb": "1781.5", "train_bsz": "5", "train_num_updates": "3280", "train_lr": "5.125e-05", "train_gnorm": "1.718", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1679"}
[2022-01-03 12:37:41,635][fairseq.trainer][INFO] - begin training epoch 83
[2022-01-03 12:37:41,636][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:37:55,513][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:37:55,996][valid][INFO] - {"epoch": 83, "valid_loss": "4.614", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "30.889", "valid_code_perplexity": "30.894", "valid_temp": "1.967", "valid_loss_0": "4.437", "valid_loss_1": "0.137", "valid_loss_2": "0.04", "valid_accuracy": "0.24406", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "3320", "valid_best_loss": "4.211"}
[2022-01-03 12:37:55,998][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 83 @ 3320 updates
[2022-01-03 12:37:55,998][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:37:59,752][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:37:59,765][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 83 @ 3320 updates, score 4.614) (writing took 3.7675212835893035 seconds)
[2022-01-03 12:37:59,766][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2022-01-03 12:37:59,778][train][INFO] - {"epoch": 83, "train_loss": "4.528", "train_ntokens": "1790.67", "train_nsentences": "4.95", "train_prob_perplexity": "31.496", "train_code_perplexity": "31.463", "train_temp": "1.967", "train_loss_0": "4.354", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.26725", "train_wps": "3936.9", "train_ups": "2.2", "train_wpb": "1790.7", "train_bsz": "5", "train_num_updates": "3320", "train_lr": "5.1875e-05", "train_gnorm": "1.841", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1697"}
[2022-01-03 12:37:59,848][fairseq.trainer][INFO] - begin training epoch 84
[2022-01-03 12:37:59,849][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:38:13,622][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:38:14,034][valid][INFO] - {"epoch": 84, "valid_loss": "4.589", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "29.839", "valid_code_perplexity": "29.779", "valid_temp": "1.967", "valid_loss_0": "4.417", "valid_loss_1": "0.138", "valid_loss_2": "0.034", "valid_accuracy": "0.26667", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "3360", "valid_best_loss": "4.211"}
[2022-01-03 12:38:14,036][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 84 @ 3360 updates
[2022-01-03 12:38:14,036][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:38:17,982][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:38:18,009][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 84 @ 3360 updates, score 4.589) (writing took 3.9728363752365112 seconds)
[2022-01-03 12:38:18,009][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2022-01-03 12:38:18,022][train][INFO] - {"epoch": 84, "train_loss": "4.544", "train_ntokens": "1794.53", "train_nsentences": "4.95", "train_prob_perplexity": "31.646", "train_code_perplexity": "31.605", "train_temp": "1.967", "train_loss_0": "4.37", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.26651", "train_wps": "3937.2", "train_ups": "2.19", "train_wpb": "1794.5", "train_bsz": "5", "train_num_updates": "3360", "train_lr": "5.25e-05", "train_gnorm": "1.86", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "1715"}
[2022-01-03 12:38:18,076][fairseq.trainer][INFO] - begin training epoch 85
[2022-01-03 12:38:18,077][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:38:31,907][train_inner][INFO] - {"epoch": 85, "update": 85.0, "loss": "4.534", "ntokens": "1786.81", "nsentences": "4.95", "prob_perplexity": "31.625", "code_perplexity": "31.591", "temp": "1.967", "loss_0": "4.36", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.26487", "wps": "3656.5", "ups": "2.05", "wpb": "1786.8", "bsz": "5", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.808", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "1729"}
[2022-01-03 12:38:31,908][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:38:32,325][valid][INFO] - {"epoch": 85, "valid_loss": "4.42", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "28.414", "valid_code_perplexity": "28.327", "valid_temp": "1.966", "valid_loss_0": "4.247", "valid_loss_1": "0.138", "valid_loss_2": "0.035", "valid_accuracy": "0.28189", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "3400", "valid_best_loss": "4.211"}
[2022-01-03 12:38:32,329][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 85 @ 3400 updates
[2022-01-03 12:38:32,330][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:38:36,306][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:38:36,334][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 85 @ 3400 updates, score 4.42) (writing took 4.004520952701569 seconds)
[2022-01-03 12:38:36,334][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2022-01-03 12:38:36,348][train][INFO] - {"epoch": 85, "train_loss": "4.504", "train_ntokens": "1787.4", "train_nsentences": "4.95", "train_prob_perplexity": "31.804", "train_code_perplexity": "31.764", "train_temp": "1.966", "train_loss_0": "4.331", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.26667", "train_wps": "3904.2", "train_ups": "2.18", "train_wpb": "1787.4", "train_bsz": "5", "train_num_updates": "3400", "train_lr": "5.3125e-05", "train_gnorm": "1.751", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1734"}
[2022-01-03 12:38:36,402][fairseq.trainer][INFO] - begin training epoch 86
[2022-01-03 12:38:36,403][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:38:50,215][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:38:50,618][valid][INFO] - {"epoch": 86, "valid_loss": "4.071", "valid_ntokens": "706", "valid_nsentences": "2", "valid_prob_perplexity": "29.828", "valid_code_perplexity": "29.871", "valid_temp": "1.966", "valid_loss_0": "3.898", "valid_loss_1": "0.138", "valid_loss_2": "0.036", "valid_accuracy": "0.33003", "valid_wps": "0", "valid_wpb": "706", "valid_bsz": "2", "valid_num_updates": "3440", "valid_best_loss": "4.071"}
[2022-01-03 12:38:50,621][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 86 @ 3440 updates
[2022-01-03 12:38:50,622][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:38:54,564][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:39:01,806][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 86 @ 3440 updates, score 4.071) (writing took 11.184245105832815 seconds)
[2022-01-03 12:39:01,806][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2022-01-03 12:39:01,819][train][INFO] - {"epoch": 86, "train_loss": "4.507", "train_ntokens": "1790.05", "train_nsentences": "4.95", "train_prob_perplexity": "31.766", "train_code_perplexity": "31.74", "train_temp": "1.966", "train_loss_0": "4.333", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.26555", "train_wps": "2812.5", "train_ups": "1.57", "train_wpb": "1790", "train_bsz": "5", "train_num_updates": "3440", "train_lr": "5.375e-05", "train_gnorm": "1.725", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "1759"}
[2022-01-03 12:39:01,906][fairseq.trainer][INFO] - begin training epoch 87
[2022-01-03 12:39:01,907][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:39:15,687][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:39:16,082][valid][INFO] - {"epoch": 87, "valid_loss": "4.456", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "30.489", "valid_code_perplexity": "30.539", "valid_temp": "1.966", "valid_loss_0": "4.279", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.27273", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "3480", "valid_best_loss": "4.071"}
[2022-01-03 12:39:16,085][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 87 @ 3480 updates
[2022-01-03 12:39:16,086][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:39:20,023][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:39:20,044][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 87 @ 3480 updates, score 4.456) (writing took 3.9593098759651184 seconds)
[2022-01-03 12:39:20,045][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2022-01-03 12:39:20,057][train][INFO] - {"epoch": 87, "train_loss": "4.535", "train_ntokens": "1800.35", "train_nsentences": "4.95", "train_prob_perplexity": "31.5", "train_code_perplexity": "31.462", "train_temp": "1.966", "train_loss_0": "4.36", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.26531", "train_wps": "3951.2", "train_ups": "2.19", "train_wpb": "1800.3", "train_bsz": "5", "train_num_updates": "3480", "train_lr": "5.4375e-05", "train_gnorm": "1.787", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "1777"}
[2022-01-03 12:39:20,116][fairseq.trainer][INFO] - begin training epoch 88
[2022-01-03 12:39:20,116][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:39:33,960][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:39:34,372][valid][INFO] - {"epoch": 88, "valid_loss": "4.68", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "29.853", "valid_code_perplexity": "29.817", "valid_temp": "1.965", "valid_loss_0": "4.506", "valid_loss_1": "0.138", "valid_loss_2": "0.037", "valid_accuracy": "0.25", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "3520", "valid_best_loss": "4.071"}
[2022-01-03 12:39:34,375][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 88 @ 3520 updates
[2022-01-03 12:39:34,376][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:39:38,223][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:39:38,247][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 88 @ 3520 updates, score 4.68) (writing took 3.8721319707110524 seconds)
[2022-01-03 12:39:38,248][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2022-01-03 12:39:38,260][train][INFO] - {"epoch": 88, "train_loss": "4.517", "train_ntokens": "1795.28", "train_nsentences": "4.95", "train_prob_perplexity": "31.607", "train_code_perplexity": "31.566", "train_temp": "1.965", "train_loss_0": "4.342", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.26443", "train_wps": "3947.7", "train_ups": "2.2", "train_wpb": "1795.3", "train_bsz": "5", "train_num_updates": "3520", "train_lr": "5.5e-05", "train_gnorm": "1.789", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1796"}
[2022-01-03 12:39:38,306][fairseq.trainer][INFO] - begin training epoch 89
[2022-01-03 12:39:38,307][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:39:52,245][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:39:52,675][valid][INFO] - {"epoch": 89, "valid_loss": "4.49", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "29.769", "valid_code_perplexity": "29.722", "valid_temp": "1.965", "valid_loss_0": "4.316", "valid_loss_1": "0.138", "valid_loss_2": "0.036", "valid_accuracy": "0.25798", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "3560", "valid_best_loss": "4.071"}
[2022-01-03 12:39:52,678][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 89 @ 3560 updates
[2022-01-03 12:39:52,679][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:39:56,470][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:39:56,498][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 89 @ 3560 updates, score 4.49) (writing took 3.819755625911057 seconds)
[2022-01-03 12:39:56,498][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2022-01-03 12:39:56,511][train][INFO] - {"epoch": 89, "train_loss": "4.54", "train_ntokens": "1789.12", "train_nsentences": "4.95", "train_prob_perplexity": "31.843", "train_code_perplexity": "31.803", "train_temp": "1.965", "train_loss_0": "4.367", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.26359", "train_wps": "3923.8", "train_ups": "2.19", "train_wpb": "1789.1", "train_bsz": "5", "train_num_updates": "3560", "train_lr": "5.5625e-05", "train_gnorm": "1.987", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1814"}
[2022-01-03 12:39:56,588][fairseq.trainer][INFO] - begin training epoch 90
[2022-01-03 12:39:56,588][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:40:10,478][train_inner][INFO] - {"epoch": 90, "update": 90.0, "loss": "4.514", "ntokens": "1795.53", "nsentences": "4.95", "prob_perplexity": "31.642", "code_perplexity": "31.608", "temp": "1.965", "loss_0": "4.34", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.26512", "wps": "3643.6", "ups": "2.03", "wpb": "1795.5", "bsz": "5", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.825", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "1828"}
[2022-01-03 12:40:10,479][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:40:10,890][valid][INFO] - {"epoch": 90, "valid_loss": "4.596", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "30.569", "valid_code_perplexity": "30.545", "valid_temp": "1.964", "valid_loss_0": "4.423", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.25198", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "3600", "valid_best_loss": "4.071"}
[2022-01-03 12:40:10,893][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 3600 updates
[2022-01-03 12:40:10,894][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:40:14,851][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:40:14,876][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 90 @ 3600 updates, score 4.596) (writing took 3.983103227801621 seconds)
[2022-01-03 12:40:14,877][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2022-01-03 12:40:14,889][train][INFO] - {"epoch": 90, "train_loss": "4.474", "train_ntokens": "1802.85", "train_nsentences": "4.95", "train_prob_perplexity": "31.496", "train_code_perplexity": "31.471", "train_temp": "1.965", "train_loss_0": "4.3", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.26669", "train_wps": "3926.6", "train_ups": "2.18", "train_wpb": "1802.8", "train_bsz": "5", "train_num_updates": "3600", "train_lr": "5.625e-05", "train_gnorm": "1.836", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1832"}
[2022-01-03 12:40:14,955][fairseq.trainer][INFO] - begin training epoch 91
[2022-01-03 12:40:14,956][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:40:28,959][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:40:29,361][valid][INFO] - {"epoch": 91, "valid_loss": "4.366", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "31.927", "valid_code_perplexity": "31.817", "valid_temp": "1.964", "valid_loss_0": "4.192", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.29922", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "3640", "valid_best_loss": "4.071"}
[2022-01-03 12:40:29,363][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 91 @ 3640 updates
[2022-01-03 12:40:29,363][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:40:32,976][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:40:33,003][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 91 @ 3640 updates, score 4.366) (writing took 3.6406407672911882 seconds)
[2022-01-03 12:40:33,004][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2022-01-03 12:40:33,017][train][INFO] - {"epoch": 91, "train_loss": "4.467", "train_ntokens": "1782.5", "train_nsentences": "4.95", "train_prob_perplexity": "32.109", "train_code_perplexity": "32.076", "train_temp": "1.964", "train_loss_0": "4.294", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.26741", "train_wps": "3936.1", "train_ups": "2.21", "train_wpb": "1782.5", "train_bsz": "5", "train_num_updates": "3640", "train_lr": "5.6875e-05", "train_gnorm": "1.792", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "1850"}
[2022-01-03 12:40:33,096][fairseq.trainer][INFO] - begin training epoch 92
[2022-01-03 12:40:33,096][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:40:47,110][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:40:47,511][valid][INFO] - {"epoch": 92, "valid_loss": "4.653", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "30.281", "valid_code_perplexity": "30.196", "valid_temp": "1.964", "valid_loss_0": "4.477", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.24935", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "3680", "valid_best_loss": "4.071"}
[2022-01-03 12:40:47,514][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 92 @ 3680 updates
[2022-01-03 12:40:47,515][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:40:51,195][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:40:51,222][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 92 @ 3680 updates, score 4.653) (writing took 3.708044147118926 seconds)
[2022-01-03 12:40:51,223][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2022-01-03 12:40:51,235][train][INFO] - {"epoch": 92, "train_loss": "4.474", "train_ntokens": "1797.58", "train_nsentences": "4.95", "train_prob_perplexity": "32.004", "train_code_perplexity": "31.98", "train_temp": "1.964", "train_loss_0": "4.301", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.2721", "train_wps": "3949.6", "train_ups": "2.2", "train_wpb": "1797.6", "train_bsz": "5", "train_num_updates": "3680", "train_lr": "5.75e-05", "train_gnorm": "1.762", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "1869"}
[2022-01-03 12:40:51,312][fairseq.trainer][INFO] - begin training epoch 93
[2022-01-03 12:40:51,313][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:41:05,160][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:41:05,562][valid][INFO] - {"epoch": 93, "valid_loss": "4.622", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "30.372", "valid_code_perplexity": "30.4", "valid_temp": "1.963", "valid_loss_0": "4.447", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.25139", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "3720", "valid_best_loss": "4.071"}
[2022-01-03 12:41:05,564][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 93 @ 3720 updates
[2022-01-03 12:41:05,565][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:41:09,488][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:41:09,514][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 93 @ 3720 updates, score 4.622) (writing took 3.9494241680949926 seconds)
[2022-01-03 12:41:09,514][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2022-01-03 12:41:09,527][train][INFO] - {"epoch": 93, "train_loss": "4.495", "train_ntokens": "1784.15", "train_nsentences": "4.95", "train_prob_perplexity": "32.113", "train_code_perplexity": "32.088", "train_temp": "1.963", "train_loss_0": "4.321", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.26668", "train_wps": "3904.2", "train_ups": "2.19", "train_wpb": "1784.2", "train_bsz": "5", "train_num_updates": "3720", "train_lr": "5.8125e-05", "train_gnorm": "1.778", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1887"}
[2022-01-03 12:41:09,600][fairseq.trainer][INFO] - begin training epoch 94
[2022-01-03 12:41:09,601][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:41:23,449][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:41:23,848][valid][INFO] - {"epoch": 94, "valid_loss": "4.736", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "29.52", "valid_code_perplexity": "29.513", "valid_temp": "1.963", "valid_loss_0": "4.56", "valid_loss_1": "0.138", "valid_loss_2": "0.039", "valid_accuracy": "0.25066", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "3760", "valid_best_loss": "4.071"}
[2022-01-03 12:41:23,851][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 94 @ 3760 updates
[2022-01-03 12:41:23,852][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:41:27,678][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:41:27,706][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 94 @ 3760 updates, score 4.736) (writing took 3.854531979188323 seconds)
[2022-01-03 12:41:27,707][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2022-01-03 12:41:27,721][train][INFO] - {"epoch": 94, "train_loss": "4.493", "train_ntokens": "1787.9", "train_nsentences": "4.95", "train_prob_perplexity": "31.877", "train_code_perplexity": "31.85", "train_temp": "1.963", "train_loss_0": "4.318", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.267", "train_wps": "3933.8", "train_ups": "2.2", "train_wpb": "1787.9", "train_bsz": "5", "train_num_updates": "3760", "train_lr": "5.875e-05", "train_gnorm": "1.726", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1905"}
[2022-01-03 12:41:27,804][fairseq.trainer][INFO] - begin training epoch 95
[2022-01-03 12:41:27,805][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:41:41,724][train_inner][INFO] - {"epoch": 95, "update": 95.0, "loss": "4.48", "ntokens": "1790.68", "nsentences": "4.95", "prob_perplexity": "32.015", "code_perplexity": "31.987", "temp": "1.963", "loss_0": "4.306", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.26861", "wps": "3925.5", "ups": "2.19", "wpb": "1790.7", "bsz": "5", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.765", "clip": "0", "train_wall": "67", "gb_free": "7.2", "wall": "1919"}
[2022-01-03 12:41:41,725][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:41:42,211][valid][INFO] - {"epoch": 95, "valid_loss": "4.482", "valid_ntokens": "800", "valid_nsentences": "2", "valid_prob_perplexity": "30.535", "valid_code_perplexity": "30.566", "valid_temp": "1.962", "valid_loss_0": "4.313", "valid_loss_1": "0.137", "valid_loss_2": "0.031", "valid_accuracy": "0.265", "valid_wps": "0", "valid_wpb": "800", "valid_bsz": "2", "valid_num_updates": "3800", "valid_best_loss": "4.071"}
[2022-01-03 12:41:42,213][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 95 @ 3800 updates
[2022-01-03 12:41:42,214][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:41:45,901][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:41:45,929][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 95 @ 3800 updates, score 4.482) (writing took 3.7158900229260325 seconds)
[2022-01-03 12:41:45,930][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2022-01-03 12:41:45,942][train][INFO] - {"epoch": 95, "train_loss": "4.471", "train_ntokens": "1801.28", "train_nsentences": "4.95", "train_prob_perplexity": "31.974", "train_code_perplexity": "31.942", "train_temp": "1.963", "train_loss_0": "4.297", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.26981", "train_wps": "3956.9", "train_ups": "2.2", "train_wpb": "1801.3", "train_bsz": "5", "train_num_updates": "3800", "train_lr": "5.9375e-05", "train_gnorm": "1.767", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "1923"}
[2022-01-03 12:41:45,994][fairseq.trainer][INFO] - begin training epoch 96
[2022-01-03 12:41:45,995][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:41:59,967][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:42:00,481][valid][INFO] - {"epoch": 96, "valid_loss": "4.463", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "31.086", "valid_code_perplexity": "31.096", "valid_temp": "1.962", "valid_loss_0": "4.293", "valid_loss_1": "0.137", "valid_loss_2": "0.033", "valid_accuracy": "0.26357", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "3840", "valid_best_loss": "4.071"}
[2022-01-03 12:42:00,483][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 96 @ 3840 updates
[2022-01-03 12:42:00,484][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:42:04,154][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:42:04,182][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 96 @ 3840 updates, score 4.463) (writing took 3.6992020504549146 seconds)
[2022-01-03 12:42:04,183][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2022-01-03 12:42:04,196][train][INFO] - {"epoch": 96, "train_loss": "4.455", "train_ntokens": "1799.65", "train_nsentences": "4.95", "train_prob_perplexity": "31.603", "train_code_perplexity": "31.575", "train_temp": "1.962", "train_loss_0": "4.282", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.27241", "train_wps": "3946.4", "train_ups": "2.19", "train_wpb": "1799.7", "train_bsz": "5", "train_num_updates": "3840", "train_lr": "6e-05", "train_gnorm": "1.806", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "1942"}
[2022-01-03 12:42:04,277][fairseq.trainer][INFO] - begin training epoch 97
[2022-01-03 12:42:04,278][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:42:18,133][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:42:18,633][valid][INFO] - {"epoch": 97, "valid_loss": "4.31", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "29.738", "valid_code_perplexity": "29.71", "valid_temp": "1.962", "valid_loss_0": "4.138", "valid_loss_1": "0.138", "valid_loss_2": "0.035", "valid_accuracy": "0.28099", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "3880", "valid_best_loss": "4.071"}
[2022-01-03 12:42:18,635][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 97 @ 3880 updates
[2022-01-03 12:42:18,636][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:42:22,397][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:42:22,424][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 97 @ 3880 updates, score 4.31) (writing took 3.789064174517989 seconds)
[2022-01-03 12:42:22,425][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2022-01-03 12:42:22,437][train][INFO] - {"epoch": 97, "train_loss": "4.419", "train_ntokens": "1766.55", "train_nsentences": "4.95", "train_prob_perplexity": "31.95", "train_code_perplexity": "31.925", "train_temp": "1.962", "train_loss_0": "4.244", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.27414", "train_wps": "3876.3", "train_ups": "2.19", "train_wpb": "1766.5", "train_bsz": "5", "train_num_updates": "3880", "train_lr": "6.0625e-05", "train_gnorm": "1.764", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "1960"}
[2022-01-03 12:42:22,513][fairseq.trainer][INFO] - begin training epoch 98
[2022-01-03 12:42:22,513][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:42:36,508][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:42:36,993][valid][INFO] - {"epoch": 98, "valid_loss": "4.702", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "29.014", "valid_code_perplexity": "28.918", "valid_temp": "1.961", "valid_loss_0": "4.526", "valid_loss_1": "0.138", "valid_loss_2": "0.038", "valid_accuracy": "0.24543", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "3920", "valid_best_loss": "4.071"}
[2022-01-03 12:42:36,995][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 98 @ 3920 updates
[2022-01-03 12:42:36,995][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:42:40,647][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:42:40,676][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 98 @ 3920 updates, score 4.702) (writing took 3.6814005998894572 seconds)
[2022-01-03 12:42:40,677][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2022-01-03 12:42:40,690][train][INFO] - {"epoch": 98, "train_loss": "4.442", "train_ntokens": "1805.47", "train_nsentences": "4.95", "train_prob_perplexity": "31.816", "train_code_perplexity": "31.784", "train_temp": "1.961", "train_loss_0": "4.269", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.27479", "train_wps": "3959.5", "train_ups": "2.19", "train_wpb": "1805.5", "train_bsz": "5", "train_num_updates": "3920", "train_lr": "6.125e-05", "train_gnorm": "1.77", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "1978"}
[2022-01-03 12:42:40,760][fairseq.trainer][INFO] - begin training epoch 99
[2022-01-03 12:42:40,760][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:42:54,649][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:42:55,046][valid][INFO] - {"epoch": 99, "valid_loss": "4.447", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "31.937", "valid_code_perplexity": "31.92", "valid_temp": "1.961", "valid_loss_0": "4.272", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.26777", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "3960", "valid_best_loss": "4.071"}
[2022-01-03 12:42:55,049][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 99 @ 3960 updates
[2022-01-03 12:42:55,050][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:42:58,972][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:42:58,999][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 99 @ 3960 updates, score 4.447) (writing took 3.9501308696344495 seconds)
[2022-01-03 12:42:59,000][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2022-01-03 12:42:59,013][train][INFO] - {"epoch": 99, "train_loss": "4.433", "train_ntokens": "1790.15", "train_nsentences": "4.95", "train_prob_perplexity": "31.987", "train_code_perplexity": "31.958", "train_temp": "1.961", "train_loss_0": "4.258", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.27591", "train_wps": "3910.8", "train_ups": "2.18", "train_wpb": "1790.2", "train_bsz": "5", "train_num_updates": "3960", "train_lr": "6.1875e-05", "train_gnorm": "1.782", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "1996"}
[2022-01-03 12:42:59,089][fairseq.trainer][INFO] - begin training epoch 100
[2022-01-03 12:42:59,090][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:43:12,930][train_inner][INFO] - {"epoch": 100, "update": 100.0, "loss": "4.435", "ntokens": "1789.24", "nsentences": "4.95", "prob_perplexity": "31.993", "code_perplexity": "31.964", "temp": "1.961", "loss_0": "4.261", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.27418", "wps": "3924", "ups": "2.19", "wpb": "1789.2", "bsz": "5", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.778", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "2010"}
[2022-01-03 12:43:12,932][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:43:13,408][valid][INFO] - {"epoch": 100, "valid_loss": "4.562", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "31.296", "valid_code_perplexity": "31.307", "valid_temp": "1.96", "valid_loss_0": "4.387", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.23333", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "4000", "valid_best_loss": "4.071"}
[2022-01-03 12:43:13,409][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 4000 updates
[2022-01-03 12:43:13,410][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:43:17,180][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:43:17,209][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 100 @ 4000 updates, score 4.562) (writing took 3.7992248199880123 seconds)
[2022-01-03 12:43:17,209][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2022-01-03 12:43:17,222][train][INFO] - {"epoch": 100, "train_loss": "4.428", "train_ntokens": "1784.38", "train_nsentences": "4.95", "train_prob_perplexity": "32.61", "train_code_perplexity": "32.576", "train_temp": "1.961", "train_loss_0": "4.253", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.27367", "train_wps": "3922.5", "train_ups": "2.2", "train_wpb": "1784.4", "train_bsz": "5", "train_num_updates": "4000", "train_lr": "6.25e-05", "train_gnorm": "1.77", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2015"}
[2022-01-03 12:43:17,280][fairseq.trainer][INFO] - begin training epoch 101
[2022-01-03 12:43:17,280][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:43:31,180][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:43:31,573][valid][INFO] - {"epoch": 101, "valid_loss": "4.705", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "31.842", "valid_code_perplexity": "31.772", "valid_temp": "1.96", "valid_loss_0": "4.531", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.25", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "4040", "valid_best_loss": "4.071"}
[2022-01-03 12:43:31,575][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 101 @ 4040 updates
[2022-01-03 12:43:31,576][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:43:35,506][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:43:35,533][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 101 @ 4040 updates, score 4.705) (writing took 3.957991416566074 seconds)
[2022-01-03 12:43:35,534][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2022-01-03 12:43:35,546][train][INFO] - {"epoch": 101, "train_loss": "4.442", "train_ntokens": "1787.17", "train_nsentences": "4.95", "train_prob_perplexity": "31.994", "train_code_perplexity": "31.953", "train_temp": "1.96", "train_loss_0": "4.269", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.27595", "train_wps": "3903.8", "train_ups": "2.18", "train_wpb": "1787.2", "train_bsz": "5", "train_num_updates": "4040", "train_lr": "6.3125e-05", "train_gnorm": "1.796", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2033"}
[2022-01-03 12:43:35,597][fairseq.trainer][INFO] - begin training epoch 102
[2022-01-03 12:43:35,598][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:43:49,602][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:43:50,043][valid][INFO] - {"epoch": 102, "valid_loss": "4.403", "valid_ntokens": "684", "valid_nsentences": "2", "valid_prob_perplexity": "29.507", "valid_code_perplexity": "29.524", "valid_temp": "1.96", "valid_loss_0": "4.227", "valid_loss_1": "0.138", "valid_loss_2": "0.038", "valid_accuracy": "0.26901", "valid_wps": "0", "valid_wpb": "684", "valid_bsz": "2", "valid_num_updates": "4080", "valid_best_loss": "4.071"}
[2022-01-03 12:43:50,046][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 102 @ 4080 updates
[2022-01-03 12:43:50,046][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:43:53,681][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:43:53,707][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 102 @ 4080 updates, score 4.403) (writing took 3.66172381862998 seconds)
[2022-01-03 12:43:53,708][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2022-01-03 12:43:53,720][train][INFO] - {"epoch": 102, "train_loss": "4.455", "train_ntokens": "1789.53", "train_nsentences": "4.95", "train_prob_perplexity": "31.988", "train_code_perplexity": "31.963", "train_temp": "1.96", "train_loss_0": "4.28", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.27006", "train_wps": "3941.3", "train_ups": "2.2", "train_wpb": "1789.5", "train_bsz": "5", "train_num_updates": "4080", "train_lr": "6.375e-05", "train_gnorm": "1.77", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2051"}
[2022-01-03 12:43:53,777][fairseq.trainer][INFO] - begin training epoch 103
[2022-01-03 12:43:53,777][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:44:07,514][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:44:07,908][valid][INFO] - {"epoch": 103, "valid_loss": "4.327", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "31.877", "valid_code_perplexity": "31.853", "valid_temp": "1.959", "valid_loss_0": "4.157", "valid_loss_1": "0.137", "valid_loss_2": "0.032", "valid_accuracy": "0.28249", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "4120", "valid_best_loss": "4.071"}
[2022-01-03 12:44:07,911][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 103 @ 4120 updates
[2022-01-03 12:44:07,912][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:44:11,833][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:44:11,860][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 103 @ 4120 updates, score 4.327) (writing took 3.9493097458034754 seconds)
[2022-01-03 12:44:11,861][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2022-01-03 12:44:11,874][train][INFO] - {"epoch": 103, "train_loss": "4.47", "train_ntokens": "1794.8", "train_nsentences": "4.95", "train_prob_perplexity": "32.618", "train_code_perplexity": "32.583", "train_temp": "1.959", "train_loss_0": "4.297", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.26853", "train_wps": "3957.6", "train_ups": "2.21", "train_wpb": "1794.8", "train_bsz": "5", "train_num_updates": "4120", "train_lr": "6.4375e-05", "train_gnorm": "1.715", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "2069"}
[2022-01-03 12:44:11,957][fairseq.trainer][INFO] - begin training epoch 104
[2022-01-03 12:44:11,957][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:44:25,911][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:44:26,398][valid][INFO] - {"epoch": 104, "valid_loss": "4.439", "valid_ntokens": "798", "valid_nsentences": "2", "valid_prob_perplexity": "29.904", "valid_code_perplexity": "29.995", "valid_temp": "1.959", "valid_loss_0": "4.268", "valid_loss_1": "0.138", "valid_loss_2": "0.033", "valid_accuracy": "0.28822", "valid_wps": "0", "valid_wpb": "798", "valid_bsz": "2", "valid_num_updates": "4160", "valid_best_loss": "4.071"}
[2022-01-03 12:44:26,400][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 104 @ 4160 updates
[2022-01-03 12:44:26,400][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:44:30,035][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:44:30,066][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 104 @ 4160 updates, score 4.439) (writing took 3.6666649291291833 seconds)
[2022-01-03 12:44:30,067][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2022-01-03 12:44:30,080][train][INFO] - {"epoch": 104, "train_loss": "4.422", "train_ntokens": "1792.85", "train_nsentences": "4.95", "train_prob_perplexity": "33.063", "train_code_perplexity": "33.034", "train_temp": "1.959", "train_loss_0": "4.25", "train_loss_1": "0.137", "train_loss_2": "0.035", "train_accuracy": "0.27279", "train_wps": "3941.9", "train_ups": "2.2", "train_wpb": "1792.8", "train_bsz": "5", "train_num_updates": "4160", "train_lr": "6.5e-05", "train_gnorm": "1.792", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "2087"}
[2022-01-03 12:44:30,127][fairseq.trainer][INFO] - begin training epoch 105
[2022-01-03 12:44:30,128][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:44:44,000][train_inner][INFO] - {"epoch": 105, "update": 105.0, "loss": "4.448", "ntokens": "1791.55", "nsentences": "4.95", "prob_perplexity": "32.512", "code_perplexity": "32.482", "temp": "1.959", "loss_0": "4.275", "loss_1": "0.137", "loss_2": "0.036", "accuracy": "0.27125", "wps": "3935", "ups": "2.2", "wpb": "1791.5", "bsz": "5", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.766", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "2101"}
[2022-01-03 12:44:44,001][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:44:44,430][valid][INFO] - {"epoch": 105, "valid_loss": "4.689", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "31.91", "valid_code_perplexity": "31.901", "valid_temp": "1.958", "valid_loss_0": "4.52", "valid_loss_1": "0.137", "valid_loss_2": "0.032", "valid_accuracy": "0.25532", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "4200", "valid_best_loss": "4.071"}
[2022-01-03 12:44:44,433][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 105 @ 4200 updates
[2022-01-03 12:44:44,434][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:44:48,261][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:44:48,290][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 105 @ 4200 updates, score 4.689) (writing took 3.8567302618175745 seconds)
[2022-01-03 12:44:48,290][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2022-01-03 12:44:48,303][train][INFO] - {"epoch": 105, "train_loss": "4.452", "train_ntokens": "1793.4", "train_nsentences": "4.95", "train_prob_perplexity": "32.896", "train_code_perplexity": "32.875", "train_temp": "1.959", "train_loss_0": "4.279", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.26896", "train_wps": "3939.3", "train_ups": "2.2", "train_wpb": "1793.4", "train_bsz": "5", "train_num_updates": "4200", "train_lr": "6.5625e-05", "train_gnorm": "1.757", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2106"}
[2022-01-03 12:44:48,385][fairseq.trainer][INFO] - begin training epoch 106
[2022-01-03 12:44:48,386][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:45:02,246][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:45:02,677][valid][INFO] - {"epoch": 106, "valid_loss": "4.504", "valid_ntokens": "646", "valid_nsentences": "2", "valid_prob_perplexity": "31.219", "valid_code_perplexity": "31.227", "valid_temp": "1.958", "valid_loss_0": "4.331", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.26006", "valid_wps": "0", "valid_wpb": "646", "valid_bsz": "2", "valid_num_updates": "4240", "valid_best_loss": "4.071"}
[2022-01-03 12:45:02,680][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 106 @ 4240 updates
[2022-01-03 12:45:02,681][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:45:06,493][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:45:06,522][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 106 @ 4240 updates, score 4.504) (writing took 3.8419778291136026 seconds)
[2022-01-03 12:45:06,522][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2022-01-03 12:45:06,535][train][INFO] - {"epoch": 106, "train_loss": "4.425", "train_ntokens": "1787.67", "train_nsentences": "4.95", "train_prob_perplexity": "32.154", "train_code_perplexity": "32.135", "train_temp": "1.958", "train_loss_0": "4.252", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.2761", "train_wps": "3924.8", "train_ups": "2.2", "train_wpb": "1787.7", "train_bsz": "5", "train_num_updates": "4240", "train_lr": "6.625e-05", "train_gnorm": "1.794", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2124"}
[2022-01-03 12:45:06,613][fairseq.trainer][INFO] - begin training epoch 107
[2022-01-03 12:45:06,614][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:45:20,553][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:45:20,949][valid][INFO] - {"epoch": 107, "valid_loss": "4.684", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "33.961", "valid_code_perplexity": "33.761", "valid_temp": "1.958", "valid_loss_0": "4.511", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.24541", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "4280", "valid_best_loss": "4.071"}
[2022-01-03 12:45:20,952][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 107 @ 4280 updates
[2022-01-03 12:45:20,952][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:45:24,734][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:45:24,767][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 107 @ 4280 updates, score 4.684) (writing took 3.8150995764881372 seconds)
[2022-01-03 12:45:24,767][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2022-01-03 12:45:24,780][train][INFO] - {"epoch": 107, "train_loss": "4.401", "train_ntokens": "1787.2", "train_nsentences": "4.95", "train_prob_perplexity": "32.723", "train_code_perplexity": "32.686", "train_temp": "1.958", "train_loss_0": "4.228", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.27486", "train_wps": "3920.9", "train_ups": "2.19", "train_wpb": "1787.2", "train_bsz": "5", "train_num_updates": "4280", "train_lr": "6.6875e-05", "train_gnorm": "1.773", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2142"}
[2022-01-03 12:45:24,863][fairseq.trainer][INFO] - begin training epoch 108
[2022-01-03 12:45:24,863][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:45:38,858][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:45:39,262][valid][INFO] - {"epoch": 108, "valid_loss": "4.446", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "28.493", "valid_code_perplexity": "28.511", "valid_temp": "1.957", "valid_loss_0": "4.274", "valid_loss_1": "0.138", "valid_loss_2": "0.034", "valid_accuracy": "0.26501", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "4320", "valid_best_loss": "4.071"}
[2022-01-03 12:45:39,264][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 108 @ 4320 updates
[2022-01-03 12:45:39,265][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:45:42,973][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:45:43,003][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 108 @ 4320 updates, score 4.446) (writing took 3.7385741071775556 seconds)
[2022-01-03 12:45:43,004][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2022-01-03 12:45:43,016][train][INFO] - {"epoch": 108, "train_loss": "4.427", "train_ntokens": "1792.97", "train_nsentences": "4.95", "train_prob_perplexity": "33.309", "train_code_perplexity": "33.289", "train_temp": "1.957", "train_loss_0": "4.252", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.26885", "train_wps": "3935.5", "train_ups": "2.19", "train_wpb": "1793", "train_bsz": "5", "train_num_updates": "4320", "train_lr": "6.75e-05", "train_gnorm": "1.702", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2160"}
[2022-01-03 12:45:43,097][fairseq.trainer][INFO] - begin training epoch 109
[2022-01-03 12:45:43,098][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:45:57,030][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:45:57,441][valid][INFO] - {"epoch": 109, "valid_loss": "4.549", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "30.072", "valid_code_perplexity": "30.078", "valid_temp": "1.957", "valid_loss_0": "4.374", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.2549", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "4360", "valid_best_loss": "4.071"}
[2022-01-03 12:45:57,444][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 109 @ 4360 updates
[2022-01-03 12:45:57,446][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:46:01,216][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:46:01,243][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 109 @ 4360 updates, score 4.549) (writing took 3.7988639175891876 seconds)
[2022-01-03 12:46:01,244][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2022-01-03 12:46:01,257][train][INFO] - {"epoch": 109, "train_loss": "4.386", "train_ntokens": "1788.88", "train_nsentences": "4.95", "train_prob_perplexity": "33.233", "train_code_perplexity": "33.202", "train_temp": "1.957", "train_loss_0": "4.213", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.27733", "train_wps": "3925.7", "train_ups": "2.19", "train_wpb": "1788.9", "train_bsz": "5", "train_num_updates": "4360", "train_lr": "6.8125e-05", "train_gnorm": "1.689", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "2179"}
[2022-01-03 12:46:01,334][fairseq.trainer][INFO] - begin training epoch 110
[2022-01-03 12:46:01,335][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:46:15,167][train_inner][INFO] - {"epoch": 110, "update": 110.0, "loss": "4.411", "ntokens": "1788.01", "nsentences": "4.95", "prob_perplexity": "32.805", "code_perplexity": "32.776", "temp": "1.957", "loss_0": "4.237", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.27485", "wps": "3923.1", "ups": "2.19", "wpb": "1788", "bsz": "5", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.748", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "2193"}
[2022-01-03 12:46:15,168][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:46:15,690][valid][INFO] - {"epoch": 110, "valid_loss": "4.442", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "30.518", "valid_code_perplexity": "30.474", "valid_temp": "1.956", "valid_loss_0": "4.268", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.27324", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "4400", "valid_best_loss": "4.071"}
[2022-01-03 12:46:15,692][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 110 @ 4400 updates
[2022-01-03 12:46:15,693][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:46:19,481][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:46:19,509][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 110 @ 4400 updates, score 4.442) (writing took 3.8167218854650855 seconds)
[2022-01-03 12:46:19,509][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2022-01-03 12:46:19,522][train][INFO] - {"epoch": 110, "train_loss": "4.415", "train_ntokens": "1783.3", "train_nsentences": "4.95", "train_prob_perplexity": "32.605", "train_code_perplexity": "32.57", "train_temp": "1.957", "train_loss_0": "4.241", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.27711", "train_wps": "3908.1", "train_ups": "2.19", "train_wpb": "1783.3", "train_bsz": "5", "train_num_updates": "4400", "train_lr": "6.875e-05", "train_gnorm": "1.783", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "2197"}
[2022-01-03 12:46:19,599][fairseq.trainer][INFO] - begin training epoch 111
[2022-01-03 12:46:19,599][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:46:33,416][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:46:33,863][valid][INFO] - {"epoch": 111, "valid_loss": "4.605", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "32.625", "valid_code_perplexity": "32.566", "valid_temp": "1.956", "valid_loss_0": "4.431", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.23196", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "4440", "valid_best_loss": "4.071"}
[2022-01-03 12:46:33,866][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 111 @ 4440 updates
[2022-01-03 12:46:33,867][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:46:37,743][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:46:37,771][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 111 @ 4440 updates, score 4.605) (writing took 3.905372701585293 seconds)
[2022-01-03 12:46:37,772][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2022-01-03 12:46:37,784][train][INFO] - {"epoch": 111, "train_loss": "4.391", "train_ntokens": "1795.38", "train_nsentences": "4.95", "train_prob_perplexity": "32.447", "train_code_perplexity": "32.423", "train_temp": "1.956", "train_loss_0": "4.218", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.27952", "train_wps": "3935.1", "train_ups": "2.19", "train_wpb": "1795.4", "train_bsz": "5", "train_num_updates": "4440", "train_lr": "6.9375e-05", "train_gnorm": "1.756", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "2215"}
[2022-01-03 12:46:37,841][fairseq.trainer][INFO] - begin training epoch 112
[2022-01-03 12:46:37,842][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:46:51,818][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:46:52,224][valid][INFO] - {"epoch": 112, "valid_loss": "4.181", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "31.38", "valid_code_perplexity": "31.371", "valid_temp": "1.956", "valid_loss_0": "4.008", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.26795", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "4480", "valid_best_loss": "4.071"}
[2022-01-03 12:46:52,227][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 112 @ 4480 updates
[2022-01-03 12:46:52,227][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:46:55,953][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:46:55,980][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 112 @ 4480 updates, score 4.181) (writing took 3.753587265498936 seconds)
[2022-01-03 12:46:55,981][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2022-01-03 12:46:55,995][train][INFO] - {"epoch": 112, "train_loss": "4.403", "train_ntokens": "1782.25", "train_nsentences": "4.95", "train_prob_perplexity": "32.711", "train_code_perplexity": "32.694", "train_temp": "1.956", "train_loss_0": "4.229", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.27747", "train_wps": "3917.8", "train_ups": "2.2", "train_wpb": "1782.2", "train_bsz": "5", "train_num_updates": "4480", "train_lr": "7e-05", "train_gnorm": "1.659", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "2233"}
[2022-01-03 12:46:56,076][fairseq.trainer][INFO] - begin training epoch 113
[2022-01-03 12:46:56,077][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:47:10,103][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:47:10,501][valid][INFO] - {"epoch": 113, "valid_loss": "4.392", "valid_ntokens": "802", "valid_nsentences": "2", "valid_prob_perplexity": "31.977", "valid_code_perplexity": "31.923", "valid_temp": "1.955", "valid_loss_0": "4.218", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.27681", "valid_wps": "0", "valid_wpb": "802", "valid_bsz": "2", "valid_num_updates": "4520", "valid_best_loss": "4.071"}
[2022-01-03 12:47:10,503][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 113 @ 4520 updates
[2022-01-03 12:47:10,504][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:47:14,217][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:47:14,247][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 113 @ 4520 updates, score 4.392) (writing took 3.743956223130226 seconds)
[2022-01-03 12:47:14,248][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2022-01-03 12:47:14,261][train][INFO] - {"epoch": 113, "train_loss": "4.38", "train_ntokens": "1784.8", "train_nsentences": "4.95", "train_prob_perplexity": "32.98", "train_code_perplexity": "32.966", "train_temp": "1.956", "train_loss_0": "4.208", "train_loss_1": "0.137", "train_loss_2": "0.035", "train_accuracy": "0.27815", "train_wps": "3911.4", "train_ups": "2.19", "train_wpb": "1784.8", "train_bsz": "5", "train_num_updates": "4520", "train_lr": "7.0625e-05", "train_gnorm": "1.734", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "2252"}
[2022-01-03 12:47:14,344][fairseq.trainer][INFO] - begin training epoch 114
[2022-01-03 12:47:14,344][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:47:28,473][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:47:28,881][valid][INFO] - {"epoch": 114, "valid_loss": "4.248", "valid_ntokens": "692", "valid_nsentences": "2", "valid_prob_perplexity": "32.248", "valid_code_perplexity": "32.252", "valid_temp": "1.955", "valid_loss_0": "4.073", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.3078", "valid_wps": "0", "valid_wpb": "692", "valid_bsz": "2", "valid_num_updates": "4560", "valid_best_loss": "4.071"}
[2022-01-03 12:47:28,885][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 114 @ 4560 updates
[2022-01-03 12:47:28,886][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:47:32,548][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:47:32,563][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 114 @ 4560 updates, score 4.248) (writing took 3.6784368958324194 seconds)
[2022-01-03 12:47:32,564][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2022-01-03 12:47:32,576][train][INFO] - {"epoch": 114, "train_loss": "4.391", "train_ntokens": "1789.28", "train_nsentences": "4.95", "train_prob_perplexity": "32.863", "train_code_perplexity": "32.854", "train_temp": "1.955", "train_loss_0": "4.217", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.27771", "train_wps": "3910.4", "train_ups": "2.19", "train_wpb": "1789.3", "train_bsz": "5", "train_num_updates": "4560", "train_lr": "7.125e-05", "train_gnorm": "1.666", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2270"}
[2022-01-03 12:47:32,657][fairseq.trainer][INFO] - begin training epoch 115
[2022-01-03 12:47:32,658][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:47:46,730][train_inner][INFO] - {"epoch": 115, "update": 115.0, "loss": "4.385", "ntokens": "1790.51", "nsentences": "4.95", "prob_perplexity": "32.926", "code_perplexity": "32.907", "temp": "1.956", "loss_0": "4.212", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.27863", "wps": "3911.5", "ups": "2.18", "wpb": "1790.5", "bsz": "5", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.695", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "2284"}
[2022-01-03 12:47:46,731][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:47:47,166][valid][INFO] - {"epoch": 115, "valid_loss": "4.226", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "28.908", "valid_code_perplexity": "28.96", "valid_temp": "1.955", "valid_loss_0": "4.052", "valid_loss_1": "0.138", "valid_loss_2": "0.036", "valid_accuracy": "0.29749", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "4600", "valid_best_loss": "4.071"}
[2022-01-03 12:47:47,169][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 115 @ 4600 updates
[2022-01-03 12:47:47,170][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:47:51,095][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:47:51,104][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 115 @ 4600 updates, score 4.226) (writing took 3.9353016493842006 seconds)
[2022-01-03 12:47:51,105][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2022-01-03 12:47:51,117][train][INFO] - {"epoch": 115, "train_loss": "4.361", "train_ntokens": "1800.85", "train_nsentences": "4.95", "train_prob_perplexity": "33.627", "train_code_perplexity": "33.599", "train_temp": "1.955", "train_loss_0": "4.187", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.28026", "train_wps": "3887.8", "train_ups": "2.16", "train_wpb": "1800.8", "train_bsz": "5", "train_num_updates": "4600", "train_lr": "7.1875e-05", "train_gnorm": "1.662", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2289"}
[2022-01-03 12:47:51,170][fairseq.trainer][INFO] - begin training epoch 116
[2022-01-03 12:47:51,171][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:48:05,195][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:48:05,633][valid][INFO] - {"epoch": 116, "valid_loss": "4.674", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "33.055", "valid_code_perplexity": "33.006", "valid_temp": "1.954", "valid_loss_0": "4.5", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.23181", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "4640", "valid_best_loss": "4.071"}
[2022-01-03 12:48:05,637][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 116 @ 4640 updates
[2022-01-03 12:48:05,638][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:48:09,334][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:48:09,362][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 116 @ 4640 updates, score 4.674) (writing took 3.72511497605592 seconds)
[2022-01-03 12:48:09,362][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2022-01-03 12:48:09,375][train][INFO] - {"epoch": 116, "train_loss": "4.4", "train_ntokens": "1796.55", "train_nsentences": "4.95", "train_prob_perplexity": "33.266", "train_code_perplexity": "33.244", "train_temp": "1.954", "train_loss_0": "4.228", "train_loss_1": "0.137", "train_loss_2": "0.035", "train_accuracy": "0.27499", "train_wps": "3938.7", "train_ups": "2.19", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "4640", "train_lr": "7.25e-05", "train_gnorm": "1.721", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2307"}
[2022-01-03 12:48:09,427][fairseq.trainer][INFO] - begin training epoch 117
[2022-01-03 12:48:09,428][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:48:23,449][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:48:23,943][valid][INFO] - {"epoch": 117, "valid_loss": "4.217", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "30.846", "valid_code_perplexity": "30.834", "valid_temp": "1.954", "valid_loss_0": "4.047", "valid_loss_1": "0.137", "valid_loss_2": "0.032", "valid_accuracy": "0.29867", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "4680", "valid_best_loss": "4.071"}
[2022-01-03 12:48:23,946][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 117 @ 4680 updates
[2022-01-03 12:48:23,947][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:48:27,584][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:48:27,612][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 117 @ 4680 updates, score 4.217) (writing took 3.6663543079048395 seconds)
[2022-01-03 12:48:27,613][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2022-01-03 12:48:27,625][train][INFO] - {"epoch": 117, "train_loss": "4.355", "train_ntokens": "1802.25", "train_nsentences": "4.95", "train_prob_perplexity": "33.434", "train_code_perplexity": "33.406", "train_temp": "1.954", "train_loss_0": "4.182", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.27836", "train_wps": "3952.8", "train_ups": "2.19", "train_wpb": "1802.2", "train_bsz": "5", "train_num_updates": "4680", "train_lr": "7.3125e-05", "train_gnorm": "1.705", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "2325"}
[2022-01-03 12:48:27,683][fairseq.trainer][INFO] - begin training epoch 118
[2022-01-03 12:48:27,683][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:48:41,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:48:42,111][valid][INFO] - {"epoch": 118, "valid_loss": "4.372", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "33.395", "valid_code_perplexity": "33.492", "valid_temp": "1.953", "valid_loss_0": "4.195", "valid_loss_1": "0.137", "valid_loss_2": "0.04", "valid_accuracy": "0.28927", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "4720", "valid_best_loss": "4.071"}
[2022-01-03 12:48:42,113][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 118 @ 4720 updates
[2022-01-03 12:48:42,114][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:48:45,795][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:48:45,825][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 118 @ 4720 updates, score 4.372) (writing took 3.7115194462239742 seconds)
[2022-01-03 12:48:45,825][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2022-01-03 12:48:45,838][train][INFO] - {"epoch": 118, "train_loss": "4.329", "train_ntokens": "1791.25", "train_nsentences": "4.95", "train_prob_perplexity": "33.253", "train_code_perplexity": "33.239", "train_temp": "1.954", "train_loss_0": "4.154", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.2812", "train_wps": "3936.9", "train_ups": "2.2", "train_wpb": "1791.2", "train_bsz": "5", "train_num_updates": "4720", "train_lr": "7.375e-05", "train_gnorm": "1.705", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "2343"}
[2022-01-03 12:48:45,897][fairseq.trainer][INFO] - begin training epoch 119
[2022-01-03 12:48:45,898][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:48:59,786][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:49:00,273][valid][INFO] - {"epoch": 119, "valid_loss": "4.544", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "32.202", "valid_code_perplexity": "32.208", "valid_temp": "1.953", "valid_loss_0": "4.37", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.23747", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "4760", "valid_best_loss": "4.071"}
[2022-01-03 12:49:00,275][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 119 @ 4760 updates
[2022-01-03 12:49:00,275][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:49:04,019][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:49:04,046][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 119 @ 4760 updates, score 4.544) (writing took 3.7710509030148387 seconds)
[2022-01-03 12:49:04,046][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2022-01-03 12:49:04,059][train][INFO] - {"epoch": 119, "train_loss": "4.347", "train_ntokens": "1779.17", "train_nsentences": "4.95", "train_prob_perplexity": "33.652", "train_code_perplexity": "33.626", "train_temp": "1.953", "train_loss_0": "4.173", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.27999", "train_wps": "3908.4", "train_ups": "2.2", "train_wpb": "1779.2", "train_bsz": "5", "train_num_updates": "4760", "train_lr": "7.4375e-05", "train_gnorm": "1.708", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.8", "train_wall": "2361"}
[2022-01-03 12:49:04,106][fairseq.trainer][INFO] - begin training epoch 120
[2022-01-03 12:49:04,107][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:49:18,132][train_inner][INFO] - {"epoch": 120, "update": 120.0, "loss": "4.358", "ntokens": "1795.36", "nsentences": "4.95", "prob_perplexity": "33.266", "code_perplexity": "33.246", "temp": "1.954", "loss_0": "4.184", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.27984", "wps": "3929", "ups": "2.19", "wpb": "1795.4", "bsz": "5", "num_updates": "4800", "lr": "7.5e-05", "gnorm": "1.71", "clip": "0", "train_wall": "68", "gb_free": "6.6", "wall": "2376"}
[2022-01-03 12:49:18,133][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:49:18,614][valid][INFO] - {"epoch": 120, "valid_loss": "4.297", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "31.347", "valid_code_perplexity": "31.316", "valid_temp": "1.953", "valid_loss_0": "4.123", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.30997", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "4800", "valid_best_loss": "4.071"}
[2022-01-03 12:49:18,616][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 4800 updates
[2022-01-03 12:49:18,617][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:49:22,279][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:49:22,309][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 120 @ 4800 updates, score 4.297) (writing took 3.6927432296797633 seconds)
[2022-01-03 12:49:22,310][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2022-01-03 12:49:22,322][train][INFO] - {"epoch": 120, "train_loss": "4.357", "train_ntokens": "1807.58", "train_nsentences": "4.95", "train_prob_perplexity": "32.727", "train_code_perplexity": "32.714", "train_temp": "1.953", "train_loss_0": "4.184", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.28462", "train_wps": "3961.6", "train_ups": "2.19", "train_wpb": "1807.6", "train_bsz": "5", "train_num_updates": "4800", "train_lr": "7.5e-05", "train_gnorm": "1.709", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "2380"}
[2022-01-03 12:49:22,375][fairseq.trainer][INFO] - begin training epoch 121
[2022-01-03 12:49:22,376][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:49:36,230][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:49:36,728][valid][INFO] - {"epoch": 121, "valid_loss": "4.664", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "31.885", "valid_code_perplexity": "31.877", "valid_temp": "1.952", "valid_loss_0": "4.488", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.21892", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "4840", "valid_best_loss": "4.071"}
[2022-01-03 12:49:36,730][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 121 @ 4840 updates
[2022-01-03 12:49:36,730][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:49:40,549][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:49:40,577][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 121 @ 4840 updates, score 4.664) (writing took 3.847189518623054 seconds)
[2022-01-03 12:49:40,577][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2022-01-03 12:49:40,590][train][INFO] - {"epoch": 121, "train_loss": "4.342", "train_ntokens": "1793.67", "train_nsentences": "4.95", "train_prob_perplexity": "33.027", "train_code_perplexity": "33.013", "train_temp": "1.952", "train_loss_0": "4.169", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.28074", "train_wps": "3930.3", "train_ups": "2.19", "train_wpb": "1793.7", "train_bsz": "5", "train_num_updates": "4840", "train_lr": "7.5625e-05", "train_gnorm": "1.695", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "2398"}
[2022-01-03 12:49:40,657][fairseq.trainer][INFO] - begin training epoch 122
[2022-01-03 12:49:40,657][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:49:54,596][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:49:55,006][valid][INFO] - {"epoch": 122, "valid_loss": "4.513", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "31.498", "valid_code_perplexity": "31.473", "valid_temp": "1.952", "valid_loss_0": "4.338", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.25282", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "4880", "valid_best_loss": "4.071"}
[2022-01-03 12:49:55,010][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 122 @ 4880 updates
[2022-01-03 12:49:55,011][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:49:58,730][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:49:58,757][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 122 @ 4880 updates, score 4.513) (writing took 3.747536459006369 seconds)
[2022-01-03 12:49:58,758][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2022-01-03 12:49:58,771][train][INFO] - {"epoch": 122, "train_loss": "4.317", "train_ntokens": "1792.75", "train_nsentences": "4.95", "train_prob_perplexity": "33.047", "train_code_perplexity": "33.018", "train_temp": "1.952", "train_loss_0": "4.143", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.28692", "train_wps": "3947.2", "train_ups": "2.2", "train_wpb": "1792.8", "train_bsz": "5", "train_num_updates": "4880", "train_lr": "7.625e-05", "train_gnorm": "1.628", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "2416"}
[2022-01-03 12:49:58,848][fairseq.trainer][INFO] - begin training epoch 123
[2022-01-03 12:49:58,849][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:50:12,734][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:50:13,146][valid][INFO] - {"epoch": 123, "valid_loss": "4.273", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "29.478", "valid_code_perplexity": "29.497", "valid_temp": "1.951", "valid_loss_0": "4.1", "valid_loss_1": "0.138", "valid_loss_2": "0.035", "valid_accuracy": "0.2963", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "4920", "valid_best_loss": "4.071"}
[2022-01-03 12:50:13,149][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 123 @ 4920 updates
[2022-01-03 12:50:13,150][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:50:16,990][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:50:17,018][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 123 @ 4920 updates, score 4.273) (writing took 3.8692649826407433 seconds)
[2022-01-03 12:50:17,019][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2022-01-03 12:50:17,031][train][INFO] - {"epoch": 123, "train_loss": "4.363", "train_ntokens": "1795.53", "train_nsentences": "4.95", "train_prob_perplexity": "33.285", "train_code_perplexity": "33.263", "train_temp": "1.952", "train_loss_0": "4.188", "train_loss_1": "0.137", "train_loss_2": "0.038", "train_accuracy": "0.27883", "train_wps": "3935.8", "train_ups": "2.19", "train_wpb": "1795.5", "train_bsz": "5", "train_num_updates": "4920", "train_lr": "7.6875e-05", "train_gnorm": "1.672", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "2434"}
[2022-01-03 12:50:17,114][fairseq.trainer][INFO] - begin training epoch 124
[2022-01-03 12:50:17,114][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:50:31,022][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:50:31,453][valid][INFO] - {"epoch": 124, "valid_loss": "4.381", "valid_ntokens": "680", "valid_nsentences": "2", "valid_prob_perplexity": "29.62", "valid_code_perplexity": "29.631", "valid_temp": "1.951", "valid_loss_0": "4.212", "valid_loss_1": "0.138", "valid_loss_2": "0.032", "valid_accuracy": "0.27206", "valid_wps": "0", "valid_wpb": "680", "valid_bsz": "2", "valid_num_updates": "4960", "valid_best_loss": "4.071"}
[2022-01-03 12:50:31,456][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 124 @ 4960 updates
[2022-01-03 12:50:31,457][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:50:35,222][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:50:35,249][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 124 @ 4960 updates, score 4.381) (writing took 3.792697260156274 seconds)
[2022-01-03 12:50:35,249][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2022-01-03 12:50:35,262][train][INFO] - {"epoch": 124, "train_loss": "4.321", "train_ntokens": "1777.1", "train_nsentences": "4.95", "train_prob_perplexity": "32.973", "train_code_perplexity": "32.955", "train_temp": "1.951", "train_loss_0": "4.147", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.28575", "train_wps": "3901.9", "train_ups": "2.2", "train_wpb": "1777.1", "train_bsz": "5", "train_num_updates": "4960", "train_lr": "7.75e-05", "train_gnorm": "1.663", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "2453"}
[2022-01-03 12:50:35,326][fairseq.trainer][INFO] - begin training epoch 125
[2022-01-03 12:50:35,327][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:50:49,353][train_inner][INFO] - {"epoch": 125, "update": 125.0, "loss": "4.337", "ntokens": "1793.28", "nsentences": "4.95", "prob_perplexity": "33.081", "code_perplexity": "33.06", "temp": "1.952", "loss_0": "4.163", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.28349", "wps": "3932.3", "ups": "2.19", "wpb": "1793.3", "bsz": "5", "num_updates": "5000", "lr": "7.8125e-05", "gnorm": "1.662", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "2467"}
[2022-01-03 12:50:49,354][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:50:49,783][valid][INFO] - {"epoch": 125, "valid_loss": "4.351", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "34.465", "valid_code_perplexity": "34.515", "valid_temp": "1.951", "valid_loss_0": "4.176", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.29381", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "5000", "valid_best_loss": "4.071"}
[2022-01-03 12:50:49,785][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 125 @ 5000 updates
[2022-01-03 12:50:49,786][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:50:53,472][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:50:53,497][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 125 @ 5000 updates, score 4.351) (writing took 3.711199400946498 seconds)
[2022-01-03 12:50:53,497][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2022-01-03 12:50:53,510][train][INFO] - {"epoch": 125, "train_loss": "4.34", "train_ntokens": "1807.35", "train_nsentences": "4.95", "train_prob_perplexity": "33.074", "train_code_perplexity": "33.049", "train_temp": "1.951", "train_loss_0": "4.166", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.28525", "train_wps": "3964.5", "train_ups": "2.19", "train_wpb": "1807.3", "train_bsz": "5", "train_num_updates": "5000", "train_lr": "7.8125e-05", "train_gnorm": "1.652", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2471"}
[2022-01-03 12:50:53,582][fairseq.trainer][INFO] - begin training epoch 126
[2022-01-03 12:50:53,583][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:51:07,515][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:51:07,921][valid][INFO] - {"epoch": 126, "valid_loss": "4.407", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "31.351", "valid_code_perplexity": "31.401", "valid_temp": "1.95", "valid_loss_0": "4.234", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.28368", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "5040", "valid_best_loss": "4.071"}
[2022-01-03 12:51:07,924][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 126 @ 5040 updates
[2022-01-03 12:51:07,924][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:51:11,719][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:51:11,746][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 126 @ 5040 updates, score 4.407) (writing took 3.8228344367817044 seconds)
[2022-01-03 12:51:11,747][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2022-01-03 12:51:11,760][train][INFO] - {"epoch": 126, "train_loss": "4.348", "train_ntokens": "1793.35", "train_nsentences": "4.95", "train_prob_perplexity": "33.638", "train_code_perplexity": "33.609", "train_temp": "1.95", "train_loss_0": "4.175", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.28055", "train_wps": "3933.4", "train_ups": "2.19", "train_wpb": "1793.3", "train_bsz": "5", "train_num_updates": "5040", "train_lr": "7.875e-05", "train_gnorm": "1.615", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "2489"}
[2022-01-03 12:51:11,835][fairseq.trainer][INFO] - begin training epoch 127
[2022-01-03 12:51:11,836][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:51:25,769][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:51:26,239][valid][INFO] - {"epoch": 127, "valid_loss": "4.626", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "33.419", "valid_code_perplexity": "33.49", "valid_temp": "1.95", "valid_loss_0": "4.452", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.21545", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "5080", "valid_best_loss": "4.071"}
[2022-01-03 12:51:26,241][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 127 @ 5080 updates
[2022-01-03 12:51:26,241][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:51:29,942][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:51:29,972][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 127 @ 5080 updates, score 4.626) (writing took 3.7309684474021196 seconds)
[2022-01-03 12:51:29,972][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2022-01-03 12:51:29,985][train][INFO] - {"epoch": 127, "train_loss": "4.334", "train_ntokens": "1788.6", "train_nsentences": "4.95", "train_prob_perplexity": "33.535", "train_code_perplexity": "33.516", "train_temp": "1.95", "train_loss_0": "4.161", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.28405", "train_wps": "3928.4", "train_ups": "2.2", "train_wpb": "1788.6", "train_bsz": "5", "train_num_updates": "5080", "train_lr": "7.9375e-05", "train_gnorm": "1.648", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2507"}
[2022-01-03 12:51:30,072][fairseq.trainer][INFO] - begin training epoch 128
[2022-01-03 12:51:30,072][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:51:43,941][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:51:44,459][valid][INFO] - {"epoch": 128, "valid_loss": "4.246", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "32.019", "valid_code_perplexity": "32.035", "valid_temp": "1.949", "valid_loss_0": "4.075", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.28691", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "5120", "valid_best_loss": "4.071"}
[2022-01-03 12:51:44,462][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 128 @ 5120 updates
[2022-01-03 12:51:44,462][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:51:48,226][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:51:48,256][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 128 @ 5120 updates, score 4.246) (writing took 3.794631947763264 seconds)
[2022-01-03 12:51:48,257][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2022-01-03 12:51:48,269][train][INFO] - {"epoch": 128, "train_loss": "4.33", "train_ntokens": "1793.28", "train_nsentences": "4.95", "train_prob_perplexity": "33.399", "train_code_perplexity": "33.391", "train_temp": "1.95", "train_loss_0": "4.157", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.28614", "train_wps": "3925.8", "train_ups": "2.19", "train_wpb": "1793.3", "train_bsz": "5", "train_num_updates": "5120", "train_lr": "8e-05", "train_gnorm": "1.595", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "2526"}
[2022-01-03 12:51:48,351][fairseq.trainer][INFO] - begin training epoch 129
[2022-01-03 12:51:48,351][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:52:02,236][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:52:02,662][valid][INFO] - {"epoch": 129, "valid_loss": "4.317", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "29.138", "valid_code_perplexity": "29.068", "valid_temp": "1.949", "valid_loss_0": "4.144", "valid_loss_1": "0.138", "valid_loss_2": "0.035", "valid_accuracy": "0.28976", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "5160", "valid_best_loss": "4.071"}
[2022-01-03 12:52:02,665][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 129 @ 5160 updates
[2022-01-03 12:52:02,666][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:52:06,452][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:52:06,481][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 129 @ 5160 updates, score 4.317) (writing took 3.815501781180501 seconds)
[2022-01-03 12:52:06,481][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2022-01-03 12:52:06,494][train][INFO] - {"epoch": 129, "train_loss": "4.359", "train_ntokens": "1795.83", "train_nsentences": "4.95", "train_prob_perplexity": "34.285", "train_code_perplexity": "34.249", "train_temp": "1.949", "train_loss_0": "4.186", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.27911", "train_wps": "3944.2", "train_ups": "2.2", "train_wpb": "1795.8", "train_bsz": "5", "train_num_updates": "5160", "train_lr": "8.0625e-05", "train_gnorm": "1.65", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2544"}
[2022-01-03 12:52:06,556][fairseq.trainer][INFO] - begin training epoch 130
[2022-01-03 12:52:06,557][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:52:20,477][train_inner][INFO] - {"epoch": 130, "update": 130.0, "loss": "4.344", "ntokens": "1793.94", "nsentences": "4.95", "prob_perplexity": "33.818", "code_perplexity": "33.795", "temp": "1.95", "loss_0": "4.17", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.2817", "wps": "3937.9", "ups": "2.2", "wpb": "1793.9", "bsz": "5", "num_updates": "5200", "lr": "8.125e-05", "gnorm": "1.628", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "2558"}
[2022-01-03 12:52:20,478][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:52:20,978][valid][INFO] - {"epoch": 130, "valid_loss": "4.245", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "34.937", "valid_code_perplexity": "35.031", "valid_temp": "1.949", "valid_loss_0": "4.069", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.29133", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "5200", "valid_best_loss": "4.071"}
[2022-01-03 12:52:20,979][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 130 @ 5200 updates
[2022-01-03 12:52:20,980][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:52:24,723][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:52:24,747][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 130 @ 5200 updates, score 4.245) (writing took 3.7671690974384546 seconds)
[2022-01-03 12:52:24,747][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2022-01-03 12:52:24,761][train][INFO] - {"epoch": 130, "train_loss": "4.347", "train_ntokens": "1798.67", "train_nsentences": "4.95", "train_prob_perplexity": "34.234", "train_code_perplexity": "34.212", "train_temp": "1.949", "train_loss_0": "4.173", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.27866", "train_wps": "3941.5", "train_ups": "2.19", "train_wpb": "1798.7", "train_bsz": "5", "train_num_updates": "5200", "train_lr": "8.125e-05", "train_gnorm": "1.632", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "2562"}
[2022-01-03 12:52:24,814][fairseq.trainer][INFO] - begin training epoch 131
[2022-01-03 12:52:24,815][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:52:38,768][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:52:39,203][valid][INFO] - {"epoch": 131, "valid_loss": "4.633", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "32.9", "valid_code_perplexity": "32.889", "valid_temp": "1.948", "valid_loss_0": "4.459", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.23219", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "5240", "valid_best_loss": "4.071"}
[2022-01-03 12:52:39,205][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 131 @ 5240 updates
[2022-01-03 12:52:39,205][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:52:42,939][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:52:42,953][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 131 @ 5240 updates, score 4.633) (writing took 3.7476969277486205 seconds)
[2022-01-03 12:52:42,953][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2022-01-03 12:52:42,968][train][INFO] - {"epoch": 131, "train_loss": "4.327", "train_ntokens": "1793.7", "train_nsentences": "4.95", "train_prob_perplexity": "34.27", "train_code_perplexity": "34.249", "train_temp": "1.948", "train_loss_0": "4.153", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.28259", "train_wps": "3944", "train_ups": "2.2", "train_wpb": "1793.7", "train_bsz": "5", "train_num_updates": "5240", "train_lr": "8.1875e-05", "train_gnorm": "1.629", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2580"}
[2022-01-03 12:52:43,043][fairseq.trainer][INFO] - begin training epoch 132
[2022-01-03 12:52:43,043][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:52:56,952][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:52:57,437][valid][INFO] - {"epoch": 132, "valid_loss": "4.407", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "31.599", "valid_code_perplexity": "31.533", "valid_temp": "1.948", "valid_loss_0": "4.237", "valid_loss_1": "0.137", "valid_loss_2": "0.033", "valid_accuracy": "0.27128", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "5280", "valid_best_loss": "4.071"}
[2022-01-03 12:52:57,439][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 132 @ 5280 updates
[2022-01-03 12:52:57,440][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:53:01,184][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:53:01,210][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 132 @ 5280 updates, score 4.407) (writing took 3.77129871211946 seconds)
[2022-01-03 12:53:01,211][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2022-01-03 12:53:01,223][train][INFO] - {"epoch": 132, "train_loss": "4.338", "train_ntokens": "1794.1", "train_nsentences": "4.95", "train_prob_perplexity": "33.825", "train_code_perplexity": "33.805", "train_temp": "1.948", "train_loss_0": "4.165", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.2811", "train_wps": "3933.8", "train_ups": "2.19", "train_wpb": "1794.1", "train_bsz": "5", "train_num_updates": "5280", "train_lr": "8.25e-05", "train_gnorm": "1.508", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "2599"}
[2022-01-03 12:53:01,274][fairseq.trainer][INFO] - begin training epoch 133
[2022-01-03 12:53:01,275][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:53:15,202][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:53:15,626][valid][INFO] - {"epoch": 133, "valid_loss": "3.857", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "31.75", "valid_code_perplexity": "31.779", "valid_temp": "1.948", "valid_loss_0": "3.68", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.32353", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "5320", "valid_best_loss": "3.857"}
[2022-01-03 12:53:15,631][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 133 @ 5320 updates
[2022-01-03 12:53:15,632][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:53:19,428][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 12:53:26,317][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 133 @ 5320 updates, score 3.857) (writing took 10.686329300515354 seconds)
[2022-01-03 12:53:26,317][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2022-01-03 12:53:26,330][train][INFO] - {"epoch": 133, "train_loss": "4.343", "train_ntokens": "1802.15", "train_nsentences": "4.95", "train_prob_perplexity": "33.389", "train_code_perplexity": "33.369", "train_temp": "1.948", "train_loss_0": "4.169", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.28065", "train_wps": "2872.6", "train_ups": "1.59", "train_wpb": "1802.2", "train_bsz": "5", "train_num_updates": "5320", "train_lr": "8.3125e-05", "train_gnorm": "1.635", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "2624"}
[2022-01-03 12:53:26,389][fairseq.trainer][INFO] - begin training epoch 134
[2022-01-03 12:53:26,390][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:53:40,221][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:53:40,725][valid][INFO] - {"epoch": 134, "valid_loss": "4.325", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "33.349", "valid_code_perplexity": "33.31", "valid_temp": "1.947", "valid_loss_0": "4.151", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.27733", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "5360", "valid_best_loss": "3.857"}
[2022-01-03 12:53:40,727][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 134 @ 5360 updates
[2022-01-03 12:53:40,728][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:53:44,628][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:53:44,648][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 134 @ 5360 updates, score 4.325) (writing took 3.9212537789717317 seconds)
[2022-01-03 12:53:44,649][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2022-01-03 12:53:44,662][train][INFO] - {"epoch": 134, "train_loss": "4.271", "train_ntokens": "1787.03", "train_nsentences": "4.95", "train_prob_perplexity": "34.549", "train_code_perplexity": "34.532", "train_temp": "1.947", "train_loss_0": "4.097", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28873", "train_wps": "3902", "train_ups": "2.18", "train_wpb": "1787", "train_bsz": "5", "train_num_updates": "5360", "train_lr": "8.375e-05", "train_gnorm": "1.524", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2642"}
[2022-01-03 12:53:44,733][fairseq.trainer][INFO] - begin training epoch 135
[2022-01-03 12:53:44,734][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:53:58,655][train_inner][INFO] - {"epoch": 135, "update": 135.0, "loss": "4.32", "ntokens": "1792.56", "nsentences": "4.95", "prob_perplexity": "33.987", "code_perplexity": "33.968", "temp": "1.948", "loss_0": "4.146", "loss_1": "0.137", "loss_2": "0.037", "accuracy": "0.28355", "wps": "3652.2", "ups": "2.04", "wpb": "1792.6", "bsz": "5", "num_updates": "5400", "lr": "8.4375e-05", "gnorm": "1.58", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "2656"}
[2022-01-03 12:53:58,656][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:53:59,102][valid][INFO] - {"epoch": 135, "valid_loss": "4.084", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "28.044", "valid_code_perplexity": "28.025", "valid_temp": "1.947", "valid_loss_0": "3.909", "valid_loss_1": "0.138", "valid_loss_2": "0.037", "valid_accuracy": "0.33008", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "5400", "valid_best_loss": "3.857"}
[2022-01-03 12:53:59,105][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 135 @ 5400 updates
[2022-01-03 12:53:59,106][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:54:02,793][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:54:02,822][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 135 @ 5400 updates, score 4.084) (writing took 3.716696774587035 seconds)
[2022-01-03 12:54:02,822][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2022-01-03 12:54:02,835][train][INFO] - {"epoch": 135, "train_loss": "4.319", "train_ntokens": "1785.83", "train_nsentences": "4.95", "train_prob_perplexity": "33.9", "train_code_perplexity": "33.887", "train_temp": "1.947", "train_loss_0": "4.145", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.2847", "train_wps": "3933.4", "train_ups": "2.2", "train_wpb": "1785.8", "train_bsz": "5", "train_num_updates": "5400", "train_lr": "8.4375e-05", "train_gnorm": "1.605", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2660"}
[2022-01-03 12:54:02,918][fairseq.trainer][INFO] - begin training epoch 136
[2022-01-03 12:54:02,919][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:54:16,738][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:54:17,154][valid][INFO] - {"epoch": 136, "valid_loss": "4.105", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "34.413", "valid_code_perplexity": "34.401", "valid_temp": "1.946", "valid_loss_0": "3.932", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.30959", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "5440", "valid_best_loss": "3.857"}
[2022-01-03 12:54:17,157][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 136 @ 5440 updates
[2022-01-03 12:54:17,158][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:54:21,121][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:54:21,148][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 136 @ 5440 updates, score 4.105) (writing took 3.9908082112669945 seconds)
[2022-01-03 12:54:21,149][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2022-01-03 12:54:21,162][train][INFO] - {"epoch": 136, "train_loss": "4.296", "train_ntokens": "1784.53", "train_nsentences": "4.95", "train_prob_perplexity": "34.807", "train_code_perplexity": "34.788", "train_temp": "1.947", "train_loss_0": "4.123", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28537", "train_wps": "3897.7", "train_ups": "2.18", "train_wpb": "1784.5", "train_bsz": "5", "train_num_updates": "5440", "train_lr": "8.5e-05", "train_gnorm": "1.597", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2679"}
[2022-01-03 12:54:21,239][fairseq.trainer][INFO] - begin training epoch 137
[2022-01-03 12:54:21,240][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:54:35,192][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:54:35,680][valid][INFO] - {"epoch": 137, "valid_loss": "4.082", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "32.378", "valid_code_perplexity": "32.408", "valid_temp": "1.946", "valid_loss_0": "3.909", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.30894", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "5480", "valid_best_loss": "3.857"}
[2022-01-03 12:54:35,682][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 137 @ 5480 updates
[2022-01-03 12:54:35,682][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:54:39,344][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:54:39,371][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 137 @ 5480 updates, score 4.082) (writing took 3.688940953463316 seconds)
[2022-01-03 12:54:39,371][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2022-01-03 12:54:39,385][train][INFO] - {"epoch": 137, "train_loss": "4.307", "train_ntokens": "1795.38", "train_nsentences": "4.95", "train_prob_perplexity": "34.736", "train_code_perplexity": "34.722", "train_temp": "1.946", "train_loss_0": "4.133", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28555", "train_wps": "3943.9", "train_ups": "2.2", "train_wpb": "1795.4", "train_bsz": "5", "train_num_updates": "5480", "train_lr": "8.5625e-05", "train_gnorm": "1.522", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2697"}
[2022-01-03 12:54:39,464][fairseq.trainer][INFO] - begin training epoch 138
[2022-01-03 12:54:39,465][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:54:53,247][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:54:53,665][valid][INFO] - {"epoch": 138, "valid_loss": "4.65", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "29.958", "valid_code_perplexity": "29.994", "valid_temp": "1.946", "valid_loss_0": "4.478", "valid_loss_1": "0.138", "valid_loss_2": "0.034", "valid_accuracy": "0.24679", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "5520", "valid_best_loss": "3.857"}
[2022-01-03 12:54:53,668][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 138 @ 5520 updates
[2022-01-03 12:54:53,669][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:54:57,609][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:54:57,638][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 138 @ 5520 updates, score 4.65) (writing took 3.9699256466701627 seconds)
[2022-01-03 12:54:57,639][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2022-01-03 12:54:57,652][train][INFO] - {"epoch": 138, "train_loss": "4.312", "train_ntokens": "1788.67", "train_nsentences": "4.95", "train_prob_perplexity": "34.06", "train_code_perplexity": "34.045", "train_temp": "1.946", "train_loss_0": "4.14", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.28233", "train_wps": "3919.5", "train_ups": "2.19", "train_wpb": "1788.7", "train_bsz": "5", "train_num_updates": "5520", "train_lr": "8.625e-05", "train_gnorm": "1.554", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "2715"}
[2022-01-03 12:54:57,732][fairseq.trainer][INFO] - begin training epoch 139
[2022-01-03 12:54:57,733][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:55:11,613][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:55:12,009][valid][INFO] - {"epoch": 139, "valid_loss": "4.406", "valid_ntokens": "804", "valid_nsentences": "2", "valid_prob_perplexity": "33.344", "valid_code_perplexity": "33.309", "valid_temp": "1.945", "valid_loss_0": "4.232", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.27488", "valid_wps": "0", "valid_wpb": "804", "valid_bsz": "2", "valid_num_updates": "5560", "valid_best_loss": "3.857"}
[2022-01-03 12:55:12,011][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 139 @ 5560 updates
[2022-01-03 12:55:12,012][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:55:15,802][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:55:15,829][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 139 @ 5560 updates, score 4.406) (writing took 3.8174856677651405 seconds)
[2022-01-03 12:55:15,829][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2022-01-03 12:55:15,843][train][INFO] - {"epoch": 139, "train_loss": "4.298", "train_ntokens": "1798.2", "train_nsentences": "4.95", "train_prob_perplexity": "34.507", "train_code_perplexity": "34.495", "train_temp": "1.945", "train_loss_0": "4.125", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28267", "train_wps": "3957", "train_ups": "2.2", "train_wpb": "1798.2", "train_bsz": "5", "train_num_updates": "5560", "train_lr": "8.6875e-05", "train_gnorm": "1.505", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2733"}
[2022-01-03 12:55:15,914][fairseq.trainer][INFO] - begin training epoch 140
[2022-01-03 12:55:15,915][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:55:29,933][train_inner][INFO] - {"epoch": 140, "update": 140.0, "loss": "4.302", "ntokens": "1794.95", "nsentences": "4.95", "prob_perplexity": "34.467", "code_perplexity": "34.451", "temp": "1.946", "loss_0": "4.128", "loss_1": "0.136", "loss_2": "0.037", "accuracy": "0.28424", "wps": "3933.5", "ups": "2.19", "wpb": "1795", "bsz": "5", "num_updates": "5600", "lr": "8.75e-05", "gnorm": "1.561", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "2747"}
[2022-01-03 12:55:29,935][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:55:30,365][valid][INFO] - {"epoch": 140, "valid_loss": "4.077", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "32.151", "valid_code_perplexity": "32.134", "valid_temp": "1.945", "valid_loss_0": "3.901", "valid_loss_1": "0.137", "valid_loss_2": "0.04", "valid_accuracy": "0.33241", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "5600", "valid_best_loss": "3.857"}
[2022-01-03 12:55:30,367][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 140 @ 5600 updates
[2022-01-03 12:55:30,368][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:55:34,040][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:55:34,071][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 140 @ 5600 updates, score 4.077) (writing took 3.7033791160210967 seconds)
[2022-01-03 12:55:34,071][fairseq_cli.train][INFO] - end of epoch 140 (average epoch stats below)
[2022-01-03 12:55:34,083][train][INFO] - {"epoch": 140, "train_loss": "4.295", "train_ntokens": "1808", "train_nsentences": "4.95", "train_prob_perplexity": "34.226", "train_code_perplexity": "34.205", "train_temp": "1.945", "train_loss_0": "4.121", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.28527", "train_wps": "3967.5", "train_ups": "2.19", "train_wpb": "1808", "train_bsz": "5", "train_num_updates": "5600", "train_lr": "8.75e-05", "train_gnorm": "1.626", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2751"}
[2022-01-03 12:55:34,138][fairseq.trainer][INFO] - begin training epoch 141
[2022-01-03 12:55:34,139][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:55:48,060][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:55:48,489][valid][INFO] - {"epoch": 141, "valid_loss": "4.48", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "31.251", "valid_code_perplexity": "31.259", "valid_temp": "1.944", "valid_loss_0": "4.308", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.27542", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "5640", "valid_best_loss": "3.857"}
[2022-01-03 12:55:48,492][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 141 @ 5640 updates
[2022-01-03 12:55:48,493][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:55:52,264][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:55:52,293][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 141 @ 5640 updates, score 4.48) (writing took 3.8007248966023326 seconds)
[2022-01-03 12:55:52,293][fairseq_cli.train][INFO] - end of epoch 141 (average epoch stats below)
[2022-01-03 12:55:52,306][train][INFO] - {"epoch": 141, "train_loss": "4.264", "train_ntokens": "1800.12", "train_nsentences": "4.95", "train_prob_perplexity": "34.196", "train_code_perplexity": "34.179", "train_temp": "1.945", "train_loss_0": "4.089", "train_loss_1": "0.137", "train_loss_2": "0.039", "train_accuracy": "0.29259", "train_wps": "3954.1", "train_ups": "2.2", "train_wpb": "1800.1", "train_bsz": "5", "train_num_updates": "5640", "train_lr": "8.8125e-05", "train_gnorm": "1.529", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "2770"}
[2022-01-03 12:55:52,388][fairseq.trainer][INFO] - begin training epoch 142
[2022-01-03 12:55:52,389][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:56:06,367][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:56:06,909][valid][INFO] - {"epoch": 142, "valid_loss": "4.232", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "34.715", "valid_code_perplexity": "34.737", "valid_temp": "1.944", "valid_loss_0": "4.058", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.27919", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "5680", "valid_best_loss": "3.857"}
[2022-01-03 12:56:06,911][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 142 @ 5680 updates
[2022-01-03 12:56:06,912][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:56:10,523][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:56:10,552][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 142 @ 5680 updates, score 4.232) (writing took 3.6404023775830865 seconds)
[2022-01-03 12:56:10,552][fairseq_cli.train][INFO] - end of epoch 142 (average epoch stats below)
[2022-01-03 12:56:10,567][train][INFO] - {"epoch": 142, "train_loss": "4.291", "train_ntokens": "1782.35", "train_nsentences": "4.95", "train_prob_perplexity": "33.783", "train_code_perplexity": "33.764", "train_temp": "1.944", "train_loss_0": "4.117", "train_loss_1": "0.137", "train_loss_2": "0.037", "train_accuracy": "0.29136", "train_wps": "3907.4", "train_ups": "2.19", "train_wpb": "1782.3", "train_bsz": "5", "train_num_updates": "5680", "train_lr": "8.875e-05", "train_gnorm": "1.501", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "2788"}
[2022-01-03 12:56:10,650][fairseq.trainer][INFO] - begin training epoch 143
[2022-01-03 12:56:10,651][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:56:24,676][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:56:25,081][valid][INFO] - {"epoch": 143, "valid_loss": "4.229", "valid_ntokens": "702", "valid_nsentences": "2", "valid_prob_perplexity": "32.561", "valid_code_perplexity": "32.552", "valid_temp": "1.944", "valid_loss_0": "4.059", "valid_loss_1": "0.137", "valid_loss_2": "0.033", "valid_accuracy": "0.28775", "valid_wps": "0", "valid_wpb": "702", "valid_bsz": "2", "valid_num_updates": "5720", "valid_best_loss": "3.857"}
[2022-01-03 12:56:25,085][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 143 @ 5720 updates
[2022-01-03 12:56:25,086][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:56:28,748][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:56:28,772][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 143 @ 5720 updates, score 4.229) (writing took 3.6868434930220246 seconds)
[2022-01-03 12:56:28,772][fairseq_cli.train][INFO] - end of epoch 143 (average epoch stats below)
[2022-01-03 12:56:28,785][train][INFO] - {"epoch": 143, "train_loss": "4.276", "train_ntokens": "1779.08", "train_nsentences": "4.95", "train_prob_perplexity": "34.664", "train_code_perplexity": "34.646", "train_temp": "1.944", "train_loss_0": "4.101", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28578", "train_wps": "3908.9", "train_ups": "2.2", "train_wpb": "1779.1", "train_bsz": "5", "train_num_updates": "5720", "train_lr": "8.9375e-05", "train_gnorm": "1.522", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.8", "train_wall": "2806"}
[2022-01-03 12:56:28,852][fairseq.trainer][INFO] - begin training epoch 144
[2022-01-03 12:56:28,853][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:56:42,778][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:56:43,193][valid][INFO] - {"epoch": 144, "valid_loss": "4.24", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "33.301", "valid_code_perplexity": "33.307", "valid_temp": "1.943", "valid_loss_0": "4.068", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.29589", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "5760", "valid_best_loss": "3.857"}
[2022-01-03 12:56:43,195][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 144 @ 5760 updates
[2022-01-03 12:56:43,196][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:56:47,116][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:56:47,142][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 144 @ 5760 updates, score 4.24) (writing took 3.946470472961664 seconds)
[2022-01-03 12:56:47,142][fairseq_cli.train][INFO] - end of epoch 144 (average epoch stats below)
[2022-01-03 12:56:47,155][train][INFO] - {"epoch": 144, "train_loss": "4.324", "train_ntokens": "1784", "train_nsentences": "4.95", "train_prob_perplexity": "34.737", "train_code_perplexity": "34.72", "train_temp": "1.943", "train_loss_0": "4.15", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28224", "train_wps": "3887.2", "train_ups": "2.18", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "5760", "train_lr": "9e-05", "train_gnorm": "1.473", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "2825"}
[2022-01-03 12:56:47,221][fairseq.trainer][INFO] - begin training epoch 145
[2022-01-03 12:56:47,221][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:57:01,036][train_inner][INFO] - {"epoch": 145, "update": 145.0, "loss": "4.285", "ntokens": "1782.83", "nsentences": "4.95", "prob_perplexity": "34.357", "code_perplexity": "34.339", "temp": "1.944", "loss_0": "4.111", "loss_1": "0.137", "loss_2": "0.038", "accuracy": "0.28772", "wps": "3914.4", "ups": "2.2", "wpb": "1782.8", "bsz": "5", "num_updates": "5800", "lr": "9.0625e-05", "gnorm": "1.509", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "2838"}
[2022-01-03 12:57:01,037][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:57:01,435][valid][INFO] - {"epoch": 145, "valid_loss": "4.376", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "34.3", "valid_code_perplexity": "34.295", "valid_temp": "1.943", "valid_loss_0": "4.205", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.26184", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "5800", "valid_best_loss": "3.857"}
[2022-01-03 12:57:01,438][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 145 @ 5800 updates
[2022-01-03 12:57:01,438][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:57:05,226][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:57:05,254][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 145 @ 5800 updates, score 4.376) (writing took 3.8157701455056667 seconds)
[2022-01-03 12:57:05,254][fairseq_cli.train][INFO] - end of epoch 145 (average epoch stats below)
[2022-01-03 12:57:05,267][train][INFO] - {"epoch": 145, "train_loss": "4.27", "train_ntokens": "1768.58", "train_nsentences": "4.95", "train_prob_perplexity": "34.404", "train_code_perplexity": "34.386", "train_temp": "1.943", "train_loss_0": "4.097", "train_loss_1": "0.137", "train_loss_2": "0.036", "train_accuracy": "0.28659", "train_wps": "3908.7", "train_ups": "2.21", "train_wpb": "1768.6", "train_bsz": "5", "train_num_updates": "5800", "train_lr": "9.0625e-05", "train_gnorm": "1.519", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "2843"}
[2022-01-03 12:57:05,340][fairseq.trainer][INFO] - begin training epoch 146
[2022-01-03 12:57:05,340][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:57:19,300][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:57:19,780][valid][INFO] - {"epoch": 146, "valid_loss": "4.574", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "34.23", "valid_code_perplexity": "34.134", "valid_temp": "1.942", "valid_loss_0": "4.401", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.22466", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "5840", "valid_best_loss": "3.857"}
[2022-01-03 12:57:19,781][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 146 @ 5840 updates
[2022-01-03 12:57:19,782][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:57:23,475][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:57:23,502][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 146 @ 5840 updates, score 4.574) (writing took 3.72096093185246 seconds)
[2022-01-03 12:57:23,503][fairseq_cli.train][INFO] - end of epoch 146 (average epoch stats below)
[2022-01-03 12:57:23,515][train][INFO] - {"epoch": 146, "train_loss": "4.324", "train_ntokens": "1775.08", "train_nsentences": "4.95", "train_prob_perplexity": "35.026", "train_code_perplexity": "35.005", "train_temp": "1.943", "train_loss_0": "4.15", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28095", "train_wps": "3893.5", "train_ups": "2.19", "train_wpb": "1775.1", "train_bsz": "5", "train_num_updates": "5840", "train_lr": "9.125e-05", "train_gnorm": "1.47", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2861"}
[2022-01-03 12:57:23,575][fairseq.trainer][INFO] - begin training epoch 147
[2022-01-03 12:57:23,576][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:57:37,770][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:57:38,293][valid][INFO] - {"epoch": 147, "valid_loss": "3.956", "valid_ntokens": "802", "valid_nsentences": "2", "valid_prob_perplexity": "33.314", "valid_code_perplexity": "33.278", "valid_temp": "1.942", "valid_loss_0": "3.781", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.33666", "valid_wps": "0", "valid_wpb": "802", "valid_bsz": "2", "valid_num_updates": "5880", "valid_best_loss": "3.857"}
[2022-01-03 12:57:38,295][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 147 @ 5880 updates
[2022-01-03 12:57:38,296][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:57:42,195][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:57:42,221][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 147 @ 5880 updates, score 3.956) (writing took 3.925257579423487 seconds)
[2022-01-03 12:57:42,221][fairseq_cli.train][INFO] - end of epoch 147 (average epoch stats below)
[2022-01-03 12:57:42,235][train][INFO] - {"epoch": 147, "train_loss": "4.259", "train_ntokens": "1806.75", "train_nsentences": "4.95", "train_prob_perplexity": "34.708", "train_code_perplexity": "34.695", "train_temp": "1.942", "train_loss_0": "4.084", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28835", "train_wps": "3863.4", "train_ups": "2.14", "train_wpb": "1806.8", "train_bsz": "5", "train_num_updates": "5880", "train_lr": "9.1875e-05", "train_gnorm": "1.499", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "2880"}
[2022-01-03 12:57:42,296][fairseq.trainer][INFO] - begin training epoch 148
[2022-01-03 12:57:42,296][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:57:56,170][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:57:56,646][valid][INFO] - {"epoch": 148, "valid_loss": "4.372", "valid_ntokens": "816", "valid_nsentences": "2", "valid_prob_perplexity": "35.091", "valid_code_perplexity": "35.019", "valid_temp": "1.942", "valid_loss_0": "4.196", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.26838", "valid_wps": "0", "valid_wpb": "816", "valid_bsz": "2", "valid_num_updates": "5920", "valid_best_loss": "3.857"}
[2022-01-03 12:57:56,647][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 148 @ 5920 updates
[2022-01-03 12:57:56,648][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:58:00,551][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:58:00,577][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 148 @ 5920 updates, score 4.372) (writing took 3.9291438031941652 seconds)
[2022-01-03 12:58:00,577][fairseq_cli.train][INFO] - end of epoch 148 (average epoch stats below)
[2022-01-03 12:58:00,590][train][INFO] - {"epoch": 148, "train_loss": "4.262", "train_ntokens": "1783.25", "train_nsentences": "4.95", "train_prob_perplexity": "35.379", "train_code_perplexity": "35.358", "train_temp": "1.942", "train_loss_0": "4.087", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28775", "train_wps": "3888.8", "train_ups": "2.18", "train_wpb": "1783.2", "train_bsz": "5", "train_num_updates": "5920", "train_lr": "9.25e-05", "train_gnorm": "1.463", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "2898"}
[2022-01-03 12:58:00,665][fairseq.trainer][INFO] - begin training epoch 149
[2022-01-03 12:58:00,666][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:58:14,680][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:58:15,189][valid][INFO] - {"epoch": 149, "valid_loss": "4.428", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "34.698", "valid_code_perplexity": "34.671", "valid_temp": "1.941", "valid_loss_0": "4.257", "valid_loss_1": "0.136", "valid_loss_2": "0.035", "valid_accuracy": "0.26762", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "5960", "valid_best_loss": "3.857"}
[2022-01-03 12:58:15,190][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 149 @ 5960 updates
[2022-01-03 12:58:15,191][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:58:18,800][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:58:18,828][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 149 @ 5960 updates, score 4.428) (writing took 3.6373263290151954 seconds)
[2022-01-03 12:58:18,828][fairseq_cli.train][INFO] - end of epoch 149 (average epoch stats below)
[2022-01-03 12:58:18,842][train][INFO] - {"epoch": 149, "train_loss": "4.272", "train_ntokens": "1806.17", "train_nsentences": "4.95", "train_prob_perplexity": "35.386", "train_code_perplexity": "35.362", "train_temp": "1.941", "train_loss_0": "4.099", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28917", "train_wps": "3961.2", "train_ups": "2.19", "train_wpb": "1806.2", "train_bsz": "5", "train_num_updates": "5960", "train_lr": "9.3125e-05", "train_gnorm": "1.497", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "2916"}
[2022-01-03 12:58:18,909][fairseq.trainer][INFO] - begin training epoch 150
[2022-01-03 12:58:18,910][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:58:32,847][train_inner][INFO] - {"epoch": 150, "update": 150.0, "loss": "4.281", "ntokens": "1792.31", "nsentences": "4.95", "prob_perplexity": "35.136", "code_perplexity": "35.116", "temp": "1.942", "loss_0": "4.107", "loss_1": "0.136", "loss_2": "0.037", "accuracy": "0.28656", "wps": "3905", "ups": "2.18", "wpb": "1792.3", "bsz": "5", "num_updates": "6000", "lr": "9.375e-05", "gnorm": "1.478", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "2930"}
[2022-01-03 12:58:32,848][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:58:33,269][valid][INFO] - {"epoch": 150, "valid_loss": "4.379", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "32.793", "valid_code_perplexity": "32.769", "valid_temp": "1.941", "valid_loss_0": "4.209", "valid_loss_1": "0.137", "valid_loss_2": "0.033", "valid_accuracy": "0.26166", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "6000", "valid_best_loss": "3.857"}
[2022-01-03 12:58:33,271][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 150 @ 6000 updates
[2022-01-03 12:58:33,272][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:58:37,215][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:58:37,242][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 150 @ 6000 updates, score 4.379) (writing took 3.9709198866039515 seconds)
[2022-01-03 12:58:37,243][fairseq_cli.train][INFO] - end of epoch 150 (average epoch stats below)
[2022-01-03 12:58:37,255][train][INFO] - {"epoch": 150, "train_loss": "4.29", "train_ntokens": "1790.3", "train_nsentences": "4.95", "train_prob_perplexity": "35.178", "train_code_perplexity": "35.16", "train_temp": "1.941", "train_loss_0": "4.117", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28652", "train_wps": "3891.8", "train_ups": "2.17", "train_wpb": "1790.3", "train_bsz": "5", "train_num_updates": "6000", "train_lr": "9.375e-05", "train_gnorm": "1.459", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "2935"}
[2022-01-03 12:58:37,331][fairseq.trainer][INFO] - begin training epoch 151
[2022-01-03 12:58:37,332][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:58:51,196][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:58:51,686][valid][INFO] - {"epoch": 151, "valid_loss": "4.09", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "33.749", "valid_code_perplexity": "33.799", "valid_temp": "1.941", "valid_loss_0": "3.916", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.32162", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "6040", "valid_best_loss": "3.857"}
[2022-01-03 12:58:51,688][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 151 @ 6040 updates
[2022-01-03 12:58:51,688][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:58:55,406][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:58:55,435][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 151 @ 6040 updates, score 4.09) (writing took 3.7474915329366922 seconds)
[2022-01-03 12:58:55,436][fairseq_cli.train][INFO] - end of epoch 151 (average epoch stats below)
[2022-01-03 12:58:55,449][train][INFO] - {"epoch": 151, "train_loss": "4.253", "train_ntokens": "1783.92", "train_nsentences": "4.95", "train_prob_perplexity": "34.888", "train_code_perplexity": "34.868", "train_temp": "1.941", "train_loss_0": "4.08", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.29081", "train_wps": "3924.9", "train_ups": "2.2", "train_wpb": "1783.9", "train_bsz": "5", "train_num_updates": "6040", "train_lr": "9.4375e-05", "train_gnorm": "1.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "2953"}
[2022-01-03 12:58:55,532][fairseq.trainer][INFO] - begin training epoch 152
[2022-01-03 12:58:55,533][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:59:09,471][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:59:09,995][valid][INFO] - {"epoch": 152, "valid_loss": "4.288", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "34.165", "valid_code_perplexity": "34.19", "valid_temp": "1.94", "valid_loss_0": "4.117", "valid_loss_1": "0.137", "valid_loss_2": "0.034", "valid_accuracy": "0.28026", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "6080", "valid_best_loss": "3.857"}
[2022-01-03 12:59:09,997][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 152 @ 6080 updates
[2022-01-03 12:59:09,998][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:59:13,667][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:59:13,692][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 152 @ 6080 updates, score 4.288) (writing took 3.694412086158991 seconds)
[2022-01-03 12:59:13,692][fairseq_cli.train][INFO] - end of epoch 152 (average epoch stats below)
[2022-01-03 12:59:13,704][train][INFO] - {"epoch": 152, "train_loss": "4.27", "train_ntokens": "1793.45", "train_nsentences": "4.95", "train_prob_perplexity": "34.572", "train_code_perplexity": "34.555", "train_temp": "1.94", "train_loss_0": "4.096", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28936", "train_wps": "3932.4", "train_ups": "2.19", "train_wpb": "1793.5", "train_bsz": "5", "train_num_updates": "6080", "train_lr": "9.5e-05", "train_gnorm": "1.498", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "2971"}
[2022-01-03 12:59:13,774][fairseq.trainer][INFO] - begin training epoch 153
[2022-01-03 12:59:13,775][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:59:27,804][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:59:28,289][valid][INFO] - {"epoch": 153, "valid_loss": "4.392", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "33.094", "valid_code_perplexity": "33.114", "valid_temp": "1.94", "valid_loss_0": "4.221", "valid_loss_1": "0.137", "valid_loss_2": "0.034", "valid_accuracy": "0.26892", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "6120", "valid_best_loss": "3.857"}
[2022-01-03 12:59:28,290][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 153 @ 6120 updates
[2022-01-03 12:59:28,291][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:59:31,932][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:59:31,953][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 153 @ 6120 updates, score 4.392) (writing took 3.6627232022583485 seconds)
[2022-01-03 12:59:31,953][fairseq_cli.train][INFO] - end of epoch 153 (average epoch stats below)
[2022-01-03 12:59:31,966][train][INFO] - {"epoch": 153, "train_loss": "4.305", "train_ntokens": "1795.03", "train_nsentences": "4.95", "train_prob_perplexity": "34.872", "train_code_perplexity": "34.855", "train_temp": "1.94", "train_loss_0": "4.131", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28413", "train_wps": "3934.5", "train_ups": "2.19", "train_wpb": "1795", "train_bsz": "5", "train_num_updates": "6120", "train_lr": "9.5625e-05", "train_gnorm": "1.486", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "2989"}
[2022-01-03 12:59:32,016][fairseq.trainer][INFO] - begin training epoch 154
[2022-01-03 12:59:32,017][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 12:59:46,053][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 12:59:46,470][valid][INFO] - {"epoch": 154, "valid_loss": "4.143", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "34.425", "valid_code_perplexity": "34.382", "valid_temp": "1.939", "valid_loss_0": "3.97", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.30801", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "6160", "valid_best_loss": "3.857"}
[2022-01-03 12:59:46,472][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 154 @ 6160 updates
[2022-01-03 12:59:46,473][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:59:50,143][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 12:59:50,171][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 154 @ 6160 updates, score 4.143) (writing took 3.698435863479972 seconds)
[2022-01-03 12:59:50,171][fairseq_cli.train][INFO] - end of epoch 154 (average epoch stats below)
[2022-01-03 12:59:50,184][train][INFO] - {"epoch": 154, "train_loss": "4.298", "train_ntokens": "1799.33", "train_nsentences": "4.95", "train_prob_perplexity": "35.23", "train_code_perplexity": "35.217", "train_temp": "1.94", "train_loss_0": "4.123", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28226", "train_wps": "3953.5", "train_ups": "2.2", "train_wpb": "1799.3", "train_bsz": "5", "train_num_updates": "6160", "train_lr": "9.625e-05", "train_gnorm": "1.395", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "3008"}
[2022-01-03 12:59:50,250][fairseq.trainer][INFO] - begin training epoch 155
[2022-01-03 12:59:50,251][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:00:04,251][train_inner][INFO] - {"epoch": 155, "update": 155.0, "loss": "4.289", "ntokens": "1796.52", "nsentences": "4.95", "prob_perplexity": "34.938", "code_perplexity": "34.92", "temp": "1.94", "loss_0": "4.114", "loss_1": "0.136", "loss_2": "0.038", "accuracy": "0.28541", "wps": "3931.4", "ups": "2.19", "wpb": "1796.5", "bsz": "5", "num_updates": "6200", "lr": "9.6875e-05", "gnorm": "1.456", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "3022"}
[2022-01-03 13:00:04,252][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:00:04,681][valid][INFO] - {"epoch": 155, "valid_loss": "4.73", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "31.742", "valid_code_perplexity": "31.626", "valid_temp": "1.939", "valid_loss_0": "4.56", "valid_loss_1": "0.137", "valid_loss_2": "0.034", "valid_accuracy": "0.268", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "6200", "valid_best_loss": "3.857"}
[2022-01-03 13:00:04,683][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 155 @ 6200 updates
[2022-01-03 13:00:04,683][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:00:08,385][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:00:08,418][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 155 @ 6200 updates, score 4.73) (writing took 3.735213005915284 seconds)
[2022-01-03 13:00:08,418][fairseq_cli.train][INFO] - end of epoch 155 (average epoch stats below)
[2022-01-03 13:00:08,431][train][INFO] - {"epoch": 155, "train_loss": "4.316", "train_ntokens": "1810.88", "train_nsentences": "4.95", "train_prob_perplexity": "35.127", "train_code_perplexity": "35.107", "train_temp": "1.939", "train_loss_0": "4.142", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28057", "train_wps": "3972.4", "train_ups": "2.19", "train_wpb": "1810.9", "train_bsz": "5", "train_num_updates": "6200", "train_lr": "9.6875e-05", "train_gnorm": "1.391", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "3026"}
[2022-01-03 13:00:08,509][fairseq.trainer][INFO] - begin training epoch 156
[2022-01-03 13:00:08,509][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:00:22,532][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:00:23,011][valid][INFO] - {"epoch": 156, "valid_loss": "4.44", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "33.521", "valid_code_perplexity": "33.495", "valid_temp": "1.939", "valid_loss_0": "4.267", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.27236", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "6240", "valid_best_loss": "3.857"}
[2022-01-03 13:00:23,014][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 156 @ 6240 updates
[2022-01-03 13:00:23,014][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:00:26,637][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:00:26,666][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 156 @ 6240 updates, score 4.44) (writing took 3.6519722305238247 seconds)
[2022-01-03 13:00:26,666][fairseq_cli.train][INFO] - end of epoch 156 (average epoch stats below)
[2022-01-03 13:00:26,679][train][INFO] - {"epoch": 156, "train_loss": "4.319", "train_ntokens": "1789.85", "train_nsentences": "4.95", "train_prob_perplexity": "34.957", "train_code_perplexity": "34.926", "train_temp": "1.939", "train_loss_0": "4.147", "train_loss_1": "0.136", "train_loss_2": "0.036", "train_accuracy": "0.27836", "train_wps": "3926", "train_ups": "2.19", "train_wpb": "1789.8", "train_bsz": "5", "train_num_updates": "6240", "train_lr": "9.75e-05", "train_gnorm": "1.41", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3044"}
[2022-01-03 13:00:26,744][fairseq.trainer][INFO] - begin training epoch 157
[2022-01-03 13:00:26,745][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:00:40,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:00:41,090][valid][INFO] - {"epoch": 157, "valid_loss": "4.176", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "32.435", "valid_code_perplexity": "32.459", "valid_temp": "1.938", "valid_loss_0": "4.004", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.27708", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "6280", "valid_best_loss": "3.857"}
[2022-01-03 13:00:41,092][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 157 @ 6280 updates
[2022-01-03 13:00:41,093][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:00:44,871][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:00:44,895][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 157 @ 6280 updates, score 4.176) (writing took 3.8023943910375237 seconds)
[2022-01-03 13:00:44,895][fairseq_cli.train][INFO] - end of epoch 157 (average epoch stats below)
[2022-01-03 13:00:44,908][train][INFO] - {"epoch": 157, "train_loss": "4.288", "train_ntokens": "1783.62", "train_nsentences": "4.95", "train_prob_perplexity": "35.032", "train_code_perplexity": "35.009", "train_temp": "1.938", "train_loss_0": "4.115", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28357", "train_wps": "3916.6", "train_ups": "2.2", "train_wpb": "1783.6", "train_bsz": "5", "train_num_updates": "6280", "train_lr": "9.8125e-05", "train_gnorm": "1.474", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3062"}
[2022-01-03 13:00:44,949][fairseq.trainer][INFO] - begin training epoch 158
[2022-01-03 13:00:44,950][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:00:58,882][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:00:59,326][valid][INFO] - {"epoch": 158, "valid_loss": "4.236", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "33.252", "valid_code_perplexity": "33.178", "valid_temp": "1.938", "valid_loss_0": "4.063", "valid_loss_1": "0.137", "valid_loss_2": "0.036", "valid_accuracy": "0.28792", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "6320", "valid_best_loss": "3.857"}
[2022-01-03 13:00:59,329][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 158 @ 6320 updates
[2022-01-03 13:00:59,329][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:01:03,116][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:01:03,143][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 158 @ 6320 updates, score 4.236) (writing took 3.814580255188048 seconds)
[2022-01-03 13:01:03,144][fairseq_cli.train][INFO] - end of epoch 158 (average epoch stats below)
[2022-01-03 13:01:03,157][train][INFO] - {"epoch": 158, "train_loss": "4.292", "train_ntokens": "1800.3", "train_nsentences": "4.95", "train_prob_perplexity": "34.34", "train_code_perplexity": "34.318", "train_temp": "1.938", "train_loss_0": "4.116", "train_loss_1": "0.137", "train_loss_2": "0.039", "train_accuracy": "0.28415", "train_wps": "3948.8", "train_ups": "2.19", "train_wpb": "1800.3", "train_bsz": "5", "train_num_updates": "6320", "train_lr": "9.875e-05", "train_gnorm": "1.397", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "3081"}
[2022-01-03 13:01:03,236][fairseq.trainer][INFO] - begin training epoch 159
[2022-01-03 13:01:03,237][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:01:17,260][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:01:17,655][valid][INFO] - {"epoch": 159, "valid_loss": "4.311", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "32.963", "valid_code_perplexity": "32.926", "valid_temp": "1.937", "valid_loss_0": "4.14", "valid_loss_1": "0.137", "valid_loss_2": "0.034", "valid_accuracy": "0.28068", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "6360", "valid_best_loss": "3.857"}
[2022-01-03 13:01:17,657][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 159 @ 6360 updates
[2022-01-03 13:01:17,658][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:01:21,378][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:01:21,401][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 159 @ 6360 updates, score 4.311) (writing took 3.7439701333642006 seconds)
[2022-01-03 13:01:21,402][fairseq_cli.train][INFO] - end of epoch 159 (average epoch stats below)
[2022-01-03 13:01:21,416][train][INFO] - {"epoch": 159, "train_loss": "4.262", "train_ntokens": "1772.65", "train_nsentences": "4.95", "train_prob_perplexity": "35.211", "train_code_perplexity": "35.185", "train_temp": "1.938", "train_loss_0": "4.088", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.2879", "train_wps": "3886.3", "train_ups": "2.19", "train_wpb": "1772.7", "train_bsz": "5", "train_num_updates": "6360", "train_lr": "9.9375e-05", "train_gnorm": "1.443", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "3099"}
[2022-01-03 13:01:21,469][fairseq.trainer][INFO] - begin training epoch 160
[2022-01-03 13:01:21,470][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:01:35,425][train_inner][INFO] - {"epoch": 160, "update": 160.0, "loss": "4.287", "ntokens": "1788.32", "nsentences": "4.95", "prob_perplexity": "34.966", "code_perplexity": "34.942", "temp": "1.938", "loss_0": "4.114", "loss_1": "0.136", "loss_2": "0.037", "accuracy": "0.28402", "wps": "3923.5", "ups": "2.19", "wpb": "1788.3", "bsz": "5", "num_updates": "6400", "lr": "0.0001", "gnorm": "1.422", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "3113"}
[2022-01-03 13:01:35,426][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:01:35,815][valid][INFO] - {"epoch": 160, "valid_loss": "4.379", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "32.165", "valid_code_perplexity": "32.183", "valid_temp": "1.937", "valid_loss_0": "4.205", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.28439", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "6400", "valid_best_loss": "3.857"}
[2022-01-03 13:01:35,819][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 160 @ 6400 updates
[2022-01-03 13:01:35,819][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:01:39,627][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:01:39,653][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 160 @ 6400 updates, score 4.379) (writing took 3.8344441428780556 seconds)
[2022-01-03 13:01:39,653][fairseq_cli.train][INFO] - end of epoch 160 (average epoch stats below)
[2022-01-03 13:01:39,666][train][INFO] - {"epoch": 160, "train_loss": "4.275", "train_ntokens": "1795.15", "train_nsentences": "4.95", "train_prob_perplexity": "35.288", "train_code_perplexity": "35.27", "train_temp": "1.937", "train_loss_0": "4.102", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28613", "train_wps": "3937.3", "train_ups": "2.19", "train_wpb": "1795.2", "train_bsz": "5", "train_num_updates": "6400", "train_lr": "0.0001", "train_gnorm": "1.385", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "3117"}
[2022-01-03 13:01:39,750][fairseq.trainer][INFO] - begin training epoch 161
[2022-01-03 13:01:39,751][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:01:53,681][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:01:54,081][valid][INFO] - {"epoch": 161, "valid_loss": "4.184", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "34.217", "valid_code_perplexity": "34.248", "valid_temp": "1.937", "valid_loss_0": "4.01", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.31398", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "6440", "valid_best_loss": "3.857"}
[2022-01-03 13:01:54,084][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 161 @ 6440 updates
[2022-01-03 13:01:54,085][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:01:57,888][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:01:57,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 161 @ 6440 updates, score 4.184) (writing took 3.832171441987157 seconds)
[2022-01-03 13:01:57,917][fairseq_cli.train][INFO] - end of epoch 161 (average epoch stats below)
[2022-01-03 13:01:57,930][train][INFO] - {"epoch": 161, "train_loss": "4.244", "train_ntokens": "1781.47", "train_nsentences": "4.95", "train_prob_perplexity": "35.16", "train_code_perplexity": "35.146", "train_temp": "1.937", "train_loss_0": "4.069", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28966", "train_wps": "3904.4", "train_ups": "2.19", "train_wpb": "1781.5", "train_bsz": "5", "train_num_updates": "6440", "train_lr": "0.000100625", "train_gnorm": "1.386", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "3135"}
[2022-01-03 13:01:58,002][fairseq.trainer][INFO] - begin training epoch 162
[2022-01-03 13:01:58,003][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:02:12,112][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:02:12,593][valid][INFO] - {"epoch": 162, "valid_loss": "4.321", "valid_ntokens": "686", "valid_nsentences": "2", "valid_prob_perplexity": "32.194", "valid_code_perplexity": "32.164", "valid_temp": "1.936", "valid_loss_0": "4.146", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.28571", "valid_wps": "0", "valid_wpb": "686", "valid_bsz": "2", "valid_num_updates": "6480", "valid_best_loss": "3.857"}
[2022-01-03 13:02:12,595][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 162 @ 6480 updates
[2022-01-03 13:02:12,596][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:02:16,504][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:02:16,534][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 162 @ 6480 updates, score 4.321) (writing took 3.939022636041045 seconds)
[2022-01-03 13:02:16,535][fairseq_cli.train][INFO] - end of epoch 162 (average epoch stats below)
[2022-01-03 13:02:16,548][train][INFO] - {"epoch": 162, "train_loss": "4.272", "train_ntokens": "1782.92", "train_nsentences": "4.95", "train_prob_perplexity": "35.317", "train_code_perplexity": "35.298", "train_temp": "1.936", "train_loss_0": "4.097", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28633", "train_wps": "3833.2", "train_ups": "2.15", "train_wpb": "1782.9", "train_bsz": "5", "train_num_updates": "6480", "train_lr": "0.00010125", "train_gnorm": "1.445", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3154"}
[2022-01-03 13:02:16,608][fairseq.trainer][INFO] - begin training epoch 163
[2022-01-03 13:02:16,609][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:02:30,519][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:02:31,024][valid][INFO] - {"epoch": 163, "valid_loss": "4.677", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "34.183", "valid_code_perplexity": "34.158", "valid_temp": "1.936", "valid_loss_0": "4.503", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.22715", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "6520", "valid_best_loss": "3.857"}
[2022-01-03 13:02:31,026][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 163 @ 6520 updates
[2022-01-03 13:02:31,026][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:02:35,075][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:02:35,105][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 163 @ 6520 updates, score 4.677) (writing took 4.0792104145511985 seconds)
[2022-01-03 13:02:35,106][fairseq_cli.train][INFO] - end of epoch 163 (average epoch stats below)
[2022-01-03 13:02:35,119][train][INFO] - {"epoch": 163, "train_loss": "4.27", "train_ntokens": "1799.4", "train_nsentences": "4.95", "train_prob_perplexity": "35.017", "train_code_perplexity": "35.012", "train_temp": "1.936", "train_loss_0": "4.097", "train_loss_1": "0.136", "train_loss_2": "0.036", "train_accuracy": "0.2874", "train_wps": "3878.5", "train_ups": "2.16", "train_wpb": "1799.4", "train_bsz": "5", "train_num_updates": "6520", "train_lr": "0.000101875", "train_gnorm": "1.414", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3173"}
[2022-01-03 13:02:35,182][fairseq.trainer][INFO] - begin training epoch 164
[2022-01-03 13:02:35,183][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:02:49,178][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:02:49,679][valid][INFO] - {"epoch": 164, "valid_loss": "4.188", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "33.398", "valid_code_perplexity": "33.311", "valid_temp": "1.935", "valid_loss_0": "4.014", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.2867", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "6560", "valid_best_loss": "3.857"}
[2022-01-03 13:02:49,680][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 164 @ 6560 updates
[2022-01-03 13:02:49,681][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:02:53,631][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:02:53,658][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 164 @ 6560 updates, score 4.188) (writing took 3.977527284063399 seconds)
[2022-01-03 13:02:53,658][fairseq_cli.train][INFO] - end of epoch 164 (average epoch stats below)
[2022-01-03 13:02:53,671][train][INFO] - {"epoch": 164, "train_loss": "4.312", "train_ntokens": "1777.08", "train_nsentences": "4.95", "train_prob_perplexity": "35.554", "train_code_perplexity": "35.54", "train_temp": "1.936", "train_loss_0": "4.138", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28001", "train_wps": "3834.2", "train_ups": "2.16", "train_wpb": "1777.1", "train_bsz": "5", "train_num_updates": "6560", "train_lr": "0.0001025", "train_gnorm": "1.399", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3191"}
[2022-01-03 13:02:53,743][fairseq.trainer][INFO] - begin training epoch 165
[2022-01-03 13:02:53,744][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:03:07,803][train_inner][INFO] - {"epoch": 165, "update": 165.0, "loss": "4.266", "ntokens": "1787.82", "nsentences": "4.95", "prob_perplexity": "35.238", "code_perplexity": "35.224", "temp": "1.936", "loss_0": "4.092", "loss_1": "0.136", "loss_2": "0.038", "accuracy": "0.28688", "wps": "3871.2", "ups": "2.17", "wpb": "1787.8", "bsz": "5", "num_updates": "6600", "lr": "0.000103125", "gnorm": "1.407", "clip": "0", "train_wall": "68", "gb_free": "6.6", "wall": "3205"}
[2022-01-03 13:03:07,804][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:03:08,207][valid][INFO] - {"epoch": 165, "valid_loss": "4.006", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "32.567", "valid_code_perplexity": "32.529", "valid_temp": "1.935", "valid_loss_0": "3.834", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.33113", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "6600", "valid_best_loss": "3.857"}
[2022-01-03 13:03:08,210][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 165 @ 6600 updates
[2022-01-03 13:03:08,210][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:03:12,119][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:03:12,143][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 165 @ 6600 updates, score 4.006) (writing took 3.933586032129824 seconds)
[2022-01-03 13:03:12,144][fairseq_cli.train][INFO] - end of epoch 165 (average epoch stats below)
[2022-01-03 13:03:12,156][train][INFO] - {"epoch": 165, "train_loss": "4.235", "train_ntokens": "1798.2", "train_nsentences": "4.95", "train_prob_perplexity": "35.143", "train_code_perplexity": "35.126", "train_temp": "1.935", "train_loss_0": "4.061", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.29092", "train_wps": "3893.7", "train_ups": "2.17", "train_wpb": "1798.2", "train_bsz": "5", "train_num_updates": "6600", "train_lr": "0.000103125", "train_gnorm": "1.392", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "3210"}
[2022-01-03 13:03:12,226][fairseq.trainer][INFO] - begin training epoch 166
[2022-01-03 13:03:12,227][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:03:26,153][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:03:26,709][valid][INFO] - {"epoch": 166, "valid_loss": "4.213", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "32.826", "valid_code_perplexity": "32.804", "valid_temp": "1.935", "valid_loss_0": "4.036", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.30845", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "6640", "valid_best_loss": "3.857"}
[2022-01-03 13:03:26,711][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 166 @ 6640 updates
[2022-01-03 13:03:26,711][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:03:30,582][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:03:30,611][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 166 @ 6640 updates, score 4.213) (writing took 3.9007458621636033 seconds)
[2022-01-03 13:03:30,612][fairseq_cli.train][INFO] - end of epoch 166 (average epoch stats below)
[2022-01-03 13:03:30,625][train][INFO] - {"epoch": 166, "train_loss": "4.27", "train_ntokens": "1788.38", "train_nsentences": "4.95", "train_prob_perplexity": "34.951", "train_code_perplexity": "34.933", "train_temp": "1.935", "train_loss_0": "4.094", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28766", "train_wps": "3876", "train_ups": "2.17", "train_wpb": "1788.4", "train_bsz": "5", "train_num_updates": "6640", "train_lr": "0.00010375", "train_gnorm": "1.396", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "3228"}
[2022-01-03 13:03:30,683][fairseq.trainer][INFO] - begin training epoch 167
[2022-01-03 13:03:30,684][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:03:44,653][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:03:45,065][valid][INFO] - {"epoch": 167, "valid_loss": "4.664", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "34.834", "valid_code_perplexity": "34.888", "valid_temp": "1.934", "valid_loss_0": "4.488", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.22507", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "6680", "valid_best_loss": "3.857"}
[2022-01-03 13:03:45,068][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 167 @ 6680 updates
[2022-01-03 13:03:45,068][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:03:48,811][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:03:48,837][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 167 @ 6680 updates, score 4.664) (writing took 3.7695001075044274 seconds)
[2022-01-03 13:03:48,838][fairseq_cli.train][INFO] - end of epoch 167 (average epoch stats below)
[2022-01-03 13:03:48,851][train][INFO] - {"epoch": 167, "train_loss": "4.267", "train_ntokens": "1777.25", "train_nsentences": "4.95", "train_prob_perplexity": "34.407", "train_code_perplexity": "34.385", "train_temp": "1.935", "train_loss_0": "4.089", "train_loss_1": "0.137", "train_loss_2": "0.041", "train_accuracy": "0.2897", "train_wps": "3903.4", "train_ups": "2.2", "train_wpb": "1777.2", "train_bsz": "5", "train_num_updates": "6680", "train_lr": "0.000104375", "train_gnorm": "1.429", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3246"}
[2022-01-03 13:03:48,895][fairseq.trainer][INFO] - begin training epoch 168
[2022-01-03 13:03:48,896][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:04:02,881][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:04:03,312][valid][INFO] - {"epoch": 168, "valid_loss": "4.207", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "30.598", "valid_code_perplexity": "30.603", "valid_temp": "1.934", "valid_loss_0": "4.03", "valid_loss_1": "0.137", "valid_loss_2": "0.04", "valid_accuracy": "0.30607", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "6720", "valid_best_loss": "3.857"}
[2022-01-03 13:04:03,314][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 168 @ 6720 updates
[2022-01-03 13:04:03,315][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:04:07,209][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:04:07,227][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 168 @ 6720 updates, score 4.207) (writing took 3.9132194006815553 seconds)
[2022-01-03 13:04:07,228][fairseq_cli.train][INFO] - end of epoch 168 (average epoch stats below)
[2022-01-03 13:04:07,240][train][INFO] - {"epoch": 168, "train_loss": "4.237", "train_ntokens": "1795.1", "train_nsentences": "4.95", "train_prob_perplexity": "35.239", "train_code_perplexity": "35.223", "train_temp": "1.934", "train_loss_0": "4.06", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29331", "train_wps": "3907.4", "train_ups": "2.18", "train_wpb": "1795.1", "train_bsz": "5", "train_num_updates": "6720", "train_lr": "0.000105", "train_gnorm": "1.349", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3265"}
[2022-01-03 13:04:07,290][fairseq.trainer][INFO] - begin training epoch 169
[2022-01-03 13:04:07,291][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:04:21,274][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:04:21,685][valid][INFO] - {"epoch": 169, "valid_loss": "4.263", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "30.832", "valid_code_perplexity": "30.823", "valid_temp": "1.934", "valid_loss_0": "4.083", "valid_loss_1": "0.137", "valid_loss_2": "0.042", "valid_accuracy": "0.28462", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "6760", "valid_best_loss": "3.857"}
[2022-01-03 13:04:21,688][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 169 @ 6760 updates
[2022-01-03 13:04:21,689][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:04:25,330][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:04:25,358][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 169 @ 6760 updates, score 4.263) (writing took 3.6701411679387093 seconds)
[2022-01-03 13:04:25,359][fairseq_cli.train][INFO] - end of epoch 169 (average epoch stats below)
[2022-01-03 13:04:25,371][train][INFO] - {"epoch": 169, "train_loss": "4.238", "train_ntokens": "1792.83", "train_nsentences": "4.95", "train_prob_perplexity": "34.484", "train_code_perplexity": "34.471", "train_temp": "1.934", "train_loss_0": "4.062", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.29233", "train_wps": "3958", "train_ups": "2.21", "train_wpb": "1792.8", "train_bsz": "5", "train_num_updates": "6760", "train_lr": "0.000105625", "train_gnorm": "1.382", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3283"}
[2022-01-03 13:04:25,447][fairseq.trainer][INFO] - begin training epoch 170
[2022-01-03 13:04:25,448][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:04:39,192][train_inner][INFO] - {"epoch": 170, "update": 170.0, "loss": "4.253", "ntokens": "1792.94", "nsentences": "4.95", "prob_perplexity": "34.847", "code_perplexity": "34.83", "temp": "1.934", "loss_0": "4.077", "loss_1": "0.136", "loss_2": "0.04", "accuracy": "0.29024", "wps": "3924.3", "ups": "2.19", "wpb": "1792.9", "bsz": "5", "num_updates": "6800", "lr": "0.00010625", "gnorm": "1.384", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "3297"}
[2022-01-03 13:04:39,193][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:04:39,658][valid][INFO] - {"epoch": 170, "valid_loss": "4.327", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "32.055", "valid_code_perplexity": "31.954", "valid_temp": "1.933", "valid_loss_0": "4.147", "valid_loss_1": "0.137", "valid_loss_2": "0.042", "valid_accuracy": "0.27415", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "6800", "valid_best_loss": "3.857"}
[2022-01-03 13:04:39,660][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 170 @ 6800 updates
[2022-01-03 13:04:39,660][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:04:43,609][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:04:43,634][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 170 @ 6800 updates, score 4.327) (writing took 3.974739142693579 seconds)
[2022-01-03 13:04:43,635][fairseq_cli.train][INFO] - end of epoch 170 (average epoch stats below)
[2022-01-03 13:04:43,648][train][INFO] - {"epoch": 170, "train_loss": "4.254", "train_ntokens": "1811.15", "train_nsentences": "4.95", "train_prob_perplexity": "35.154", "train_code_perplexity": "35.14", "train_temp": "1.933", "train_loss_0": "4.078", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28819", "train_wps": "3966.7", "train_ups": "2.19", "train_wpb": "1811.2", "train_bsz": "5", "train_num_updates": "6800", "train_lr": "0.00010625", "train_gnorm": "1.367", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "3301"}
[2022-01-03 13:04:43,720][fairseq.trainer][INFO] - begin training epoch 171
[2022-01-03 13:04:43,721][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:04:57,561][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:04:57,994][valid][INFO] - {"epoch": 171, "valid_loss": "4.272", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "30.473", "valid_code_perplexity": "30.446", "valid_temp": "1.933", "valid_loss_0": "4.096", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.28571", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "6840", "valid_best_loss": "3.857"}
[2022-01-03 13:04:57,998][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 171 @ 6840 updates
[2022-01-03 13:04:57,999][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:05:01,815][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:05:01,838][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 171 @ 6840 updates, score 4.272) (writing took 3.839918375015259 seconds)
[2022-01-03 13:05:01,839][fairseq_cli.train][INFO] - end of epoch 171 (average epoch stats below)
[2022-01-03 13:05:01,854][train][INFO] - {"epoch": 171, "train_loss": "4.274", "train_ntokens": "1791.42", "train_nsentences": "4.95", "train_prob_perplexity": "35.062", "train_code_perplexity": "35.046", "train_temp": "1.933", "train_loss_0": "4.099", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28458", "train_wps": "3939.3", "train_ups": "2.2", "train_wpb": "1791.4", "train_bsz": "5", "train_num_updates": "6840", "train_lr": "0.000106875", "train_gnorm": "1.346", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3319"}
[2022-01-03 13:05:01,925][fairseq.trainer][INFO] - begin training epoch 172
[2022-01-03 13:05:01,926][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:05:16,014][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:05:16,455][valid][INFO] - {"epoch": 172, "valid_loss": "4.19", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "34.176", "valid_code_perplexity": "34.115", "valid_temp": "1.932", "valid_loss_0": "4.015", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.28068", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "6880", "valid_best_loss": "3.857"}
[2022-01-03 13:05:16,458][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 172 @ 6880 updates
[2022-01-03 13:05:16,459][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:05:20,090][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:05:20,118][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 172 @ 6880 updates, score 4.19) (writing took 3.6601176001131535 seconds)
[2022-01-03 13:05:20,119][fairseq_cli.train][INFO] - end of epoch 172 (average epoch stats below)
[2022-01-03 13:05:20,131][train][INFO] - {"epoch": 172, "train_loss": "4.245", "train_ntokens": "1805.8", "train_nsentences": "4.95", "train_prob_perplexity": "35.208", "train_code_perplexity": "35.19", "train_temp": "1.933", "train_loss_0": "4.069", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28779", "train_wps": "3954.7", "train_ups": "2.19", "train_wpb": "1805.8", "train_bsz": "5", "train_num_updates": "6880", "train_lr": "0.0001075", "train_gnorm": "1.305", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3338"}
[2022-01-03 13:05:20,187][fairseq.trainer][INFO] - begin training epoch 173
[2022-01-03 13:05:20,188][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:05:34,083][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:05:34,488][valid][INFO] - {"epoch": 173, "valid_loss": "4.415", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "35.325", "valid_code_perplexity": "35.237", "valid_temp": "1.932", "valid_loss_0": "4.24", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.25565", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "6920", "valid_best_loss": "3.857"}
[2022-01-03 13:05:34,491][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 173 @ 6920 updates
[2022-01-03 13:05:34,492][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:05:38,295][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:05:38,309][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 173 @ 6920 updates, score 4.415) (writing took 3.817805319093168 seconds)
[2022-01-03 13:05:38,309][fairseq_cli.train][INFO] - end of epoch 173 (average epoch stats below)
[2022-01-03 13:05:38,322][train][INFO] - {"epoch": 173, "train_loss": "4.274", "train_ntokens": "1797.12", "train_nsentences": "4.95", "train_prob_perplexity": "35.567", "train_code_perplexity": "35.549", "train_temp": "1.932", "train_loss_0": "4.096", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.28447", "train_wps": "3954.5", "train_ups": "2.2", "train_wpb": "1797.1", "train_bsz": "5", "train_num_updates": "6920", "train_lr": "0.000108125", "train_gnorm": "1.318", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "3356"}
[2022-01-03 13:05:38,394][fairseq.trainer][INFO] - begin training epoch 174
[2022-01-03 13:05:38,394][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:05:52,514][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:05:53,025][valid][INFO] - {"epoch": 174, "valid_loss": "3.989", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "34.856", "valid_code_perplexity": "34.86", "valid_temp": "1.932", "valid_loss_0": "3.813", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.33429", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "6960", "valid_best_loss": "3.857"}
[2022-01-03 13:05:53,027][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 174 @ 6960 updates
[2022-01-03 13:05:53,027][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:05:57,120][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:05:57,149][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 174 @ 6960 updates, score 3.989) (writing took 4.122596664354205 seconds)
[2022-01-03 13:05:57,150][fairseq_cli.train][INFO] - end of epoch 174 (average epoch stats below)
[2022-01-03 13:05:57,162][train][INFO] - {"epoch": 174, "train_loss": "4.226", "train_ntokens": "1800.97", "train_nsentences": "4.95", "train_prob_perplexity": "35.128", "train_code_perplexity": "35.105", "train_temp": "1.932", "train_loss_0": "4.05", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.29263", "train_wps": "3826.2", "train_ups": "2.12", "train_wpb": "1801", "train_bsz": "5", "train_num_updates": "6960", "train_lr": "0.00010875", "train_gnorm": "1.295", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3375"}
[2022-01-03 13:05:57,221][fairseq.trainer][INFO] - begin training epoch 175
[2022-01-03 13:05:57,221][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:06:11,035][train_inner][INFO] - {"epoch": 175, "update": 175.0, "loss": "4.257", "ntokens": "1797.96", "nsentences": "4.95", "prob_perplexity": "35.211", "code_perplexity": "35.192", "temp": "1.932", "loss_0": "4.081", "loss_1": "0.136", "loss_2": "0.04", "accuracy": "0.28674", "wps": "3915.8", "ups": "2.18", "wpb": "1798", "bsz": "5", "num_updates": "7000", "lr": "0.000109375", "gnorm": "1.314", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "3388"}
[2022-01-03 13:06:11,036][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:06:11,435][valid][INFO] - {"epoch": 175, "valid_loss": "3.851", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "34.582", "valid_code_perplexity": "34.531", "valid_temp": "1.931", "valid_loss_0": "3.678", "valid_loss_1": "0.136", "valid_loss_2": "0.036", "valid_accuracy": "0.32984", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "7000", "valid_best_loss": "3.851"}
[2022-01-03 13:06:11,438][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 175 @ 7000 updates
[2022-01-03 13:06:11,439][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 13:06:15,404][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 13:06:22,679][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 175 @ 7000 updates, score 3.851) (writing took 11.240596543997526 seconds)
[2022-01-03 13:06:22,679][fairseq_cli.train][INFO] - end of epoch 175 (average epoch stats below)
[2022-01-03 13:06:22,692][train][INFO] - {"epoch": 175, "train_loss": "4.267", "train_ntokens": "1794.5", "train_nsentences": "4.95", "train_prob_perplexity": "35.089", "train_code_perplexity": "35.071", "train_temp": "1.931", "train_loss_0": "4.091", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.2842", "train_wps": "2813.1", "train_ups": "1.57", "train_wpb": "1794.5", "train_bsz": "5", "train_num_updates": "7000", "train_lr": "0.000109375", "train_gnorm": "1.307", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3400"}
[2022-01-03 13:06:22,789][fairseq.trainer][INFO] - begin training epoch 176
[2022-01-03 13:06:22,790][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:06:36,558][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:06:36,977][valid][INFO] - {"epoch": 176, "valid_loss": "4.538", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "35.594", "valid_code_perplexity": "35.583", "valid_temp": "1.931", "valid_loss_0": "4.363", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.23713", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "7040", "valid_best_loss": "3.851"}
[2022-01-03 13:06:36,979][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 176 @ 7040 updates
[2022-01-03 13:06:36,980][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:06:40,913][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:06:40,935][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 176 @ 7040 updates, score 4.538) (writing took 3.9562209956347942 seconds)
[2022-01-03 13:06:40,936][fairseq_cli.train][INFO] - end of epoch 176 (average epoch stats below)
[2022-01-03 13:06:40,949][train][INFO] - {"epoch": 176, "train_loss": "4.234", "train_ntokens": "1780.6", "train_nsentences": "4.95", "train_prob_perplexity": "35.064", "train_code_perplexity": "35.046", "train_temp": "1.931", "train_loss_0": "4.061", "train_loss_1": "0.136", "train_loss_2": "0.036", "train_accuracy": "0.29138", "train_wps": "3904", "train_ups": "2.19", "train_wpb": "1780.6", "train_bsz": "5", "train_num_updates": "7040", "train_lr": "0.00011", "train_gnorm": "1.319", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "3418"}
[2022-01-03 13:06:41,029][fairseq.trainer][INFO] - begin training epoch 177
[2022-01-03 13:06:41,030][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:06:54,991][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:06:55,481][valid][INFO] - {"epoch": 177, "valid_loss": "4.311", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "31.803", "valid_code_perplexity": "31.774", "valid_temp": "1.93", "valid_loss_0": "4.137", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.30155", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "7080", "valid_best_loss": "3.851"}
[2022-01-03 13:06:55,483][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 177 @ 7080 updates
[2022-01-03 13:06:55,484][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:06:59,125][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:06:59,149][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 177 @ 7080 updates, score 4.311) (writing took 3.666027526371181 seconds)
[2022-01-03 13:06:59,150][fairseq_cli.train][INFO] - end of epoch 177 (average epoch stats below)
[2022-01-03 13:06:59,164][train][INFO] - {"epoch": 177, "train_loss": "4.247", "train_ntokens": "1788.15", "train_nsentences": "4.95", "train_prob_perplexity": "35.987", "train_code_perplexity": "35.964", "train_temp": "1.931", "train_loss_0": "4.074", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28745", "train_wps": "3929.8", "train_ups": "2.2", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "7080", "train_lr": "0.000110625", "train_gnorm": "1.298", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "3437"}
[2022-01-03 13:06:59,241][fairseq.trainer][INFO] - begin training epoch 178
[2022-01-03 13:06:59,241][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:07:13,079][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:07:13,504][valid][INFO] - {"epoch": 178, "valid_loss": "4.492", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "32.738", "valid_code_perplexity": "32.708", "valid_temp": "1.93", "valid_loss_0": "4.316", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.25714", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "7120", "valid_best_loss": "3.851"}
[2022-01-03 13:07:13,506][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 178 @ 7120 updates
[2022-01-03 13:07:13,507][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:07:17,390][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:07:17,404][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 178 @ 7120 updates, score 4.492) (writing took 3.8982338486239314 seconds)
[2022-01-03 13:07:17,405][fairseq_cli.train][INFO] - end of epoch 178 (average epoch stats below)
[2022-01-03 13:07:17,418][train][INFO] - {"epoch": 178, "train_loss": "4.265", "train_ntokens": "1806.05", "train_nsentences": "4.95", "train_prob_perplexity": "34.736", "train_code_perplexity": "34.719", "train_temp": "1.93", "train_loss_0": "4.091", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28643", "train_wps": "3960.4", "train_ups": "2.19", "train_wpb": "1806", "train_bsz": "5", "train_num_updates": "7120", "train_lr": "0.00011125", "train_gnorm": "1.301", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3455"}
[2022-01-03 13:07:17,493][fairseq.trainer][INFO] - begin training epoch 179
[2022-01-03 13:07:17,494][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:07:31,491][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:07:31,894][valid][INFO] - {"epoch": 179, "valid_loss": "4.152", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "34.853", "valid_code_perplexity": "34.813", "valid_temp": "1.93", "valid_loss_0": "3.975", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.3094", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "7160", "valid_best_loss": "3.851"}
[2022-01-03 13:07:31,897][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 179 @ 7160 updates
[2022-01-03 13:07:31,897][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:07:35,597][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:07:35,626][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 179 @ 7160 updates, score 4.152) (writing took 3.729446940124035 seconds)
[2022-01-03 13:07:35,627][fairseq_cli.train][INFO] - end of epoch 179 (average epoch stats below)
[2022-01-03 13:07:35,639][train][INFO] - {"epoch": 179, "train_loss": "4.219", "train_ntokens": "1791.35", "train_nsentences": "4.95", "train_prob_perplexity": "35.312", "train_code_perplexity": "35.284", "train_temp": "1.93", "train_loss_0": "4.043", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.2939", "train_wps": "3935.2", "train_ups": "2.2", "train_wpb": "1791.3", "train_bsz": "5", "train_num_updates": "7160", "train_lr": "0.000111875", "train_gnorm": "1.272", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3473"}
[2022-01-03 13:07:35,691][fairseq.trainer][INFO] - begin training epoch 180
[2022-01-03 13:07:35,692][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:07:49,761][train_inner][INFO] - {"epoch": 180, "update": 180.0, "loss": "4.245", "ntokens": "1791.18", "nsentences": "4.95", "prob_perplexity": "35.416", "code_perplexity": "35.396", "temp": "1.93", "loss_0": "4.07", "loss_1": "0.136", "loss_2": "0.039", "accuracy": "0.28915", "wps": "3629.1", "ups": "2.03", "wpb": "1791.2", "bsz": "5", "num_updates": "7200", "lr": "0.0001125", "gnorm": "1.307", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "3487"}
[2022-01-03 13:07:49,763][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:07:50,218][valid][INFO] - {"epoch": 180, "valid_loss": "4.337", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "32.518", "valid_code_perplexity": "32.568", "valid_temp": "1.929", "valid_loss_0": "4.161", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.29716", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "7200", "valid_best_loss": "3.851"}
[2022-01-03 13:07:50,220][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 180 @ 7200 updates
[2022-01-03 13:07:50,221][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:07:53,867][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:07:53,892][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 180 @ 7200 updates, score 4.337) (writing took 3.671348593197763 seconds)
[2022-01-03 13:07:53,892][fairseq_cli.train][INFO] - end of epoch 180 (average epoch stats below)
[2022-01-03 13:07:53,905][train][INFO] - {"epoch": 180, "train_loss": "4.26", "train_ntokens": "1789.78", "train_nsentences": "4.95", "train_prob_perplexity": "35.981", "train_code_perplexity": "35.969", "train_temp": "1.929", "train_loss_0": "4.082", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.28664", "train_wps": "3922.1", "train_ups": "2.19", "train_wpb": "1789.8", "train_bsz": "5", "train_num_updates": "7200", "train_lr": "0.0001125", "train_gnorm": "1.345", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "3491"}
[2022-01-03 13:07:53,966][fairseq.trainer][INFO] - begin training epoch 181
[2022-01-03 13:07:53,967][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:08:07,782][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:08:08,262][valid][INFO] - {"epoch": 181, "valid_loss": "4.745", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "35.221", "valid_code_perplexity": "35.263", "valid_temp": "1.929", "valid_loss_0": "4.571", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.20533", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "7240", "valid_best_loss": "3.851"}
[2022-01-03 13:08:08,264][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 181 @ 7240 updates
[2022-01-03 13:08:08,264][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:08:12,174][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:08:12,201][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 181 @ 7240 updates, score 4.745) (writing took 3.9371639089658856 seconds)
[2022-01-03 13:08:12,201][fairseq_cli.train][INFO] - end of epoch 181 (average epoch stats below)
[2022-01-03 13:08:12,214][train][INFO] - {"epoch": 181, "train_loss": "4.236", "train_ntokens": "1781.97", "train_nsentences": "4.95", "train_prob_perplexity": "35.694", "train_code_perplexity": "35.677", "train_temp": "1.929", "train_loss_0": "4.06", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29218", "train_wps": "3895.9", "train_ups": "2.19", "train_wpb": "1782", "train_bsz": "5", "train_num_updates": "7240", "train_lr": "0.000113125", "train_gnorm": "1.281", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3510"}
[2022-01-03 13:08:12,286][fairseq.trainer][INFO] - begin training epoch 182
[2022-01-03 13:08:12,287][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:08:26,143][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:08:26,641][valid][INFO] - {"epoch": 182, "valid_loss": "4.174", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "35.983", "valid_code_perplexity": "35.937", "valid_temp": "1.929", "valid_loss_0": "3.999", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.27684", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "7280", "valid_best_loss": "3.851"}
[2022-01-03 13:08:26,643][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 182 @ 7280 updates
[2022-01-03 13:08:26,644][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:08:30,368][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:08:30,398][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 182 @ 7280 updates, score 4.174) (writing took 3.7544791977852583 seconds)
[2022-01-03 13:08:30,398][fairseq_cli.train][INFO] - end of epoch 182 (average epoch stats below)
[2022-01-03 13:08:30,411][train][INFO] - {"epoch": 182, "train_loss": "4.233", "train_ntokens": "1797.33", "train_nsentences": "4.95", "train_prob_perplexity": "36.118", "train_code_perplexity": "36.107", "train_temp": "1.929", "train_loss_0": "4.057", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.28786", "train_wps": "3953.6", "train_ups": "2.2", "train_wpb": "1797.3", "train_bsz": "5", "train_num_updates": "7280", "train_lr": "0.00011375", "train_gnorm": "1.362", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3528"}
[2022-01-03 13:08:30,487][fairseq.trainer][INFO] - begin training epoch 183
[2022-01-03 13:08:30,488][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:08:44,528][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:08:45,020][valid][INFO] - {"epoch": 183, "valid_loss": "4.179", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "36.337", "valid_code_perplexity": "36.3", "valid_temp": "1.928", "valid_loss_0": "4.005", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.2894", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "7320", "valid_best_loss": "3.851"}
[2022-01-03 13:08:45,023][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 183 @ 7320 updates
[2022-01-03 13:08:45,023][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:08:49,031][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:08:49,059][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 183 @ 7320 updates, score 4.179) (writing took 4.035925328731537 seconds)
[2022-01-03 13:08:49,059][fairseq_cli.train][INFO] - end of epoch 183 (average epoch stats below)
[2022-01-03 13:08:49,072][train][INFO] - {"epoch": 183, "train_loss": "4.263", "train_ntokens": "1799.8", "train_nsentences": "4.95", "train_prob_perplexity": "36.313", "train_code_perplexity": "36.295", "train_temp": "1.928", "train_loss_0": "4.089", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28502", "train_wps": "3860.5", "train_ups": "2.14", "train_wpb": "1799.8", "train_bsz": "5", "train_num_updates": "7320", "train_lr": "0.000114375", "train_gnorm": "1.249", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3546"}
[2022-01-03 13:08:49,129][fairseq.trainer][INFO] - begin training epoch 184
[2022-01-03 13:08:49,130][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:09:03,133][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:09:03,536][valid][INFO] - {"epoch": 184, "valid_loss": "4.158", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "34.048", "valid_code_perplexity": "34.039", "valid_temp": "1.928", "valid_loss_0": "3.984", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.2963", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "7360", "valid_best_loss": "3.851"}
[2022-01-03 13:09:03,538][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 184 @ 7360 updates
[2022-01-03 13:09:03,539][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:09:07,590][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:09:07,618][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 184 @ 7360 updates, score 4.158) (writing took 4.079660155810416 seconds)
[2022-01-03 13:09:07,619][fairseq_cli.train][INFO] - end of epoch 184 (average epoch stats below)
[2022-01-03 13:09:07,631][train][INFO] - {"epoch": 184, "train_loss": "4.254", "train_ntokens": "1795.5", "train_nsentences": "4.95", "train_prob_perplexity": "35.339", "train_code_perplexity": "35.318", "train_temp": "1.928", "train_loss_0": "4.077", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.28741", "train_wps": "3872.4", "train_ups": "2.16", "train_wpb": "1795.5", "train_bsz": "5", "train_num_updates": "7360", "train_lr": "0.000115", "train_gnorm": "1.294", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3565"}
[2022-01-03 13:09:07,701][fairseq.trainer][INFO] - begin training epoch 185
[2022-01-03 13:09:07,702][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:09:21,738][train_inner][INFO] - {"epoch": 185, "update": 185.0, "loss": "4.239", "ntokens": "1789.94", "nsentences": "4.95", "prob_perplexity": "35.92", "code_perplexity": "35.904", "temp": "1.928", "loss_0": "4.063", "loss_1": "0.136", "loss_2": "0.04", "accuracy": "0.28944", "wps": "3892.7", "ups": "2.17", "wpb": "1789.9", "bsz": "5", "num_updates": "7400", "lr": "0.000115625", "gnorm": "1.3", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "3579"}
[2022-01-03 13:09:21,739][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:09:22,155][valid][INFO] - {"epoch": 185, "valid_loss": "4.377", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "33.453", "valid_code_perplexity": "33.457", "valid_temp": "1.927", "valid_loss_0": "4.2", "valid_loss_1": "0.137", "valid_loss_2": "0.04", "valid_accuracy": "0.2619", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "7400", "valid_best_loss": "3.851"}
[2022-01-03 13:09:22,158][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 185 @ 7400 updates
[2022-01-03 13:09:22,158][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:09:26,096][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:09:26,124][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 185 @ 7400 updates, score 4.377) (writing took 3.966896465048194 seconds)
[2022-01-03 13:09:26,125][fairseq_cli.train][INFO] - end of epoch 185 (average epoch stats below)
[2022-01-03 13:09:26,141][train][INFO] - {"epoch": 185, "train_loss": "4.21", "train_ntokens": "1775.12", "train_nsentences": "4.95", "train_prob_perplexity": "36.137", "train_code_perplexity": "36.121", "train_temp": "1.928", "train_loss_0": "4.033", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29481", "train_wps": "3839.4", "train_ups": "2.16", "train_wpb": "1775.1", "train_bsz": "5", "train_num_updates": "7400", "train_lr": "0.000115625", "train_gnorm": "1.312", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3584"}
[2022-01-03 13:09:26,206][fairseq.trainer][INFO] - begin training epoch 186
[2022-01-03 13:09:26,207][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:09:40,165][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:09:40,664][valid][INFO] - {"epoch": 186, "valid_loss": "3.866", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "33.981", "valid_code_perplexity": "33.964", "valid_temp": "1.927", "valid_loss_0": "3.686", "valid_loss_1": "0.137", "valid_loss_2": "0.044", "valid_accuracy": "0.35028", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "7440", "valid_best_loss": "3.851"}
[2022-01-03 13:09:40,666][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 186 @ 7440 updates
[2022-01-03 13:09:40,666][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:09:44,536][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:09:44,563][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 186 @ 7440 updates, score 3.866) (writing took 3.8967072386294603 seconds)
[2022-01-03 13:09:44,563][fairseq_cli.train][INFO] - end of epoch 186 (average epoch stats below)
[2022-01-03 13:09:44,576][train][INFO] - {"epoch": 186, "train_loss": "4.212", "train_ntokens": "1769.5", "train_nsentences": "4.95", "train_prob_perplexity": "35.341", "train_code_perplexity": "35.316", "train_temp": "1.927", "train_loss_0": "4.037", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.2946", "train_wps": "3842.1", "train_ups": "2.17", "train_wpb": "1769.5", "train_bsz": "5", "train_num_updates": "7440", "train_lr": "0.00011625", "train_gnorm": "1.31", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "3602"}
[2022-01-03 13:09:44,646][fairseq.trainer][INFO] - begin training epoch 187
[2022-01-03 13:09:44,647][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:09:58,606][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:09:59,015][valid][INFO] - {"epoch": 187, "valid_loss": "4.291", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "33.974", "valid_code_perplexity": "33.943", "valid_temp": "1.927", "valid_loss_0": "4.116", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.29444", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "7480", "valid_best_loss": "3.851"}
[2022-01-03 13:09:59,019][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 187 @ 7480 updates
[2022-01-03 13:09:59,019][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:10:02,917][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:10:02,930][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 187 @ 7480 updates, score 4.291) (writing took 3.91077540256083 seconds)
[2022-01-03 13:10:02,930][fairseq_cli.train][INFO] - end of epoch 187 (average epoch stats below)
[2022-01-03 13:10:02,943][train][INFO] - {"epoch": 187, "train_loss": "4.246", "train_ntokens": "1782.95", "train_nsentences": "4.95", "train_prob_perplexity": "36.13", "train_code_perplexity": "36.112", "train_temp": "1.927", "train_loss_0": "4.069", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.28831", "train_wps": "3885.7", "train_ups": "2.18", "train_wpb": "1783", "train_bsz": "5", "train_num_updates": "7480", "train_lr": "0.000116875", "train_gnorm": "1.272", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3620"}
[2022-01-03 13:10:02,996][fairseq.trainer][INFO] - begin training epoch 188
[2022-01-03 13:10:02,997][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:10:17,025][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:10:17,527][valid][INFO] - {"epoch": 188, "valid_loss": "4.33", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "35.753", "valid_code_perplexity": "35.711", "valid_temp": "1.926", "valid_loss_0": "4.156", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.26762", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "7520", "valid_best_loss": "3.851"}
[2022-01-03 13:10:17,529][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 188 @ 7520 updates
[2022-01-03 13:10:17,530][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:10:21,187][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:10:21,214][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 188 @ 7520 updates, score 4.33) (writing took 3.6850598510354757 seconds)
[2022-01-03 13:10:21,215][fairseq_cli.train][INFO] - end of epoch 188 (average epoch stats below)
[2022-01-03 13:10:21,228][train][INFO] - {"epoch": 188, "train_loss": "4.191", "train_ntokens": "1784.38", "train_nsentences": "4.95", "train_prob_perplexity": "36.223", "train_code_perplexity": "36.209", "train_temp": "1.926", "train_loss_0": "4.018", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.29314", "train_wps": "3906.2", "train_ups": "2.19", "train_wpb": "1784.4", "train_bsz": "5", "train_num_updates": "7520", "train_lr": "0.0001175", "train_gnorm": "1.298", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "3639"}
[2022-01-03 13:10:21,279][fairseq.trainer][INFO] - begin training epoch 189
[2022-01-03 13:10:21,280][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:10:35,114][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:10:35,602][valid][INFO] - {"epoch": 189, "valid_loss": "3.94", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "35.159", "valid_code_perplexity": "35.127", "valid_temp": "1.926", "valid_loss_0": "3.765", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.33418", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "7560", "valid_best_loss": "3.851"}
[2022-01-03 13:10:35,604][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 189 @ 7560 updates
[2022-01-03 13:10:35,605][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:10:39,530][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:10:39,557][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 189 @ 7560 updates, score 3.94) (writing took 3.952913422137499 seconds)
[2022-01-03 13:10:39,558][fairseq_cli.train][INFO] - end of epoch 189 (average epoch stats below)
[2022-01-03 13:10:39,572][train][INFO] - {"epoch": 189, "train_loss": "4.255", "train_ntokens": "1791.67", "train_nsentences": "4.95", "train_prob_perplexity": "36.173", "train_code_perplexity": "36.162", "train_temp": "1.926", "train_loss_0": "4.081", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28401", "train_wps": "3909.8", "train_ups": "2.18", "train_wpb": "1791.7", "train_bsz": "5", "train_num_updates": "7560", "train_lr": "0.000118125", "train_gnorm": "1.265", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "3657"}
[2022-01-03 13:10:39,645][fairseq.trainer][INFO] - begin training epoch 190
[2022-01-03 13:10:39,645][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:10:53,640][train_inner][INFO] - {"epoch": 190, "update": 190.0, "loss": "4.223", "ntokens": "1781.01", "nsentences": "4.95", "prob_perplexity": "36.042", "code_perplexity": "36.025", "temp": "1.926", "loss_0": "4.047", "loss_1": "0.136", "loss_2": "0.039", "accuracy": "0.29007", "wps": "3876.4", "ups": "2.18", "wpb": "1781", "bsz": "5", "num_updates": "7600", "lr": "0.00011875", "gnorm": "1.276", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "3671"}
[2022-01-03 13:10:53,641][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:10:54,056][valid][INFO] - {"epoch": 190, "valid_loss": "4.339", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "34.74", "valid_code_perplexity": "34.707", "valid_temp": "1.925", "valid_loss_0": "4.168", "valid_loss_1": "0.136", "valid_loss_2": "0.034", "valid_accuracy": "0.25789", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "7600", "valid_best_loss": "3.851"}
[2022-01-03 13:10:54,062][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 190 @ 7600 updates
[2022-01-03 13:10:54,063][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:10:58,332][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:10:58,360][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 190 @ 7600 updates, score 4.339) (writing took 4.298616245388985 seconds)
[2022-01-03 13:10:58,361][fairseq_cli.train][INFO] - end of epoch 190 (average epoch stats below)
[2022-01-03 13:10:58,373][train][INFO] - {"epoch": 190, "train_loss": "4.207", "train_ntokens": "1776.55", "train_nsentences": "4.95", "train_prob_perplexity": "36.344", "train_code_perplexity": "36.325", "train_temp": "1.926", "train_loss_0": "4.033", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.29034", "train_wps": "3782.1", "train_ups": "2.13", "train_wpb": "1776.5", "train_bsz": "5", "train_num_updates": "7600", "train_lr": "0.00011875", "train_gnorm": "1.237", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "3676"}
[2022-01-03 13:10:58,454][fairseq.trainer][INFO] - begin training epoch 191
[2022-01-03 13:10:58,455][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:11:12,295][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:11:12,702][valid][INFO] - {"epoch": 191, "valid_loss": "4.408", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "33.383", "valid_code_perplexity": "33.251", "valid_temp": "1.925", "valid_loss_0": "4.234", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.26974", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "7640", "valid_best_loss": "3.851"}
[2022-01-03 13:11:12,706][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 191 @ 7640 updates
[2022-01-03 13:11:12,707][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:11:16,619][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:11:16,646][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 191 @ 7640 updates, score 4.408) (writing took 3.9393774857744575 seconds)
[2022-01-03 13:11:16,646][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2022-01-03 13:11:16,659][train][INFO] - {"epoch": 191, "train_loss": "4.246", "train_ntokens": "1793.83", "train_nsentences": "4.95", "train_prob_perplexity": "36.655", "train_code_perplexity": "36.637", "train_temp": "1.925", "train_loss_0": "4.072", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.28746", "train_wps": "3926.8", "train_ups": "2.19", "train_wpb": "1793.8", "train_bsz": "5", "train_num_updates": "7640", "train_lr": "0.000119375", "train_gnorm": "1.244", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "3694"}
[2022-01-03 13:11:16,730][fairseq.trainer][INFO] - begin training epoch 192
[2022-01-03 13:11:16,730][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:11:30,628][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:11:31,029][valid][INFO] - {"epoch": 192, "valid_loss": "4.466", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "33.157", "valid_code_perplexity": "33.111", "valid_temp": "1.925", "valid_loss_0": "4.292", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.26622", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "7680", "valid_best_loss": "3.851"}
[2022-01-03 13:11:31,032][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 192 @ 7680 updates
[2022-01-03 13:11:31,033][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:11:34,813][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:11:34,842][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 192 @ 7680 updates, score 4.466) (writing took 3.809985891915858 seconds)
[2022-01-03 13:11:34,843][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2022-01-03 13:11:34,856][train][INFO] - {"epoch": 192, "train_loss": "4.249", "train_ntokens": "1797.4", "train_nsentences": "4.95", "train_prob_perplexity": "36.687", "train_code_perplexity": "36.665", "train_temp": "1.925", "train_loss_0": "4.074", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.2848", "train_wps": "3954", "train_ups": "2.2", "train_wpb": "1797.4", "train_bsz": "5", "train_num_updates": "7680", "train_lr": "0.00012", "train_gnorm": "1.31", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3712"}
[2022-01-03 13:11:34,936][fairseq.trainer][INFO] - begin training epoch 193
[2022-01-03 13:11:34,937][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:11:48,750][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:11:49,244][valid][INFO] - {"epoch": 193, "valid_loss": "4.104", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "31.719", "valid_code_perplexity": "31.642", "valid_temp": "1.924", "valid_loss_0": "3.928", "valid_loss_1": "0.137", "valid_loss_2": "0.039", "valid_accuracy": "0.28474", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "7720", "valid_best_loss": "3.851"}
[2022-01-03 13:11:49,245][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 193 @ 7720 updates
[2022-01-03 13:11:49,246][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:11:53,130][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:11:53,158][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 193 @ 7720 updates, score 4.104) (writing took 3.9124744841828942 seconds)
[2022-01-03 13:11:53,159][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2022-01-03 13:11:53,172][train][INFO] - {"epoch": 193, "train_loss": "4.249", "train_ntokens": "1799.12", "train_nsentences": "4.95", "train_prob_perplexity": "36.605", "train_code_perplexity": "36.595", "train_temp": "1.924", "train_loss_0": "4.072", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.28778", "train_wps": "3931.9", "train_ups": "2.19", "train_wpb": "1799.1", "train_bsz": "5", "train_num_updates": "7720", "train_lr": "0.000120625", "train_gnorm": "1.21", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "3731"}
[2022-01-03 13:11:53,240][fairseq.trainer][INFO] - begin training epoch 194
[2022-01-03 13:11:53,241][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:12:07,349][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:12:07,756][valid][INFO] - {"epoch": 194, "valid_loss": "4.293", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "36.068", "valid_code_perplexity": "36.029", "valid_temp": "1.924", "valid_loss_0": "4.118", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.28385", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "7760", "valid_best_loss": "3.851"}
[2022-01-03 13:12:07,759][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 194 @ 7760 updates
[2022-01-03 13:12:07,760][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:12:11,511][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:12:11,538][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 194 @ 7760 updates, score 4.293) (writing took 3.779390995390713 seconds)
[2022-01-03 13:12:11,539][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2022-01-03 13:12:11,553][train][INFO] - {"epoch": 194, "train_loss": "4.198", "train_ntokens": "1785.62", "train_nsentences": "4.95", "train_prob_perplexity": "36.223", "train_code_perplexity": "36.204", "train_temp": "1.924", "train_loss_0": "4.025", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.29205", "train_wps": "3888.7", "train_ups": "2.18", "train_wpb": "1785.6", "train_bsz": "5", "train_num_updates": "7760", "train_lr": "0.00012125", "train_gnorm": "1.237", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3749"}
[2022-01-03 13:12:11,606][fairseq.trainer][INFO] - begin training epoch 195
[2022-01-03 13:12:11,606][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:12:25,646][train_inner][INFO] - {"epoch": 195, "update": 195.0, "loss": "4.229", "ntokens": "1793.52", "nsentences": "4.95", "prob_perplexity": "36.594", "code_perplexity": "36.577", "temp": "1.924", "loss_0": "4.054", "loss_1": "0.136", "loss_2": "0.039", "accuracy": "0.28895", "wps": "3899.3", "ups": "2.17", "wpb": "1793.5", "bsz": "5", "num_updates": "7800", "lr": "0.000121875", "gnorm": "1.239", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "3763"}
[2022-01-03 13:12:25,647][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:12:26,179][valid][INFO] - {"epoch": 195, "valid_loss": "4.362", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "33.137", "valid_code_perplexity": "33.088", "valid_temp": "1.924", "valid_loss_0": "4.19", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.29452", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "7800", "valid_best_loss": "3.851"}
[2022-01-03 13:12:26,182][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 195 @ 7800 updates
[2022-01-03 13:12:26,182][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:12:30,077][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:12:30,106][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 195 @ 7800 updates, score 4.362) (writing took 3.9244088316336274 seconds)
[2022-01-03 13:12:30,106][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2022-01-03 13:12:30,120][train][INFO] - {"epoch": 195, "train_loss": "4.205", "train_ntokens": "1791.6", "train_nsentences": "4.95", "train_prob_perplexity": "36.799", "train_code_perplexity": "36.785", "train_temp": "1.924", "train_loss_0": "4.029", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29267", "train_wps": "3862.5", "train_ups": "2.16", "train_wpb": "1791.6", "train_bsz": "5", "train_num_updates": "7800", "train_lr": "0.000121875", "train_gnorm": "1.194", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "3768"}
[2022-01-03 13:12:30,201][fairseq.trainer][INFO] - begin training epoch 196
[2022-01-03 13:12:30,202][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:12:44,184][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:12:44,595][valid][INFO] - {"epoch": 196, "valid_loss": "4.339", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "36.344", "valid_code_perplexity": "36.284", "valid_temp": "1.923", "valid_loss_0": "4.165", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.27298", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "7840", "valid_best_loss": "3.851"}
[2022-01-03 13:12:44,598][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 196 @ 7840 updates
[2022-01-03 13:12:44,599][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:12:48,424][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:12:48,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 196 @ 7840 updates, score 4.339) (writing took 3.8545665135607123 seconds)
[2022-01-03 13:12:48,453][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2022-01-03 13:12:48,466][train][INFO] - {"epoch": 196, "train_loss": "4.178", "train_ntokens": "1788.45", "train_nsentences": "4.95", "train_prob_perplexity": "36.86", "train_code_perplexity": "36.843", "train_temp": "1.923", "train_loss_0": "4.003", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.29513", "train_wps": "3902", "train_ups": "2.18", "train_wpb": "1788.5", "train_bsz": "5", "train_num_updates": "7840", "train_lr": "0.0001225", "train_gnorm": "1.203", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3786"}
[2022-01-03 13:12:48,541][fairseq.trainer][INFO] - begin training epoch 197
[2022-01-03 13:12:48,542][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:13:02,643][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:13:03,044][valid][INFO] - {"epoch": 197, "valid_loss": "4.174", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "34.82", "valid_code_perplexity": "34.793", "valid_temp": "1.923", "valid_loss_0": "3.998", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.30242", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "7880", "valid_best_loss": "3.851"}
[2022-01-03 13:13:03,047][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 197 @ 7880 updates
[2022-01-03 13:13:03,048][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:13:06,969][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:13:06,993][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 197 @ 7880 updates, score 4.174) (writing took 3.9454369712620974 seconds)
[2022-01-03 13:13:06,993][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2022-01-03 13:13:07,006][train][INFO] - {"epoch": 197, "train_loss": "4.194", "train_ntokens": "1790.17", "train_nsentences": "4.95", "train_prob_perplexity": "36.185", "train_code_perplexity": "36.173", "train_temp": "1.923", "train_loss_0": "4.021", "train_loss_1": "0.136", "train_loss_2": "0.037", "train_accuracy": "0.29627", "train_wps": "3865", "train_ups": "2.16", "train_wpb": "1790.2", "train_bsz": "5", "train_num_updates": "7880", "train_lr": "0.000123125", "train_gnorm": "1.225", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "3804"}
[2022-01-03 13:13:07,083][fairseq.trainer][INFO] - begin training epoch 198
[2022-01-03 13:13:07,084][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:13:20,927][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:13:21,328][valid][INFO] - {"epoch": 198, "valid_loss": "4.124", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "36.433", "valid_code_perplexity": "36.498", "valid_temp": "1.922", "valid_loss_0": "3.948", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.31092", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "7920", "valid_best_loss": "3.851"}
[2022-01-03 13:13:21,331][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 198 @ 7920 updates
[2022-01-03 13:13:21,332][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:13:25,244][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:13:25,270][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 198 @ 7920 updates, score 4.124) (writing took 3.9395371107384562 seconds)
[2022-01-03 13:13:25,271][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2022-01-03 13:13:25,283][train][INFO] - {"epoch": 198, "train_loss": "4.2", "train_ntokens": "1802.53", "train_nsentences": "4.95", "train_prob_perplexity": "35.736", "train_code_perplexity": "35.726", "train_temp": "1.923", "train_loss_0": "4.024", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29531", "train_wps": "3947.6", "train_ups": "2.19", "train_wpb": "1802.5", "train_bsz": "5", "train_num_updates": "7920", "train_lr": "0.00012375", "train_gnorm": "1.241", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "3823"}
[2022-01-03 13:13:25,333][fairseq.trainer][INFO] - begin training epoch 199
[2022-01-03 13:13:25,333][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:13:39,254][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:13:39,670][valid][INFO] - {"epoch": 199, "valid_loss": "4.216", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "34.253", "valid_code_perplexity": "34.218", "valid_temp": "1.922", "valid_loss_0": "4.043", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.28133", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "7960", "valid_best_loss": "3.851"}
[2022-01-03 13:13:39,674][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 199 @ 7960 updates
[2022-01-03 13:13:39,676][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:13:43,496][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:13:43,522][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 199 @ 7960 updates, score 4.216) (writing took 3.8476994866505265 seconds)
[2022-01-03 13:13:43,523][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2022-01-03 13:13:43,535][train][INFO] - {"epoch": 199, "train_loss": "4.18", "train_ntokens": "1802.95", "train_nsentences": "4.95", "train_prob_perplexity": "36.455", "train_code_perplexity": "36.439", "train_temp": "1.922", "train_loss_0": "4.004", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.29672", "train_wps": "3953.9", "train_ups": "2.19", "train_wpb": "1803", "train_bsz": "5", "train_num_updates": "7960", "train_lr": "0.000124375", "train_gnorm": "1.219", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3841"}
[2022-01-03 13:13:43,608][fairseq.trainer][INFO] - begin training epoch 200
[2022-01-03 13:13:43,609][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:13:57,574][train_inner][INFO] - {"epoch": 200, "update": 200.0, "loss": "4.191", "ntokens": "1796.42", "nsentences": "4.95", "prob_perplexity": "36.438", "code_perplexity": "36.423", "temp": "1.923", "loss_0": "4.016", "loss_1": "0.136", "loss_2": "0.039", "accuracy": "0.29471", "wps": "3908.9", "ups": "2.18", "wpb": "1796.4", "bsz": "5", "num_updates": "8000", "lr": "0.000125", "gnorm": "1.216", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "3855"}
[2022-01-03 13:13:57,575][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:13:57,988][valid][INFO] - {"epoch": 200, "valid_loss": "4.28", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "36.157", "valid_code_perplexity": "36.015", "valid_temp": "1.922", "valid_loss_0": "4.102", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.27514", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "8000", "valid_best_loss": "3.851"}
[2022-01-03 13:13:57,991][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 8000 updates
[2022-01-03 13:13:57,991][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:14:01,755][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:14:01,783][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 200 @ 8000 updates, score 4.28) (writing took 3.7925573838874698 seconds)
[2022-01-03 13:14:01,784][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2022-01-03 13:14:01,796][train][INFO] - {"epoch": 200, "train_loss": "4.204", "train_ntokens": "1798", "train_nsentences": "4.95", "train_prob_perplexity": "36.953", "train_code_perplexity": "36.934", "train_temp": "1.922", "train_loss_0": "4.027", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.2901", "train_wps": "3941.2", "train_ups": "2.19", "train_wpb": "1798", "train_bsz": "5", "train_num_updates": "8000", "train_lr": "0.000125", "train_gnorm": "1.193", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3859"}
[2022-01-03 13:14:01,861][fairseq.trainer][INFO] - begin training epoch 201
[2022-01-03 13:14:01,862][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:14:15,677][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:14:16,152][valid][INFO] - {"epoch": 201, "valid_loss": "4.346", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "34.324", "valid_code_perplexity": "34.296", "valid_temp": "1.921", "valid_loss_0": "4.173", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.25255", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "8040", "valid_best_loss": "3.851"}
[2022-01-03 13:14:16,154][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 201 @ 8040 updates
[2022-01-03 13:14:16,155][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:14:19,962][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:14:19,991][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 201 @ 8040 updates, score 4.346) (writing took 3.837210824713111 seconds)
[2022-01-03 13:14:19,992][fairseq_cli.train][INFO] - end of epoch 201 (average epoch stats below)
[2022-01-03 13:14:20,004][train][INFO] - {"epoch": 201, "train_loss": "4.212", "train_ntokens": "1793.42", "train_nsentences": "4.95", "train_prob_perplexity": "36.992", "train_code_perplexity": "36.973", "train_temp": "1.921", "train_loss_0": "4.037", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28929", "train_wps": "3942.5", "train_ups": "2.2", "train_wpb": "1793.4", "train_bsz": "5", "train_num_updates": "8040", "train_lr": "0.000125625", "train_gnorm": "1.216", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3877"}
[2022-01-03 13:14:20,068][fairseq.trainer][INFO] - begin training epoch 202
[2022-01-03 13:14:20,069][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:14:34,021][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:14:34,557][valid][INFO] - {"epoch": 202, "valid_loss": "4.206", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "36.854", "valid_code_perplexity": "36.827", "valid_temp": "1.921", "valid_loss_0": "4.032", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.28212", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "8080", "valid_best_loss": "3.851"}
[2022-01-03 13:14:34,559][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 202 @ 8080 updates
[2022-01-03 13:14:34,559][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:14:38,223][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:14:38,229][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 202 @ 8080 updates, score 4.206) (writing took 3.669914056546986 seconds)
[2022-01-03 13:14:38,229][fairseq_cli.train][INFO] - end of epoch 202 (average epoch stats below)
[2022-01-03 13:14:38,242][train][INFO] - {"epoch": 202, "train_loss": "4.19", "train_ntokens": "1787.03", "train_nsentences": "4.95", "train_prob_perplexity": "37.102", "train_code_perplexity": "37.088", "train_temp": "1.921", "train_loss_0": "4.015", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.29167", "train_wps": "3922.1", "train_ups": "2.19", "train_wpb": "1787", "train_bsz": "5", "train_num_updates": "8080", "train_lr": "0.00012625", "train_gnorm": "1.231", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3896"}
[2022-01-03 13:14:38,313][fairseq.trainer][INFO] - begin training epoch 203
[2022-01-03 13:14:38,313][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:14:51,989][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:14:52,392][valid][INFO] - {"epoch": 203, "valid_loss": "3.994", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "35.05", "valid_code_perplexity": "35.02", "valid_temp": "1.92", "valid_loss_0": "3.819", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.31378", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "8120", "valid_best_loss": "3.851"}
[2022-01-03 13:14:52,395][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 203 @ 8120 updates
[2022-01-03 13:14:52,395][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:14:56,445][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:14:56,451][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 203 @ 8120 updates, score 3.994) (writing took 4.05615166015923 seconds)
[2022-01-03 13:14:56,451][fairseq_cli.train][INFO] - end of epoch 203 (average epoch stats below)
[2022-01-03 13:14:56,464][train][INFO] - {"epoch": 203, "train_loss": "4.233", "train_ntokens": "1786.65", "train_nsentences": "4.95", "train_prob_perplexity": "36.959", "train_code_perplexity": "36.942", "train_temp": "1.921", "train_loss_0": "4.058", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.28608", "train_wps": "3924.8", "train_ups": "2.2", "train_wpb": "1786.7", "train_bsz": "5", "train_num_updates": "8120", "train_lr": "0.000126875", "train_gnorm": "1.231", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "3914"}
[2022-01-03 13:14:56,537][fairseq.trainer][INFO] - begin training epoch 204
[2022-01-03 13:14:56,538][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:15:10,434][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:15:10,825][valid][INFO] - {"epoch": 204, "valid_loss": "4.383", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "36.901", "valid_code_perplexity": "36.839", "valid_temp": "1.92", "valid_loss_0": "4.208", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.2635", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "8160", "valid_best_loss": "3.851"}
[2022-01-03 13:15:10,828][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 204 @ 8160 updates
[2022-01-03 13:15:10,829][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:15:14,649][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:15:14,674][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 204 @ 8160 updates, score 4.383) (writing took 3.846271621994674 seconds)
[2022-01-03 13:15:14,675][fairseq_cli.train][INFO] - end of epoch 204 (average epoch stats below)
[2022-01-03 13:15:14,687][train][INFO] - {"epoch": 204, "train_loss": "4.186", "train_ntokens": "1797.45", "train_nsentences": "4.95", "train_prob_perplexity": "36.763", "train_code_perplexity": "36.738", "train_temp": "1.92", "train_loss_0": "4.009", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29169", "train_wps": "3948.3", "train_ups": "2.2", "train_wpb": "1797.5", "train_bsz": "5", "train_num_updates": "8160", "train_lr": "0.0001275", "train_gnorm": "1.211", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3932"}
[2022-01-03 13:15:14,759][fairseq.trainer][INFO] - begin training epoch 205
[2022-01-03 13:15:14,759][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:15:28,575][train_inner][INFO] - {"epoch": 205, "update": 205.0, "loss": "4.209", "ntokens": "1791.4", "nsentences": "4.95", "prob_perplexity": "36.893", "code_perplexity": "36.874", "temp": "1.921", "loss_0": "4.033", "loss_1": "0.136", "loss_2": "0.04", "accuracy": "0.28962", "wps": "3937.7", "ups": "2.2", "wpb": "1791.4", "bsz": "5", "num_updates": "8200", "lr": "0.000128125", "gnorm": "1.216", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "3946"}
[2022-01-03 13:15:28,576][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:15:28,976][valid][INFO] - {"epoch": 205, "valid_loss": "3.975", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "36.277", "valid_code_perplexity": "36.276", "valid_temp": "1.92", "valid_loss_0": "3.798", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.31169", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "8200", "valid_best_loss": "3.851"}
[2022-01-03 13:15:28,978][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 205 @ 8200 updates
[2022-01-03 13:15:28,979][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:15:32,875][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:15:32,901][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 205 @ 8200 updates, score 3.975) (writing took 3.923024542629719 seconds)
[2022-01-03 13:15:32,902][fairseq_cli.train][INFO] - end of epoch 205 (average epoch stats below)
[2022-01-03 13:15:32,914][train][INFO] - {"epoch": 205, "train_loss": "4.221", "train_ntokens": "1792.45", "train_nsentences": "4.95", "train_prob_perplexity": "36.648", "train_code_perplexity": "36.63", "train_temp": "1.92", "train_loss_0": "4.046", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.28937", "train_wps": "3936.4", "train_ups": "2.2", "train_wpb": "1792.5", "train_bsz": "5", "train_num_updates": "8200", "train_lr": "0.000128125", "train_gnorm": "1.193", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3950"}
[2022-01-03 13:15:32,982][fairseq.trainer][INFO] - begin training epoch 206
[2022-01-03 13:15:32,982][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:15:46,811][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:15:47,210][valid][INFO] - {"epoch": 206, "valid_loss": "4.294", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "34.534", "valid_code_perplexity": "34.43", "valid_temp": "1.919", "valid_loss_0": "4.117", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.28426", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "8240", "valid_best_loss": "3.851"}
[2022-01-03 13:15:47,213][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 206 @ 8240 updates
[2022-01-03 13:15:47,213][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:15:51,196][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:15:51,224][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 206 @ 8240 updates, score 4.294) (writing took 4.0115339970216155 seconds)
[2022-01-03 13:15:51,225][fairseq_cli.train][INFO] - end of epoch 206 (average epoch stats below)
[2022-01-03 13:15:51,237][train][INFO] - {"epoch": 206, "train_loss": "4.226", "train_ntokens": "1787.55", "train_nsentences": "4.95", "train_prob_perplexity": "36.539", "train_code_perplexity": "36.52", "train_temp": "1.919", "train_loss_0": "4.05", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.28866", "train_wps": "3904.9", "train_ups": "2.18", "train_wpb": "1787.5", "train_bsz": "5", "train_num_updates": "8240", "train_lr": "0.00012875", "train_gnorm": "1.169", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "3969"}
[2022-01-03 13:15:51,312][fairseq.trainer][INFO] - begin training epoch 207
[2022-01-03 13:15:51,313][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:16:05,256][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:16:05,726][valid][INFO] - {"epoch": 207, "valid_loss": "4.191", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "34.98", "valid_code_perplexity": "34.927", "valid_temp": "1.919", "valid_loss_0": "4.02", "valid_loss_1": "0.136", "valid_loss_2": "0.034", "valid_accuracy": "0.2989", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "8280", "valid_best_loss": "3.851"}
[2022-01-03 13:16:05,728][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 207 @ 8280 updates
[2022-01-03 13:16:05,729][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:16:09,462][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:16:09,491][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 207 @ 8280 updates, score 4.191) (writing took 3.762924442999065 seconds)
[2022-01-03 13:16:09,492][fairseq_cli.train][INFO] - end of epoch 207 (average epoch stats below)
[2022-01-03 13:16:09,506][train][INFO] - {"epoch": 207, "train_loss": "4.186", "train_ntokens": "1805", "train_nsentences": "4.95", "train_prob_perplexity": "36.614", "train_code_perplexity": "36.596", "train_temp": "1.919", "train_loss_0": "4.011", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.29542", "train_wps": "3955.2", "train_ups": "2.19", "train_wpb": "1805", "train_bsz": "5", "train_num_updates": "8280", "train_lr": "0.000129375", "train_gnorm": "1.174", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "3987"}
[2022-01-03 13:16:09,563][fairseq.trainer][INFO] - begin training epoch 208
[2022-01-03 13:16:09,564][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:16:23,480][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:16:23,931][valid][INFO] - {"epoch": 208, "valid_loss": "3.963", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "36.795", "valid_code_perplexity": "36.72", "valid_temp": "1.919", "valid_loss_0": "3.789", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.31467", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "8320", "valid_best_loss": "3.851"}
[2022-01-03 13:16:23,933][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 208 @ 8320 updates
[2022-01-03 13:16:23,934][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:16:27,677][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:16:27,706][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 208 @ 8320 updates, score 3.963) (writing took 3.772379300557077 seconds)
[2022-01-03 13:16:27,706][fairseq_cli.train][INFO] - end of epoch 208 (average epoch stats below)
[2022-01-03 13:16:27,719][train][INFO] - {"epoch": 208, "train_loss": "4.168", "train_ntokens": "1780.2", "train_nsentences": "4.95", "train_prob_perplexity": "36.811", "train_code_perplexity": "36.799", "train_temp": "1.919", "train_loss_0": "3.993", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.2949", "train_wps": "3912.5", "train_ups": "2.2", "train_wpb": "1780.2", "train_bsz": "5", "train_num_updates": "8320", "train_lr": "0.00013", "train_gnorm": "1.172", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4005"}
[2022-01-03 13:16:27,776][fairseq.trainer][INFO] - begin training epoch 209
[2022-01-03 13:16:27,777][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:16:41,806][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:16:42,298][valid][INFO] - {"epoch": 209, "valid_loss": "4.196", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "33.777", "valid_code_perplexity": "33.741", "valid_temp": "1.918", "valid_loss_0": "4.024", "valid_loss_1": "0.137", "valid_loss_2": "0.035", "valid_accuracy": "0.2732", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "8360", "valid_best_loss": "3.851"}
[2022-01-03 13:16:42,299][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 209 @ 8360 updates
[2022-01-03 13:16:42,300][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:16:45,940][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:16:45,965][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 209 @ 8360 updates, score 4.196) (writing took 3.6656498182564974 seconds)
[2022-01-03 13:16:45,965][fairseq_cli.train][INFO] - end of epoch 209 (average epoch stats below)
[2022-01-03 13:16:45,978][train][INFO] - {"epoch": 209, "train_loss": "4.164", "train_ntokens": "1795.5", "train_nsentences": "4.95", "train_prob_perplexity": "36.724", "train_code_perplexity": "36.715", "train_temp": "1.918", "train_loss_0": "3.99", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.29478", "train_wps": "3936.2", "train_ups": "2.19", "train_wpb": "1795.5", "train_bsz": "5", "train_num_updates": "8360", "train_lr": "0.000130625", "train_gnorm": "1.155", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "4023"}
[2022-01-03 13:16:46,045][fairseq.trainer][INFO] - begin training epoch 210
[2022-01-03 13:16:46,045][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:16:59,899][train_inner][INFO] - {"epoch": 210, "update": 210.0, "loss": "4.189", "ntokens": "1792.35", "nsentences": "4.95", "prob_perplexity": "36.696", "code_perplexity": "36.68", "temp": "1.919", "loss_0": "4.014", "loss_1": "0.136", "loss_2": "0.039", "accuracy": "0.29296", "wps": "3925.8", "ups": "2.19", "wpb": "1792.3", "bsz": "5", "num_updates": "8400", "lr": "0.00013125", "gnorm": "1.169", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "4037"}
[2022-01-03 13:16:59,900][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:17:00,298][valid][INFO] - {"epoch": 210, "valid_loss": "4.256", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "35.787", "valid_code_perplexity": "35.755", "valid_temp": "1.918", "valid_loss_0": "4.082", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.28743", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "8400", "valid_best_loss": "3.851"}
[2022-01-03 13:17:00,302][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 210 @ 8400 updates
[2022-01-03 13:17:00,302][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:17:04,199][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:17:04,222][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 210 @ 8400 updates, score 4.256) (writing took 3.920808097347617 seconds)
[2022-01-03 13:17:04,223][fairseq_cli.train][INFO] - end of epoch 210 (average epoch stats below)
[2022-01-03 13:17:04,235][train][INFO] - {"epoch": 210, "train_loss": "4.203", "train_ntokens": "1793.5", "train_nsentences": "4.95", "train_prob_perplexity": "36.789", "train_code_perplexity": "36.768", "train_temp": "1.918", "train_loss_0": "4.028", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.29105", "train_wps": "3932", "train_ups": "2.19", "train_wpb": "1793.5", "train_bsz": "5", "train_num_updates": "8400", "train_lr": "0.00013125", "train_gnorm": "1.174", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "4042"}
[2022-01-03 13:17:04,300][fairseq.trainer][INFO] - begin training epoch 211
[2022-01-03 13:17:04,300][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:17:18,337][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:17:18,796][valid][INFO] - {"epoch": 211, "valid_loss": "4.09", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "36.233", "valid_code_perplexity": "36.231", "valid_temp": "1.917", "valid_loss_0": "3.916", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.30423", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "8440", "valid_best_loss": "3.851"}
[2022-01-03 13:17:18,800][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 211 @ 8440 updates
[2022-01-03 13:17:18,801][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:17:22,431][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:17:22,459][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 211 @ 8440 updates, score 4.09) (writing took 3.658360389061272 seconds)
[2022-01-03 13:17:22,459][fairseq_cli.train][INFO] - end of epoch 211 (average epoch stats below)
[2022-01-03 13:17:22,472][train][INFO] - {"epoch": 211, "train_loss": "4.193", "train_ntokens": "1802.45", "train_nsentences": "4.95", "train_prob_perplexity": "37.389", "train_code_perplexity": "37.37", "train_temp": "1.918", "train_loss_0": "4.019", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.28906", "train_wps": "3956.3", "train_ups": "2.19", "train_wpb": "1802.5", "train_bsz": "5", "train_num_updates": "8440", "train_lr": "0.000131875", "train_gnorm": "1.161", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "4060"}
[2022-01-03 13:17:22,528][fairseq.trainer][INFO] - begin training epoch 212
[2022-01-03 13:17:22,529][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:17:36,429][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:17:36,830][valid][INFO] - {"epoch": 212, "valid_loss": "4.169", "valid_ntokens": "814", "valid_nsentences": "2", "valid_prob_perplexity": "35.495", "valid_code_perplexity": "35.526", "valid_temp": "1.917", "valid_loss_0": "3.994", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.28378", "valid_wps": "0", "valid_wpb": "814", "valid_bsz": "2", "valid_num_updates": "8480", "valid_best_loss": "3.851"}
[2022-01-03 13:17:36,834][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 212 @ 8480 updates
[2022-01-03 13:17:36,835][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:17:40,650][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:17:40,679][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 212 @ 8480 updates, score 4.169) (writing took 3.8456861283630133 seconds)
[2022-01-03 13:17:40,680][fairseq_cli.train][INFO] - end of epoch 212 (average epoch stats below)
[2022-01-03 13:17:40,693][train][INFO] - {"epoch": 212, "train_loss": "4.186", "train_ntokens": "1795.1", "train_nsentences": "4.95", "train_prob_perplexity": "36.958", "train_code_perplexity": "36.933", "train_temp": "1.917", "train_loss_0": "4.01", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.28887", "train_wps": "3943.5", "train_ups": "2.2", "train_wpb": "1795.1", "train_bsz": "5", "train_num_updates": "8480", "train_lr": "0.0001325", "train_gnorm": "1.114", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4078"}
[2022-01-03 13:17:40,773][fairseq.trainer][INFO] - begin training epoch 213
[2022-01-03 13:17:40,774][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:17:54,668][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:17:55,065][valid][INFO] - {"epoch": 213, "valid_loss": "4.177", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "37.062", "valid_code_perplexity": "37.103", "valid_temp": "1.917", "valid_loss_0": "4.002", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.24011", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "8520", "valid_best_loss": "3.851"}
[2022-01-03 13:17:55,068][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 213 @ 8520 updates
[2022-01-03 13:17:55,069][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:17:58,970][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:17:58,998][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 213 @ 8520 updates, score 4.177) (writing took 3.9302344508469105 seconds)
[2022-01-03 13:17:58,999][fairseq_cli.train][INFO] - end of epoch 213 (average epoch stats below)
[2022-01-03 13:17:59,013][train][INFO] - {"epoch": 213, "train_loss": "4.198", "train_ntokens": "1805.47", "train_nsentences": "4.95", "train_prob_perplexity": "37.229", "train_code_perplexity": "37.2", "train_temp": "1.917", "train_loss_0": "4.02", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.28954", "train_wps": "3945.1", "train_ups": "2.19", "train_wpb": "1805.5", "train_bsz": "5", "train_num_updates": "8520", "train_lr": "0.000133125", "train_gnorm": "1.142", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4096"}
[2022-01-03 13:17:59,086][fairseq.trainer][INFO] - begin training epoch 214
[2022-01-03 13:17:59,086][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:18:13,100][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:18:13,497][valid][INFO] - {"epoch": 214, "valid_loss": "4.122", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "35.187", "valid_code_perplexity": "35.209", "valid_temp": "1.916", "valid_loss_0": "3.948", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.32162", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "8560", "valid_best_loss": "3.851"}
[2022-01-03 13:18:13,500][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 214 @ 8560 updates
[2022-01-03 13:18:13,501][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:18:17,144][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:18:17,172][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 214 @ 8560 updates, score 4.122) (writing took 3.6721769412979484 seconds)
[2022-01-03 13:18:17,173][fairseq_cli.train][INFO] - end of epoch 214 (average epoch stats below)
[2022-01-03 13:18:17,185][train][INFO] - {"epoch": 214, "train_loss": "4.196", "train_ntokens": "1790.17", "train_nsentences": "4.95", "train_prob_perplexity": "37.188", "train_code_perplexity": "37.169", "train_temp": "1.916", "train_loss_0": "4.019", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29274", "train_wps": "3943.2", "train_ups": "2.2", "train_wpb": "1790.2", "train_bsz": "5", "train_num_updates": "8560", "train_lr": "0.00013375", "train_gnorm": "1.142", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "4115"}
[2022-01-03 13:18:17,265][fairseq.trainer][INFO] - begin training epoch 215
[2022-01-03 13:18:17,265][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:18:31,156][train_inner][INFO] - {"epoch": 215, "update": 215.0, "loss": "4.187", "ntokens": "1796.8", "nsentences": "4.95", "prob_perplexity": "37.109", "code_perplexity": "37.088", "temp": "1.917", "loss_0": "4.011", "loss_1": "0.136", "loss_2": "0.04", "accuracy": "0.29127", "wps": "3938.4", "ups": "2.19", "wpb": "1796.8", "bsz": "5", "num_updates": "8600", "lr": "0.000134375", "gnorm": "1.136", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "4129"}
[2022-01-03 13:18:31,157][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:18:31,557][valid][INFO] - {"epoch": 215, "valid_loss": "4.079", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "34.868", "valid_code_perplexity": "34.942", "valid_temp": "1.916", "valid_loss_0": "3.905", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.28393", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "8600", "valid_best_loss": "3.851"}
[2022-01-03 13:18:31,560][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 215 @ 8600 updates
[2022-01-03 13:18:31,561][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:18:35,371][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:18:35,398][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 215 @ 8600 updates, score 4.079) (writing took 3.837927150540054 seconds)
[2022-01-03 13:18:35,399][fairseq_cli.train][INFO] - end of epoch 215 (average epoch stats below)
[2022-01-03 13:18:35,411][train][INFO] - {"epoch": 215, "train_loss": "4.162", "train_ntokens": "1790.78", "train_nsentences": "4.95", "train_prob_perplexity": "36.782", "train_code_perplexity": "36.765", "train_temp": "1.916", "train_loss_0": "3.986", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29618", "train_wps": "3932.8", "train_ups": "2.2", "train_wpb": "1790.8", "train_bsz": "5", "train_num_updates": "8600", "train_lr": "0.000134375", "train_gnorm": "1.119", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "4133"}
[2022-01-03 13:18:35,491][fairseq.trainer][INFO] - begin training epoch 216
[2022-01-03 13:18:35,491][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:18:49,482][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:18:49,874][valid][INFO] - {"epoch": 216, "valid_loss": "4.263", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "32.488", "valid_code_perplexity": "32.502", "valid_temp": "1.915", "valid_loss_0": "4.082", "valid_loss_1": "0.137", "valid_loss_2": "0.044", "valid_accuracy": "0.3", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "8640", "valid_best_loss": "3.851"}
[2022-01-03 13:18:49,878][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 216 @ 8640 updates
[2022-01-03 13:18:49,879][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:18:53,592][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:18:53,620][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 216 @ 8640 updates, score 4.263) (writing took 3.7419742811471224 seconds)
[2022-01-03 13:18:53,621][fairseq_cli.train][INFO] - end of epoch 216 (average epoch stats below)
[2022-01-03 13:18:53,634][train][INFO] - {"epoch": 216, "train_loss": "4.145", "train_ntokens": "1776.78", "train_nsentences": "4.95", "train_prob_perplexity": "37.203", "train_code_perplexity": "37.186", "train_temp": "1.916", "train_loss_0": "3.969", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.30109", "train_wps": "3903", "train_ups": "2.2", "train_wpb": "1776.8", "train_bsz": "5", "train_num_updates": "8640", "train_lr": "0.000135", "train_gnorm": "1.122", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "4151"}
[2022-01-03 13:18:53,710][fairseq.trainer][INFO] - begin training epoch 217
[2022-01-03 13:18:53,711][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:19:07,671][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:19:08,068][valid][INFO] - {"epoch": 217, "valid_loss": "4.014", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "37.085", "valid_code_perplexity": "37.056", "valid_temp": "1.915", "valid_loss_0": "3.836", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.32114", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "8680", "valid_best_loss": "3.851"}
[2022-01-03 13:19:08,071][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 217 @ 8680 updates
[2022-01-03 13:19:08,072][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:19:11,857][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:19:11,885][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 217 @ 8680 updates, score 4.014) (writing took 3.8134229946881533 seconds)
[2022-01-03 13:19:11,885][fairseq_cli.train][INFO] - end of epoch 217 (average epoch stats below)
[2022-01-03 13:19:11,899][train][INFO] - {"epoch": 217, "train_loss": "4.206", "train_ntokens": "1786.55", "train_nsentences": "4.95", "train_prob_perplexity": "37.85", "train_code_perplexity": "37.84", "train_temp": "1.915", "train_loss_0": "4.029", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.2875", "train_wps": "3915.3", "train_ups": "2.19", "train_wpb": "1786.5", "train_bsz": "5", "train_num_updates": "8680", "train_lr": "0.000135625", "train_gnorm": "1.121", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "4169"}
[2022-01-03 13:19:11,977][fairseq.trainer][INFO] - begin training epoch 218
[2022-01-03 13:19:11,978][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:19:25,921][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:19:26,326][valid][INFO] - {"epoch": 218, "valid_loss": "4.318", "valid_ntokens": "790", "valid_nsentences": "2", "valid_prob_perplexity": "34.102", "valid_code_perplexity": "34.08", "valid_temp": "1.915", "valid_loss_0": "4.141", "valid_loss_1": "0.137", "valid_loss_2": "0.04", "valid_accuracy": "0.29241", "valid_wps": "0", "valid_wpb": "790", "valid_bsz": "2", "valid_num_updates": "8720", "valid_best_loss": "3.851"}
[2022-01-03 13:19:26,330][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 218 @ 8720 updates
[2022-01-03 13:19:26,331][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:19:30,128][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:19:30,155][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 218 @ 8720 updates, score 4.318) (writing took 3.8246719539165497 seconds)
[2022-01-03 13:19:30,156][fairseq_cli.train][INFO] - end of epoch 218 (average epoch stats below)
[2022-01-03 13:19:30,168][train][INFO] - {"epoch": 218, "train_loss": "4.197", "train_ntokens": "1808.42", "train_nsentences": "4.95", "train_prob_perplexity": "37.731", "train_code_perplexity": "37.722", "train_temp": "1.915", "train_loss_0": "4.021", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.28938", "train_wps": "3962.2", "train_ups": "2.19", "train_wpb": "1808.4", "train_bsz": "5", "train_num_updates": "8720", "train_lr": "0.00013625", "train_gnorm": "1.123", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "4188"}
[2022-01-03 13:19:30,246][fairseq.trainer][INFO] - begin training epoch 219
[2022-01-03 13:19:30,246][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:19:44,095][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:19:44,509][valid][INFO] - {"epoch": 219, "valid_loss": "4.352", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "36.509", "valid_code_perplexity": "36.508", "valid_temp": "1.914", "valid_loss_0": "4.177", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.27212", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "8760", "valid_best_loss": "3.851"}
[2022-01-03 13:19:44,512][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 219 @ 8760 updates
[2022-01-03 13:19:44,513][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:19:48,428][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:19:48,455][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 219 @ 8760 updates, score 4.352) (writing took 3.9436047170311213 seconds)
[2022-01-03 13:19:48,456][fairseq_cli.train][INFO] - end of epoch 219 (average epoch stats below)
[2022-01-03 13:19:48,468][train][INFO] - {"epoch": 219, "train_loss": "4.158", "train_ntokens": "1794.95", "train_nsentences": "4.95", "train_prob_perplexity": "37.848", "train_code_perplexity": "37.839", "train_temp": "1.914", "train_loss_0": "3.983", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.2957", "train_wps": "3926", "train_ups": "2.19", "train_wpb": "1795", "train_bsz": "5", "train_num_updates": "8760", "train_lr": "0.000136875", "train_gnorm": "1.099", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4206"}
[2022-01-03 13:19:48,539][fairseq.trainer][INFO] - begin training epoch 220
[2022-01-03 13:19:48,540][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:20:02,585][train_inner][INFO] - {"epoch": 220, "update": 220.0, "loss": "4.177", "ntokens": "1790.65", "nsentences": "4.95", "prob_perplexity": "37.582", "code_perplexity": "37.572", "temp": "1.915", "loss_0": "4.001", "loss_1": "0.136", "loss_2": "0.04", "accuracy": "0.29392", "wps": "3917.6", "ups": "2.19", "wpb": "1790.7", "bsz": "5", "num_updates": "8800", "lr": "0.0001375", "gnorm": "1.116", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "4220"}
[2022-01-03 13:20:02,586][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:20:03,061][valid][INFO] - {"epoch": 220, "valid_loss": "4.166", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "34.611", "valid_code_perplexity": "34.475", "valid_temp": "1.914", "valid_loss_0": "3.991", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.31456", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "8800", "valid_best_loss": "3.851"}
[2022-01-03 13:20:03,063][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 220 @ 8800 updates
[2022-01-03 13:20:03,064][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:20:06,710][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:20:06,739][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 220 @ 8800 updates, score 4.166) (writing took 3.6756104566156864 seconds)
[2022-01-03 13:20:06,739][fairseq_cli.train][INFO] - end of epoch 220 (average epoch stats below)
[2022-01-03 13:20:06,751][train][INFO] - {"epoch": 220, "train_loss": "4.177", "train_ntokens": "1786.58", "train_nsentences": "4.95", "train_prob_perplexity": "37.278", "train_code_perplexity": "37.272", "train_temp": "1.914", "train_loss_0": "4.002", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.296", "train_wps": "3911.4", "train_ups": "2.19", "train_wpb": "1786.6", "train_bsz": "5", "train_num_updates": "8800", "train_lr": "0.0001375", "train_gnorm": "1.118", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "4224"}
[2022-01-03 13:20:06,828][fairseq.trainer][INFO] - begin training epoch 221
[2022-01-03 13:20:06,829][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:20:20,776][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:20:21,189][valid][INFO] - {"epoch": 221, "valid_loss": "4.129", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "35.982", "valid_code_perplexity": "35.944", "valid_temp": "1.914", "valid_loss_0": "3.952", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.28904", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "8840", "valid_best_loss": "3.851"}
[2022-01-03 13:20:21,192][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 221 @ 8840 updates
[2022-01-03 13:20:21,193][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:20:24,925][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:20:24,954][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 221 @ 8840 updates, score 4.129) (writing took 3.761483810842037 seconds)
[2022-01-03 13:20:24,954][fairseq_cli.train][INFO] - end of epoch 221 (average epoch stats below)
[2022-01-03 13:20:24,967][train][INFO] - {"epoch": 221, "train_loss": "4.204", "train_ntokens": "1785.12", "train_nsentences": "4.95", "train_prob_perplexity": "37.986", "train_code_perplexity": "37.973", "train_temp": "1.914", "train_loss_0": "4.027", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.28837", "train_wps": "3922.7", "train_ups": "2.2", "train_wpb": "1785.1", "train_bsz": "5", "train_num_updates": "8840", "train_lr": "0.000138125", "train_gnorm": "1.167", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "4242"}
[2022-01-03 13:20:25,023][fairseq.trainer][INFO] - begin training epoch 222
[2022-01-03 13:20:25,023][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:20:38,860][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:20:39,257][valid][INFO] - {"epoch": 222, "valid_loss": "4.582", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "35.713", "valid_code_perplexity": "35.622", "valid_temp": "1.913", "valid_loss_0": "4.406", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.23978", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "8880", "valid_best_loss": "3.851"}
[2022-01-03 13:20:39,260][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 222 @ 8880 updates
[2022-01-03 13:20:39,261][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:20:43,198][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:20:43,225][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 222 @ 8880 updates, score 4.582) (writing took 3.965603359043598 seconds)
[2022-01-03 13:20:43,226][fairseq_cli.train][INFO] - end of epoch 222 (average epoch stats below)
[2022-01-03 13:20:43,239][train][INFO] - {"epoch": 222, "train_loss": "4.166", "train_ntokens": "1787.22", "train_nsentences": "4.95", "train_prob_perplexity": "37.641", "train_code_perplexity": "37.626", "train_temp": "1.913", "train_loss_0": "3.99", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29684", "train_wps": "3915.2", "train_ups": "2.19", "train_wpb": "1787.2", "train_bsz": "5", "train_num_updates": "8880", "train_lr": "0.00013875", "train_gnorm": "1.154", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "4261"}
[2022-01-03 13:20:43,300][fairseq.trainer][INFO] - begin training epoch 223
[2022-01-03 13:20:43,301][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:20:57,106][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:20:57,510][valid][INFO] - {"epoch": 223, "valid_loss": "4.285", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "34.636", "valid_code_perplexity": "34.567", "valid_temp": "1.913", "valid_loss_0": "4.113", "valid_loss_1": "0.136", "valid_loss_2": "0.036", "valid_accuracy": "0.25962", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "8920", "valid_best_loss": "3.851"}
[2022-01-03 13:20:57,513][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 223 @ 8920 updates
[2022-01-03 13:20:57,514][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:21:01,475][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:21:01,504][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 223 @ 8920 updates, score 4.285) (writing took 3.991030003875494 seconds)
[2022-01-03 13:21:01,504][fairseq_cli.train][INFO] - end of epoch 223 (average epoch stats below)
[2022-01-03 13:21:01,517][train][INFO] - {"epoch": 223, "train_loss": "4.172", "train_ntokens": "1789.78", "train_nsentences": "4.95", "train_prob_perplexity": "37.784", "train_code_perplexity": "37.769", "train_temp": "1.913", "train_loss_0": "3.995", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29191", "train_wps": "3919.4", "train_ups": "2.19", "train_wpb": "1789.8", "train_bsz": "5", "train_num_updates": "8920", "train_lr": "0.000139375", "train_gnorm": "1.08", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "4279"}
[2022-01-03 13:21:01,596][fairseq.trainer][INFO] - begin training epoch 224
[2022-01-03 13:21:01,597][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:21:15,437][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:21:15,832][valid][INFO] - {"epoch": 224, "valid_loss": "3.882", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "35.54", "valid_code_perplexity": "35.551", "valid_temp": "1.912", "valid_loss_0": "3.706", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.32725", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "8960", "valid_best_loss": "3.851"}
[2022-01-03 13:21:15,835][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 224 @ 8960 updates
[2022-01-03 13:21:15,836][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:21:19,788][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:21:19,817][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 224 @ 8960 updates, score 3.882) (writing took 3.9811536073684692 seconds)
[2022-01-03 13:21:19,817][fairseq_cli.train][INFO] - end of epoch 224 (average epoch stats below)
[2022-01-03 13:21:19,829][train][INFO] - {"epoch": 224, "train_loss": "4.179", "train_ntokens": "1804.85", "train_nsentences": "4.95", "train_prob_perplexity": "37.647", "train_code_perplexity": "37.627", "train_temp": "1.913", "train_loss_0": "4.004", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29137", "train_wps": "3945", "train_ups": "2.19", "train_wpb": "1804.8", "train_bsz": "5", "train_num_updates": "8960", "train_lr": "0.00014", "train_gnorm": "1.089", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4297"}
[2022-01-03 13:21:19,903][fairseq.trainer][INFO] - begin training epoch 225
[2022-01-03 13:21:19,904][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:21:33,818][train_inner][INFO] - {"epoch": 225, "update": 225.0, "loss": "4.17", "ntokens": "1787.97", "nsentences": "4.95", "prob_perplexity": "37.779", "code_perplexity": "37.763", "temp": "1.913", "loss_0": "3.993", "loss_1": "0.136", "loss_2": "0.041", "accuracy": "0.29414", "wps": "3920.1", "ups": "2.19", "wpb": "1788", "bsz": "5", "num_updates": "9000", "lr": "0.000140625", "gnorm": "1.116", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "4311"}
[2022-01-03 13:21:33,819][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:21:34,213][valid][INFO] - {"epoch": 225, "valid_loss": "4.055", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "31.741", "valid_code_perplexity": "31.804", "valid_temp": "1.912", "valid_loss_0": "3.873", "valid_loss_1": "0.137", "valid_loss_2": "0.045", "valid_accuracy": "0.3356", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "9000", "valid_best_loss": "3.851"}
[2022-01-03 13:21:34,216][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 225 @ 9000 updates
[2022-01-03 13:21:34,217][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:21:38,039][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:21:38,068][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 225 @ 9000 updates, score 4.055) (writing took 3.8521311385557055 seconds)
[2022-01-03 13:21:38,069][fairseq_cli.train][INFO] - end of epoch 225 (average epoch stats below)
[2022-01-03 13:21:38,082][train][INFO] - {"epoch": 225, "train_loss": "4.126", "train_ntokens": "1772.88", "train_nsentences": "4.95", "train_prob_perplexity": "37.836", "train_code_perplexity": "37.821", "train_temp": "1.912", "train_loss_0": "3.948", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.30231", "train_wps": "3888.1", "train_ups": "2.19", "train_wpb": "1772.9", "train_bsz": "5", "train_num_updates": "9000", "train_lr": "0.000140625", "train_gnorm": "1.093", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "4315"}
[2022-01-03 13:21:38,173][fairseq.trainer][INFO] - begin training epoch 226
[2022-01-03 13:21:38,174][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:21:51,982][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:21:52,384][valid][INFO] - {"epoch": 226, "valid_loss": "4.29", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "29.729", "valid_code_perplexity": "29.731", "valid_temp": "1.912", "valid_loss_0": "4.111", "valid_loss_1": "0.138", "valid_loss_2": "0.042", "valid_accuracy": "0.32782", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "9040", "valid_best_loss": "3.851"}
[2022-01-03 13:21:52,388][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 226 @ 9040 updates
[2022-01-03 13:21:52,389][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:21:56,332][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:21:56,361][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 226 @ 9040 updates, score 4.29) (writing took 3.9731634007766843 seconds)
[2022-01-03 13:21:56,361][fairseq_cli.train][INFO] - end of epoch 226 (average epoch stats below)
[2022-01-03 13:21:56,374][train][INFO] - {"epoch": 226, "train_loss": "4.161", "train_ntokens": "1785.03", "train_nsentences": "4.95", "train_prob_perplexity": "37.488", "train_code_perplexity": "37.475", "train_temp": "1.912", "train_loss_0": "3.984", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29911", "train_wps": "3906", "train_ups": "2.19", "train_wpb": "1785", "train_bsz": "5", "train_num_updates": "9040", "train_lr": "0.00014125", "train_gnorm": "1.094", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "4334"}
[2022-01-03 13:21:56,453][fairseq.trainer][INFO] - begin training epoch 227
[2022-01-03 13:21:56,454][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:22:10,374][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:22:10,766][valid][INFO] - {"epoch": 227, "valid_loss": "4.255", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "37.457", "valid_code_perplexity": "37.475", "valid_temp": "1.911", "valid_loss_0": "4.082", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.3008", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "9080", "valid_best_loss": "3.851"}
[2022-01-03 13:22:10,769][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 227 @ 9080 updates
[2022-01-03 13:22:10,770][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:22:14,497][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:22:14,525][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 227 @ 9080 updates, score 4.255) (writing took 3.7557760076597333 seconds)
[2022-01-03 13:22:14,526][fairseq_cli.train][INFO] - end of epoch 227 (average epoch stats below)
[2022-01-03 13:22:14,538][train][INFO] - {"epoch": 227, "train_loss": "4.154", "train_ntokens": "1780.95", "train_nsentences": "4.95", "train_prob_perplexity": "37.164", "train_code_perplexity": "37.155", "train_temp": "1.911", "train_loss_0": "3.977", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29918", "train_wps": "3924.7", "train_ups": "2.2", "train_wpb": "1781", "train_bsz": "5", "train_num_updates": "9080", "train_lr": "0.000141875", "train_gnorm": "1.109", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4352"}
[2022-01-03 13:22:14,593][fairseq.trainer][INFO] - begin training epoch 228
[2022-01-03 13:22:14,593][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:22:28,507][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:22:28,913][valid][INFO] - {"epoch": 228, "valid_loss": "4.23", "valid_ntokens": "666", "valid_nsentences": "2", "valid_prob_perplexity": "35.909", "valid_code_perplexity": "35.814", "valid_temp": "1.911", "valid_loss_0": "4.054", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.2958", "valid_wps": "0", "valid_wpb": "666", "valid_bsz": "2", "valid_num_updates": "9120", "valid_best_loss": "3.851"}
[2022-01-03 13:22:28,916][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 228 @ 9120 updates
[2022-01-03 13:22:28,917][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:22:32,822][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:22:32,850][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 228 @ 9120 updates, score 4.23) (writing took 3.9341207491233945 seconds)
[2022-01-03 13:22:32,851][fairseq_cli.train][INFO] - end of epoch 228 (average epoch stats below)
[2022-01-03 13:22:32,863][train][INFO] - {"epoch": 228, "train_loss": "4.163", "train_ntokens": "1789.85", "train_nsentences": "4.95", "train_prob_perplexity": "36.882", "train_code_perplexity": "36.868", "train_temp": "1.911", "train_loss_0": "3.987", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29702", "train_wps": "3909.5", "train_ups": "2.18", "train_wpb": "1789.8", "train_bsz": "5", "train_num_updates": "9120", "train_lr": "0.0001425", "train_gnorm": "1.104", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "4370"}
[2022-01-03 13:22:32,941][fairseq.trainer][INFO] - begin training epoch 229
[2022-01-03 13:22:32,942][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:22:46,902][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:22:47,306][valid][INFO] - {"epoch": 229, "valid_loss": "4.24", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "37.329", "valid_code_perplexity": "37.392", "valid_temp": "1.91", "valid_loss_0": "4.064", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.2679", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "9160", "valid_best_loss": "3.851"}
[2022-01-03 13:22:47,309][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 229 @ 9160 updates
[2022-01-03 13:22:47,310][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:22:51,021][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:22:51,049][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 229 @ 9160 updates, score 4.24) (writing took 3.7399642830714583 seconds)
[2022-01-03 13:22:51,049][fairseq_cli.train][INFO] - end of epoch 229 (average epoch stats below)
[2022-01-03 13:22:51,062][train][INFO] - {"epoch": 229, "train_loss": "4.223", "train_ntokens": "1802.4", "train_nsentences": "4.95", "train_prob_perplexity": "37.318", "train_code_perplexity": "37.309", "train_temp": "1.911", "train_loss_0": "4.045", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.28792", "train_wps": "3964.4", "train_ups": "2.2", "train_wpb": "1802.4", "train_bsz": "5", "train_num_updates": "9160", "train_lr": "0.000143125", "train_gnorm": "1.081", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "4388"}
[2022-01-03 13:22:51,137][fairseq.trainer][INFO] - begin training epoch 230
[2022-01-03 13:22:51,138][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:23:04,978][train_inner][INFO] - {"epoch": 230, "update": 230.0, "loss": "4.176", "ntokens": "1790.39", "nsentences": "4.95", "prob_perplexity": "37.223", "code_perplexity": "37.211", "temp": "1.911", "loss_0": "3.998", "loss_1": "0.136", "loss_2": "0.041", "accuracy": "0.29542", "wps": "3928.6", "ups": "2.19", "wpb": "1790.4", "bsz": "5", "num_updates": "9200", "lr": "0.00014375", "gnorm": "1.092", "clip": "0", "train_wall": "67", "gb_free": "7.2", "wall": "4402"}
[2022-01-03 13:23:04,979][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:23:05,385][valid][INFO] - {"epoch": 230, "valid_loss": "4.454", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "36.129", "valid_code_perplexity": "36.095", "valid_temp": "1.91", "valid_loss_0": "4.279", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.23056", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "9200", "valid_best_loss": "3.851"}
[2022-01-03 13:23:05,390][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 230 @ 9200 updates
[2022-01-03 13:23:05,390][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:23:09,338][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:23:09,367][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 230 @ 9200 updates, score 4.454) (writing took 3.9773377273231745 seconds)
[2022-01-03 13:23:09,367][fairseq_cli.train][INFO] - end of epoch 230 (average epoch stats below)
[2022-01-03 13:23:09,380][train][INFO] - {"epoch": 230, "train_loss": "4.175", "train_ntokens": "1793.72", "train_nsentences": "4.95", "train_prob_perplexity": "37.262", "train_code_perplexity": "37.246", "train_temp": "1.91", "train_loss_0": "3.998", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29397", "train_wps": "3919.6", "train_ups": "2.19", "train_wpb": "1793.7", "train_bsz": "5", "train_num_updates": "9200", "train_lr": "0.00014375", "train_gnorm": "1.072", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "4407"}
[2022-01-03 13:23:09,463][fairseq.trainer][INFO] - begin training epoch 231
[2022-01-03 13:23:09,464][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:23:23,413][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:23:23,810][valid][INFO] - {"epoch": 231, "valid_loss": "4.081", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "37.187", "valid_code_perplexity": "37.232", "valid_temp": "1.91", "valid_loss_0": "3.904", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.30709", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "9240", "valid_best_loss": "3.851"}
[2022-01-03 13:23:23,813][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 231 @ 9240 updates
[2022-01-03 13:23:23,814][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:23:27,601][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:23:27,629][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 231 @ 9240 updates, score 4.081) (writing took 3.8156863525509834 seconds)
[2022-01-03 13:23:27,629][fairseq_cli.train][INFO] - end of epoch 231 (average epoch stats below)
[2022-01-03 13:23:27,642][train][INFO] - {"epoch": 231, "train_loss": "4.149", "train_ntokens": "1773.25", "train_nsentences": "4.95", "train_prob_perplexity": "37.418", "train_code_perplexity": "37.406", "train_temp": "1.91", "train_loss_0": "3.974", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29684", "train_wps": "3886.8", "train_ups": "2.19", "train_wpb": "1773.2", "train_bsz": "5", "train_num_updates": "9240", "train_lr": "0.000144375", "train_gnorm": "1.119", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "4425"}
[2022-01-03 13:23:27,696][fairseq.trainer][INFO] - begin training epoch 232
[2022-01-03 13:23:27,697][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:23:41,788][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:23:42,189][valid][INFO] - {"epoch": 232, "valid_loss": "3.82", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "33.141", "valid_code_perplexity": "33.138", "valid_temp": "1.909", "valid_loss_0": "3.642", "valid_loss_1": "0.137", "valid_loss_2": "0.041", "valid_accuracy": "0.35559", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "9280", "valid_best_loss": "3.82"}
[2022-01-03 13:23:42,192][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 232 @ 9280 updates
[2022-01-03 13:23:42,193][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 13:23:45,842][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 13:23:52,784][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 232 @ 9280 updates, score 3.82) (writing took 10.59217712469399 seconds)
[2022-01-03 13:23:52,785][fairseq_cli.train][INFO] - end of epoch 232 (average epoch stats below)
[2022-01-03 13:23:52,797][train][INFO] - {"epoch": 232, "train_loss": "4.219", "train_ntokens": "1814.6", "train_nsentences": "4.95", "train_prob_perplexity": "37.136", "train_code_perplexity": "37.112", "train_temp": "1.91", "train_loss_0": "4.042", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29064", "train_wps": "2886.9", "train_ups": "1.59", "train_wpb": "1814.6", "train_bsz": "5", "train_num_updates": "9280", "train_lr": "0.000145", "train_gnorm": "1.049", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.4", "train_wall": "4450"}
[2022-01-03 13:23:52,882][fairseq.trainer][INFO] - begin training epoch 233
[2022-01-03 13:23:52,883][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:24:06,684][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:24:07,083][valid][INFO] - {"epoch": 233, "valid_loss": "4.053", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "36.511", "valid_code_perplexity": "36.455", "valid_temp": "1.909", "valid_loss_0": "3.879", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.28021", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "9320", "valid_best_loss": "3.82"}
[2022-01-03 13:24:07,086][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 233 @ 9320 updates
[2022-01-03 13:24:07,087][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:24:11,002][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:24:11,024][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 233 @ 9320 updates, score 4.053) (writing took 3.9385238271206617 seconds)
[2022-01-03 13:24:11,025][fairseq_cli.train][INFO] - end of epoch 233 (average epoch stats below)
[2022-01-03 13:24:11,037][train][INFO] - {"epoch": 233, "train_loss": "4.176", "train_ntokens": "1790.5", "train_nsentences": "4.95", "train_prob_perplexity": "38.077", "train_code_perplexity": "38.065", "train_temp": "1.909", "train_loss_0": "3.998", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29014", "train_wps": "3929.1", "train_ups": "2.19", "train_wpb": "1790.5", "train_bsz": "5", "train_num_updates": "9320", "train_lr": "0.000145625", "train_gnorm": "1.114", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4468"}
[2022-01-03 13:24:11,116][fairseq.trainer][INFO] - begin training epoch 234
[2022-01-03 13:24:11,116][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:24:25,037][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:24:25,431][valid][INFO] - {"epoch": 234, "valid_loss": "4.128", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "37.114", "valid_code_perplexity": "37.139", "valid_temp": "1.909", "valid_loss_0": "3.953", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.28297", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "9360", "valid_best_loss": "3.82"}
[2022-01-03 13:24:25,434][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 234 @ 9360 updates
[2022-01-03 13:24:25,435][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:24:29,186][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:24:29,215][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 234 @ 9360 updates, score 4.128) (writing took 3.780660421587527 seconds)
[2022-01-03 13:24:29,215][fairseq_cli.train][INFO] - end of epoch 234 (average epoch stats below)
[2022-01-03 13:24:29,228][train][INFO] - {"epoch": 234, "train_loss": "4.147", "train_ntokens": "1788.83", "train_nsentences": "4.95", "train_prob_perplexity": "38.136", "train_code_perplexity": "38.127", "train_temp": "1.909", "train_loss_0": "3.969", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29258", "train_wps": "3936.2", "train_ups": "2.2", "train_wpb": "1788.8", "train_bsz": "5", "train_num_updates": "9360", "train_lr": "0.00014625", "train_gnorm": "1.048", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4487"}
[2022-01-03 13:24:29,311][fairseq.trainer][INFO] - begin training epoch 235
[2022-01-03 13:24:29,312][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:24:43,060][train_inner][INFO] - {"epoch": 235, "update": 235.0, "loss": "4.174", "ntokens": "1792.17", "nsentences": "4.95", "prob_perplexity": "37.703", "code_perplexity": "37.689", "temp": "1.909", "loss_0": "3.998", "loss_1": "0.136", "loss_2": "0.04", "accuracy": "0.2926", "wps": "3654.9", "ups": "2.04", "wpb": "1792.2", "bsz": "5", "num_updates": "9400", "lr": "0.000146875", "gnorm": "1.079", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "4500"}
[2022-01-03 13:24:43,061][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:24:43,461][valid][INFO] - {"epoch": 235, "valid_loss": "4.253", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "37.217", "valid_code_perplexity": "37.144", "valid_temp": "1.908", "valid_loss_0": "4.081", "valid_loss_1": "0.136", "valid_loss_2": "0.036", "valid_accuracy": "0.27003", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "9400", "valid_best_loss": "3.82"}
[2022-01-03 13:24:43,464][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 235 @ 9400 updates
[2022-01-03 13:24:43,465][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:24:47,381][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:24:47,408][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 235 @ 9400 updates, score 4.253) (writing took 3.9433751460164785 seconds)
[2022-01-03 13:24:47,408][fairseq_cli.train][INFO] - end of epoch 235 (average epoch stats below)
[2022-01-03 13:24:47,421][train][INFO] - {"epoch": 235, "train_loss": "4.18", "train_ntokens": "1793.7", "train_nsentences": "4.95", "train_prob_perplexity": "37.748", "train_code_perplexity": "37.734", "train_temp": "1.908", "train_loss_0": "4.007", "train_loss_1": "0.136", "train_loss_2": "0.038", "train_accuracy": "0.29284", "train_wps": "3946.6", "train_ups": "2.2", "train_wpb": "1793.7", "train_bsz": "5", "train_num_updates": "9400", "train_lr": "0.000146875", "train_gnorm": "1.068", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4505"}
[2022-01-03 13:24:47,470][fairseq.trainer][INFO] - begin training epoch 236
[2022-01-03 13:24:47,471][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:25:01,354][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:25:01,750][valid][INFO] - {"epoch": 236, "valid_loss": "4.742", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "37.011", "valid_code_perplexity": "36.881", "valid_temp": "1.908", "valid_loss_0": "4.563", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.19061", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "9440", "valid_best_loss": "3.82"}
[2022-01-03 13:25:01,753][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 236 @ 9440 updates
[2022-01-03 13:25:01,754][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:25:05,588][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:25:05,617][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 236 @ 9440 updates, score 4.742) (writing took 3.863630442880094 seconds)
[2022-01-03 13:25:05,617][fairseq_cli.train][INFO] - end of epoch 236 (average epoch stats below)
[2022-01-03 13:25:05,630][train][INFO] - {"epoch": 236, "train_loss": "4.174", "train_ntokens": "1796.58", "train_nsentences": "4.95", "train_prob_perplexity": "38.41", "train_code_perplexity": "38.397", "train_temp": "1.908", "train_loss_0": "3.997", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29356", "train_wps": "3949.3", "train_ups": "2.2", "train_wpb": "1796.6", "train_bsz": "5", "train_num_updates": "9440", "train_lr": "0.0001475", "train_gnorm": "1.022", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4523"}
[2022-01-03 13:25:05,706][fairseq.trainer][INFO] - begin training epoch 237
[2022-01-03 13:25:05,707][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:25:19,661][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:25:20,060][valid][INFO] - {"epoch": 237, "valid_loss": "4.117", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "35.357", "valid_code_perplexity": "35.363", "valid_temp": "1.907", "valid_loss_0": "3.942", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.2907", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "9480", "valid_best_loss": "3.82"}
[2022-01-03 13:25:20,064][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 237 @ 9480 updates
[2022-01-03 13:25:20,065][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:25:23,801][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:25:23,829][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 237 @ 9480 updates, score 4.117) (writing took 3.76478408370167 seconds)
[2022-01-03 13:25:23,829][fairseq_cli.train][INFO] - end of epoch 237 (average epoch stats below)
[2022-01-03 13:25:23,842][train][INFO] - {"epoch": 237, "train_loss": "4.133", "train_ntokens": "1779.22", "train_nsentences": "4.95", "train_prob_perplexity": "37.519", "train_code_perplexity": "37.506", "train_temp": "1.908", "train_loss_0": "3.956", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.30021", "train_wps": "3910.5", "train_ups": "2.2", "train_wpb": "1779.2", "train_bsz": "5", "train_num_updates": "9480", "train_lr": "0.000148125", "train_gnorm": "1.002", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.6", "train_wall": "4541"}
[2022-01-03 13:25:23,894][fairseq.trainer][INFO] - begin training epoch 238
[2022-01-03 13:25:23,895][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:25:37,831][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:25:38,239][valid][INFO] - {"epoch": 238, "valid_loss": "4.123", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "37.517", "valid_code_perplexity": "37.464", "valid_temp": "1.907", "valid_loss_0": "3.948", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.27532", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "9520", "valid_best_loss": "3.82"}
[2022-01-03 13:25:38,241][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 238 @ 9520 updates
[2022-01-03 13:25:38,241][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:25:42,059][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:25:42,088][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 238 @ 9520 updates, score 4.123) (writing took 3.8472489612177014 seconds)
[2022-01-03 13:25:42,089][fairseq_cli.train][INFO] - end of epoch 238 (average epoch stats below)
[2022-01-03 13:25:42,101][train][INFO] - {"epoch": 238, "train_loss": "4.169", "train_ntokens": "1779.67", "train_nsentences": "4.95", "train_prob_perplexity": "37.471", "train_code_perplexity": "37.461", "train_temp": "1.907", "train_loss_0": "3.992", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29616", "train_wps": "3901.4", "train_ups": "2.19", "train_wpb": "1779.7", "train_bsz": "5", "train_num_updates": "9520", "train_lr": "0.00014875", "train_gnorm": "1.079", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "4559"}
[2022-01-03 13:25:42,180][fairseq.trainer][INFO] - begin training epoch 239
[2022-01-03 13:25:42,181][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:25:56,038][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:25:56,427][valid][INFO] - {"epoch": 239, "valid_loss": "4.383", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "32.874", "valid_code_perplexity": "32.85", "valid_temp": "1.907", "valid_loss_0": "4.205", "valid_loss_1": "0.137", "valid_loss_2": "0.041", "valid_accuracy": "0.2875", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "9560", "valid_best_loss": "3.82"}
[2022-01-03 13:25:56,432][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 239 @ 9560 updates
[2022-01-03 13:25:56,433][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:26:00,389][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:26:00,418][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 239 @ 9560 updates, score 4.383) (writing took 3.9867501873522997 seconds)
[2022-01-03 13:26:00,419][fairseq_cli.train][INFO] - end of epoch 239 (average epoch stats below)
[2022-01-03 13:26:00,431][train][INFO] - {"epoch": 239, "train_loss": "4.179", "train_ntokens": "1790.08", "train_nsentences": "4.95", "train_prob_perplexity": "38.222", "train_code_perplexity": "38.211", "train_temp": "1.907", "train_loss_0": "4.001", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29053", "train_wps": "3909.1", "train_ups": "2.18", "train_wpb": "1790.1", "train_bsz": "5", "train_num_updates": "9560", "train_lr": "0.000149375", "train_gnorm": "1.078", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "4578"}
[2022-01-03 13:26:00,512][fairseq.trainer][INFO] - begin training epoch 240
[2022-01-03 13:26:00,513][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:26:14,368][train_inner][INFO] - {"epoch": 240, "update": 240.0, "loss": "4.161", "ntokens": "1786.28", "nsentences": "4.95", "prob_perplexity": "38.031", "code_perplexity": "38.018", "temp": "1.907", "loss_0": "3.984", "loss_1": "0.136", "loss_2": "0.042", "accuracy": "0.29486", "wps": "3913.2", "ups": "2.19", "wpb": "1786.3", "bsz": "5", "num_updates": "9600", "lr": "0.00015", "gnorm": "1.05", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "4592"}
[2022-01-03 13:26:14,368][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:26:14,780][valid][INFO] - {"epoch": 240, "valid_loss": "4.111", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "37.349", "valid_code_perplexity": "37.369", "valid_temp": "1.906", "valid_loss_0": "3.934", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.29737", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "9600", "valid_best_loss": "3.82"}
[2022-01-03 13:26:14,785][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 240 @ 9600 updates
[2022-01-03 13:26:14,785][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:26:18,635][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:26:18,662][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 240 @ 9600 updates, score 4.111) (writing took 3.877703098580241 seconds)
[2022-01-03 13:26:18,663][fairseq_cli.train][INFO] - end of epoch 240 (average epoch stats below)
[2022-01-03 13:26:18,677][train][INFO] - {"epoch": 240, "train_loss": "4.152", "train_ntokens": "1785.83", "train_nsentences": "4.95", "train_prob_perplexity": "38.534", "train_code_perplexity": "38.517", "train_temp": "1.906", "train_loss_0": "3.974", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29388", "train_wps": "3918.1", "train_ups": "2.19", "train_wpb": "1785.8", "train_bsz": "5", "train_num_updates": "9600", "train_lr": "0.00015", "train_gnorm": "1.066", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "4596"}
[2022-01-03 13:26:18,749][fairseq.trainer][INFO] - begin training epoch 241
[2022-01-03 13:26:18,750][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:26:32,638][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:26:33,042][valid][INFO] - {"epoch": 241, "valid_loss": "4.384", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "37.236", "valid_code_perplexity": "37.168", "valid_temp": "1.906", "valid_loss_0": "4.205", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.24611", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "9640", "valid_best_loss": "3.82"}
[2022-01-03 13:26:33,046][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 241 @ 9640 updates
[2022-01-03 13:26:33,048][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:26:36,869][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:26:36,898][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 241 @ 9640 updates, score 4.384) (writing took 3.851748339831829 seconds)
[2022-01-03 13:26:36,899][fairseq_cli.train][INFO] - end of epoch 241 (average epoch stats below)
[2022-01-03 13:26:36,912][train][INFO] - {"epoch": 241, "train_loss": "4.192", "train_ntokens": "1791.9", "train_nsentences": "4.95", "train_prob_perplexity": "37.796", "train_code_perplexity": "37.786", "train_temp": "1.906", "train_loss_0": "4.014", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.28999", "train_wps": "3933.6", "train_ups": "2.2", "train_wpb": "1791.9", "train_bsz": "5", "train_num_updates": "9640", "train_lr": "0.000150625", "train_gnorm": "1.061", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4614"}
[2022-01-03 13:26:36,989][fairseq.trainer][INFO] - begin training epoch 242
[2022-01-03 13:26:36,990][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:26:50,906][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:26:51,302][valid][INFO] - {"epoch": 242, "valid_loss": "4.232", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "35.352", "valid_code_perplexity": "35.333", "valid_temp": "1.906", "valid_loss_0": "4.057", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.29251", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "9680", "valid_best_loss": "3.82"}
[2022-01-03 13:26:51,305][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 242 @ 9680 updates
[2022-01-03 13:26:51,306][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:26:55,093][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:26:55,123][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 242 @ 9680 updates, score 4.232) (writing took 3.817280155606568 seconds)
[2022-01-03 13:26:55,123][fairseq_cli.train][INFO] - end of epoch 242 (average epoch stats below)
[2022-01-03 13:26:55,136][train][INFO] - {"epoch": 242, "train_loss": "4.146", "train_ntokens": "1779.9", "train_nsentences": "4.95", "train_prob_perplexity": "37.696", "train_code_perplexity": "37.695", "train_temp": "1.906", "train_loss_0": "3.971", "train_loss_1": "0.136", "train_loss_2": "0.039", "train_accuracy": "0.29558", "train_wps": "3909.5", "train_ups": "2.2", "train_wpb": "1779.9", "train_bsz": "5", "train_num_updates": "9680", "train_lr": "0.00015125", "train_gnorm": "1.015", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4633"}
[2022-01-03 13:26:55,215][fairseq.trainer][INFO] - begin training epoch 243
[2022-01-03 13:26:55,216][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:27:09,117][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:27:09,510][valid][INFO] - {"epoch": 243, "valid_loss": "4.234", "valid_ntokens": "678", "valid_nsentences": "2", "valid_prob_perplexity": "37.822", "valid_code_perplexity": "37.802", "valid_temp": "1.905", "valid_loss_0": "4.057", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.24631", "valid_wps": "0", "valid_wpb": "678", "valid_bsz": "2", "valid_num_updates": "9720", "valid_best_loss": "3.82"}
[2022-01-03 13:27:09,513][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 243 @ 9720 updates
[2022-01-03 13:27:09,514][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:27:13,415][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:27:13,443][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 243 @ 9720 updates, score 4.234) (writing took 3.9294384587556124 seconds)
[2022-01-03 13:27:13,443][fairseq_cli.train][INFO] - end of epoch 243 (average epoch stats below)
[2022-01-03 13:27:13,456][train][INFO] - {"epoch": 243, "train_loss": "4.146", "train_ntokens": "1797.72", "train_nsentences": "4.95", "train_prob_perplexity": "37.497", "train_code_perplexity": "37.481", "train_temp": "1.905", "train_loss_0": "3.968", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.30091", "train_wps": "3927.9", "train_ups": "2.18", "train_wpb": "1797.7", "train_bsz": "5", "train_num_updates": "9720", "train_lr": "0.000151875", "train_gnorm": "1.07", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "4651"}
[2022-01-03 13:27:13,527][fairseq.trainer][INFO] - begin training epoch 244
[2022-01-03 13:27:13,528][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:27:27,526][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:27:27,926][valid][INFO] - {"epoch": 244, "valid_loss": "4.154", "valid_ntokens": "844", "valid_nsentences": "2", "valid_prob_perplexity": "35.737", "valid_code_perplexity": "35.708", "valid_temp": "1.905", "valid_loss_0": "3.976", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.28673", "valid_wps": "0", "valid_wpb": "844", "valid_bsz": "2", "valid_num_updates": "9760", "valid_best_loss": "3.82"}
[2022-01-03 13:27:27,930][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 244 @ 9760 updates
[2022-01-03 13:27:27,931][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:27:31,589][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:27:31,608][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 244 @ 9760 updates, score 4.154) (writing took 3.678550616838038 seconds)
[2022-01-03 13:27:31,609][fairseq_cli.train][INFO] - end of epoch 244 (average epoch stats below)
[2022-01-03 13:27:31,621][train][INFO] - {"epoch": 244, "train_loss": "4.18", "train_ntokens": "1804.7", "train_nsentences": "4.95", "train_prob_perplexity": "38.014", "train_code_perplexity": "38", "train_temp": "1.905", "train_loss_0": "4.002", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29166", "train_wps": "3976.6", "train_ups": "2.2", "train_wpb": "1804.7", "train_bsz": "5", "train_num_updates": "9760", "train_lr": "0.0001525", "train_gnorm": "1.05", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "4669"}
[2022-01-03 13:27:31,666][fairseq.trainer][INFO] - begin training epoch 245
[2022-01-03 13:27:31,667][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:27:45,552][train_inner][INFO] - {"epoch": 245, "update": 245.0, "loss": "4.16", "ntokens": "1792.49", "nsentences": "4.95", "prob_perplexity": "37.765", "code_perplexity": "37.755", "temp": "1.905", "loss_0": "3.983", "loss_1": "0.136", "loss_2": "0.041", "accuracy": "0.29543", "wps": "3932.1", "ups": "2.19", "wpb": "1792.5", "bsz": "5", "num_updates": "9800", "lr": "0.000153125", "gnorm": "1.034", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "4683"}
[2022-01-03 13:27:45,553][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:27:45,963][valid][INFO] - {"epoch": 245, "valid_loss": "4.451", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "33.49", "valid_code_perplexity": "33.559", "valid_temp": "1.904", "valid_loss_0": "4.276", "valid_loss_1": "0.137", "valid_loss_2": "0.038", "valid_accuracy": "0.28424", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "9800", "valid_best_loss": "3.82"}
[2022-01-03 13:27:45,968][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 245 @ 9800 updates
[2022-01-03 13:27:45,969][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:27:49,942][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:27:49,970][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 245 @ 9800 updates, score 4.451) (writing took 4.002448167651892 seconds)
[2022-01-03 13:27:49,970][fairseq_cli.train][INFO] - end of epoch 245 (average epoch stats below)
[2022-01-03 13:27:49,983][train][INFO] - {"epoch": 245, "train_loss": "4.135", "train_ntokens": "1788.22", "train_nsentences": "4.95", "train_prob_perplexity": "37.823", "train_code_perplexity": "37.812", "train_temp": "1.905", "train_loss_0": "3.958", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29903", "train_wps": "3898.2", "train_ups": "2.18", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "9800", "train_lr": "0.000153125", "train_gnorm": "0.972", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "4687"}
[2022-01-03 13:27:50,056][fairseq.trainer][INFO] - begin training epoch 246
[2022-01-03 13:27:50,057][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:28:03,960][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:28:04,362][valid][INFO] - {"epoch": 246, "valid_loss": "4.438", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "37.387", "valid_code_perplexity": "37.376", "valid_temp": "1.904", "valid_loss_0": "4.261", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.24744", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "9840", "valid_best_loss": "3.82"}
[2022-01-03 13:28:04,367][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 246 @ 9840 updates
[2022-01-03 13:28:04,368][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:28:08,141][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:28:08,170][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 246 @ 9840 updates, score 4.438) (writing took 3.8032060135155916 seconds)
[2022-01-03 13:28:08,170][fairseq_cli.train][INFO] - end of epoch 246 (average epoch stats below)
[2022-01-03 13:28:08,183][train][INFO] - {"epoch": 246, "train_loss": "4.128", "train_ntokens": "1796.53", "train_nsentences": "4.95", "train_prob_perplexity": "38.365", "train_code_perplexity": "38.351", "train_temp": "1.904", "train_loss_0": "3.953", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.2986", "train_wps": "3951.2", "train_ups": "2.2", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "9840", "train_lr": "0.00015375", "train_gnorm": "1.026", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "4706"}
[2022-01-03 13:28:08,258][fairseq.trainer][INFO] - begin training epoch 247
[2022-01-03 13:28:08,259][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:28:22,153][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:28:22,559][valid][INFO] - {"epoch": 247, "valid_loss": "4.071", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "37.118", "valid_code_perplexity": "37.14", "valid_temp": "1.904", "valid_loss_0": "3.893", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.29467", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "9880", "valid_best_loss": "3.82"}
[2022-01-03 13:28:22,563][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 247 @ 9880 updates
[2022-01-03 13:28:22,564][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:28:26,376][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:28:26,403][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 247 @ 9880 updates, score 4.071) (writing took 3.8398158960044384 seconds)
[2022-01-03 13:28:26,404][fairseq_cli.train][INFO] - end of epoch 247 (average epoch stats below)
[2022-01-03 13:28:26,416][train][INFO] - {"epoch": 247, "train_loss": "4.164", "train_ntokens": "1794.9", "train_nsentences": "4.95", "train_prob_perplexity": "38.099", "train_code_perplexity": "38.085", "train_temp": "1.904", "train_loss_0": "3.986", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29415", "train_wps": "3940.3", "train_ups": "2.2", "train_wpb": "1794.9", "train_bsz": "5", "train_num_updates": "9880", "train_lr": "0.000154375", "train_gnorm": "1.048", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "4724"}
[2022-01-03 13:28:26,489][fairseq.trainer][INFO] - begin training epoch 248
[2022-01-03 13:28:26,489][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:28:40,471][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:28:40,870][valid][INFO] - {"epoch": 248, "valid_loss": "4.122", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "35.123", "valid_code_perplexity": "35.124", "valid_temp": "1.903", "valid_loss_0": "3.948", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.29645", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "9920", "valid_best_loss": "3.82"}
[2022-01-03 13:28:40,874][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 248 @ 9920 updates
[2022-01-03 13:28:40,875][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:28:44,657][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:28:44,686][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 248 @ 9920 updates, score 4.122) (writing took 3.811489487066865 seconds)
[2022-01-03 13:28:44,686][fairseq_cli.train][INFO] - end of epoch 248 (average epoch stats below)
[2022-01-03 13:28:44,699][train][INFO] - {"epoch": 248, "train_loss": "4.103", "train_ntokens": "1780.38", "train_nsentences": "4.95", "train_prob_perplexity": "38.329", "train_code_perplexity": "38.317", "train_temp": "1.903", "train_loss_0": "3.924", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.30068", "train_wps": "3898", "train_ups": "2.19", "train_wpb": "1780.4", "train_bsz": "5", "train_num_updates": "9920", "train_lr": "0.000155", "train_gnorm": "0.973", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "4742"}
[2022-01-03 13:28:44,772][fairseq.trainer][INFO] - begin training epoch 249
[2022-01-03 13:28:44,772][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:28:58,851][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:28:59,245][valid][INFO] - {"epoch": 249, "valid_loss": "4.007", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "31.922", "valid_code_perplexity": "31.905", "valid_temp": "1.903", "valid_loss_0": "3.833", "valid_loss_1": "0.137", "valid_loss_2": "0.037", "valid_accuracy": "0.32763", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "9960", "valid_best_loss": "3.82"}
[2022-01-03 13:28:59,248][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 249 @ 9960 updates
[2022-01-03 13:28:59,249][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:29:02,948][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:29:02,978][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 249 @ 9960 updates, score 4.007) (writing took 3.7294843243435025 seconds)
[2022-01-03 13:29:02,979][fairseq_cli.train][INFO] - end of epoch 249 (average epoch stats below)
[2022-01-03 13:29:02,992][train][INFO] - {"epoch": 249, "train_loss": "4.154", "train_ntokens": "1813.97", "train_nsentences": "4.95", "train_prob_perplexity": "38.646", "train_code_perplexity": "38.629", "train_temp": "1.903", "train_loss_0": "3.978", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29059", "train_wps": "3969.4", "train_ups": "2.19", "train_wpb": "1814", "train_bsz": "5", "train_num_updates": "9960", "train_lr": "0.000155625", "train_gnorm": "0.975", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "4760"}
[2022-01-03 13:29:03,066][fairseq.trainer][INFO] - begin training epoch 250
[2022-01-03 13:29:03,067][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:29:16,999][train_inner][INFO] - {"epoch": 250, "update": 250.0, "loss": "4.143", "ntokens": "1795.17", "nsentences": "4.95", "prob_perplexity": "38.288", "code_perplexity": "38.274", "temp": "1.903", "loss_0": "3.966", "loss_1": "0.136", "loss_2": "0.041", "accuracy": "0.2955", "wps": "3926.7", "ups": "2.19", "wpb": "1795.2", "bsz": "5", "num_updates": "10000", "lr": "0.00015625", "gnorm": "1.006", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "4774"}
[2022-01-03 13:29:17,000][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:29:17,490][valid][INFO] - {"epoch": 250, "valid_loss": "3.791", "valid_ntokens": "682", "valid_nsentences": "2", "valid_prob_perplexity": "37.432", "valid_code_perplexity": "37.367", "valid_temp": "1.902", "valid_loss_0": "3.618", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.35484", "valid_wps": "0", "valid_wpb": "682", "valid_bsz": "2", "valid_num_updates": "10000", "valid_best_loss": "3.791"}
[2022-01-03 13:29:17,491][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 250 @ 10000 updates
[2022-01-03 13:29:17,492][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 13:29:21,179][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 13:29:27,683][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 250 @ 10000 updates, score 3.791) (writing took 10.192028895020485 seconds)
[2022-01-03 13:29:27,684][fairseq_cli.train][INFO] - end of epoch 250 (average epoch stats below)
[2022-01-03 13:29:27,696][train][INFO] - {"epoch": 250, "train_loss": "4.165", "train_ntokens": "1790.08", "train_nsentences": "4.95", "train_prob_perplexity": "37.999", "train_code_perplexity": "37.989", "train_temp": "1.903", "train_loss_0": "3.99", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29356", "train_wps": "2899.8", "train_ups": "1.62", "train_wpb": "1790.1", "train_bsz": "5", "train_num_updates": "10000", "train_lr": "0.00015625", "train_gnorm": "1.007", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4785"}
[2022-01-03 13:29:27,758][fairseq.trainer][INFO] - begin training epoch 251
[2022-01-03 13:29:27,758][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:29:41,622][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:29:42,089][valid][INFO] - {"epoch": 251, "valid_loss": "3.9", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "35.463", "valid_code_perplexity": "35.376", "valid_temp": "1.902", "valid_loss_0": "3.724", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.32917", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "10040", "valid_best_loss": "3.791"}
[2022-01-03 13:29:42,091][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 251 @ 10040 updates
[2022-01-03 13:29:42,092][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:29:45,987][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:29:45,998][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 251 @ 10040 updates, score 3.9) (writing took 3.906552934087813 seconds)
[2022-01-03 13:29:45,998][fairseq_cli.train][INFO] - end of epoch 251 (average epoch stats below)
[2022-01-03 13:29:46,011][train][INFO] - {"epoch": 251, "train_loss": "4.178", "train_ntokens": "1793.55", "train_nsentences": "4.95", "train_prob_perplexity": "38.427", "train_code_perplexity": "38.411", "train_temp": "1.902", "train_loss_0": "4", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.28965", "train_wps": "3919.9", "train_ups": "2.19", "train_wpb": "1793.5", "train_bsz": "5", "train_num_updates": "10040", "train_lr": "0.000156875", "train_gnorm": "0.998", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "4803"}
[2022-01-03 13:29:46,084][fairseq.trainer][INFO] - begin training epoch 252
[2022-01-03 13:29:46,085][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:29:59,916][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:30:00,303][valid][INFO] - {"epoch": 252, "valid_loss": "4.131", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "35.784", "valid_code_perplexity": "35.824", "valid_temp": "1.902", "valid_loss_0": "3.956", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.29973", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "10080", "valid_best_loss": "3.791"}
[2022-01-03 13:30:00,307][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 252 @ 10080 updates
[2022-01-03 13:30:00,308][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:30:04,289][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:30:04,317][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 252 @ 10080 updates, score 4.131) (writing took 4.01069790776819 seconds)
[2022-01-03 13:30:04,318][fairseq_cli.train][INFO] - end of epoch 252 (average epoch stats below)
[2022-01-03 13:30:04,330][train][INFO] - {"epoch": 252, "train_loss": "4.136", "train_ntokens": "1779.12", "train_nsentences": "4.95", "train_prob_perplexity": "38.403", "train_code_perplexity": "38.393", "train_temp": "1.902", "train_loss_0": "3.96", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29791", "train_wps": "3887.4", "train_ups": "2.19", "train_wpb": "1779.1", "train_bsz": "5", "train_num_updates": "10080", "train_lr": "0.0001575", "train_gnorm": "0.978", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4822"}
[2022-01-03 13:30:04,405][fairseq.trainer][INFO] - begin training epoch 253
[2022-01-03 13:30:04,406][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:30:18,160][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:30:18,626][valid][INFO] - {"epoch": 253, "valid_loss": "4.282", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "35.169", "valid_code_perplexity": "35.159", "valid_temp": "1.901", "valid_loss_0": "4.107", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.2989", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "10120", "valid_best_loss": "3.791"}
[2022-01-03 13:30:18,627][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 253 @ 10120 updates
[2022-01-03 13:30:18,628][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:30:22,505][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:30:22,526][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 253 @ 10120 updates, score 4.282) (writing took 3.8982185423374176 seconds)
[2022-01-03 13:30:22,526][fairseq_cli.train][INFO] - end of epoch 253 (average epoch stats below)
[2022-01-03 13:30:22,538][train][INFO] - {"epoch": 253, "train_loss": "4.166", "train_ntokens": "1797.83", "train_nsentences": "4.95", "train_prob_perplexity": "38.245", "train_code_perplexity": "38.233", "train_temp": "1.902", "train_loss_0": "3.989", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.2921", "train_wps": "3952.3", "train_ups": "2.2", "train_wpb": "1797.8", "train_bsz": "5", "train_num_updates": "10120", "train_lr": "0.000158125", "train_gnorm": "0.99", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "4840"}
[2022-01-03 13:30:22,583][fairseq.trainer][INFO] - begin training epoch 254
[2022-01-03 13:30:22,584][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:30:36,358][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:30:36,759][valid][INFO] - {"epoch": 254, "valid_loss": "4.068", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "36.433", "valid_code_perplexity": "36.339", "valid_temp": "1.901", "valid_loss_0": "3.889", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.30441", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "10160", "valid_best_loss": "3.791"}
[2022-01-03 13:30:36,763][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 254 @ 10160 updates
[2022-01-03 13:30:36,764][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:30:40,655][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:30:40,675][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 254 @ 10160 updates, score 4.068) (writing took 3.9117870731279254 seconds)
[2022-01-03 13:30:40,675][fairseq_cli.train][INFO] - end of epoch 254 (average epoch stats below)
[2022-01-03 13:30:40,688][train][INFO] - {"epoch": 254, "train_loss": "4.154", "train_ntokens": "1783.97", "train_nsentences": "4.95", "train_prob_perplexity": "38.127", "train_code_perplexity": "38.115", "train_temp": "1.901", "train_loss_0": "3.975", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.29563", "train_wps": "3934.4", "train_ups": "2.21", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "10160", "train_lr": "0.00015875", "train_gnorm": "0.98", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4858"}
[2022-01-03 13:30:40,732][fairseq.trainer][INFO] - begin training epoch 255
[2022-01-03 13:30:40,733][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:30:54,638][train_inner][INFO] - {"epoch": 255, "update": 255.0, "loss": "4.154", "ntokens": "1791.2", "nsentences": "4.95", "prob_perplexity": "38.321", "code_perplexity": "38.309", "temp": "1.902", "loss_0": "3.976", "loss_1": "0.136", "loss_2": "0.042", "accuracy": "0.29419", "wps": "3669.5", "ups": "2.05", "wpb": "1791.2", "bsz": "5", "num_updates": "10200", "lr": "0.000159375", "gnorm": "0.986", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "4872"}
[2022-01-03 13:30:54,639][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:30:55,037][valid][INFO] - {"epoch": 255, "valid_loss": "4.006", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "36.495", "valid_code_perplexity": "36.482", "valid_temp": "1.901", "valid_loss_0": "3.83", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.30055", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "10200", "valid_best_loss": "3.791"}
[2022-01-03 13:30:55,041][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 255 @ 10200 updates
[2022-01-03 13:30:55,042][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:30:59,008][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:30:59,035][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 255 @ 10200 updates, score 4.006) (writing took 3.9939989373087883 seconds)
[2022-01-03 13:30:59,036][fairseq_cli.train][INFO] - end of epoch 255 (average epoch stats below)
[2022-01-03 13:30:59,048][train][INFO] - {"epoch": 255, "train_loss": "4.136", "train_ntokens": "1801.53", "train_nsentences": "4.95", "train_prob_perplexity": "38.404", "train_code_perplexity": "38.39", "train_temp": "1.901", "train_loss_0": "3.958", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29571", "train_wps": "3927.4", "train_ups": "2.18", "train_wpb": "1801.5", "train_bsz": "5", "train_num_updates": "10200", "train_lr": "0.000159375", "train_gnorm": "0.986", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "4876"}
[2022-01-03 13:30:59,119][fairseq.trainer][INFO] - begin training epoch 256
[2022-01-03 13:30:59,119][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:31:12,889][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:31:13,294][valid][INFO] - {"epoch": 256, "valid_loss": "4.143", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "36", "valid_code_perplexity": "35.978", "valid_temp": "1.9", "valid_loss_0": "3.971", "valid_loss_1": "0.136", "valid_loss_2": "0.035", "valid_accuracy": "0.28212", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "10240", "valid_best_loss": "3.791"}
[2022-01-03 13:31:13,297][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 256 @ 10240 updates
[2022-01-03 13:31:13,298][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:31:17,149][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:31:17,176][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 256 @ 10240 updates, score 4.143) (writing took 3.8789407443255186 seconds)
[2022-01-03 13:31:17,177][fairseq_cli.train][INFO] - end of epoch 256 (average epoch stats below)
[2022-01-03 13:31:17,189][train][INFO] - {"epoch": 256, "train_loss": "4.138", "train_ntokens": "1797.95", "train_nsentences": "4.95", "train_prob_perplexity": "37.674", "train_code_perplexity": "37.662", "train_temp": "1.9", "train_loss_0": "3.961", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29428", "train_wps": "3967.1", "train_ups": "2.21", "train_wpb": "1798", "train_bsz": "5", "train_num_updates": "10240", "train_lr": "0.00016", "train_gnorm": "0.978", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "4895"}
[2022-01-03 13:31:17,263][fairseq.trainer][INFO] - begin training epoch 257
[2022-01-03 13:31:17,264][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:31:31,232][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:31:31,625][valid][INFO] - {"epoch": 257, "valid_loss": "4.056", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "38.108", "valid_code_perplexity": "38.143", "valid_temp": "1.9", "valid_loss_0": "3.879", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.31067", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "10280", "valid_best_loss": "3.791"}
[2022-01-03 13:31:31,627][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 257 @ 10280 updates
[2022-01-03 13:31:31,628][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:31:35,387][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:31:35,415][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 257 @ 10280 updates, score 4.056) (writing took 3.788248773664236 seconds)
[2022-01-03 13:31:35,416][fairseq_cli.train][INFO] - end of epoch 257 (average epoch stats below)
[2022-01-03 13:31:35,429][train][INFO] - {"epoch": 257, "train_loss": "4.138", "train_ntokens": "1780.67", "train_nsentences": "4.95", "train_prob_perplexity": "38.285", "train_code_perplexity": "38.273", "train_temp": "1.9", "train_loss_0": "3.961", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.2951", "train_wps": "3907.8", "train_ups": "2.19", "train_wpb": "1780.7", "train_bsz": "5", "train_num_updates": "10280", "train_lr": "0.000160625", "train_gnorm": "1", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "4913"}
[2022-01-03 13:31:35,509][fairseq.trainer][INFO] - begin training epoch 258
[2022-01-03 13:31:35,510][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:31:49,550][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:31:49,939][valid][INFO] - {"epoch": 258, "valid_loss": "4.023", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "33.885", "valid_code_perplexity": "33.824", "valid_temp": "1.899", "valid_loss_0": "3.844", "valid_loss_1": "0.137", "valid_loss_2": "0.042", "valid_accuracy": "0.30842", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "10320", "valid_best_loss": "3.791"}
[2022-01-03 13:31:49,942][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 258 @ 10320 updates
[2022-01-03 13:31:49,943][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:31:53,637][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:31:53,664][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 258 @ 10320 updates, score 4.023) (writing took 3.7219423642382026 seconds)
[2022-01-03 13:31:53,665][fairseq_cli.train][INFO] - end of epoch 258 (average epoch stats below)
[2022-01-03 13:31:53,677][train][INFO] - {"epoch": 258, "train_loss": "4.138", "train_ntokens": "1779.2", "train_nsentences": "4.95", "train_prob_perplexity": "38.667", "train_code_perplexity": "38.649", "train_temp": "1.9", "train_loss_0": "3.96", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29481", "train_wps": "3902.6", "train_ups": "2.19", "train_wpb": "1779.2", "train_bsz": "5", "train_num_updates": "10320", "train_lr": "0.00016125", "train_gnorm": "1.012", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "4931"}
[2022-01-03 13:31:53,749][fairseq.trainer][INFO] - begin training epoch 259
[2022-01-03 13:31:53,750][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:32:07,740][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:32:08,147][valid][INFO] - {"epoch": 259, "valid_loss": "4.267", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "33.277", "valid_code_perplexity": "33.286", "valid_temp": "1.899", "valid_loss_0": "4.087", "valid_loss_1": "0.137", "valid_loss_2": "0.043", "valid_accuracy": "0.28075", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "10360", "valid_best_loss": "3.791"}
[2022-01-03 13:32:08,151][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 259 @ 10360 updates
[2022-01-03 13:32:08,152][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:32:12,049][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:32:12,078][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 259 @ 10360 updates, score 4.267) (writing took 3.926661904901266 seconds)
[2022-01-03 13:32:12,078][fairseq_cli.train][INFO] - end of epoch 259 (average epoch stats below)
[2022-01-03 13:32:12,090][train][INFO] - {"epoch": 259, "train_loss": "4.155", "train_ntokens": "1799.38", "train_nsentences": "4.95", "train_prob_perplexity": "38.603", "train_code_perplexity": "38.589", "train_temp": "1.899", "train_loss_0": "3.978", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29268", "train_wps": "3911.5", "train_ups": "2.17", "train_wpb": "1799.4", "train_bsz": "5", "train_num_updates": "10360", "train_lr": "0.000161875", "train_gnorm": "0.955", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "4949"}
[2022-01-03 13:32:12,144][fairseq.trainer][INFO] - begin training epoch 260
[2022-01-03 13:32:12,145][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:32:26,025][train_inner][INFO] - {"epoch": 260, "update": 260.0, "loss": "4.146", "ntokens": "1789.54", "nsentences": "4.95", "prob_perplexity": "38.348", "code_perplexity": "38.333", "temp": "1.9", "loss_0": "3.968", "loss_1": "0.136", "loss_2": "0.042", "accuracy": "0.29419", "wps": "3916.9", "ups": "2.19", "wpb": "1789.5", "bsz": "5", "num_updates": "10400", "lr": "0.0001625", "gnorm": "0.992", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "4963"}
[2022-01-03 13:32:26,026][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:32:26,426][valid][INFO] - {"epoch": 260, "valid_loss": "3.834", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "37.375", "valid_code_perplexity": "37.426", "valid_temp": "1.899", "valid_loss_0": "3.655", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.31565", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "10400", "valid_best_loss": "3.791"}
[2022-01-03 13:32:26,429][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 260 @ 10400 updates
[2022-01-03 13:32:26,430][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:32:30,384][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:32:30,396][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 260 @ 10400 updates, score 3.834) (writing took 3.967230579815805 seconds)
[2022-01-03 13:32:30,397][fairseq_cli.train][INFO] - end of epoch 260 (average epoch stats below)
[2022-01-03 13:32:30,409][train][INFO] - {"epoch": 260, "train_loss": "4.161", "train_ntokens": "1790.47", "train_nsentences": "4.95", "train_prob_perplexity": "38.513", "train_code_perplexity": "38.492", "train_temp": "1.899", "train_loss_0": "3.981", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.29411", "train_wps": "3912.3", "train_ups": "2.19", "train_wpb": "1790.5", "train_bsz": "5", "train_num_updates": "10400", "train_lr": "0.0001625", "train_gnorm": "1.012", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4968"}
[2022-01-03 13:32:30,499][fairseq.trainer][INFO] - begin training epoch 261
[2022-01-03 13:32:30,500][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:32:44,360][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:32:44,763][valid][INFO] - {"epoch": 261, "valid_loss": "4.047", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "36.175", "valid_code_perplexity": "36.126", "valid_temp": "1.898", "valid_loss_0": "3.871", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.30387", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "10440", "valid_best_loss": "3.791"}
[2022-01-03 13:32:44,766][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 261 @ 10440 updates
[2022-01-03 13:32:44,766][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:32:48,705][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:32:48,734][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 261 @ 10440 updates, score 4.047) (writing took 3.968617723323405 seconds)
[2022-01-03 13:32:48,735][fairseq_cli.train][INFO] - end of epoch 261 (average epoch stats below)
[2022-01-03 13:32:48,747][train][INFO] - {"epoch": 261, "train_loss": "4.176", "train_ntokens": "1797", "train_nsentences": "4.95", "train_prob_perplexity": "38.49", "train_code_perplexity": "38.47", "train_temp": "1.898", "train_loss_0": "3.998", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.2887", "train_wps": "3922.4", "train_ups": "2.18", "train_wpb": "1797", "train_bsz": "5", "train_num_updates": "10440", "train_lr": "0.000163125", "train_gnorm": "0.954", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "4986"}
[2022-01-03 13:32:48,826][fairseq.trainer][INFO] - begin training epoch 262
[2022-01-03 13:32:48,826][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:33:02,704][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:33:03,100][valid][INFO] - {"epoch": 262, "valid_loss": "3.976", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "38.577", "valid_code_perplexity": "38.666", "valid_temp": "1.898", "valid_loss_0": "3.797", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.32548", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "10480", "valid_best_loss": "3.791"}
[2022-01-03 13:33:03,104][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 262 @ 10480 updates
[2022-01-03 13:33:03,104][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:33:06,932][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:33:06,961][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 262 @ 10480 updates, score 3.976) (writing took 3.8578271036967635 seconds)
[2022-01-03 13:33:06,962][fairseq_cli.train][INFO] - end of epoch 262 (average epoch stats below)
[2022-01-03 13:33:06,974][train][INFO] - {"epoch": 262, "train_loss": "4.122", "train_ntokens": "1778.67", "train_nsentences": "4.95", "train_prob_perplexity": "38.703", "train_code_perplexity": "38.689", "train_temp": "1.898", "train_loss_0": "3.944", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29819", "train_wps": "3905.9", "train_ups": "2.2", "train_wpb": "1778.7", "train_bsz": "5", "train_num_updates": "10480", "train_lr": "0.00016375", "train_gnorm": "0.968", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5004"}
[2022-01-03 13:33:07,056][fairseq.trainer][INFO] - begin training epoch 263
[2022-01-03 13:33:07,056][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:33:20,931][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:33:21,321][valid][INFO] - {"epoch": 263, "valid_loss": "4.017", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "36.032", "valid_code_perplexity": "35.981", "valid_temp": "1.898", "valid_loss_0": "3.844", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.31067", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "10520", "valid_best_loss": "3.791"}
[2022-01-03 13:33:21,325][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 263 @ 10520 updates
[2022-01-03 13:33:21,326][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:33:25,250][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:33:25,278][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 263 @ 10520 updates, score 4.017) (writing took 3.9524287953972816 seconds)
[2022-01-03 13:33:25,278][fairseq_cli.train][INFO] - end of epoch 263 (average epoch stats below)
[2022-01-03 13:33:25,290][train][INFO] - {"epoch": 263, "train_loss": "4.16", "train_ntokens": "1800.78", "train_nsentences": "4.95", "train_prob_perplexity": "38.707", "train_code_perplexity": "38.702", "train_temp": "1.898", "train_loss_0": "3.984", "train_loss_1": "0.136", "train_loss_2": "0.04", "train_accuracy": "0.29367", "train_wps": "3935.3", "train_ups": "2.19", "train_wpb": "1800.8", "train_bsz": "5", "train_num_updates": "10520", "train_lr": "0.000164375", "train_gnorm": "0.997", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "5023"}
[2022-01-03 13:33:25,361][fairseq.trainer][INFO] - begin training epoch 264
[2022-01-03 13:33:25,362][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:33:39,274][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:33:39,668][valid][INFO] - {"epoch": 264, "valid_loss": "3.706", "valid_ntokens": "702", "valid_nsentences": "2", "valid_prob_perplexity": "28.878", "valid_code_perplexity": "28.865", "valid_temp": "1.897", "valid_loss_0": "3.527", "valid_loss_1": "0.138", "valid_loss_2": "0.041", "valid_accuracy": "0.38746", "valid_wps": "0", "valid_wpb": "702", "valid_bsz": "2", "valid_num_updates": "10560", "valid_best_loss": "3.706"}
[2022-01-03 13:33:39,670][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 264 @ 10560 updates
[2022-01-03 13:33:39,671][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 13:33:43,420][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 13:33:51,962][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 264 @ 10560 updates, score 3.706) (writing took 12.291145823895931 seconds)
[2022-01-03 13:33:51,962][fairseq_cli.train][INFO] - end of epoch 264 (average epoch stats below)
[2022-01-03 13:33:51,975][train][INFO] - {"epoch": 264, "train_loss": "4.144", "train_ntokens": "1788.75", "train_nsentences": "4.95", "train_prob_perplexity": "38.652", "train_code_perplexity": "38.63", "train_temp": "1.897", "train_loss_0": "3.967", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29368", "train_wps": "2682.6", "train_ups": "1.5", "train_wpb": "1788.8", "train_bsz": "5", "train_num_updates": "10560", "train_lr": "0.000165", "train_gnorm": "0.993", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5049"}
[2022-01-03 13:33:52,052][fairseq.trainer][INFO] - begin training epoch 265
[2022-01-03 13:33:52,052][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:34:05,900][train_inner][INFO] - {"epoch": 265, "update": 265.0, "loss": "4.141", "ntokens": "1791.91", "nsentences": "4.95", "prob_perplexity": "38.632", "code_perplexity": "38.615", "temp": "1.898", "loss_0": "3.964", "loss_1": "0.136", "loss_2": "0.042", "accuracy": "0.29477", "wps": "3588.8", "ups": "2", "wpb": "1791.9", "bsz": "5", "num_updates": "10600", "lr": "0.000165625", "gnorm": "0.971", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "5063"}
[2022-01-03 13:34:05,901][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:34:06,339][valid][INFO] - {"epoch": 265, "valid_loss": "4.11", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "36.922", "valid_code_perplexity": "37.001", "valid_temp": "1.897", "valid_loss_0": "3.929", "valid_loss_1": "0.136", "valid_loss_2": "0.045", "valid_accuracy": "0.3103", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "10600", "valid_best_loss": "3.706"}
[2022-01-03 13:34:06,343][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 265 @ 10600 updates
[2022-01-03 13:34:06,343][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:34:10,306][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:34:10,329][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 265 @ 10600 updates, score 4.11) (writing took 3.9864235585555434 seconds)
[2022-01-03 13:34:10,330][fairseq_cli.train][INFO] - end of epoch 265 (average epoch stats below)
[2022-01-03 13:34:10,342][train][INFO] - {"epoch": 265, "train_loss": "4.103", "train_ntokens": "1794.35", "train_nsentences": "4.95", "train_prob_perplexity": "38.608", "train_code_perplexity": "38.584", "train_temp": "1.897", "train_loss_0": "3.926", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.29963", "train_wps": "3910.5", "train_ups": "2.18", "train_wpb": "1794.3", "train_bsz": "5", "train_num_updates": "10600", "train_lr": "0.000165625", "train_gnorm": "0.944", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "5068"}
[2022-01-03 13:34:10,420][fairseq.trainer][INFO] - begin training epoch 266
[2022-01-03 13:34:10,420][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:34:24,037][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:34:24,506][valid][INFO] - {"epoch": 266, "valid_loss": "4.536", "valid_ntokens": "814", "valid_nsentences": "2", "valid_prob_perplexity": "37.218", "valid_code_perplexity": "37.16", "valid_temp": "1.896", "valid_loss_0": "4.357", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.2285", "valid_wps": "0", "valid_wpb": "814", "valid_bsz": "2", "valid_num_updates": "10640", "valid_best_loss": "3.706"}
[2022-01-03 13:34:24,508][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 266 @ 10640 updates
[2022-01-03 13:34:24,508][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:34:28,392][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:34:28,417][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 266 @ 10640 updates, score 4.536) (writing took 3.9097359515726566 seconds)
[2022-01-03 13:34:28,418][fairseq_cli.train][INFO] - end of epoch 266 (average epoch stats below)
[2022-01-03 13:34:28,430][train][INFO] - {"epoch": 266, "train_loss": "4.121", "train_ntokens": "1786.78", "train_nsentences": "4.95", "train_prob_perplexity": "38.335", "train_code_perplexity": "38.323", "train_temp": "1.897", "train_loss_0": "3.941", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.30216", "train_wps": "3953.9", "train_ups": "2.21", "train_wpb": "1786.8", "train_bsz": "5", "train_num_updates": "10640", "train_lr": "0.00016625", "train_gnorm": "0.983", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5086"}
[2022-01-03 13:34:28,504][fairseq.trainer][INFO] - begin training epoch 267
[2022-01-03 13:34:28,504][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:34:42,137][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:34:42,530][valid][INFO] - {"epoch": 267, "valid_loss": "4.316", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "39.145", "valid_code_perplexity": "39.179", "valid_temp": "1.896", "valid_loss_0": "4.132", "valid_loss_1": "0.135", "valid_loss_2": "0.049", "valid_accuracy": "0.24721", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "10680", "valid_best_loss": "3.706"}
[2022-01-03 13:34:42,534][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 267 @ 10680 updates
[2022-01-03 13:34:42,535][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:34:46,437][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:34:46,455][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 267 @ 10680 updates, score 4.316) (writing took 3.921474227681756 seconds)
[2022-01-03 13:34:46,456][fairseq_cli.train][INFO] - end of epoch 267 (average epoch stats below)
[2022-01-03 13:34:46,468][train][INFO] - {"epoch": 267, "train_loss": "4.121", "train_ntokens": "1797.67", "train_nsentences": "4.95", "train_prob_perplexity": "38.277", "train_code_perplexity": "38.269", "train_temp": "1.896", "train_loss_0": "3.943", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.30005", "train_wps": "3989.3", "train_ups": "2.22", "train_wpb": "1797.7", "train_bsz": "5", "train_num_updates": "10680", "train_lr": "0.000166875", "train_gnorm": "0.969", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "5104"}
[2022-01-03 13:34:46,505][fairseq.trainer][INFO] - begin training epoch 268
[2022-01-03 13:34:46,506][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:35:00,420][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:35:00,897][valid][INFO] - {"epoch": 268, "valid_loss": "4.24", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "38.085", "valid_code_perplexity": "38.069", "valid_temp": "1.896", "valid_loss_0": "4.061", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.26923", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "10720", "valid_best_loss": "3.706"}
[2022-01-03 13:35:00,899][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 268 @ 10720 updates
[2022-01-03 13:35:00,899][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:35:04,682][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:35:04,709][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 268 @ 10720 updates, score 4.24) (writing took 3.8101186491549015 seconds)
[2022-01-03 13:35:04,710][fairseq_cli.train][INFO] - end of epoch 268 (average epoch stats below)
[2022-01-03 13:35:04,722][train][INFO] - {"epoch": 268, "train_loss": "4.136", "train_ntokens": "1781.9", "train_nsentences": "4.95", "train_prob_perplexity": "38.864", "train_code_perplexity": "38.852", "train_temp": "1.896", "train_loss_0": "3.956", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.29412", "train_wps": "3907.3", "train_ups": "2.19", "train_wpb": "1781.9", "train_bsz": "5", "train_num_updates": "10720", "train_lr": "0.0001675", "train_gnorm": "0.965", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5122"}
[2022-01-03 13:35:04,791][fairseq.trainer][INFO] - begin training epoch 269
[2022-01-03 13:35:04,792][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:35:18,637][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:35:19,113][valid][INFO] - {"epoch": 269, "valid_loss": "4.228", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "39.312", "valid_code_perplexity": "39.296", "valid_temp": "1.895", "valid_loss_0": "4.05", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.26593", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "10760", "valid_best_loss": "3.706"}
[2022-01-03 13:35:19,115][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 269 @ 10760 updates
[2022-01-03 13:35:19,116][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:35:22,958][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:35:22,978][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 269 @ 10760 updates, score 4.228) (writing took 3.86273886077106 seconds)
[2022-01-03 13:35:22,979][fairseq_cli.train][INFO] - end of epoch 269 (average epoch stats below)
[2022-01-03 13:35:22,991][train][INFO] - {"epoch": 269, "train_loss": "4.128", "train_ntokens": "1788.2", "train_nsentences": "4.95", "train_prob_perplexity": "38.887", "train_code_perplexity": "38.875", "train_temp": "1.895", "train_loss_0": "3.949", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.2976", "train_wps": "3917.9", "train_ups": "2.19", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "10760", "train_lr": "0.000168125", "train_gnorm": "0.958", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.7", "train_wall": "5140"}
[2022-01-03 13:35:23,049][fairseq.trainer][INFO] - begin training epoch 270
[2022-01-03 13:35:23,049][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:35:36,933][train_inner][INFO] - {"epoch": 270, "update": 270.0, "loss": "4.134", "ntokens": "1788.41", "nsentences": "4.95", "prob_perplexity": "38.648", "code_perplexity": "38.635", "temp": "1.896", "loss_0": "3.955", "loss_1": "0.136", "loss_2": "0.043", "accuracy": "0.29688", "wps": "3929.7", "ups": "2.2", "wpb": "1788.4", "bsz": "5", "num_updates": "10800", "lr": "0.00016875", "gnorm": "0.959", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "5154"}
[2022-01-03 13:35:36,934][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:35:37,334][valid][INFO] - {"epoch": 270, "valid_loss": "4.259", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "38.137", "valid_code_perplexity": "38.232", "valid_temp": "1.895", "valid_loss_0": "4.075", "valid_loss_1": "0.136", "valid_loss_2": "0.048", "valid_accuracy": "0.28933", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "10800", "valid_best_loss": "3.706"}
[2022-01-03 13:35:37,336][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 270 @ 10800 updates
[2022-01-03 13:35:37,337][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:35:41,184][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:35:41,213][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 270 @ 10800 updates, score 4.259) (writing took 3.8762189727276564 seconds)
[2022-01-03 13:35:41,213][fairseq_cli.train][INFO] - end of epoch 270 (average epoch stats below)
[2022-01-03 13:35:41,225][train][INFO] - {"epoch": 270, "train_loss": "4.164", "train_ntokens": "1787.5", "train_nsentences": "4.95", "train_prob_perplexity": "38.876", "train_code_perplexity": "38.855", "train_temp": "1.895", "train_loss_0": "3.985", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29045", "train_wps": "3923.7", "train_ups": "2.2", "train_wpb": "1787.5", "train_bsz": "5", "train_num_updates": "10800", "train_lr": "0.00016875", "train_gnorm": "0.922", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "5159"}
[2022-01-03 13:35:41,288][fairseq.trainer][INFO] - begin training epoch 271
[2022-01-03 13:35:41,289][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:35:55,284][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:35:55,684][valid][INFO] - {"epoch": 271, "valid_loss": "3.786", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "36.615", "valid_code_perplexity": "36.563", "valid_temp": "1.894", "valid_loss_0": "3.613", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.37887", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "10840", "valid_best_loss": "3.706"}
[2022-01-03 13:35:55,687][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 271 @ 10840 updates
[2022-01-03 13:35:55,688][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:35:59,393][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:35:59,421][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 271 @ 10840 updates, score 3.786) (writing took 3.734000421129167 seconds)
[2022-01-03 13:35:59,421][fairseq_cli.train][INFO] - end of epoch 271 (average epoch stats below)
[2022-01-03 13:35:59,434][train][INFO] - {"epoch": 271, "train_loss": "4.137", "train_ntokens": "1793.62", "train_nsentences": "4.95", "train_prob_perplexity": "38.446", "train_code_perplexity": "38.433", "train_temp": "1.895", "train_loss_0": "3.958", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29393", "train_wps": "3942.9", "train_ups": "2.2", "train_wpb": "1793.6", "train_bsz": "5", "train_num_updates": "10840", "train_lr": "0.000169375", "train_gnorm": "0.912", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5177"}
[2022-01-03 13:35:59,488][fairseq.trainer][INFO] - begin training epoch 272
[2022-01-03 13:35:59,488][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:36:13,588][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:36:13,997][valid][INFO] - {"epoch": 272, "valid_loss": "4.433", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "34.597", "valid_code_perplexity": "34.624", "valid_temp": "1.894", "valid_loss_0": "4.249", "valid_loss_1": "0.136", "valid_loss_2": "0.047", "valid_accuracy": "0.27397", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "10880", "valid_best_loss": "3.706"}
[2022-01-03 13:36:14,000][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 272 @ 10880 updates
[2022-01-03 13:36:14,000][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:36:17,670][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:36:17,701][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 272 @ 10880 updates, score 4.433) (writing took 3.7016649544239044 seconds)
[2022-01-03 13:36:17,702][fairseq_cli.train][INFO] - end of epoch 272 (average epoch stats below)
[2022-01-03 13:36:17,715][train][INFO] - {"epoch": 272, "train_loss": "4.099", "train_ntokens": "1801.03", "train_nsentences": "4.95", "train_prob_perplexity": "38.862", "train_code_perplexity": "38.849", "train_temp": "1.894", "train_loss_0": "3.922", "train_loss_1": "0.136", "train_loss_2": "0.042", "train_accuracy": "0.2999", "train_wps": "3943.6", "train_ups": "2.19", "train_wpb": "1801", "train_bsz": "5", "train_num_updates": "10880", "train_lr": "0.00017", "train_gnorm": "0.921", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5195"}
[2022-01-03 13:36:17,801][fairseq.trainer][INFO] - begin training epoch 273
[2022-01-03 13:36:17,802][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:36:31,623][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:36:32,028][valid][INFO] - {"epoch": 273, "valid_loss": "3.945", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "37.97", "valid_code_perplexity": "38.009", "valid_temp": "1.894", "valid_loss_0": "3.767", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.31122", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "10920", "valid_best_loss": "3.706"}
[2022-01-03 13:36:32,030][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 273 @ 10920 updates
[2022-01-03 13:36:32,031][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:36:35,985][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:36:36,008][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 273 @ 10920 updates, score 3.945) (writing took 3.97807695902884 seconds)
[2022-01-03 13:36:36,009][fairseq_cli.train][INFO] - end of epoch 273 (average epoch stats below)
[2022-01-03 13:36:36,021][train][INFO] - {"epoch": 273, "train_loss": "4.131", "train_ntokens": "1794.15", "train_nsentences": "4.95", "train_prob_perplexity": "38.743", "train_code_perplexity": "38.728", "train_temp": "1.894", "train_loss_0": "3.952", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29494", "train_wps": "3923.1", "train_ups": "2.19", "train_wpb": "1794.2", "train_bsz": "5", "train_num_updates": "10920", "train_lr": "0.000170625", "train_gnorm": "0.92", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5213"}
[2022-01-03 13:36:36,081][fairseq.trainer][INFO] - begin training epoch 274
[2022-01-03 13:36:36,082][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:36:49,952][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:36:50,441][valid][INFO] - {"epoch": 274, "valid_loss": "4.077", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "39.431", "valid_code_perplexity": "39.45", "valid_temp": "1.893", "valid_loss_0": "3.9", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.2859", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "10960", "valid_best_loss": "3.706"}
[2022-01-03 13:36:50,443][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 274 @ 10960 updates
[2022-01-03 13:36:50,444][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:36:54,199][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:36:54,226][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 274 @ 10960 updates, score 4.077) (writing took 3.7826088024303317 seconds)
[2022-01-03 13:36:54,226][fairseq_cli.train][INFO] - end of epoch 274 (average epoch stats below)
[2022-01-03 13:36:54,239][train][INFO] - {"epoch": 274, "train_loss": "4.154", "train_ntokens": "1812.7", "train_nsentences": "4.95", "train_prob_perplexity": "38.91", "train_code_perplexity": "38.902", "train_temp": "1.894", "train_loss_0": "3.977", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29448", "train_wps": "3982.8", "train_ups": "2.2", "train_wpb": "1812.7", "train_bsz": "5", "train_num_updates": "10960", "train_lr": "0.00017125", "train_gnorm": "0.913", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "5232"}
[2022-01-03 13:36:54,291][fairseq.trainer][INFO] - begin training epoch 275
[2022-01-03 13:36:54,292][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:37:08,323][train_inner][INFO] - {"epoch": 275, "update": 275.0, "loss": "4.137", "ntokens": "1798.64", "nsentences": "4.95", "prob_perplexity": "38.687", "code_perplexity": "38.675", "temp": "1.894", "loss_0": "3.959", "loss_1": "0.136", "loss_2": "0.043", "accuracy": "0.29554", "wps": "3936.7", "ups": "2.19", "wpb": "1798.6", "bsz": "5", "num_updates": "11000", "lr": "0.000171875", "gnorm": "0.923", "clip": "0", "train_wall": "68", "gb_free": "6.1", "wall": "5246"}
[2022-01-03 13:37:08,324][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:37:08,755][valid][INFO] - {"epoch": 275, "valid_loss": "4.404", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "34.909", "valid_code_perplexity": "35", "valid_temp": "1.893", "valid_loss_0": "4.226", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.27397", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "11000", "valid_best_loss": "3.706"}
[2022-01-03 13:37:08,762][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 275 @ 11000 updates
[2022-01-03 13:37:08,763][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:37:12,437][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:37:12,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 275 @ 11000 updates, score 4.404) (writing took 3.6977503495290875 seconds)
[2022-01-03 13:37:12,461][fairseq_cli.train][INFO] - end of epoch 275 (average epoch stats below)
[2022-01-03 13:37:12,474][train][INFO] - {"epoch": 275, "train_loss": "4.162", "train_ntokens": "1791.7", "train_nsentences": "4.95", "train_prob_perplexity": "38.475", "train_code_perplexity": "38.463", "train_temp": "1.893", "train_loss_0": "3.984", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29444", "train_wps": "3932.9", "train_ups": "2.2", "train_wpb": "1791.7", "train_bsz": "5", "train_num_updates": "11000", "train_lr": "0.000171875", "train_gnorm": "0.95", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "5250"}
[2022-01-03 13:37:12,542][fairseq.trainer][INFO] - begin training epoch 276
[2022-01-03 13:37:12,543][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:37:26,467][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:37:26,864][valid][INFO] - {"epoch": 276, "valid_loss": "4.166", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "36.489", "valid_code_perplexity": "36.519", "valid_temp": "1.893", "valid_loss_0": "3.987", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.27249", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "11040", "valid_best_loss": "3.706"}
[2022-01-03 13:37:26,867][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 276 @ 11040 updates
[2022-01-03 13:37:26,867][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:37:30,662][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:37:30,691][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 276 @ 11040 updates, score 4.166) (writing took 3.8237761752679944 seconds)
[2022-01-03 13:37:30,691][fairseq_cli.train][INFO] - end of epoch 276 (average epoch stats below)
[2022-01-03 13:37:30,705][train][INFO] - {"epoch": 276, "train_loss": "4.128", "train_ntokens": "1792.83", "train_nsentences": "4.95", "train_prob_perplexity": "38.673", "train_code_perplexity": "38.66", "train_temp": "1.893", "train_loss_0": "3.948", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.29844", "train_wps": "3936.6", "train_ups": "2.2", "train_wpb": "1792.8", "train_bsz": "5", "train_num_updates": "11040", "train_lr": "0.0001725", "train_gnorm": "0.983", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "5268"}
[2022-01-03 13:37:30,782][fairseq.trainer][INFO] - begin training epoch 277
[2022-01-03 13:37:30,783][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:37:44,720][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:37:45,119][valid][INFO] - {"epoch": 277, "valid_loss": "4.644", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "38.725", "valid_code_perplexity": "38.709", "valid_temp": "1.892", "valid_loss_0": "4.464", "valid_loss_1": "0.136", "valid_loss_2": "0.044", "valid_accuracy": "0.24084", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "11080", "valid_best_loss": "3.706"}
[2022-01-03 13:37:45,123][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 277 @ 11080 updates
[2022-01-03 13:37:45,124][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:37:48,890][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:37:48,919][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 277 @ 11080 updates, score 4.644) (writing took 3.796108853071928 seconds)
[2022-01-03 13:37:48,919][fairseq_cli.train][INFO] - end of epoch 277 (average epoch stats below)
[2022-01-03 13:37:48,932][train][INFO] - {"epoch": 277, "train_loss": "4.109", "train_ntokens": "1799.83", "train_nsentences": "4.95", "train_prob_perplexity": "38.78", "train_code_perplexity": "38.767", "train_temp": "1.892", "train_loss_0": "3.93", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29929", "train_wps": "3952.6", "train_ups": "2.2", "train_wpb": "1799.8", "train_bsz": "5", "train_num_updates": "11080", "train_lr": "0.000173125", "train_gnorm": "0.929", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "5286"}
[2022-01-03 13:37:49,012][fairseq.trainer][INFO] - begin training epoch 278
[2022-01-03 13:37:49,013][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:38:03,025][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:38:03,433][valid][INFO] - {"epoch": 278, "valid_loss": "4.333", "valid_ntokens": "678", "valid_nsentences": "2", "valid_prob_perplexity": "37.773", "valid_code_perplexity": "37.794", "valid_temp": "1.892", "valid_loss_0": "4.154", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.29204", "valid_wps": "0", "valid_wpb": "678", "valid_bsz": "2", "valid_num_updates": "11120", "valid_best_loss": "3.706"}
[2022-01-03 13:38:03,437][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 278 @ 11120 updates
[2022-01-03 13:38:03,437][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:38:07,151][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:38:07,181][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 278 @ 11120 updates, score 4.333) (writing took 3.7439695484936237 seconds)
[2022-01-03 13:38:07,181][fairseq_cli.train][INFO] - end of epoch 278 (average epoch stats below)
[2022-01-03 13:38:07,194][train][INFO] - {"epoch": 278, "train_loss": "4.087", "train_ntokens": "1783.22", "train_nsentences": "4.95", "train_prob_perplexity": "38.974", "train_code_perplexity": "38.965", "train_temp": "1.892", "train_loss_0": "3.907", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29853", "train_wps": "3908.6", "train_ups": "2.19", "train_wpb": "1783.2", "train_bsz": "5", "train_num_updates": "11120", "train_lr": "0.00017375", "train_gnorm": "0.943", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "5305"}
[2022-01-03 13:38:07,271][fairseq.trainer][INFO] - begin training epoch 279
[2022-01-03 13:38:07,272][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:38:21,241][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:38:21,639][valid][INFO] - {"epoch": 279, "valid_loss": "4.001", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "38.368", "valid_code_perplexity": "38.317", "valid_temp": "1.891", "valid_loss_0": "3.825", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.30226", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "11160", "valid_best_loss": "3.706"}
[2022-01-03 13:38:21,641][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 279 @ 11160 updates
[2022-01-03 13:38:21,642][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:38:25,375][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:38:25,403][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 279 @ 11160 updates, score 4.001) (writing took 3.7618676219135523 seconds)
[2022-01-03 13:38:25,403][fairseq_cli.train][INFO] - end of epoch 279 (average epoch stats below)
[2022-01-03 13:38:25,416][train][INFO] - {"epoch": 279, "train_loss": "4.194", "train_ntokens": "1795.58", "train_nsentences": "4.95", "train_prob_perplexity": "38.618", "train_code_perplexity": "38.597", "train_temp": "1.892", "train_loss_0": "4.012", "train_loss_1": "0.136", "train_loss_2": "0.046", "train_accuracy": "0.28808", "train_wps": "3944.3", "train_ups": "2.2", "train_wpb": "1795.6", "train_bsz": "5", "train_num_updates": "11160", "train_lr": "0.000174375", "train_gnorm": "0.942", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "5323"}
[2022-01-03 13:38:25,488][fairseq.trainer][INFO] - begin training epoch 280
[2022-01-03 13:38:25,489][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:38:39,478][train_inner][INFO] - {"epoch": 280, "update": 280.0, "loss": "4.13", "ntokens": "1792.75", "nsentences": "4.95", "prob_perplexity": "38.738", "code_perplexity": "38.723", "temp": "1.892", "loss_0": "3.951", "loss_1": "0.136", "loss_2": "0.044", "accuracy": "0.29574", "wps": "3934", "ups": "2.19", "wpb": "1792.8", "bsz": "5", "num_updates": "11200", "lr": "0.000175", "gnorm": "0.945", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "5337"}
[2022-01-03 13:38:39,479][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:38:39,887][valid][INFO] - {"epoch": 280, "valid_loss": "4.272", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "32.763", "valid_code_perplexity": "32.704", "valid_temp": "1.891", "valid_loss_0": "4.093", "valid_loss_1": "0.137", "valid_loss_2": "0.042", "valid_accuracy": "0.29442", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "11200", "valid_best_loss": "3.706"}
[2022-01-03 13:38:39,890][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 280 @ 11200 updates
[2022-01-03 13:38:39,891][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:38:43,616][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:38:43,632][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 280 @ 11200 updates, score 4.272) (writing took 3.7421822426840663 seconds)
[2022-01-03 13:38:43,633][fairseq_cli.train][INFO] - end of epoch 280 (average epoch stats below)
[2022-01-03 13:38:43,646][train][INFO] - {"epoch": 280, "train_loss": "4.135", "train_ntokens": "1792.3", "train_nsentences": "4.95", "train_prob_perplexity": "38.646", "train_code_perplexity": "38.624", "train_temp": "1.891", "train_loss_0": "3.956", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29436", "train_wps": "3935.4", "train_ups": "2.2", "train_wpb": "1792.3", "train_bsz": "5", "train_num_updates": "11200", "train_lr": "0.000175", "train_gnorm": "0.926", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5341"}
[2022-01-03 13:38:43,716][fairseq.trainer][INFO] - begin training epoch 281
[2022-01-03 13:38:43,717][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:38:57,587][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:38:57,988][valid][INFO] - {"epoch": 281, "valid_loss": "4.116", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "38.677", "valid_code_perplexity": "38.658", "valid_temp": "1.891", "valid_loss_0": "3.941", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.28771", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "11240", "valid_best_loss": "3.706"}
[2022-01-03 13:38:57,991][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 281 @ 11240 updates
[2022-01-03 13:38:57,991][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:39:01,926][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:39:01,944][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 281 @ 11240 updates, score 4.116) (writing took 3.9533868469297886 seconds)
[2022-01-03 13:39:01,945][fairseq_cli.train][INFO] - end of epoch 281 (average epoch stats below)
[2022-01-03 13:39:01,957][train][INFO] - {"epoch": 281, "train_loss": "4.144", "train_ntokens": "1806.2", "train_nsentences": "4.95", "train_prob_perplexity": "39.213", "train_code_perplexity": "39.2", "train_temp": "1.891", "train_loss_0": "3.965", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29384", "train_wps": "3948.2", "train_ups": "2.19", "train_wpb": "1806.2", "train_bsz": "5", "train_num_updates": "11240", "train_lr": "0.000175625", "train_gnorm": "0.914", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5359"}
[2022-01-03 13:39:02,021][fairseq.trainer][INFO] - begin training epoch 282
[2022-01-03 13:39:02,021][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:39:15,978][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:39:16,386][valid][INFO] - {"epoch": 282, "valid_loss": "3.952", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "38.745", "valid_code_perplexity": "38.801", "valid_temp": "1.89", "valid_loss_0": "3.774", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.3273", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "11280", "valid_best_loss": "3.706"}
[2022-01-03 13:39:16,390][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 282 @ 11280 updates
[2022-01-03 13:39:16,392][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:39:20,197][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:39:20,225][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 282 @ 11280 updates, score 3.952) (writing took 3.835310044698417 seconds)
[2022-01-03 13:39:20,226][fairseq_cli.train][INFO] - end of epoch 282 (average epoch stats below)
[2022-01-03 13:39:20,238][train][INFO] - {"epoch": 282, "train_loss": "4.107", "train_ntokens": "1791.4", "train_nsentences": "4.95", "train_prob_perplexity": "39.182", "train_code_perplexity": "39.164", "train_temp": "1.891", "train_loss_0": "3.929", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.29831", "train_wps": "3922.4", "train_ups": "2.19", "train_wpb": "1791.4", "train_bsz": "5", "train_num_updates": "11280", "train_lr": "0.00017625", "train_gnorm": "0.914", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "5378"}
[2022-01-03 13:39:20,316][fairseq.trainer][INFO] - begin training epoch 283
[2022-01-03 13:39:20,317][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:39:34,118][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:39:34,509][valid][INFO] - {"epoch": 283, "valid_loss": "4.055", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "38.382", "valid_code_perplexity": "38.318", "valid_temp": "1.89", "valid_loss_0": "3.877", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.30971", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "11320", "valid_best_loss": "3.706"}
[2022-01-03 13:39:34,512][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 283 @ 11320 updates
[2022-01-03 13:39:34,513][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:39:38,498][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:39:38,526][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 283 @ 11320 updates, score 4.055) (writing took 4.014084734022617 seconds)
[2022-01-03 13:39:38,527][fairseq_cli.train][INFO] - end of epoch 283 (average epoch stats below)
[2022-01-03 13:39:38,539][train][INFO] - {"epoch": 283, "train_loss": "4.123", "train_ntokens": "1809.2", "train_nsentences": "4.95", "train_prob_perplexity": "39.056", "train_code_perplexity": "39.046", "train_temp": "1.89", "train_loss_0": "3.945", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29606", "train_wps": "3957", "train_ups": "2.19", "train_wpb": "1809.2", "train_bsz": "5", "train_num_updates": "11320", "train_lr": "0.000176875", "train_gnorm": "0.892", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5396"}
[2022-01-03 13:39:38,577][fairseq.trainer][INFO] - begin training epoch 284
[2022-01-03 13:39:38,578][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:39:52,493][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:39:52,959][valid][INFO] - {"epoch": 284, "valid_loss": "4.315", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "36.975", "valid_code_perplexity": "37.008", "valid_temp": "1.89", "valid_loss_0": "4.138", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.26587", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "11360", "valid_best_loss": "3.706"}
[2022-01-03 13:39:52,961][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 284 @ 11360 updates
[2022-01-03 13:39:52,961][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:39:56,621][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:39:56,649][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 284 @ 11360 updates, score 4.315) (writing took 3.6882722983136773 seconds)
[2022-01-03 13:39:56,650][fairseq_cli.train][INFO] - end of epoch 284 (average epoch stats below)
[2022-01-03 13:39:56,662][train][INFO] - {"epoch": 284, "train_loss": "4.149", "train_ntokens": "1801.53", "train_nsentences": "4.95", "train_prob_perplexity": "38.972", "train_code_perplexity": "38.961", "train_temp": "1.89", "train_loss_0": "3.972", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.29518", "train_wps": "3978.9", "train_ups": "2.21", "train_wpb": "1801.5", "train_bsz": "5", "train_num_updates": "11360", "train_lr": "0.0001775", "train_gnorm": "0.901", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "5414"}
[2022-01-03 13:39:56,742][fairseq.trainer][INFO] - begin training epoch 285
[2022-01-03 13:39:56,743][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:40:10,582][train_inner][INFO] - {"epoch": 285, "update": 285.0, "loss": "4.13", "ntokens": "1799.37", "nsentences": "4.95", "prob_perplexity": "39.115", "code_perplexity": "39.102", "temp": "1.89", "loss_0": "3.952", "loss_1": "0.135", "loss_2": "0.043", "accuracy": "0.29564", "wps": "3950.7", "ups": "2.2", "wpb": "1799.4", "bsz": "5", "num_updates": "11400", "lr": "0.000178125", "gnorm": "0.91", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "5428"}
[2022-01-03 13:40:10,583][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:40:11,061][valid][INFO] - {"epoch": 285, "valid_loss": "4.266", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "35.744", "valid_code_perplexity": "35.787", "valid_temp": "1.889", "valid_loss_0": "4.091", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.28099", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "11400", "valid_best_loss": "3.706"}
[2022-01-03 13:40:11,063][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 285 @ 11400 updates
[2022-01-03 13:40:11,064][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:40:14,929][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:40:14,951][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 285 @ 11400 updates, score 4.266) (writing took 3.88832051679492 seconds)
[2022-01-03 13:40:14,952][fairseq_cli.train][INFO] - end of epoch 285 (average epoch stats below)
[2022-01-03 13:40:14,964][train][INFO] - {"epoch": 285, "train_loss": "4.129", "train_ntokens": "1788.53", "train_nsentences": "4.95", "train_prob_perplexity": "39.151", "train_code_perplexity": "39.137", "train_temp": "1.889", "train_loss_0": "3.948", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29482", "train_wps": "3911.6", "train_ups": "2.19", "train_wpb": "1788.5", "train_bsz": "5", "train_num_updates": "11400", "train_lr": "0.000178125", "train_gnorm": "0.928", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "5432"}
[2022-01-03 13:40:15,006][fairseq.trainer][INFO] - begin training epoch 286
[2022-01-03 13:40:15,007][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:40:28,912][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:40:29,312][valid][INFO] - {"epoch": 286, "valid_loss": "4.299", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "38.241", "valid_code_perplexity": "38.199", "valid_temp": "1.889", "valid_loss_0": "4.12", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.25962", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "11440", "valid_best_loss": "3.706"}
[2022-01-03 13:40:29,315][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 286 @ 11440 updates
[2022-01-03 13:40:29,316][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:40:33,227][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:40:33,242][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 286 @ 11440 updates, score 4.299) (writing took 3.926682292483747 seconds)
[2022-01-03 13:40:33,242][fairseq_cli.train][INFO] - end of epoch 286 (average epoch stats below)
[2022-01-03 13:40:33,255][train][INFO] - {"epoch": 286, "train_loss": "4.149", "train_ntokens": "1796.42", "train_nsentences": "4.95", "train_prob_perplexity": "38.897", "train_code_perplexity": "38.885", "train_temp": "1.889", "train_loss_0": "3.971", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29408", "train_wps": "3931.3", "train_ups": "2.19", "train_wpb": "1796.4", "train_bsz": "5", "train_num_updates": "11440", "train_lr": "0.00017875", "train_gnorm": "0.939", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "5451"}
[2022-01-03 13:40:33,328][fairseq.trainer][INFO] - begin training epoch 287
[2022-01-03 13:40:33,329][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:40:47,219][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:40:47,616][valid][INFO] - {"epoch": 287, "valid_loss": "4.182", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "32.668", "valid_code_perplexity": "32.639", "valid_temp": "1.888", "valid_loss_0": "4.004", "valid_loss_1": "0.137", "valid_loss_2": "0.041", "valid_accuracy": "0.30556", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "11480", "valid_best_loss": "3.706"}
[2022-01-03 13:40:47,622][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 287 @ 11480 updates
[2022-01-03 13:40:47,624][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:40:51,402][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:40:51,429][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 287 @ 11480 updates, score 4.182) (writing took 3.8069663234055042 seconds)
[2022-01-03 13:40:51,430][fairseq_cli.train][INFO] - end of epoch 287 (average epoch stats below)
[2022-01-03 13:40:51,443][train][INFO] - {"epoch": 287, "train_loss": "4.131", "train_ntokens": "1809.12", "train_nsentences": "4.95", "train_prob_perplexity": "39.186", "train_code_perplexity": "39.17", "train_temp": "1.889", "train_loss_0": "3.95", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29344", "train_wps": "3981.6", "train_ups": "2.2", "train_wpb": "1809.1", "train_bsz": "5", "train_num_updates": "11480", "train_lr": "0.000179375", "train_gnorm": "0.862", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5469"}
[2022-01-03 13:40:51,513][fairseq.trainer][INFO] - begin training epoch 288
[2022-01-03 13:40:51,513][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:41:05,526][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:41:05,989][valid][INFO] - {"epoch": 288, "valid_loss": "4.012", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "37.97", "valid_code_perplexity": "37.995", "valid_temp": "1.888", "valid_loss_0": "3.834", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.30902", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "11520", "valid_best_loss": "3.706"}
[2022-01-03 13:41:05,990][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 288 @ 11520 updates
[2022-01-03 13:41:05,991][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:41:09,646][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:41:09,675][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 288 @ 11520 updates, score 4.012) (writing took 3.6848637107759714 seconds)
[2022-01-03 13:41:09,676][fairseq_cli.train][INFO] - end of epoch 288 (average epoch stats below)
[2022-01-03 13:41:09,690][train][INFO] - {"epoch": 288, "train_loss": "4.108", "train_ntokens": "1794.03", "train_nsentences": "4.95", "train_prob_perplexity": "38.815", "train_code_perplexity": "38.806", "train_temp": "1.888", "train_loss_0": "3.929", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29802", "train_wps": "3935.7", "train_ups": "2.19", "train_wpb": "1794", "train_bsz": "5", "train_num_updates": "11520", "train_lr": "0.00018", "train_gnorm": "0.882", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "5487"}
[2022-01-03 13:41:09,750][fairseq.trainer][INFO] - begin training epoch 289
[2022-01-03 13:41:09,751][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:41:23,683][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:41:24,092][valid][INFO] - {"epoch": 289, "valid_loss": "4.543", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "38.512", "valid_code_perplexity": "38.475", "valid_temp": "1.888", "valid_loss_0": "4.362", "valid_loss_1": "0.136", "valid_loss_2": "0.046", "valid_accuracy": "0.23404", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "11560", "valid_best_loss": "3.706"}
[2022-01-03 13:41:24,095][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 289 @ 11560 updates
[2022-01-03 13:41:24,095][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:41:27,899][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:41:27,926][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 289 @ 11560 updates, score 4.543) (writing took 3.8313904674723744 seconds)
[2022-01-03 13:41:27,927][fairseq_cli.train][INFO] - end of epoch 289 (average epoch stats below)
[2022-01-03 13:41:27,940][train][INFO] - {"epoch": 289, "train_loss": "4.176", "train_ntokens": "1795.55", "train_nsentences": "4.95", "train_prob_perplexity": "38.991", "train_code_perplexity": "38.976", "train_temp": "1.888", "train_loss_0": "3.997", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.28625", "train_wps": "3938.3", "train_ups": "2.19", "train_wpb": "1795.5", "train_bsz": "5", "train_num_updates": "11560", "train_lr": "0.000180625", "train_gnorm": "0.874", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "5505"}
[2022-01-03 13:41:28,014][fairseq.trainer][INFO] - begin training epoch 290
[2022-01-03 13:41:28,015][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:41:41,877][train_inner][INFO] - {"epoch": 290, "update": 290.0, "loss": "4.134", "ntokens": "1798.38", "nsentences": "4.95", "prob_perplexity": "39.081", "code_perplexity": "39.068", "temp": "1.888", "loss_0": "3.955", "loss_1": "0.135", "loss_2": "0.043", "accuracy": "0.2936", "wps": "3940.3", "ups": "2.19", "wpb": "1798.4", "bsz": "5", "num_updates": "11600", "lr": "0.00018125", "gnorm": "0.894", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "5519"}
[2022-01-03 13:41:41,878][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:41:42,270][valid][INFO] - {"epoch": 290, "valid_loss": "4.065", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "37.46", "valid_code_perplexity": "37.505", "valid_temp": "1.887", "valid_loss_0": "3.889", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.29419", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "11600", "valid_best_loss": "3.706"}
[2022-01-03 13:41:42,273][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 290 @ 11600 updates
[2022-01-03 13:41:42,274][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:41:46,239][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:41:46,267][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 290 @ 11600 updates, score 4.065) (writing took 3.993722762912512 seconds)
[2022-01-03 13:41:46,267][fairseq_cli.train][INFO] - end of epoch 290 (average epoch stats below)
[2022-01-03 13:41:46,280][train][INFO] - {"epoch": 290, "train_loss": "4.105", "train_ntokens": "1796.78", "train_nsentences": "4.95", "train_prob_perplexity": "39.514", "train_code_perplexity": "39.501", "train_temp": "1.887", "train_loss_0": "3.926", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.2962", "train_wps": "3921.5", "train_ups": "2.18", "train_wpb": "1796.8", "train_bsz": "5", "train_num_updates": "11600", "train_lr": "0.00018125", "train_gnorm": "0.911", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5524"}
[2022-01-03 13:41:46,357][fairseq.trainer][INFO] - begin training epoch 291
[2022-01-03 13:41:46,358][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:42:00,286][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:42:00,687][valid][INFO] - {"epoch": 291, "valid_loss": "4.337", "valid_ntokens": "806", "valid_nsentences": "2", "valid_prob_perplexity": "37.499", "valid_code_perplexity": "37.44", "valid_temp": "1.887", "valid_loss_0": "4.155", "valid_loss_1": "0.136", "valid_loss_2": "0.046", "valid_accuracy": "0.26303", "valid_wps": "0", "valid_wpb": "806", "valid_bsz": "2", "valid_num_updates": "11640", "valid_best_loss": "3.706"}
[2022-01-03 13:42:00,689][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 291 @ 11640 updates
[2022-01-03 13:42:00,690][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:42:04,595][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:42:04,615][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 291 @ 11640 updates, score 4.337) (writing took 3.9256254909560084 seconds)
[2022-01-03 13:42:04,615][fairseq_cli.train][INFO] - end of epoch 291 (average epoch stats below)
[2022-01-03 13:42:04,627][train][INFO] - {"epoch": 291, "train_loss": "4.122", "train_ntokens": "1781.55", "train_nsentences": "4.95", "train_prob_perplexity": "38.873", "train_code_perplexity": "38.86", "train_temp": "1.887", "train_loss_0": "3.942", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29885", "train_wps": "3886.7", "train_ups": "2.18", "train_wpb": "1781.5", "train_bsz": "5", "train_num_updates": "11640", "train_lr": "0.000181875", "train_gnorm": "0.946", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "5542"}
[2022-01-03 13:42:04,667][fairseq.trainer][INFO] - begin training epoch 292
[2022-01-03 13:42:04,668][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:42:18,649][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:42:19,058][valid][INFO] - {"epoch": 292, "valid_loss": "4.125", "valid_ntokens": "800", "valid_nsentences": "2", "valid_prob_perplexity": "31.41", "valid_code_perplexity": "31.436", "valid_temp": "1.887", "valid_loss_0": "3.944", "valid_loss_1": "0.137", "valid_loss_2": "0.043", "valid_accuracy": "0.31125", "valid_wps": "0", "valid_wpb": "800", "valid_bsz": "2", "valid_num_updates": "11680", "valid_best_loss": "3.706"}
[2022-01-03 13:42:19,062][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 292 @ 11680 updates
[2022-01-03 13:42:19,062][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:42:22,969][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:42:22,999][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 292 @ 11680 updates, score 4.125) (writing took 3.936933389864862 seconds)
[2022-01-03 13:42:22,999][fairseq_cli.train][INFO] - end of epoch 292 (average epoch stats below)
[2022-01-03 13:42:23,011][train][INFO] - {"epoch": 292, "train_loss": "4.143", "train_ntokens": "1795.15", "train_nsentences": "4.95", "train_prob_perplexity": "39.229", "train_code_perplexity": "39.215", "train_temp": "1.887", "train_loss_0": "3.962", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29376", "train_wps": "3908.5", "train_ups": "2.18", "train_wpb": "1795.2", "train_bsz": "5", "train_num_updates": "11680", "train_lr": "0.0001825", "train_gnorm": "0.892", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5560"}
[2022-01-03 13:42:23,094][fairseq.trainer][INFO] - begin training epoch 293
[2022-01-03 13:42:23,095][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:42:37,051][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:42:37,439][valid][INFO] - {"epoch": 293, "valid_loss": "4.366", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "35.993", "valid_code_perplexity": "35.943", "valid_temp": "1.886", "valid_loss_0": "4.187", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.28223", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "11720", "valid_best_loss": "3.706"}
[2022-01-03 13:42:37,442][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 293 @ 11720 updates
[2022-01-03 13:42:37,442][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:42:41,119][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:42:41,138][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 293 @ 11720 updates, score 4.366) (writing took 3.696023678407073 seconds)
[2022-01-03 13:42:41,138][fairseq_cli.train][INFO] - end of epoch 293 (average epoch stats below)
[2022-01-03 13:42:41,150][train][INFO] - {"epoch": 293, "train_loss": "4.095", "train_ntokens": "1791.72", "train_nsentences": "4.95", "train_prob_perplexity": "38.777", "train_code_perplexity": "38.77", "train_temp": "1.886", "train_loss_0": "3.916", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.29913", "train_wps": "3953.8", "train_ups": "2.21", "train_wpb": "1791.7", "train_bsz": "5", "train_num_updates": "11720", "train_lr": "0.000183125", "train_gnorm": "0.858", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "5579"}
[2022-01-03 13:42:41,186][fairseq.trainer][INFO] - begin training epoch 294
[2022-01-03 13:42:41,187][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:42:55,024][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:42:55,422][valid][INFO] - {"epoch": 294, "valid_loss": "3.885", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "34.587", "valid_code_perplexity": "34.555", "valid_temp": "1.886", "valid_loss_0": "3.709", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.36962", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "11760", "valid_best_loss": "3.706"}
[2022-01-03 13:42:55,425][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 294 @ 11760 updates
[2022-01-03 13:42:55,426][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:42:59,327][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:42:59,356][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 294 @ 11760 updates, score 3.885) (writing took 3.93064980302006 seconds)
[2022-01-03 13:42:59,356][fairseq_cli.train][INFO] - end of epoch 294 (average epoch stats below)
[2022-01-03 13:42:59,369][train][INFO] - {"epoch": 294, "train_loss": "4.139", "train_ntokens": "1787.9", "train_nsentences": "4.95", "train_prob_perplexity": "38.785", "train_code_perplexity": "38.769", "train_temp": "1.886", "train_loss_0": "3.96", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.29694", "train_wps": "3928.2", "train_ups": "2.2", "train_wpb": "1787.9", "train_bsz": "5", "train_num_updates": "11760", "train_lr": "0.00018375", "train_gnorm": "0.887", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "5597"}
[2022-01-03 13:42:59,425][fairseq.trainer][INFO] - begin training epoch 295
[2022-01-03 13:42:59,426][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:43:13,240][train_inner][INFO] - {"epoch": 295, "update": 295.0, "loss": "4.124", "ntokens": "1790.3", "nsentences": "4.95", "prob_perplexity": "39.043", "code_perplexity": "39.029", "temp": "1.886", "loss_0": "3.944", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.29651", "wps": "3919.6", "ups": "2.19", "wpb": "1790.3", "bsz": "5", "num_updates": "11800", "lr": "0.000184375", "gnorm": "0.892", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "5611"}
[2022-01-03 13:43:13,241][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:43:13,637][valid][INFO] - {"epoch": 295, "valid_loss": "4.088", "valid_ntokens": "706", "valid_nsentences": "2", "valid_prob_perplexity": "37.298", "valid_code_perplexity": "37.235", "valid_temp": "1.885", "valid_loss_0": "3.914", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.30453", "valid_wps": "0", "valid_wpb": "706", "valid_bsz": "2", "valid_num_updates": "11800", "valid_best_loss": "3.706"}
[2022-01-03 13:43:13,641][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 295 @ 11800 updates
[2022-01-03 13:43:13,642][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:43:17,561][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:43:17,590][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 295 @ 11800 updates, score 4.088) (writing took 3.9489888716489077 seconds)
[2022-01-03 13:43:17,591][fairseq_cli.train][INFO] - end of epoch 295 (average epoch stats below)
[2022-01-03 13:43:17,603][train][INFO] - {"epoch": 295, "train_loss": "4.121", "train_ntokens": "1795.17", "train_nsentences": "4.95", "train_prob_perplexity": "39.553", "train_code_perplexity": "39.533", "train_temp": "1.886", "train_loss_0": "3.941", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29388", "train_wps": "3940.8", "train_ups": "2.2", "train_wpb": "1795.2", "train_bsz": "5", "train_num_updates": "11800", "train_lr": "0.000184375", "train_gnorm": "0.877", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5615"}
[2022-01-03 13:43:17,682][fairseq.trainer][INFO] - begin training epoch 296
[2022-01-03 13:43:17,683][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:43:31,584][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:43:31,979][valid][INFO] - {"epoch": 296, "valid_loss": "4.009", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "38.699", "valid_code_perplexity": "38.671", "valid_temp": "1.885", "valid_loss_0": "3.834", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.29199", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "11840", "valid_best_loss": "3.706"}
[2022-01-03 13:43:31,983][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 296 @ 11840 updates
[2022-01-03 13:43:31,984][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:43:35,778][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:43:35,806][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 296 @ 11840 updates, score 4.009) (writing took 3.82252099737525 seconds)
[2022-01-03 13:43:35,806][fairseq_cli.train][INFO] - end of epoch 296 (average epoch stats below)
[2022-01-03 13:43:35,819][train][INFO] - {"epoch": 296, "train_loss": "4.148", "train_ntokens": "1806.7", "train_nsentences": "4.95", "train_prob_perplexity": "39.583", "train_code_perplexity": "39.568", "train_temp": "1.885", "train_loss_0": "3.972", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.28975", "train_wps": "3970", "train_ups": "2.2", "train_wpb": "1806.7", "train_bsz": "5", "train_num_updates": "11840", "train_lr": "0.000185", "train_gnorm": "0.861", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "5633"}
[2022-01-03 13:43:35,881][fairseq.trainer][INFO] - begin training epoch 297
[2022-01-03 13:43:35,882][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:43:49,771][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:43:50,174][valid][INFO] - {"epoch": 297, "valid_loss": "4.07", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "35.029", "valid_code_perplexity": "34.915", "valid_temp": "1.885", "valid_loss_0": "3.887", "valid_loss_1": "0.136", "valid_loss_2": "0.047", "valid_accuracy": "0.30457", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "11880", "valid_best_loss": "3.706"}
[2022-01-03 13:43:50,178][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 297 @ 11880 updates
[2022-01-03 13:43:50,179][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:43:54,015][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:43:54,045][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 297 @ 11880 updates, score 4.07) (writing took 3.86691243480891 seconds)
[2022-01-03 13:43:54,045][fairseq_cli.train][INFO] - end of epoch 297 (average epoch stats below)
[2022-01-03 13:43:54,058][train][INFO] - {"epoch": 297, "train_loss": "4.092", "train_ntokens": "1779.53", "train_nsentences": "4.95", "train_prob_perplexity": "39.295", "train_code_perplexity": "39.261", "train_temp": "1.885", "train_loss_0": "3.913", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.30154", "train_wps": "3905.4", "train_ups": "2.19", "train_wpb": "1779.5", "train_bsz": "5", "train_num_updates": "11880", "train_lr": "0.000185625", "train_gnorm": "0.892", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "5651"}
[2022-01-03 13:43:54,113][fairseq.trainer][INFO] - begin training epoch 298
[2022-01-03 13:43:54,113][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:44:08,013][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:44:08,416][valid][INFO] - {"epoch": 298, "valid_loss": "4.584", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "37.746", "valid_code_perplexity": "37.724", "valid_temp": "1.884", "valid_loss_0": "4.404", "valid_loss_1": "0.136", "valid_loss_2": "0.044", "valid_accuracy": "0.21883", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "11920", "valid_best_loss": "3.706"}
[2022-01-03 13:44:08,419][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 298 @ 11920 updates
[2022-01-03 13:44:08,420][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:44:12,215][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:44:12,243][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 298 @ 11920 updates, score 4.584) (writing took 3.8241545855998993 seconds)
[2022-01-03 13:44:12,244][fairseq_cli.train][INFO] - end of epoch 298 (average epoch stats below)
[2022-01-03 13:44:12,256][train][INFO] - {"epoch": 298, "train_loss": "4.113", "train_ntokens": "1777.7", "train_nsentences": "4.95", "train_prob_perplexity": "39.327", "train_code_perplexity": "39.312", "train_temp": "1.884", "train_loss_0": "3.933", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29825", "train_wps": "3910.1", "train_ups": "2.2", "train_wpb": "1777.7", "train_bsz": "5", "train_num_updates": "11920", "train_lr": "0.00018625", "train_gnorm": "0.887", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "5670"}
[2022-01-03 13:44:12,332][fairseq.trainer][INFO] - begin training epoch 299
[2022-01-03 13:44:12,332][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:44:26,323][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:44:26,799][valid][INFO] - {"epoch": 299, "valid_loss": "4.296", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "38.319", "valid_code_perplexity": "38.359", "valid_temp": "1.884", "valid_loss_0": "4.118", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.28099", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "11960", "valid_best_loss": "3.706"}
[2022-01-03 13:44:26,801][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 299 @ 11960 updates
[2022-01-03 13:44:26,801][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:44:30,472][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:44:30,500][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 299 @ 11960 updates, score 4.296) (writing took 3.6992961522191763 seconds)
[2022-01-03 13:44:30,501][fairseq_cli.train][INFO] - end of epoch 299 (average epoch stats below)
[2022-01-03 13:44:30,514][train][INFO] - {"epoch": 299, "train_loss": "4.127", "train_ntokens": "1805.88", "train_nsentences": "4.95", "train_prob_perplexity": "39.08", "train_code_perplexity": "39.069", "train_temp": "1.884", "train_loss_0": "3.946", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29367", "train_wps": "3959.3", "train_ups": "2.19", "train_wpb": "1805.9", "train_bsz": "5", "train_num_updates": "11960", "train_lr": "0.000186875", "train_gnorm": "0.887", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "5688"}
[2022-01-03 13:44:30,592][fairseq.trainer][INFO] - begin training epoch 300
[2022-01-03 13:44:30,593][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:44:44,549][train_inner][INFO] - {"epoch": 300, "update": 300.0, "loss": "4.118", "ntokens": "1791.02", "nsentences": "4.95", "prob_perplexity": "39.281", "code_perplexity": "39.263", "temp": "1.884", "loss_0": "3.939", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.29585", "wps": "3923.5", "ups": "2.19", "wpb": "1791", "bsz": "5", "num_updates": "12000", "lr": "0.0001875", "gnorm": "0.879", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "5702"}
[2022-01-03 13:44:44,550][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:44:45,019][valid][INFO] - {"epoch": 300, "valid_loss": "4.076", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "37.415", "valid_code_perplexity": "37.468", "valid_temp": "1.884", "valid_loss_0": "3.898", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.29971", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "12000", "valid_best_loss": "3.706"}
[2022-01-03 13:44:45,021][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 300 @ 12000 updates
[2022-01-03 13:44:45,021][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:44:48,739][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:44:48,759][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 300 @ 12000 updates, score 4.076) (writing took 3.7384829306975007 seconds)
[2022-01-03 13:44:48,760][fairseq_cli.train][INFO] - end of epoch 300 (average epoch stats below)
[2022-01-03 13:44:48,772][train][INFO] - {"epoch": 300, "train_loss": "4.11", "train_ntokens": "1785.28", "train_nsentences": "4.95", "train_prob_perplexity": "39.121", "train_code_perplexity": "39.106", "train_temp": "1.884", "train_loss_0": "3.931", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29619", "train_wps": "3913.8", "train_ups": "2.19", "train_wpb": "1785.3", "train_bsz": "5", "train_num_updates": "12000", "train_lr": "0.0001875", "train_gnorm": "0.869", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5706"}
[2022-01-03 13:44:48,812][fairseq.trainer][INFO] - begin training epoch 301
[2022-01-03 13:44:48,813][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:45:02,727][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:45:03,228][valid][INFO] - {"epoch": 301, "valid_loss": "4.337", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "38.292", "valid_code_perplexity": "38.233", "valid_temp": "1.883", "valid_loss_0": "4.16", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.26747", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "12040", "valid_best_loss": "3.706"}
[2022-01-03 13:45:03,231][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 301 @ 12040 updates
[2022-01-03 13:45:03,231][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:45:07,116][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:45:07,145][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 301 @ 12040 updates, score 4.337) (writing took 3.9144254960119724 seconds)
[2022-01-03 13:45:07,146][fairseq_cli.train][INFO] - end of epoch 301 (average epoch stats below)
[2022-01-03 13:45:07,158][train][INFO] - {"epoch": 301, "train_loss": "4.133", "train_ntokens": "1793.15", "train_nsentences": "4.95", "train_prob_perplexity": "39.44", "train_code_perplexity": "39.419", "train_temp": "1.883", "train_loss_0": "3.952", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.29194", "train_wps": "3903.7", "train_ups": "2.18", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "12040", "train_lr": "0.000188125", "train_gnorm": "0.871", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "5725"}
[2022-01-03 13:45:07,236][fairseq.trainer][INFO] - begin training epoch 302
[2022-01-03 13:45:07,237][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:45:21,288][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:45:21,774][valid][INFO] - {"epoch": 302, "valid_loss": "4.133", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "38.911", "valid_code_perplexity": "38.89", "valid_temp": "1.883", "valid_loss_0": "3.95", "valid_loss_1": "0.135", "valid_loss_2": "0.048", "valid_accuracy": "0.25881", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "12080", "valid_best_loss": "3.706"}
[2022-01-03 13:45:21,777][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 302 @ 12080 updates
[2022-01-03 13:45:21,777][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:45:25,366][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:45:25,394][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 302 @ 12080 updates, score 4.133) (writing took 3.6178556652739644 seconds)
[2022-01-03 13:45:25,395][fairseq_cli.train][INFO] - end of epoch 302 (average epoch stats below)
[2022-01-03 13:45:25,408][train][INFO] - {"epoch": 302, "train_loss": "4.094", "train_ntokens": "1793.42", "train_nsentences": "4.95", "train_prob_perplexity": "39.021", "train_code_perplexity": "39.003", "train_temp": "1.883", "train_loss_0": "3.915", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.30015", "train_wps": "3933.6", "train_ups": "2.19", "train_wpb": "1793.4", "train_bsz": "5", "train_num_updates": "12080", "train_lr": "0.00018875", "train_gnorm": "0.88", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5743"}
[2022-01-03 13:45:25,481][fairseq.trainer][INFO] - begin training epoch 303
[2022-01-03 13:45:25,482][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:45:39,355][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:45:39,838][valid][INFO] - {"epoch": 303, "valid_loss": "4.171", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "39.18", "valid_code_perplexity": "39.239", "valid_temp": "1.882", "valid_loss_0": "3.994", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.26613", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "12120", "valid_best_loss": "3.706"}
[2022-01-03 13:45:39,840][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 303 @ 12120 updates
[2022-01-03 13:45:39,841][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:45:43,599][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:45:43,629][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 303 @ 12120 updates, score 4.171) (writing took 3.788721000775695 seconds)
[2022-01-03 13:45:43,629][fairseq_cli.train][INFO] - end of epoch 303 (average epoch stats below)
[2022-01-03 13:45:43,641][train][INFO] - {"epoch": 303, "train_loss": "4.114", "train_ntokens": "1807.9", "train_nsentences": "4.95", "train_prob_perplexity": "39.109", "train_code_perplexity": "39.098", "train_temp": "1.883", "train_loss_0": "3.934", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29833", "train_wps": "3968.7", "train_ups": "2.2", "train_wpb": "1807.9", "train_bsz": "5", "train_num_updates": "12120", "train_lr": "0.000189375", "train_gnorm": "0.846", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5761"}
[2022-01-03 13:45:43,721][fairseq.trainer][INFO] - begin training epoch 304
[2022-01-03 13:45:43,722][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:45:57,626][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:45:58,115][valid][INFO] - {"epoch": 304, "valid_loss": "4.102", "valid_ntokens": "800", "valid_nsentences": "2", "valid_prob_perplexity": "38.86", "valid_code_perplexity": "38.841", "valid_temp": "1.882", "valid_loss_0": "3.923", "valid_loss_1": "0.136", "valid_loss_2": "0.044", "valid_accuracy": "0.27125", "valid_wps": "0", "valid_wpb": "800", "valid_bsz": "2", "valid_num_updates": "12160", "valid_best_loss": "3.706"}
[2022-01-03 13:45:58,116][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 304 @ 12160 updates
[2022-01-03 13:45:58,117][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:46:01,821][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:46:01,849][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 304 @ 12160 updates, score 4.102) (writing took 3.732569256797433 seconds)
[2022-01-03 13:46:01,849][fairseq_cli.train][INFO] - end of epoch 304 (average epoch stats below)
[2022-01-03 13:46:01,862][train][INFO] - {"epoch": 304, "train_loss": "4.136", "train_ntokens": "1811.53", "train_nsentences": "4.95", "train_prob_perplexity": "39.343", "train_code_perplexity": "39.328", "train_temp": "1.882", "train_loss_0": "3.956", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29463", "train_wps": "3979.7", "train_ups": "2.2", "train_wpb": "1811.5", "train_bsz": "5", "train_num_updates": "12160", "train_lr": "0.00019", "train_gnorm": "0.842", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5779"}
[2022-01-03 13:46:01,937][fairseq.trainer][INFO] - begin training epoch 305
[2022-01-03 13:46:01,938][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:46:15,963][train_inner][INFO] - {"epoch": 305, "update": 305.0, "loss": "4.115", "ntokens": "1802.3", "nsentences": "4.95", "prob_perplexity": "39.114", "code_perplexity": "39.098", "temp": "1.883", "loss_0": "3.936", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.2964", "wps": "3943.7", "ups": "2.19", "wpb": "1802.3", "bsz": "5", "num_updates": "12200", "lr": "0.000190625", "gnorm": "0.856", "clip": "0", "train_wall": "68", "gb_free": "6.6", "wall": "5793"}
[2022-01-03 13:46:15,964][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:46:16,436][valid][INFO] - {"epoch": 305, "valid_loss": "3.806", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "34.191", "valid_code_perplexity": "34.13", "valid_temp": "1.882", "valid_loss_0": "3.628", "valid_loss_1": "0.137", "valid_loss_2": "0.041", "valid_accuracy": "0.34392", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "12200", "valid_best_loss": "3.706"}
[2022-01-03 13:46:16,438][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 305 @ 12200 updates
[2022-01-03 13:46:16,439][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:46:20,064][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:46:20,089][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 305 @ 12200 updates, score 3.806) (writing took 3.6505806678906083 seconds)
[2022-01-03 13:46:20,089][fairseq_cli.train][INFO] - end of epoch 305 (average epoch stats below)
[2022-01-03 13:46:20,102][train][INFO] - {"epoch": 305, "train_loss": "4.1", "train_ntokens": "1805.5", "train_nsentences": "4.95", "train_prob_perplexity": "38.66", "train_code_perplexity": "38.643", "train_temp": "1.882", "train_loss_0": "3.923", "train_loss_1": "0.136", "train_loss_2": "0.041", "train_accuracy": "0.29694", "train_wps": "3962.1", "train_ups": "2.19", "train_wpb": "1805.5", "train_bsz": "5", "train_num_updates": "12200", "train_lr": "0.000190625", "train_gnorm": "0.839", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "5797"}
[2022-01-03 13:46:20,167][fairseq.trainer][INFO] - begin training epoch 306
[2022-01-03 13:46:20,168][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:46:34,113][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:46:34,530][valid][INFO] - {"epoch": 306, "valid_loss": "4.117", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "37.975", "valid_code_perplexity": "37.986", "valid_temp": "1.881", "valid_loss_0": "3.94", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.2803", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "12240", "valid_best_loss": "3.706"}
[2022-01-03 13:46:34,536][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 306 @ 12240 updates
[2022-01-03 13:46:34,537][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:46:38,326][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:46:38,353][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 306 @ 12240 updates, score 4.117) (writing took 3.8175462568178773 seconds)
[2022-01-03 13:46:38,354][fairseq_cli.train][INFO] - end of epoch 306 (average epoch stats below)
[2022-01-03 13:46:38,366][train][INFO] - {"epoch": 306, "train_loss": "4.154", "train_ntokens": "1798.28", "train_nsentences": "4.95", "train_prob_perplexity": "38.74", "train_code_perplexity": "38.725", "train_temp": "1.881", "train_loss_0": "3.974", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.29439", "train_wps": "3941", "train_ups": "2.19", "train_wpb": "1798.3", "train_bsz": "5", "train_num_updates": "12240", "train_lr": "0.00019125", "train_gnorm": "0.837", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "5816"}
[2022-01-03 13:46:38,439][fairseq.trainer][INFO] - begin training epoch 307
[2022-01-03 13:46:38,440][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:46:52,381][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:46:52,873][valid][INFO] - {"epoch": 307, "valid_loss": "4.126", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "35.391", "valid_code_perplexity": "35.38", "valid_temp": "1.881", "valid_loss_0": "3.948", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.32031", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "12280", "valid_best_loss": "3.706"}
[2022-01-03 13:46:52,875][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 307 @ 12280 updates
[2022-01-03 13:46:52,875][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:46:56,553][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:46:56,582][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 307 @ 12280 updates, score 4.126) (writing took 3.70754558686167 seconds)
[2022-01-03 13:46:56,583][fairseq_cli.train][INFO] - end of epoch 307 (average epoch stats below)
[2022-01-03 13:46:56,596][train][INFO] - {"epoch": 307, "train_loss": "4.143", "train_ntokens": "1808.33", "train_nsentences": "4.95", "train_prob_perplexity": "39.21", "train_code_perplexity": "39.193", "train_temp": "1.881", "train_loss_0": "3.965", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29243", "train_wps": "3970.8", "train_ups": "2.2", "train_wpb": "1808.3", "train_bsz": "5", "train_num_updates": "12280", "train_lr": "0.000191875", "train_gnorm": "0.852", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5834"}
[2022-01-03 13:46:56,675][fairseq.trainer][INFO] - begin training epoch 308
[2022-01-03 13:46:56,676][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:47:10,654][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:47:11,057][valid][INFO] - {"epoch": 308, "valid_loss": "3.952", "valid_ntokens": "796", "valid_nsentences": "2", "valid_prob_perplexity": "39.591", "valid_code_perplexity": "39.606", "valid_temp": "1.881", "valid_loss_0": "3.775", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.30528", "valid_wps": "0", "valid_wpb": "796", "valid_bsz": "2", "valid_num_updates": "12320", "valid_best_loss": "3.706"}
[2022-01-03 13:47:11,061][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 308 @ 12320 updates
[2022-01-03 13:47:11,062][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:47:14,800][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:47:14,828][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 308 @ 12320 updates, score 3.952) (writing took 3.767134765163064 seconds)
[2022-01-03 13:47:14,829][fairseq_cli.train][INFO] - end of epoch 308 (average epoch stats below)
[2022-01-03 13:47:14,842][train][INFO] - {"epoch": 308, "train_loss": "4.127", "train_ntokens": "1797.53", "train_nsentences": "4.95", "train_prob_perplexity": "39.335", "train_code_perplexity": "39.321", "train_temp": "1.881", "train_loss_0": "3.949", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29417", "train_wps": "3943.5", "train_ups": "2.19", "train_wpb": "1797.5", "train_bsz": "5", "train_num_updates": "12320", "train_lr": "0.0001925", "train_gnorm": "0.818", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "5852"}
[2022-01-03 13:47:14,916][fairseq.trainer][INFO] - begin training epoch 309
[2022-01-03 13:47:14,917][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:47:28,910][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:47:29,304][valid][INFO] - {"epoch": 309, "valid_loss": "4.072", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "38.194", "valid_code_perplexity": "38.15", "valid_temp": "1.88", "valid_loss_0": "3.892", "valid_loss_1": "0.136", "valid_loss_2": "0.045", "valid_accuracy": "0.31452", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "12360", "valid_best_loss": "3.706"}
[2022-01-03 13:47:29,307][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 309 @ 12360 updates
[2022-01-03 13:47:29,307][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:47:33,027][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:47:33,055][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 309 @ 12360 updates, score 4.072) (writing took 3.747945399954915 seconds)
[2022-01-03 13:47:33,055][fairseq_cli.train][INFO] - end of epoch 309 (average epoch stats below)
[2022-01-03 13:47:33,068][train][INFO] - {"epoch": 309, "train_loss": "4.111", "train_ntokens": "1806.05", "train_nsentences": "4.95", "train_prob_perplexity": "39.203", "train_code_perplexity": "39.184", "train_temp": "1.88", "train_loss_0": "3.928", "train_loss_1": "0.135", "train_loss_2": "0.047", "train_accuracy": "0.29974", "train_wps": "3966.4", "train_ups": "2.2", "train_wpb": "1806", "train_bsz": "5", "train_num_updates": "12360", "train_lr": "0.000193125", "train_gnorm": "0.903", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5870"}
[2022-01-03 13:47:33,139][fairseq.trainer][INFO] - begin training epoch 310
[2022-01-03 13:47:33,140][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:47:47,084][train_inner][INFO] - {"epoch": 310, "update": 310.0, "loss": "4.13", "ntokens": "1801.81", "nsentences": "4.95", "prob_perplexity": "39.111", "code_perplexity": "39.094", "temp": "1.881", "loss_0": "3.949", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.29605", "wps": "3955.4", "ups": "2.2", "wpb": "1801.8", "bsz": "5", "num_updates": "12400", "lr": "0.00019375", "gnorm": "0.854", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "5884"}
[2022-01-03 13:47:47,085][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:47:47,486][valid][INFO] - {"epoch": 310, "valid_loss": "4.254", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "39.905", "valid_code_perplexity": "39.884", "valid_temp": "1.88", "valid_loss_0": "4.073", "valid_loss_1": "0.135", "valid_loss_2": "0.045", "valid_accuracy": "0.27614", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "12400", "valid_best_loss": "3.706"}
[2022-01-03 13:47:47,490][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 310 @ 12400 updates
[2022-01-03 13:47:47,491][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:47:51,250][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:47:51,270][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 310 @ 12400 updates, score 4.254) (writing took 3.7795703252777457 seconds)
[2022-01-03 13:47:51,271][fairseq_cli.train][INFO] - end of epoch 310 (average epoch stats below)
[2022-01-03 13:47:51,283][train][INFO] - {"epoch": 310, "train_loss": "4.113", "train_ntokens": "1798.88", "train_nsentences": "4.95", "train_prob_perplexity": "39.068", "train_code_perplexity": "39.048", "train_temp": "1.88", "train_loss_0": "3.93", "train_loss_1": "0.135", "train_loss_2": "0.047", "train_accuracy": "0.29953", "train_wps": "3952.9", "train_ups": "2.2", "train_wpb": "1798.9", "train_bsz": "5", "train_num_updates": "12400", "train_lr": "0.00019375", "train_gnorm": "0.862", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "5889"}
[2022-01-03 13:47:51,325][fairseq.trainer][INFO] - begin training epoch 311
[2022-01-03 13:47:51,326][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:48:05,350][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:48:05,747][valid][INFO] - {"epoch": 311, "valid_loss": "4.389", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "38.611", "valid_code_perplexity": "38.578", "valid_temp": "1.879", "valid_loss_0": "4.216", "valid_loss_1": "0.136", "valid_loss_2": "0.038", "valid_accuracy": "0.23615", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "12440", "valid_best_loss": "3.706"}
[2022-01-03 13:48:05,751][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 311 @ 12440 updates
[2022-01-03 13:48:05,751][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:48:09,490][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:48:09,510][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 311 @ 12440 updates, score 4.389) (writing took 3.7590778255835176 seconds)
[2022-01-03 13:48:09,510][fairseq_cli.train][INFO] - end of epoch 311 (average epoch stats below)
[2022-01-03 13:48:09,523][train][INFO] - {"epoch": 311, "train_loss": "4.154", "train_ntokens": "1820.67", "train_nsentences": "4.95", "train_prob_perplexity": "39.568", "train_code_perplexity": "39.555", "train_temp": "1.88", "train_loss_0": "3.975", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.28792", "train_wps": "3995.6", "train_ups": "2.19", "train_wpb": "1820.7", "train_bsz": "5", "train_num_updates": "12440", "train_lr": "0.000194375", "train_gnorm": "0.84", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5907"}
[2022-01-03 13:48:09,577][fairseq.trainer][INFO] - begin training epoch 312
[2022-01-03 13:48:09,578][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:48:23,626][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:48:24,021][valid][INFO] - {"epoch": 312, "valid_loss": "4.508", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "38.125", "valid_code_perplexity": "38.075", "valid_temp": "1.879", "valid_loss_0": "4.329", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.24665", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "12480", "valid_best_loss": "3.706"}
[2022-01-03 13:48:24,023][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 312 @ 12480 updates
[2022-01-03 13:48:24,024][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:48:27,747][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:48:27,774][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 312 @ 12480 updates, score 4.508) (writing took 3.750574352219701 seconds)
[2022-01-03 13:48:27,775][fairseq_cli.train][INFO] - end of epoch 312 (average epoch stats below)
[2022-01-03 13:48:27,787][train][INFO] - {"epoch": 312, "train_loss": "4.087", "train_ntokens": "1793.85", "train_nsentences": "4.95", "train_prob_perplexity": "38.896", "train_code_perplexity": "38.89", "train_temp": "1.879", "train_loss_0": "3.908", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.30094", "train_wps": "3931.4", "train_ups": "2.19", "train_wpb": "1793.8", "train_bsz": "5", "train_num_updates": "12480", "train_lr": "0.000195", "train_gnorm": "0.853", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "5925"}
[2022-01-03 13:48:27,845][fairseq.trainer][INFO] - begin training epoch 313
[2022-01-03 13:48:27,845][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:48:41,760][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:48:42,154][valid][INFO] - {"epoch": 313, "valid_loss": "4.666", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "38.437", "valid_code_perplexity": "38.407", "valid_temp": "1.879", "valid_loss_0": "4.481", "valid_loss_1": "0.136", "valid_loss_2": "0.049", "valid_accuracy": "0.23219", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "12520", "valid_best_loss": "3.706"}
[2022-01-03 13:48:42,157][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 313 @ 12520 updates
[2022-01-03 13:48:42,158][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:48:46,084][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:48:46,091][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 313 @ 12520 updates, score 4.666) (writing took 3.9334573233500123 seconds)
[2022-01-03 13:48:46,091][fairseq_cli.train][INFO] - end of epoch 313 (average epoch stats below)
[2022-01-03 13:48:46,103][train][INFO] - {"epoch": 313, "train_loss": "4.117", "train_ntokens": "1793.92", "train_nsentences": "4.95", "train_prob_perplexity": "39.286", "train_code_perplexity": "39.272", "train_temp": "1.879", "train_loss_0": "3.938", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29553", "train_wps": "3920.3", "train_ups": "2.19", "train_wpb": "1793.9", "train_bsz": "5", "train_num_updates": "12520", "train_lr": "0.000195625", "train_gnorm": "0.885", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "5944"}
[2022-01-03 13:48:46,140][fairseq.trainer][INFO] - begin training epoch 314
[2022-01-03 13:48:46,141][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:49:00,085][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:49:00,476][valid][INFO] - {"epoch": 314, "valid_loss": "4.035", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "36.89", "valid_code_perplexity": "36.873", "valid_temp": "1.878", "valid_loss_0": "3.851", "valid_loss_1": "0.136", "valid_loss_2": "0.048", "valid_accuracy": "0.30718", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "12560", "valid_best_loss": "3.706"}
[2022-01-03 13:49:00,479][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 314 @ 12560 updates
[2022-01-03 13:49:00,480][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:49:04,385][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:49:04,413][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 314 @ 12560 updates, score 4.035) (writing took 3.934048409573734 seconds)
[2022-01-03 13:49:04,414][fairseq_cli.train][INFO] - end of epoch 314 (average epoch stats below)
[2022-01-03 13:49:04,426][train][INFO] - {"epoch": 314, "train_loss": "4.134", "train_ntokens": "1788.25", "train_nsentences": "4.95", "train_prob_perplexity": "38.962", "train_code_perplexity": "38.944", "train_temp": "1.878", "train_loss_0": "3.952", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.29438", "train_wps": "3906.5", "train_ups": "2.18", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "12560", "train_lr": "0.00019625", "train_gnorm": "0.844", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "5962"}
[2022-01-03 13:49:04,505][fairseq.trainer][INFO] - begin training epoch 315
[2022-01-03 13:49:04,506][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:49:18,473][train_inner][INFO] - {"epoch": 315, "update": 315.0, "loss": "4.122", "ntokens": "1797.88", "nsentences": "4.95", "prob_perplexity": "39.145", "code_perplexity": "39.132", "temp": "1.879", "loss_0": "3.941", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.29473", "wps": "3935.1", "ups": "2.19", "wpb": "1797.9", "bsz": "5", "num_updates": "12600", "lr": "0.000196875", "gnorm": "0.855", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "5976"}
[2022-01-03 13:49:18,474][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:49:18,903][valid][INFO] - {"epoch": 315, "valid_loss": "4.07", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "37.517", "valid_code_perplexity": "37.531", "valid_temp": "1.878", "valid_loss_0": "3.885", "valid_loss_1": "0.136", "valid_loss_2": "0.049", "valid_accuracy": "0.29434", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "12600", "valid_best_loss": "3.706"}
[2022-01-03 13:49:18,906][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 315 @ 12600 updates
[2022-01-03 13:49:18,907][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:49:22,547][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:49:22,568][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 315 @ 12600 updates, score 4.07) (writing took 3.661350321955979 seconds)
[2022-01-03 13:49:22,568][fairseq_cli.train][INFO] - end of epoch 315 (average epoch stats below)
[2022-01-03 13:49:22,580][train][INFO] - {"epoch": 315, "train_loss": "4.117", "train_ntokens": "1792.67", "train_nsentences": "4.95", "train_prob_perplexity": "39.015", "train_code_perplexity": "39", "train_temp": "1.878", "train_loss_0": "3.934", "train_loss_1": "0.135", "train_loss_2": "0.048", "train_accuracy": "0.29496", "train_wps": "3952.6", "train_ups": "2.2", "train_wpb": "1792.7", "train_bsz": "5", "train_num_updates": "12600", "train_lr": "0.000196875", "train_gnorm": "0.854", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "5980"}
[2022-01-03 13:49:22,631][fairseq.trainer][INFO] - begin training epoch 316
[2022-01-03 13:49:22,632][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:49:36,621][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:49:37,106][valid][INFO] - {"epoch": 316, "valid_loss": "4.285", "valid_ntokens": "798", "valid_nsentences": "2", "valid_prob_perplexity": "39.005", "valid_code_perplexity": "39.052", "valid_temp": "1.878", "valid_loss_0": "4.106", "valid_loss_1": "0.135", "valid_loss_2": "0.044", "valid_accuracy": "0.27444", "valid_wps": "0", "valid_wpb": "798", "valid_bsz": "2", "valid_num_updates": "12640", "valid_best_loss": "3.706"}
[2022-01-03 13:49:37,108][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 316 @ 12640 updates
[2022-01-03 13:49:37,108][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:49:40,789][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:49:40,816][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 316 @ 12640 updates, score 4.285) (writing took 3.708527776412666 seconds)
[2022-01-03 13:49:40,817][fairseq_cli.train][INFO] - end of epoch 316 (average epoch stats below)
[2022-01-03 13:49:40,830][train][INFO] - {"epoch": 316, "train_loss": "4.127", "train_ntokens": "1777.47", "train_nsentences": "4.95", "train_prob_perplexity": "39.025", "train_code_perplexity": "39.015", "train_temp": "1.878", "train_loss_0": "3.943", "train_loss_1": "0.135", "train_loss_2": "0.049", "train_accuracy": "0.29787", "train_wps": "3898.7", "train_ups": "2.19", "train_wpb": "1777.5", "train_bsz": "5", "train_num_updates": "12640", "train_lr": "0.0001975", "train_gnorm": "0.834", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "5998"}
[2022-01-03 13:49:40,877][fairseq.trainer][INFO] - begin training epoch 317
[2022-01-03 13:49:40,878][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:49:54,730][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:49:55,129][valid][INFO] - {"epoch": 317, "valid_loss": "4.177", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "39.417", "valid_code_perplexity": "39.386", "valid_temp": "1.877", "valid_loss_0": "3.998", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.26216", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "12680", "valid_best_loss": "3.706"}
[2022-01-03 13:49:55,132][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 317 @ 12680 updates
[2022-01-03 13:49:55,133][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:49:59,066][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:49:59,093][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 317 @ 12680 updates, score 4.177) (writing took 3.9608195619657636 seconds)
[2022-01-03 13:49:59,094][fairseq_cli.train][INFO] - end of epoch 317 (average epoch stats below)
[2022-01-03 13:49:59,106][train][INFO] - {"epoch": 317, "train_loss": "4.122", "train_ntokens": "1804.83", "train_nsentences": "4.95", "train_prob_perplexity": "39.287", "train_code_perplexity": "39.279", "train_temp": "1.877", "train_loss_0": "3.944", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29346", "train_wps": "3952.8", "train_ups": "2.19", "train_wpb": "1804.8", "train_bsz": "5", "train_num_updates": "12680", "train_lr": "0.000198125", "train_gnorm": "0.793", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "6017"}
[2022-01-03 13:49:59,187][fairseq.trainer][INFO] - begin training epoch 318
[2022-01-03 13:49:59,188][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:50:13,050][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:50:13,444][valid][INFO] - {"epoch": 318, "valid_loss": "4.166", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "38.19", "valid_code_perplexity": "38.181", "valid_temp": "1.877", "valid_loss_0": "3.987", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.28517", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "12720", "valid_best_loss": "3.706"}
[2022-01-03 13:50:13,448][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 318 @ 12720 updates
[2022-01-03 13:50:13,449][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:50:17,211][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:50:17,231][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 318 @ 12720 updates, score 4.166) (writing took 3.7824146123602986 seconds)
[2022-01-03 13:50:17,231][fairseq_cli.train][INFO] - end of epoch 318 (average epoch stats below)
[2022-01-03 13:50:17,243][train][INFO] - {"epoch": 318, "train_loss": "4.107", "train_ntokens": "1786.9", "train_nsentences": "4.95", "train_prob_perplexity": "39.438", "train_code_perplexity": "39.421", "train_temp": "1.877", "train_loss_0": "3.928", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29684", "train_wps": "3943.5", "train_ups": "2.21", "train_wpb": "1786.9", "train_bsz": "5", "train_num_updates": "12720", "train_lr": "0.00019875", "train_gnorm": "0.856", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "6035"}
[2022-01-03 13:50:17,288][fairseq.trainer][INFO] - begin training epoch 319
[2022-01-03 13:50:17,289][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:50:31,245][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:50:31,656][valid][INFO] - {"epoch": 319, "valid_loss": "3.81", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "35.516", "valid_code_perplexity": "35.503", "valid_temp": "1.876", "valid_loss_0": "3.632", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.36096", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "12760", "valid_best_loss": "3.706"}
[2022-01-03 13:50:31,659][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 319 @ 12760 updates
[2022-01-03 13:50:31,659][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:50:35,581][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:50:35,609][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 319 @ 12760 updates, score 3.81) (writing took 3.950369548983872 seconds)
[2022-01-03 13:50:35,610][fairseq_cli.train][INFO] - end of epoch 319 (average epoch stats below)
[2022-01-03 13:50:35,623][train][INFO] - {"epoch": 319, "train_loss": "4.122", "train_ntokens": "1787.22", "train_nsentences": "4.95", "train_prob_perplexity": "39.044", "train_code_perplexity": "39.035", "train_temp": "1.877", "train_loss_0": "3.943", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.2967", "train_wps": "3892.4", "train_ups": "2.18", "train_wpb": "1787.2", "train_bsz": "5", "train_num_updates": "12760", "train_lr": "0.000199375", "train_gnorm": "0.85", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6053"}
[2022-01-03 13:50:35,693][fairseq.trainer][INFO] - begin training epoch 320
[2022-01-03 13:50:35,694][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:50:49,684][train_inner][INFO] - {"epoch": 320, "update": 320.0, "loss": "4.111", "ntokens": "1787.07", "nsentences": "4.95", "prob_perplexity": "39.104", "code_perplexity": "39.093", "temp": "1.877", "loss_0": "3.932", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.29772", "wps": "3919.1", "ups": "2.19", "wpb": "1787.1", "bsz": "5", "num_updates": "12800", "lr": "0.0002", "gnorm": "0.832", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "6067"}
[2022-01-03 13:50:49,685][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:50:50,084][valid][INFO] - {"epoch": 320, "valid_loss": "3.973", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "33.39", "valid_code_perplexity": "33.399", "valid_temp": "1.876", "valid_loss_0": "3.791", "valid_loss_1": "0.137", "valid_loss_2": "0.045", "valid_accuracy": "0.34711", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "12800", "valid_best_loss": "3.706"}
[2022-01-03 13:50:50,087][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 320 @ 12800 updates
[2022-01-03 13:50:50,088][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:50:53,751][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:50:53,774][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 320 @ 12800 updates, score 3.973) (writing took 3.6870178813114762 seconds)
[2022-01-03 13:50:53,775][fairseq_cli.train][INFO] - end of epoch 320 (average epoch stats below)
[2022-01-03 13:50:53,787][train][INFO] - {"epoch": 320, "train_loss": "4.079", "train_ntokens": "1778.9", "train_nsentences": "4.95", "train_prob_perplexity": "38.726", "train_code_perplexity": "38.715", "train_temp": "1.876", "train_loss_0": "3.901", "train_loss_1": "0.136", "train_loss_2": "0.043", "train_accuracy": "0.3038", "train_wps": "3920", "train_ups": "2.2", "train_wpb": "1778.9", "train_bsz": "5", "train_num_updates": "12800", "train_lr": "0.0002", "train_gnorm": "0.829", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "6071"}
[2022-01-03 13:50:53,841][fairseq.trainer][INFO] - begin training epoch 321
[2022-01-03 13:50:53,842][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:51:07,831][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:51:08,237][valid][INFO] - {"epoch": 321, "valid_loss": "4.1", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "37.999", "valid_code_perplexity": "37.995", "valid_temp": "1.876", "valid_loss_0": "3.922", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.27734", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "12840", "valid_best_loss": "3.706"}
[2022-01-03 13:51:08,240][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 321 @ 12840 updates
[2022-01-03 13:51:08,241][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:51:12,091][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:51:12,118][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 321 @ 12840 updates, score 4.1) (writing took 3.8775703087449074 seconds)
[2022-01-03 13:51:12,118][fairseq_cli.train][INFO] - end of epoch 321 (average epoch stats below)
[2022-01-03 13:51:12,131][train][INFO] - {"epoch": 321, "train_loss": "4.108", "train_ntokens": "1786.55", "train_nsentences": "4.95", "train_prob_perplexity": "39.528", "train_code_perplexity": "39.513", "train_temp": "1.876", "train_loss_0": "3.928", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29932", "train_wps": "3898.3", "train_ups": "2.18", "train_wpb": "1786.5", "train_bsz": "5", "train_num_updates": "12840", "train_lr": "0.000200625", "train_gnorm": "0.814", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6090"}
[2022-01-03 13:51:12,214][fairseq.trainer][INFO] - begin training epoch 322
[2022-01-03 13:51:12,215][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:51:26,262][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:51:26,728][valid][INFO] - {"epoch": 322, "valid_loss": "4.083", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "38.61", "valid_code_perplexity": "38.559", "valid_temp": "1.875", "valid_loss_0": "3.897", "valid_loss_1": "0.136", "valid_loss_2": "0.05", "valid_accuracy": "0.2874", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "12880", "valid_best_loss": "3.706"}
[2022-01-03 13:51:26,730][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 322 @ 12880 updates
[2022-01-03 13:51:26,730][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:51:30,532][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:51:30,562][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 322 @ 12880 updates, score 4.083) (writing took 3.83204906899482 seconds)
[2022-01-03 13:51:30,562][fairseq_cli.train][INFO] - end of epoch 322 (average epoch stats below)
[2022-01-03 13:51:30,574][train][INFO] - {"epoch": 322, "train_loss": "4.12", "train_ntokens": "1797.33", "train_nsentences": "4.95", "train_prob_perplexity": "39.211", "train_code_perplexity": "39.199", "train_temp": "1.875", "train_loss_0": "3.94", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.2958", "train_wps": "3900.8", "train_ups": "2.17", "train_wpb": "1797.3", "train_bsz": "5", "train_num_updates": "12880", "train_lr": "0.00020125", "train_gnorm": "0.831", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6108"}
[2022-01-03 13:51:30,654][fairseq.trainer][INFO] - begin training epoch 323
[2022-01-03 13:51:30,655][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:51:44,448][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:51:44,920][valid][INFO] - {"epoch": 323, "valid_loss": "4.069", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "37.153", "valid_code_perplexity": "37.118", "valid_temp": "1.875", "valid_loss_0": "3.891", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.30541", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "12920", "valid_best_loss": "3.706"}
[2022-01-03 13:51:44,921][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 323 @ 12920 updates
[2022-01-03 13:51:44,922][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:51:48,802][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:51:48,820][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 323 @ 12920 updates, score 4.069) (writing took 3.899016215465963 seconds)
[2022-01-03 13:51:48,821][fairseq_cli.train][INFO] - end of epoch 323 (average epoch stats below)
[2022-01-03 13:51:48,833][train][INFO] - {"epoch": 323, "train_loss": "4.151", "train_ntokens": "1789.17", "train_nsentences": "4.95", "train_prob_perplexity": "39.146", "train_code_perplexity": "39.126", "train_temp": "1.875", "train_loss_0": "3.968", "train_loss_1": "0.135", "train_loss_2": "0.047", "train_accuracy": "0.29614", "train_wps": "3922.3", "train_ups": "2.19", "train_wpb": "1789.2", "train_bsz": "5", "train_num_updates": "12920", "train_lr": "0.000201875", "train_gnorm": "0.857", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "6126"}
[2022-01-03 13:51:48,871][fairseq.trainer][INFO] - begin training epoch 324
[2022-01-03 13:51:48,872][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:52:02,833][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:52:03,233][valid][INFO] - {"epoch": 324, "valid_loss": "4.227", "valid_ntokens": "806", "valid_nsentences": "2", "valid_prob_perplexity": "38.228", "valid_code_perplexity": "38.153", "valid_temp": "1.875", "valid_loss_0": "4.05", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.26179", "valid_wps": "0", "valid_wpb": "806", "valid_bsz": "2", "valid_num_updates": "12960", "valid_best_loss": "3.706"}
[2022-01-03 13:52:03,236][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 324 @ 12960 updates
[2022-01-03 13:52:03,237][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:52:07,003][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:52:07,031][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 324 @ 12960 updates, score 4.227) (writing took 3.794684355147183 seconds)
[2022-01-03 13:52:07,031][fairseq_cli.train][INFO] - end of epoch 324 (average epoch stats below)
[2022-01-03 13:52:07,044][train][INFO] - {"epoch": 324, "train_loss": "4.097", "train_ntokens": "1787.4", "train_nsentences": "4.95", "train_prob_perplexity": "39.289", "train_code_perplexity": "39.279", "train_temp": "1.875", "train_loss_0": "3.919", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.2966", "train_wps": "3928.6", "train_ups": "2.2", "train_wpb": "1787.4", "train_bsz": "5", "train_num_updates": "12960", "train_lr": "0.0002025", "train_gnorm": "0.825", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "6144"}
[2022-01-03 13:52:07,120][fairseq.trainer][INFO] - begin training epoch 325
[2022-01-03 13:52:07,120][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:52:21,029][train_inner][INFO] - {"epoch": 325, "update": 325.0, "loss": "4.123", "ntokens": "1790.73", "nsentences": "4.95", "prob_perplexity": "39.301", "code_perplexity": "39.285", "temp": "1.875", "loss_0": "3.943", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.29627", "wps": "3921.3", "ups": "2.19", "wpb": "1790.7", "bsz": "5", "num_updates": "13000", "lr": "0.000203125", "gnorm": "0.829", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "6158"}
[2022-01-03 13:52:21,030][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:52:21,417][valid][INFO] - {"epoch": 325, "valid_loss": "4.421", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "39.006", "valid_code_perplexity": "38.968", "valid_temp": "1.874", "valid_loss_0": "4.242", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.26301", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "13000", "valid_best_loss": "3.706"}
[2022-01-03 13:52:21,421][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 325 @ 13000 updates
[2022-01-03 13:52:21,421][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:52:25,312][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:52:25,338][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 325 @ 13000 updates, score 4.421) (writing took 3.9168749945238233 seconds)
[2022-01-03 13:52:25,338][fairseq_cli.train][INFO] - end of epoch 325 (average epoch stats below)
[2022-01-03 13:52:25,351][train][INFO] - {"epoch": 325, "train_loss": "4.138", "train_ntokens": "1793.22", "train_nsentences": "4.95", "train_prob_perplexity": "39.331", "train_code_perplexity": "39.309", "train_temp": "1.874", "train_loss_0": "3.961", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.29352", "train_wps": "3920.8", "train_ups": "2.19", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "13000", "train_lr": "0.000203125", "train_gnorm": "0.818", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6163"}
[2022-01-03 13:52:25,427][fairseq.trainer][INFO] - begin training epoch 326
[2022-01-03 13:52:25,428][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:52:39,355][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:52:39,755][valid][INFO] - {"epoch": 326, "valid_loss": "3.78", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "38.011", "valid_code_perplexity": "38.031", "valid_temp": "1.874", "valid_loss_0": "3.601", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.34463", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "13040", "valid_best_loss": "3.706"}
[2022-01-03 13:52:39,759][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 326 @ 13040 updates
[2022-01-03 13:52:39,759][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:52:43,503][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:52:43,530][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 326 @ 13040 updates, score 3.78) (writing took 3.771157192066312 seconds)
[2022-01-03 13:52:43,530][fairseq_cli.train][INFO] - end of epoch 326 (average epoch stats below)
[2022-01-03 13:52:43,543][train][INFO] - {"epoch": 326, "train_loss": "4.097", "train_ntokens": "1785.6", "train_nsentences": "4.95", "train_prob_perplexity": "39.644", "train_code_perplexity": "39.624", "train_temp": "1.874", "train_loss_0": "3.918", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29881", "train_wps": "3928.9", "train_ups": "2.2", "train_wpb": "1785.6", "train_bsz": "5", "train_num_updates": "13040", "train_lr": "0.00020375", "train_gnorm": "0.826", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6181"}
[2022-01-03 13:52:43,613][fairseq.trainer][INFO] - begin training epoch 327
[2022-01-03 13:52:43,614][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:52:57,659][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:52:58,059][valid][INFO] - {"epoch": 327, "valid_loss": "4.12", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "34.134", "valid_code_perplexity": "34.184", "valid_temp": "1.873", "valid_loss_0": "3.942", "valid_loss_1": "0.137", "valid_loss_2": "0.041", "valid_accuracy": "0.28962", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "13080", "valid_best_loss": "3.706"}
[2022-01-03 13:52:58,063][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 327 @ 13080 updates
[2022-01-03 13:52:58,064][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:53:01,820][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:53:01,848][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 327 @ 13080 updates, score 4.12) (writing took 3.7847557347267866 seconds)
[2022-01-03 13:53:01,848][fairseq_cli.train][INFO] - end of epoch 327 (average epoch stats below)
[2022-01-03 13:53:01,860][train][INFO] - {"epoch": 327, "train_loss": "4.125", "train_ntokens": "1804.75", "train_nsentences": "4.95", "train_prob_perplexity": "39.746", "train_code_perplexity": "39.727", "train_temp": "1.874", "train_loss_0": "3.948", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.29298", "train_wps": "3943.8", "train_ups": "2.19", "train_wpb": "1804.8", "train_bsz": "5", "train_num_updates": "13080", "train_lr": "0.000204375", "train_gnorm": "0.807", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6199"}
[2022-01-03 13:53:01,912][fairseq.trainer][INFO] - begin training epoch 328
[2022-01-03 13:53:01,912][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:53:15,829][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:53:16,223][valid][INFO] - {"epoch": 328, "valid_loss": "4.181", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "38.243", "valid_code_perplexity": "38.26", "valid_temp": "1.873", "valid_loss_0": "3.998", "valid_loss_1": "0.136", "valid_loss_2": "0.047", "valid_accuracy": "0.26762", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "13120", "valid_best_loss": "3.706"}
[2022-01-03 13:53:16,226][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 328 @ 13120 updates
[2022-01-03 13:53:16,226][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:53:19,986][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:53:20,015][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 328 @ 13120 updates, score 4.181) (writing took 3.7888493724167347 seconds)
[2022-01-03 13:53:20,015][fairseq_cli.train][INFO] - end of epoch 328 (average epoch stats below)
[2022-01-03 13:53:20,028][train][INFO] - {"epoch": 328, "train_loss": "4.062", "train_ntokens": "1791.62", "train_nsentences": "4.95", "train_prob_perplexity": "38.888", "train_code_perplexity": "38.881", "train_temp": "1.873", "train_loss_0": "3.882", "train_loss_1": "0.136", "train_loss_2": "0.045", "train_accuracy": "0.30319", "train_wps": "3947.4", "train_ups": "2.2", "train_wpb": "1791.6", "train_bsz": "5", "train_num_updates": "13120", "train_lr": "0.000205", "train_gnorm": "0.833", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "6217"}
[2022-01-03 13:53:20,117][fairseq.trainer][INFO] - begin training epoch 329
[2022-01-03 13:53:20,118][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:53:33,992][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:53:34,404][valid][INFO] - {"epoch": 329, "valid_loss": "3.985", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "38.564", "valid_code_perplexity": "38.59", "valid_temp": "1.873", "valid_loss_0": "3.807", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.2965", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "13160", "valid_best_loss": "3.706"}
[2022-01-03 13:53:34,409][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 329 @ 13160 updates
[2022-01-03 13:53:34,411][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:53:38,219][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:53:38,246][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 329 @ 13160 updates, score 3.985) (writing took 3.8368820901960135 seconds)
[2022-01-03 13:53:38,247][fairseq_cli.train][INFO] - end of epoch 329 (average epoch stats below)
[2022-01-03 13:53:38,260][train][INFO] - {"epoch": 329, "train_loss": "4.085", "train_ntokens": "1786.42", "train_nsentences": "4.95", "train_prob_perplexity": "38.885", "train_code_perplexity": "38.873", "train_temp": "1.873", "train_loss_0": "3.906", "train_loss_1": "0.136", "train_loss_2": "0.044", "train_accuracy": "0.2987", "train_wps": "3922.2", "train_ups": "2.2", "train_wpb": "1786.4", "train_bsz": "5", "train_num_updates": "13160", "train_lr": "0.000205625", "train_gnorm": "0.877", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6236"}
[2022-01-03 13:53:38,337][fairseq.trainer][INFO] - begin training epoch 330
[2022-01-03 13:53:38,338][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:53:52,328][train_inner][INFO] - {"epoch": 330, "update": 330.0, "loss": "4.094", "ntokens": "1794.07", "nsentences": "4.95", "prob_perplexity": "39.33", "code_perplexity": "39.315", "temp": "1.873", "loss_0": "3.915", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.29827", "wps": "3930.7", "ups": "2.19", "wpb": "1794.1", "bsz": "5", "num_updates": "13200", "lr": "0.00020625", "gnorm": "0.837", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "6250"}
[2022-01-03 13:53:52,329][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:53:52,725][valid][INFO] - {"epoch": 330, "valid_loss": "4.505", "valid_ntokens": "692", "valid_nsentences": "2", "valid_prob_perplexity": "34.851", "valid_code_perplexity": "34.845", "valid_temp": "1.872", "valid_loss_0": "4.327", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.25", "valid_wps": "0", "valid_wpb": "692", "valid_bsz": "2", "valid_num_updates": "13200", "valid_best_loss": "3.706"}
[2022-01-03 13:53:52,728][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 330 @ 13200 updates
[2022-01-03 13:53:52,729][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:53:56,406][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:53:56,426][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 330 @ 13200 updates, score 4.505) (writing took 3.6976736672222614 seconds)
[2022-01-03 13:53:56,426][fairseq_cli.train][INFO] - end of epoch 330 (average epoch stats below)
[2022-01-03 13:53:56,439][train][INFO] - {"epoch": 330, "train_loss": "4.102", "train_ntokens": "1801.92", "train_nsentences": "4.95", "train_prob_perplexity": "39.486", "train_code_perplexity": "39.472", "train_temp": "1.872", "train_loss_0": "3.922", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29772", "train_wps": "3967.6", "train_ups": "2.2", "train_wpb": "1801.9", "train_bsz": "5", "train_num_updates": "13200", "train_lr": "0.00020625", "train_gnorm": "0.844", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6254"}
[2022-01-03 13:53:56,484][fairseq.trainer][INFO] - begin training epoch 331
[2022-01-03 13:53:56,485][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:54:10,456][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:54:10,873][valid][INFO] - {"epoch": 331, "valid_loss": "4.064", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "35.146", "valid_code_perplexity": "35.163", "valid_temp": "1.872", "valid_loss_0": "3.883", "valid_loss_1": "0.136", "valid_loss_2": "0.045", "valid_accuracy": "0.32846", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "13240", "valid_best_loss": "3.706"}
[2022-01-03 13:54:10,879][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 331 @ 13240 updates
[2022-01-03 13:54:10,880][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:54:14,679][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:54:14,692][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 331 @ 13240 updates, score 4.064) (writing took 3.8130525993183255 seconds)
[2022-01-03 13:54:14,692][fairseq_cli.train][INFO] - end of epoch 331 (average epoch stats below)
[2022-01-03 13:54:14,705][train][INFO] - {"epoch": 331, "train_loss": "4.133", "train_ntokens": "1772.25", "train_nsentences": "4.95", "train_prob_perplexity": "38.785", "train_code_perplexity": "38.774", "train_temp": "1.872", "train_loss_0": "3.952", "train_loss_1": "0.136", "train_loss_2": "0.046", "train_accuracy": "0.29479", "train_wps": "3883.6", "train_ups": "2.19", "train_wpb": "1772.2", "train_bsz": "5", "train_num_updates": "13240", "train_lr": "0.000206875", "train_gnorm": "0.832", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6272"}
[2022-01-03 13:54:14,754][fairseq.trainer][INFO] - begin training epoch 332
[2022-01-03 13:54:14,755][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:54:28,811][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:54:29,217][valid][INFO] - {"epoch": 332, "valid_loss": "4.093", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "35.969", "valid_code_perplexity": "35.953", "valid_temp": "1.872", "valid_loss_0": "3.914", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.30688", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "13280", "valid_best_loss": "3.706"}
[2022-01-03 13:54:29,220][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 332 @ 13280 updates
[2022-01-03 13:54:29,221][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:54:32,911][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:54:32,940][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 332 @ 13280 updates, score 4.093) (writing took 3.719761502929032 seconds)
[2022-01-03 13:54:32,941][fairseq_cli.train][INFO] - end of epoch 332 (average epoch stats below)
[2022-01-03 13:54:32,953][train][INFO] - {"epoch": 332, "train_loss": "4.067", "train_ntokens": "1784.2", "train_nsentences": "4.95", "train_prob_perplexity": "39.714", "train_code_perplexity": "39.698", "train_temp": "1.872", "train_loss_0": "3.888", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.30355", "train_wps": "3913.7", "train_ups": "2.19", "train_wpb": "1784.2", "train_bsz": "5", "train_num_updates": "13280", "train_lr": "0.0002075", "train_gnorm": "0.794", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "6290"}
[2022-01-03 13:54:33,014][fairseq.trainer][INFO] - begin training epoch 333
[2022-01-03 13:54:33,015][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:54:46,978][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:54:47,387][valid][INFO] - {"epoch": 333, "valid_loss": "4.173", "valid_ntokens": "682", "valid_nsentences": "2", "valid_prob_perplexity": "33.225", "valid_code_perplexity": "33.243", "valid_temp": "1.871", "valid_loss_0": "3.991", "valid_loss_1": "0.137", "valid_loss_2": "0.045", "valid_accuracy": "0.30792", "valid_wps": "0", "valid_wpb": "682", "valid_bsz": "2", "valid_num_updates": "13320", "valid_best_loss": "3.706"}
[2022-01-03 13:54:47,390][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 333 @ 13320 updates
[2022-01-03 13:54:47,391][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:54:51,130][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:54:51,157][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 333 @ 13320 updates, score 4.173) (writing took 3.766639887355268 seconds)
[2022-01-03 13:54:51,157][fairseq_cli.train][INFO] - end of epoch 333 (average epoch stats below)
[2022-01-03 13:54:51,170][train][INFO] - {"epoch": 333, "train_loss": "4.117", "train_ntokens": "1791.45", "train_nsentences": "4.95", "train_prob_perplexity": "39.463", "train_code_perplexity": "39.444", "train_temp": "1.871", "train_loss_0": "3.935", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.2956", "train_wps": "3936.2", "train_ups": "2.2", "train_wpb": "1791.5", "train_bsz": "5", "train_num_updates": "13320", "train_lr": "0.000208125", "train_gnorm": "0.789", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6309"}
[2022-01-03 13:54:51,243][fairseq.trainer][INFO] - begin training epoch 334
[2022-01-03 13:54:51,244][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:55:05,169][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:55:05,577][valid][INFO] - {"epoch": 334, "valid_loss": "3.977", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "37.868", "valid_code_perplexity": "37.882", "valid_temp": "1.871", "valid_loss_0": "3.798", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.30307", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "13360", "valid_best_loss": "3.706"}
[2022-01-03 13:55:05,580][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 334 @ 13360 updates
[2022-01-03 13:55:05,581][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:55:09,375][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:55:09,394][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 334 @ 13360 updates, score 3.977) (writing took 3.8138560308143497 seconds)
[2022-01-03 13:55:09,395][fairseq_cli.train][INFO] - end of epoch 334 (average epoch stats below)
[2022-01-03 13:55:09,407][train][INFO] - {"epoch": 334, "train_loss": "4.098", "train_ntokens": "1789.28", "train_nsentences": "4.95", "train_prob_perplexity": "39.578", "train_code_perplexity": "39.562", "train_temp": "1.871", "train_loss_0": "3.917", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29828", "train_wps": "3927.2", "train_ups": "2.19", "train_wpb": "1789.3", "train_bsz": "5", "train_num_updates": "13360", "train_lr": "0.00020875", "train_gnorm": "0.783", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6327"}
[2022-01-03 13:55:09,460][fairseq.trainer][INFO] - begin training epoch 335
[2022-01-03 13:55:09,461][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:55:23,422][train_inner][INFO] - {"epoch": 335, "update": 335.0, "loss": "4.096", "ntokens": "1784.47", "nsentences": "4.95", "prob_perplexity": "39.494", "code_perplexity": "39.478", "temp": "1.871", "loss_0": "3.917", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.29902", "wps": "3918.4", "ups": "2.2", "wpb": "1784.5", "bsz": "5", "num_updates": "13400", "lr": "0.000209375", "gnorm": "0.809", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "6341"}
[2022-01-03 13:55:23,423][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:55:23,832][valid][INFO] - {"epoch": 335, "valid_loss": "4.053", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "39.178", "valid_code_perplexity": "39.198", "valid_temp": "1.87", "valid_loss_0": "3.876", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.30217", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "13400", "valid_best_loss": "3.706"}
[2022-01-03 13:55:23,835][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 335 @ 13400 updates
[2022-01-03 13:55:23,836][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:55:27,583][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:55:27,603][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 335 @ 13400 updates, score 4.053) (writing took 3.7680321764200926 seconds)
[2022-01-03 13:55:27,604][fairseq_cli.train][INFO] - end of epoch 335 (average epoch stats below)
[2022-01-03 13:55:27,616][train][INFO] - {"epoch": 335, "train_loss": "4.068", "train_ntokens": "1785.2", "train_nsentences": "4.95", "train_prob_perplexity": "39.928", "train_code_perplexity": "39.913", "train_temp": "1.871", "train_loss_0": "3.891", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.30287", "train_wps": "3924.3", "train_ups": "2.2", "train_wpb": "1785.2", "train_bsz": "5", "train_num_updates": "13400", "train_lr": "0.000209375", "train_gnorm": "0.847", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "6345"}
[2022-01-03 13:55:27,658][fairseq.trainer][INFO] - begin training epoch 336
[2022-01-03 13:55:27,659][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:55:41,561][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:55:41,962][valid][INFO] - {"epoch": 336, "valid_loss": "4.311", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "38.401", "valid_code_perplexity": "38.435", "valid_temp": "1.87", "valid_loss_0": "4.135", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.26913", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "13440", "valid_best_loss": "3.706"}
[2022-01-03 13:55:41,965][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 336 @ 13440 updates
[2022-01-03 13:55:41,966][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:55:45,857][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:55:45,884][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 336 @ 13440 updates, score 4.311) (writing took 3.919475588016212 seconds)
[2022-01-03 13:55:45,885][fairseq_cli.train][INFO] - end of epoch 336 (average epoch stats below)
[2022-01-03 13:55:45,897][train][INFO] - {"epoch": 336, "train_loss": "4.089", "train_ntokens": "1792.95", "train_nsentences": "4.95", "train_prob_perplexity": "39.438", "train_code_perplexity": "39.423", "train_temp": "1.87", "train_loss_0": "3.911", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29827", "train_wps": "3925.7", "train_ups": "2.19", "train_wpb": "1793", "train_bsz": "5", "train_num_updates": "13440", "train_lr": "0.00021", "train_gnorm": "0.81", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6363"}
[2022-01-03 13:55:45,942][fairseq.trainer][INFO] - begin training epoch 337
[2022-01-03 13:55:45,943][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:55:59,806][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:56:00,220][valid][INFO] - {"epoch": 337, "valid_loss": "4.164", "valid_ntokens": "680", "valid_nsentences": "2", "valid_prob_perplexity": "37.69", "valid_code_perplexity": "37.571", "valid_temp": "1.87", "valid_loss_0": "3.987", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.27794", "valid_wps": "0", "valid_wpb": "680", "valid_bsz": "2", "valid_num_updates": "13480", "valid_best_loss": "3.706"}
[2022-01-03 13:56:00,225][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 337 @ 13480 updates
[2022-01-03 13:56:00,226][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:56:04,133][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:56:04,159][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 337 @ 13480 updates, score 4.164) (writing took 3.933804202824831 seconds)
[2022-01-03 13:56:04,159][fairseq_cli.train][INFO] - end of epoch 337 (average epoch stats below)
[2022-01-03 13:56:04,171][train][INFO] - {"epoch": 337, "train_loss": "4.139", "train_ntokens": "1801.38", "train_nsentences": "4.95", "train_prob_perplexity": "39.397", "train_code_perplexity": "39.393", "train_temp": "1.87", "train_loss_0": "3.961", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.28856", "train_wps": "3945.5", "train_ups": "2.19", "train_wpb": "1801.4", "train_bsz": "5", "train_num_updates": "13480", "train_lr": "0.000210625", "train_gnorm": "0.828", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "6382"}
[2022-01-03 13:56:04,240][fairseq.trainer][INFO] - begin training epoch 338
[2022-01-03 13:56:04,240][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:56:18,122][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:56:18,614][valid][INFO] - {"epoch": 338, "valid_loss": "3.954", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "38.415", "valid_code_perplexity": "38.435", "valid_temp": "1.869", "valid_loss_0": "3.772", "valid_loss_1": "0.136", "valid_loss_2": "0.046", "valid_accuracy": "0.30226", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "13520", "valid_best_loss": "3.706"}
[2022-01-03 13:56:18,616][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 338 @ 13520 updates
[2022-01-03 13:56:18,616][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:56:22,325][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:56:22,356][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 338 @ 13520 updates, score 3.954) (writing took 3.7401810232549906 seconds)
[2022-01-03 13:56:22,357][fairseq_cli.train][INFO] - end of epoch 338 (average epoch stats below)
[2022-01-03 13:56:22,370][train][INFO] - {"epoch": 338, "train_loss": "4.082", "train_ntokens": "1785.42", "train_nsentences": "4.95", "train_prob_perplexity": "39.195", "train_code_perplexity": "39.176", "train_temp": "1.869", "train_loss_0": "3.902", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.3028", "train_wps": "3927.2", "train_ups": "2.2", "train_wpb": "1785.4", "train_bsz": "5", "train_num_updates": "13520", "train_lr": "0.00021125", "train_gnorm": "0.808", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.8", "train_wall": "6400"}
[2022-01-03 13:56:22,445][fairseq.trainer][INFO] - begin training epoch 339
[2022-01-03 13:56:22,446][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:56:36,240][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:56:36,721][valid][INFO] - {"epoch": 339, "valid_loss": "4.204", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "38.864", "valid_code_perplexity": "38.79", "valid_temp": "1.869", "valid_loss_0": "4.024", "valid_loss_1": "0.136", "valid_loss_2": "0.044", "valid_accuracy": "0.27441", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "13560", "valid_best_loss": "3.706"}
[2022-01-03 13:56:36,723][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 339 @ 13560 updates
[2022-01-03 13:56:36,724][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:56:40,587][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:56:40,614][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 339 @ 13560 updates, score 4.204) (writing took 3.8911057580262423 seconds)
[2022-01-03 13:56:40,615][fairseq_cli.train][INFO] - end of epoch 339 (average epoch stats below)
[2022-01-03 13:56:40,628][train][INFO] - {"epoch": 339, "train_loss": "4.079", "train_ntokens": "1786.33", "train_nsentences": "4.95", "train_prob_perplexity": "39.476", "train_code_perplexity": "39.45", "train_temp": "1.869", "train_loss_0": "3.898", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29981", "train_wps": "3916.3", "train_ups": "2.19", "train_wpb": "1786.3", "train_bsz": "5", "train_num_updates": "13560", "train_lr": "0.000211875", "train_gnorm": "0.781", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "6418"}
[2022-01-03 13:56:40,698][fairseq.trainer][INFO] - begin training epoch 340
[2022-01-03 13:56:40,698][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:56:54,592][train_inner][INFO] - {"epoch": 340, "update": 340.0, "loss": "4.096", "ntokens": "1790.32", "nsentences": "4.95", "prob_perplexity": "39.559", "code_perplexity": "39.545", "temp": "1.869", "loss_0": "3.916", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.29747", "wps": "3928", "ups": "2.19", "wpb": "1790.3", "bsz": "5", "num_updates": "13600", "lr": "0.0002125", "gnorm": "0.808", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "6432"}
[2022-01-03 13:56:54,593][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:56:55,081][valid][INFO] - {"epoch": 340, "valid_loss": "4.503", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "40.365", "valid_code_perplexity": "40.298", "valid_temp": "1.869", "valid_loss_0": "4.322", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.236", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "13600", "valid_best_loss": "3.706"}
[2022-01-03 13:56:55,083][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 340 @ 13600 updates
[2022-01-03 13:56:55,083][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:56:58,813][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:56:58,842][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 340 @ 13600 updates, score 4.503) (writing took 3.759033102542162 seconds)
[2022-01-03 13:56:58,842][fairseq_cli.train][INFO] - end of epoch 340 (average epoch stats below)
[2022-01-03 13:56:58,855][train][INFO] - {"epoch": 340, "train_loss": "4.089", "train_ntokens": "1785.53", "train_nsentences": "4.95", "train_prob_perplexity": "40.287", "train_code_perplexity": "40.281", "train_temp": "1.869", "train_loss_0": "3.906", "train_loss_1": "0.135", "train_loss_2": "0.047", "train_accuracy": "0.29802", "train_wps": "3921.1", "train_ups": "2.2", "train_wpb": "1785.5", "train_bsz": "5", "train_num_updates": "13600", "train_lr": "0.0002125", "train_gnorm": "0.815", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "6436"}
[2022-01-03 13:56:58,915][fairseq.trainer][INFO] - begin training epoch 341
[2022-01-03 13:56:58,916][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:57:12,890][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:57:13,291][valid][INFO] - {"epoch": 341, "valid_loss": "4.535", "valid_ntokens": "804", "valid_nsentences": "2", "valid_prob_perplexity": "39.123", "valid_code_perplexity": "39.06", "valid_temp": "1.868", "valid_loss_0": "4.354", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.22761", "valid_wps": "0", "valid_wpb": "804", "valid_bsz": "2", "valid_num_updates": "13640", "valid_best_loss": "3.706"}
[2022-01-03 13:57:13,295][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 341 @ 13640 updates
[2022-01-03 13:57:13,296][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:57:17,050][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:57:17,059][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 341 @ 13640 updates, score 4.535) (writing took 3.7638026950880885 seconds)
[2022-01-03 13:57:17,060][fairseq_cli.train][INFO] - end of epoch 341 (average epoch stats below)
[2022-01-03 13:57:17,072][train][INFO] - {"epoch": 341, "train_loss": "4.069", "train_ntokens": "1784.35", "train_nsentences": "4.95", "train_prob_perplexity": "40.012", "train_code_perplexity": "39.992", "train_temp": "1.868", "train_loss_0": "3.889", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.30447", "train_wps": "3920.7", "train_ups": "2.2", "train_wpb": "1784.3", "train_bsz": "5", "train_num_updates": "13640", "train_lr": "0.000213125", "train_gnorm": "0.845", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6454"}
[2022-01-03 13:57:17,112][fairseq.trainer][INFO] - begin training epoch 342
[2022-01-03 13:57:17,113][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:57:31,065][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:57:31,470][valid][INFO] - {"epoch": 342, "valid_loss": "4.345", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "37.109", "valid_code_perplexity": "37.137", "valid_temp": "1.868", "valid_loss_0": "4.166", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.24934", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "13680", "valid_best_loss": "3.706"}
[2022-01-03 13:57:31,472][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 342 @ 13680 updates
[2022-01-03 13:57:31,473][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:57:35,328][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:57:35,340][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 342 @ 13680 updates, score 4.345) (writing took 3.8681091479957104 seconds)
[2022-01-03 13:57:35,341][fairseq_cli.train][INFO] - end of epoch 342 (average epoch stats below)
[2022-01-03 13:57:35,354][train][INFO] - {"epoch": 342, "train_loss": "4.135", "train_ntokens": "1792.67", "train_nsentences": "4.95", "train_prob_perplexity": "40.067", "train_code_perplexity": "40.055", "train_temp": "1.868", "train_loss_0": "3.954", "train_loss_1": "0.135", "train_loss_2": "0.047", "train_accuracy": "0.29317", "train_wps": "3925", "train_ups": "2.19", "train_wpb": "1792.7", "train_bsz": "5", "train_num_updates": "13680", "train_lr": "0.00021375", "train_gnorm": "0.777", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6473"}
[2022-01-03 13:57:35,418][fairseq.trainer][INFO] - begin training epoch 343
[2022-01-03 13:57:35,419][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:57:49,406][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:57:49,804][valid][INFO] - {"epoch": 343, "valid_loss": "4.126", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "39.823", "valid_code_perplexity": "39.781", "valid_temp": "1.867", "valid_loss_0": "3.946", "valid_loss_1": "0.135", "valid_loss_2": "0.044", "valid_accuracy": "0.30214", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "13720", "valid_best_loss": "3.706"}
[2022-01-03 13:57:49,807][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 343 @ 13720 updates
[2022-01-03 13:57:49,808][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:57:53,535][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:57:53,563][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 343 @ 13720 updates, score 4.126) (writing took 3.755625246092677 seconds)
[2022-01-03 13:57:53,564][fairseq_cli.train][INFO] - end of epoch 343 (average epoch stats below)
[2022-01-03 13:57:53,576][train][INFO] - {"epoch": 343, "train_loss": "4.121", "train_ntokens": "1783.75", "train_nsentences": "4.95", "train_prob_perplexity": "40.266", "train_code_perplexity": "40.251", "train_temp": "1.868", "train_loss_0": "3.938", "train_loss_1": "0.135", "train_loss_2": "0.048", "train_accuracy": "0.2962", "train_wps": "3918.3", "train_ups": "2.2", "train_wpb": "1783.8", "train_bsz": "5", "train_num_updates": "13720", "train_lr": "0.000214375", "train_gnorm": "0.772", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "6491"}
[2022-01-03 13:57:53,651][fairseq.trainer][INFO] - begin training epoch 344
[2022-01-03 13:57:53,652][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:58:07,545][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:58:07,965][valid][INFO] - {"epoch": 344, "valid_loss": "4.084", "valid_ntokens": "704", "valid_nsentences": "2", "valid_prob_perplexity": "38.457", "valid_code_perplexity": "38.476", "valid_temp": "1.867", "valid_loss_0": "3.909", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.27415", "valid_wps": "0", "valid_wpb": "704", "valid_bsz": "2", "valid_num_updates": "13760", "valid_best_loss": "3.706"}
[2022-01-03 13:58:07,968][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 344 @ 13760 updates
[2022-01-03 13:58:07,968][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:58:11,797][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:58:11,824][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 344 @ 13760 updates, score 4.084) (writing took 3.8559216735884547 seconds)
[2022-01-03 13:58:11,824][fairseq_cli.train][INFO] - end of epoch 344 (average epoch stats below)
[2022-01-03 13:58:11,837][train][INFO] - {"epoch": 344, "train_loss": "4.082", "train_ntokens": "1792.8", "train_nsentences": "4.95", "train_prob_perplexity": "39.78", "train_code_perplexity": "39.76", "train_temp": "1.867", "train_loss_0": "3.902", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.30107", "train_wps": "3929.9", "train_ups": "2.19", "train_wpb": "1792.8", "train_bsz": "5", "train_num_updates": "13760", "train_lr": "0.000215", "train_gnorm": "0.807", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "6509"}
[2022-01-03 13:58:11,888][fairseq.trainer][INFO] - begin training epoch 345
[2022-01-03 13:58:11,889][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:58:25,740][train_inner][INFO] - {"epoch": 345, "update": 345.0, "loss": "4.1", "ntokens": "1786.71", "nsentences": "4.95", "prob_perplexity": "40.106", "code_perplexity": "40.092", "temp": "1.868", "loss_0": "3.92", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.29869", "wps": "3921", "ups": "2.19", "wpb": "1786.7", "bsz": "5", "num_updates": "13800", "lr": "0.000215625", "gnorm": "0.808", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "6523"}
[2022-01-03 13:58:25,741][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:58:26,159][valid][INFO] - {"epoch": 345, "valid_loss": "4.13", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "39.101", "valid_code_perplexity": "39.139", "valid_temp": "1.867", "valid_loss_0": "3.955", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.2954", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "13800", "valid_best_loss": "3.706"}
[2022-01-03 13:58:26,162][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 345 @ 13800 updates
[2022-01-03 13:58:26,163][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:58:30,095][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:58:30,115][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 345 @ 13800 updates, score 4.13) (writing took 3.9532680260017514 seconds)
[2022-01-03 13:58:30,116][fairseq_cli.train][INFO] - end of epoch 345 (average epoch stats below)
[2022-01-03 13:58:30,128][train][INFO] - {"epoch": 345, "train_loss": "4.095", "train_ntokens": "1779.97", "train_nsentences": "4.95", "train_prob_perplexity": "40.404", "train_code_perplexity": "40.399", "train_temp": "1.867", "train_loss_0": "3.916", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29857", "train_wps": "3895.2", "train_ups": "2.19", "train_wpb": "1780", "train_bsz": "5", "train_num_updates": "13800", "train_lr": "0.000215625", "train_gnorm": "0.842", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6528"}
[2022-01-03 13:58:30,171][fairseq.trainer][INFO] - begin training epoch 346
[2022-01-03 13:58:30,172][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:58:44,083][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:58:44,491][valid][INFO] - {"epoch": 346, "valid_loss": "4.342", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "39.26", "valid_code_perplexity": "39.25", "valid_temp": "1.866", "valid_loss_0": "4.162", "valid_loss_1": "0.135", "valid_loss_2": "0.044", "valid_accuracy": "0.26904", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "13840", "valid_best_loss": "3.706"}
[2022-01-03 13:58:44,494][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 346 @ 13840 updates
[2022-01-03 13:58:44,495][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:58:48,457][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:58:48,486][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 346 @ 13840 updates, score 4.342) (writing took 3.991534747183323 seconds)
[2022-01-03 13:58:48,486][fairseq_cli.train][INFO] - end of epoch 346 (average epoch stats below)
[2022-01-03 13:58:48,499][train][INFO] - {"epoch": 346, "train_loss": "4.095", "train_ntokens": "1803.62", "train_nsentences": "4.95", "train_prob_perplexity": "39.688", "train_code_perplexity": "39.682", "train_temp": "1.866", "train_loss_0": "3.916", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.2975", "train_wps": "3929.8", "train_ups": "2.18", "train_wpb": "1803.6", "train_bsz": "5", "train_num_updates": "13840", "train_lr": "0.00021625", "train_gnorm": "0.786", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6546"}
[2022-01-03 13:58:48,574][fairseq.trainer][INFO] - begin training epoch 347
[2022-01-03 13:58:48,575][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:59:02,553][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:59:02,958][valid][INFO] - {"epoch": 347, "valid_loss": "4.153", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "40.602", "valid_code_perplexity": "40.533", "valid_temp": "1.866", "valid_loss_0": "3.974", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.28515", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "13880", "valid_best_loss": "3.706"}
[2022-01-03 13:59:02,961][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 347 @ 13880 updates
[2022-01-03 13:59:02,962][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:59:06,638][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:59:06,666][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 347 @ 13880 updates, score 4.153) (writing took 3.7054592268541455 seconds)
[2022-01-03 13:59:06,667][fairseq_cli.train][INFO] - end of epoch 347 (average epoch stats below)
[2022-01-03 13:59:06,680][train][INFO] - {"epoch": 347, "train_loss": "4.071", "train_ntokens": "1792.42", "train_nsentences": "4.95", "train_prob_perplexity": "40.203", "train_code_perplexity": "40.193", "train_temp": "1.866", "train_loss_0": "3.891", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.30372", "train_wps": "3946.4", "train_ups": "2.2", "train_wpb": "1792.4", "train_bsz": "5", "train_num_updates": "13880", "train_lr": "0.000216875", "train_gnorm": "0.803", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "6564"}
[2022-01-03 13:59:06,757][fairseq.trainer][INFO] - begin training epoch 348
[2022-01-03 13:59:06,758][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:59:20,784][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:59:21,276][valid][INFO] - {"epoch": 348, "valid_loss": "4.162", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "39.453", "valid_code_perplexity": "39.464", "valid_temp": "1.866", "valid_loss_0": "3.98", "valid_loss_1": "0.135", "valid_loss_2": "0.047", "valid_accuracy": "0.2808", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "13920", "valid_best_loss": "3.706"}
[2022-01-03 13:59:21,278][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 348 @ 13920 updates
[2022-01-03 13:59:21,279][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:59:24,892][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:59:24,917][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 348 @ 13920 updates, score 4.162) (writing took 3.6390661215409636 seconds)
[2022-01-03 13:59:24,918][fairseq_cli.train][INFO] - end of epoch 348 (average epoch stats below)
[2022-01-03 13:59:24,931][train][INFO] - {"epoch": 348, "train_loss": "4.092", "train_ntokens": "1790.5", "train_nsentences": "4.95", "train_prob_perplexity": "40.71", "train_code_perplexity": "40.698", "train_temp": "1.866", "train_loss_0": "3.914", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29538", "train_wps": "3927", "train_ups": "2.19", "train_wpb": "1790.5", "train_bsz": "5", "train_num_updates": "13920", "train_lr": "0.0002175", "train_gnorm": "0.836", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "6582"}
[2022-01-03 13:59:25,001][fairseq.trainer][INFO] - begin training epoch 349
[2022-01-03 13:59:25,002][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:59:39,007][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:59:39,408][valid][INFO] - {"epoch": 349, "valid_loss": "3.976", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "39.96", "valid_code_perplexity": "39.906", "valid_temp": "1.865", "valid_loss_0": "3.795", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.3293", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "13960", "valid_best_loss": "3.706"}
[2022-01-03 13:59:39,413][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 349 @ 13960 updates
[2022-01-03 13:59:39,414][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:59:43,065][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 13:59:43,084][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 349 @ 13960 updates, score 3.976) (writing took 3.6714940555393696 seconds)
[2022-01-03 13:59:43,085][fairseq_cli.train][INFO] - end of epoch 349 (average epoch stats below)
[2022-01-03 13:59:43,097][train][INFO] - {"epoch": 349, "train_loss": "4.089", "train_ntokens": "1807.65", "train_nsentences": "4.95", "train_prob_perplexity": "40.043", "train_code_perplexity": "40.027", "train_temp": "1.865", "train_loss_0": "3.909", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.30033", "train_wps": "3982.9", "train_ups": "2.2", "train_wpb": "1807.7", "train_bsz": "5", "train_num_updates": "13960", "train_lr": "0.000218125", "train_gnorm": "0.788", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "6600"}
[2022-01-03 13:59:43,143][fairseq.trainer][INFO] - begin training epoch 350
[2022-01-03 13:59:43,143][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 13:59:57,147][train_inner][INFO] - {"epoch": 350, "update": 350.0, "loss": "4.097", "ntokens": "1797.81", "nsentences": "4.95", "prob_perplexity": "40.18", "code_perplexity": "40.17", "temp": "1.866", "loss_0": "3.917", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.2975", "wps": "3934.2", "ups": "2.19", "wpb": "1797.8", "bsz": "5", "num_updates": "14000", "lr": "0.00021875", "gnorm": "0.8", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "6615"}
[2022-01-03 13:59:57,148][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 13:59:57,554][valid][INFO] - {"epoch": 350, "valid_loss": "4.718", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "39.435", "valid_code_perplexity": "39.422", "valid_temp": "1.865", "valid_loss_0": "4.54", "valid_loss_1": "0.135", "valid_loss_2": "0.042", "valid_accuracy": "0.19525", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "14000", "valid_best_loss": "3.706"}
[2022-01-03 13:59:57,557][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 350 @ 14000 updates
[2022-01-03 13:59:57,558][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:00:01,331][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:00:01,357][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 350 @ 14000 updates, score 4.718) (writing took 3.799880080856383 seconds)
[2022-01-03 14:00:01,357][fairseq_cli.train][INFO] - end of epoch 350 (average epoch stats below)
[2022-01-03 14:00:01,369][train][INFO] - {"epoch": 350, "train_loss": "4.136", "train_ntokens": "1794.83", "train_nsentences": "4.95", "train_prob_perplexity": "40.254", "train_code_perplexity": "40.248", "train_temp": "1.865", "train_loss_0": "3.956", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29053", "train_wps": "3931.7", "train_ups": "2.19", "train_wpb": "1794.8", "train_bsz": "5", "train_num_updates": "14000", "train_lr": "0.00021875", "train_gnorm": "0.789", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "6619"}
[2022-01-03 14:00:01,438][fairseq.trainer][INFO] - begin training epoch 351
[2022-01-03 14:00:01,438][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:00:15,425][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:00:15,822][valid][INFO] - {"epoch": 351, "valid_loss": "4.049", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "38.391", "valid_code_perplexity": "38.43", "valid_temp": "1.864", "valid_loss_0": "3.874", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.31755", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "14040", "valid_best_loss": "3.706"}
[2022-01-03 14:00:15,826][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 351 @ 14040 updates
[2022-01-03 14:00:15,827][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:00:19,577][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:00:19,603][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 351 @ 14040 updates, score 4.049) (writing took 3.777607075870037 seconds)
[2022-01-03 14:00:19,604][fairseq_cli.train][INFO] - end of epoch 351 (average epoch stats below)
[2022-01-03 14:00:19,616][train][INFO] - {"epoch": 351, "train_loss": "4.084", "train_ntokens": "1807.72", "train_nsentences": "4.95", "train_prob_perplexity": "40.346", "train_code_perplexity": "40.329", "train_temp": "1.865", "train_loss_0": "3.904", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.30126", "train_wps": "3965.5", "train_ups": "2.19", "train_wpb": "1807.7", "train_bsz": "5", "train_num_updates": "14040", "train_lr": "0.000219375", "train_gnorm": "0.788", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "6637"}
[2022-01-03 14:00:19,672][fairseq.trainer][INFO] - begin training epoch 352
[2022-01-03 14:00:19,673][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:00:33,627][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:00:34,035][valid][INFO] - {"epoch": 352, "valid_loss": "4.356", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "40.353", "valid_code_perplexity": "40.346", "valid_temp": "1.864", "valid_loss_0": "4.174", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.26554", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "14080", "valid_best_loss": "3.706"}
[2022-01-03 14:00:34,038][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 352 @ 14080 updates
[2022-01-03 14:00:34,039][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:00:37,848][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:00:37,876][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 352 @ 14080 updates, score 4.356) (writing took 3.8376783253625035 seconds)
[2022-01-03 14:00:37,876][fairseq_cli.train][INFO] - end of epoch 352 (average epoch stats below)
[2022-01-03 14:00:37,889][train][INFO] - {"epoch": 352, "train_loss": "4.1", "train_ntokens": "1799.6", "train_nsentences": "4.95", "train_prob_perplexity": "40.699", "train_code_perplexity": "40.68", "train_temp": "1.864", "train_loss_0": "3.92", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29722", "train_wps": "3942.1", "train_ups": "2.19", "train_wpb": "1799.6", "train_bsz": "5", "train_num_updates": "14080", "train_lr": "0.00022", "train_gnorm": "0.761", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "6655"}
[2022-01-03 14:00:37,966][fairseq.trainer][INFO] - begin training epoch 353
[2022-01-03 14:00:37,966][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:00:51,831][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:00:52,223][valid][INFO] - {"epoch": 353, "valid_loss": "4.254", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "37.467", "valid_code_perplexity": "37.486", "valid_temp": "1.864", "valid_loss_0": "4.076", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.24735", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "14120", "valid_best_loss": "3.706"}
[2022-01-03 14:00:52,226][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 353 @ 14120 updates
[2022-01-03 14:00:52,226][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:00:56,126][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:00:56,155][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 353 @ 14120 updates, score 4.254) (writing took 3.9289462566375732 seconds)
[2022-01-03 14:00:56,155][fairseq_cli.train][INFO] - end of epoch 353 (average epoch stats below)
[2022-01-03 14:00:56,168][train][INFO] - {"epoch": 353, "train_loss": "4.049", "train_ntokens": "1777.4", "train_nsentences": "4.95", "train_prob_perplexity": "40.406", "train_code_perplexity": "40.399", "train_temp": "1.864", "train_loss_0": "3.868", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.30588", "train_wps": "3892.4", "train_ups": "2.19", "train_wpb": "1777.4", "train_bsz": "5", "train_num_updates": "14120", "train_lr": "0.000220625", "train_gnorm": "0.797", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6674"}
[2022-01-03 14:00:56,251][fairseq.trainer][INFO] - begin training epoch 354
[2022-01-03 14:00:56,252][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:01:10,177][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:01:10,584][valid][INFO] - {"epoch": 354, "valid_loss": "4.463", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "40.576", "valid_code_perplexity": "40.501", "valid_temp": "1.863", "valid_loss_0": "4.282", "valid_loss_1": "0.135", "valid_loss_2": "0.045", "valid_accuracy": "0.26053", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "14160", "valid_best_loss": "3.706"}
[2022-01-03 14:01:10,588][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 354 @ 14160 updates
[2022-01-03 14:01:10,589][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:01:14,281][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:01:14,301][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 354 @ 14160 updates, score 4.463) (writing took 3.713354952633381 seconds)
[2022-01-03 14:01:14,301][fairseq_cli.train][INFO] - end of epoch 354 (average epoch stats below)
[2022-01-03 14:01:14,313][train][INFO] - {"epoch": 354, "train_loss": "4.113", "train_ntokens": "1775.72", "train_nsentences": "4.95", "train_prob_perplexity": "40.435", "train_code_perplexity": "40.422", "train_temp": "1.863", "train_loss_0": "3.928", "train_loss_1": "0.135", "train_loss_2": "0.05", "train_accuracy": "0.30009", "train_wps": "3917.1", "train_ups": "2.21", "train_wpb": "1775.7", "train_bsz": "5", "train_num_updates": "14160", "train_lr": "0.00022125", "train_gnorm": "0.762", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6692"}
[2022-01-03 14:01:14,370][fairseq.trainer][INFO] - begin training epoch 355
[2022-01-03 14:01:14,371][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:01:28,430][train_inner][INFO] - {"epoch": 355, "update": 355.0, "loss": "4.087", "ntokens": "1792.39", "nsentences": "4.95", "prob_perplexity": "40.535", "code_perplexity": "40.52", "temp": "1.864", "loss_0": "3.906", "loss_1": "0.135", "loss_2": "0.046", "accuracy": "0.30086", "wps": "3927.7", "ups": "2.19", "wpb": "1792.4", "bsz": "5", "num_updates": "14200", "lr": "0.000221875", "gnorm": "0.78", "clip": "0", "train_wall": "68", "gb_free": "6.1", "wall": "6706"}
[2022-01-03 14:01:28,431][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:01:28,863][valid][INFO] - {"epoch": 355, "valid_loss": "4.164", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "37.864", "valid_code_perplexity": "37.886", "valid_temp": "1.863", "valid_loss_0": "3.982", "valid_loss_1": "0.136", "valid_loss_2": "0.046", "valid_accuracy": "0.28927", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "14200", "valid_best_loss": "3.706"}
[2022-01-03 14:01:28,866][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 355 @ 14200 updates
[2022-01-03 14:01:28,867][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:01:32,571][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:01:32,597][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 355 @ 14200 updates, score 4.164) (writing took 3.7305998681113124 seconds)
[2022-01-03 14:01:32,597][fairseq_cli.train][INFO] - end of epoch 355 (average epoch stats below)
[2022-01-03 14:01:32,610][train][INFO] - {"epoch": 355, "train_loss": "4.088", "train_ntokens": "1801.5", "train_nsentences": "4.95", "train_prob_perplexity": "40.787", "train_code_perplexity": "40.771", "train_temp": "1.863", "train_loss_0": "3.91", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29989", "train_wps": "3941.1", "train_ups": "2.19", "train_wpb": "1801.5", "train_bsz": "5", "train_num_updates": "14200", "train_lr": "0.000221875", "train_gnorm": "0.791", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "6710"}
[2022-01-03 14:01:32,652][fairseq.trainer][INFO] - begin training epoch 356
[2022-01-03 14:01:32,652][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:01:46,500][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:01:46,900][valid][INFO] - {"epoch": 356, "valid_loss": "4.378", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "40.467", "valid_code_perplexity": "40.428", "valid_temp": "1.863", "valid_loss_0": "4.2", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.26747", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "14240", "valid_best_loss": "3.706"}
[2022-01-03 14:01:46,904][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 356 @ 14240 updates
[2022-01-03 14:01:46,905][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:01:50,834][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:01:50,862][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 356 @ 14240 updates, score 4.378) (writing took 3.957510894164443 seconds)
[2022-01-03 14:01:50,862][fairseq_cli.train][INFO] - end of epoch 356 (average epoch stats below)
[2022-01-03 14:01:50,875][train][INFO] - {"epoch": 356, "train_loss": "4.1", "train_ntokens": "1786.42", "train_nsentences": "4.95", "train_prob_perplexity": "40.955", "train_code_perplexity": "40.934", "train_temp": "1.863", "train_loss_0": "3.919", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.29847", "train_wps": "3915", "train_ups": "2.19", "train_wpb": "1786.4", "train_bsz": "5", "train_num_updates": "14240", "train_lr": "0.0002225", "train_gnorm": "0.777", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "6728"}
[2022-01-03 14:01:50,952][fairseq.trainer][INFO] - begin training epoch 357
[2022-01-03 14:01:50,953][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:02:04,886][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:02:05,305][valid][INFO] - {"epoch": 357, "valid_loss": "4.24", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "39.066", "valid_code_perplexity": "38.962", "valid_temp": "1.862", "valid_loss_0": "4.058", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.27863", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "14280", "valid_best_loss": "3.706"}
[2022-01-03 14:02:05,310][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 357 @ 14280 updates
[2022-01-03 14:02:05,311][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:02:09,187][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:02:09,211][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 357 @ 14280 updates, score 4.24) (writing took 3.9015224622562528 seconds)
[2022-01-03 14:02:09,212][fairseq_cli.train][INFO] - end of epoch 357 (average epoch stats below)
[2022-01-03 14:02:09,224][train][INFO] - {"epoch": 357, "train_loss": "4.083", "train_ntokens": "1795.58", "train_nsentences": "4.95", "train_prob_perplexity": "40.692", "train_code_perplexity": "40.675", "train_temp": "1.862", "train_loss_0": "3.903", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.30078", "train_wps": "3916.9", "train_ups": "2.18", "train_wpb": "1795.6", "train_bsz": "5", "train_num_updates": "14280", "train_lr": "0.000223125", "train_gnorm": "0.784", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6747"}
[2022-01-03 14:02:09,262][fairseq.trainer][INFO] - begin training epoch 358
[2022-01-03 14:02:09,263][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:02:23,111][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:02:23,510][valid][INFO] - {"epoch": 358, "valid_loss": "4.088", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "40.287", "valid_code_perplexity": "40.257", "valid_temp": "1.862", "valid_loss_0": "3.907", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.2679", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "14320", "valid_best_loss": "3.706"}
[2022-01-03 14:02:23,514][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 358 @ 14320 updates
[2022-01-03 14:02:23,515][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:02:27,433][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:02:27,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 358 @ 14320 updates, score 4.088) (writing took 3.946099180728197 seconds)
[2022-01-03 14:02:27,461][fairseq_cli.train][INFO] - end of epoch 358 (average epoch stats below)
[2022-01-03 14:02:27,473][train][INFO] - {"epoch": 358, "train_loss": "4.086", "train_ntokens": "1804.6", "train_nsentences": "4.95", "train_prob_perplexity": "40.468", "train_code_perplexity": "40.453", "train_temp": "1.862", "train_loss_0": "3.905", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29717", "train_wps": "3958.3", "train_ups": "2.19", "train_wpb": "1804.6", "train_bsz": "5", "train_num_updates": "14320", "train_lr": "0.00022375", "train_gnorm": "0.759", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "6765"}
[2022-01-03 14:02:27,546][fairseq.trainer][INFO] - begin training epoch 359
[2022-01-03 14:02:27,547][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:02:41,337][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:02:41,731][valid][INFO] - {"epoch": 359, "valid_loss": "4.301", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "39.524", "valid_code_perplexity": "39.51", "valid_temp": "1.861", "valid_loss_0": "4.123", "valid_loss_1": "0.135", "valid_loss_2": "0.042", "valid_accuracy": "0.264", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "14360", "valid_best_loss": "3.706"}
[2022-01-03 14:02:41,734][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 359 @ 14360 updates
[2022-01-03 14:02:41,734][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:02:45,660][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:02:45,689][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 359 @ 14360 updates, score 4.301) (writing took 3.954959179274738 seconds)
[2022-01-03 14:02:45,689][fairseq_cli.train][INFO] - end of epoch 359 (average epoch stats below)
[2022-01-03 14:02:45,701][train][INFO] - {"epoch": 359, "train_loss": "4.108", "train_ntokens": "1803.97", "train_nsentences": "4.95", "train_prob_perplexity": "40.541", "train_code_perplexity": "40.526", "train_temp": "1.862", "train_loss_0": "3.929", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29443", "train_wps": "3961.3", "train_ups": "2.2", "train_wpb": "1804", "train_bsz": "5", "train_num_updates": "14360", "train_lr": "0.000224375", "train_gnorm": "0.787", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6783"}
[2022-01-03 14:02:45,783][fairseq.trainer][INFO] - begin training epoch 360
[2022-01-03 14:02:45,784][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:02:59,804][train_inner][INFO] - {"epoch": 360, "update": 360.0, "loss": "4.085", "ntokens": "1795.19", "nsentences": "4.95", "prob_perplexity": "40.524", "code_perplexity": "40.505", "temp": "1.862", "loss_0": "3.905", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.29912", "wps": "3929.8", "ups": "2.19", "wpb": "1795.2", "bsz": "5", "num_updates": "14400", "lr": "0.000225", "gnorm": "0.778", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "6797"}
[2022-01-03 14:02:59,805][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:03:00,207][valid][INFO] - {"epoch": 360, "valid_loss": "4.326", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "34.416", "valid_code_perplexity": "34.351", "valid_temp": "1.861", "valid_loss_0": "4.145", "valid_loss_1": "0.137", "valid_loss_2": "0.044", "valid_accuracy": "0.27514", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "14400", "valid_best_loss": "3.706"}
[2022-01-03 14:03:00,213][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 360 @ 14400 updates
[2022-01-03 14:03:00,215][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:03:03,922][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:03:03,949][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 360 @ 14400 updates, score 4.326) (writing took 3.73593248706311 seconds)
[2022-01-03 14:03:03,949][fairseq_cli.train][INFO] - end of epoch 360 (average epoch stats below)
[2022-01-03 14:03:03,962][train][INFO] - {"epoch": 360, "train_loss": "4.05", "train_ntokens": "1785.4", "train_nsentences": "4.95", "train_prob_perplexity": "39.965", "train_code_perplexity": "39.937", "train_temp": "1.861", "train_loss_0": "3.871", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.30479", "train_wps": "3913.7", "train_ups": "2.19", "train_wpb": "1785.4", "train_bsz": "5", "train_num_updates": "14400", "train_lr": "0.000225", "train_gnorm": "0.784", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "6801"}
[2022-01-03 14:03:04,024][fairseq.trainer][INFO] - begin training epoch 361
[2022-01-03 14:03:04,025][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:03:18,012][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:03:18,370][valid][INFO] - {"epoch": 361, "valid_loss": "4.159", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "38.19", "valid_code_perplexity": "38.175", "valid_temp": "1.861", "valid_loss_0": "3.979", "valid_loss_1": "0.136", "valid_loss_2": "0.045", "valid_accuracy": "0.29834", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "14440", "valid_best_loss": "3.706"}
[2022-01-03 14:03:18,374][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 361 @ 14440 updates
[2022-01-03 14:03:18,375][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:03:22,295][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:03:22,322][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 361 @ 14440 updates, score 4.159) (writing took 3.9475693851709366 seconds)
[2022-01-03 14:03:22,322][fairseq_cli.train][INFO] - end of epoch 361 (average epoch stats below)
[2022-01-03 14:03:22,335][train][INFO] - {"epoch": 361, "train_loss": "4.061", "train_ntokens": "1776.88", "train_nsentences": "4.95", "train_prob_perplexity": "40.522", "train_code_perplexity": "40.507", "train_temp": "1.861", "train_loss_0": "3.883", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29951", "train_wps": "3871.1", "train_ups": "2.18", "train_wpb": "1776.9", "train_bsz": "5", "train_num_updates": "14440", "train_lr": "0.000225625", "train_gnorm": "0.787", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "6820"}
[2022-01-03 14:03:22,388][fairseq.trainer][INFO] - begin training epoch 362
[2022-01-03 14:03:22,389][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:03:36,272][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:03:36,701][valid][INFO] - {"epoch": 362, "valid_loss": "3.942", "valid_ntokens": "672", "valid_nsentences": "2", "valid_prob_perplexity": "39.787", "valid_code_perplexity": "39.823", "valid_temp": "1.86", "valid_loss_0": "3.761", "valid_loss_1": "0.135", "valid_loss_2": "0.045", "valid_accuracy": "0.32143", "valid_wps": "0", "valid_wpb": "672", "valid_bsz": "2", "valid_num_updates": "14480", "valid_best_loss": "3.706"}
[2022-01-03 14:03:36,705][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 362 @ 14480 updates
[2022-01-03 14:03:36,706][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:03:40,495][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:03:40,523][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 362 @ 14480 updates, score 3.942) (writing took 3.8180937180295587 seconds)
[2022-01-03 14:03:40,523][fairseq_cli.train][INFO] - end of epoch 362 (average epoch stats below)
[2022-01-03 14:03:40,537][train][INFO] - {"epoch": 362, "train_loss": "4.098", "train_ntokens": "1806.8", "train_nsentences": "4.95", "train_prob_perplexity": "40.659", "train_code_perplexity": "40.642", "train_temp": "1.861", "train_loss_0": "3.919", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29681", "train_wps": "3973.6", "train_ups": "2.2", "train_wpb": "1806.8", "train_bsz": "5", "train_num_updates": "14480", "train_lr": "0.00022625", "train_gnorm": "0.737", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6838"}
[2022-01-03 14:03:40,597][fairseq.trainer][INFO] - begin training epoch 363
[2022-01-03 14:03:40,598][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:03:54,491][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:03:54,892][valid][INFO] - {"epoch": 363, "valid_loss": "3.967", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "39.074", "valid_code_perplexity": "39.061", "valid_temp": "1.86", "valid_loss_0": "3.786", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.32105", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "14520", "valid_best_loss": "3.706"}
[2022-01-03 14:03:54,895][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 363 @ 14520 updates
[2022-01-03 14:03:54,896][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:03:58,755][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:03:58,780][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 363 @ 14520 updates, score 3.967) (writing took 3.8848479287698865 seconds)
[2022-01-03 14:03:58,780][fairseq_cli.train][INFO] - end of epoch 363 (average epoch stats below)
[2022-01-03 14:03:58,792][train][INFO] - {"epoch": 363, "train_loss": "4.082", "train_ntokens": "1789.47", "train_nsentences": "4.95", "train_prob_perplexity": "40.244", "train_code_perplexity": "40.236", "train_temp": "1.86", "train_loss_0": "3.902", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.30009", "train_wps": "3923.5", "train_ups": "2.19", "train_wpb": "1789.5", "train_bsz": "5", "train_num_updates": "14520", "train_lr": "0.000226875", "train_gnorm": "0.751", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6856"}
[2022-01-03 14:03:58,860][fairseq.trainer][INFO] - begin training epoch 364
[2022-01-03 14:03:58,861][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:04:12,718][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:04:13,108][valid][INFO] - {"epoch": 364, "valid_loss": "4.284", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "39.793", "valid_code_perplexity": "39.797", "valid_temp": "1.86", "valid_loss_0": "4.101", "valid_loss_1": "0.135", "valid_loss_2": "0.048", "valid_accuracy": "0.25504", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "14560", "valid_best_loss": "3.706"}
[2022-01-03 14:04:13,110][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 364 @ 14560 updates
[2022-01-03 14:04:13,111][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:04:17,024][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:04:17,046][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 364 @ 14560 updates, score 4.284) (writing took 3.935242088511586 seconds)
[2022-01-03 14:04:17,046][fairseq_cli.train][INFO] - end of epoch 364 (average epoch stats below)
[2022-01-03 14:04:17,058][train][INFO] - {"epoch": 364, "train_loss": "4.067", "train_ntokens": "1789.3", "train_nsentences": "4.95", "train_prob_perplexity": "40.714", "train_code_perplexity": "40.704", "train_temp": "1.86", "train_loss_0": "3.884", "train_loss_1": "0.135", "train_loss_2": "0.048", "train_accuracy": "0.299", "train_wps": "3921", "train_ups": "2.19", "train_wpb": "1789.3", "train_bsz": "5", "train_num_updates": "14560", "train_lr": "0.0002275", "train_gnorm": "0.781", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "6874"}
[2022-01-03 14:04:17,103][fairseq.trainer][INFO] - begin training epoch 365
[2022-01-03 14:04:17,104][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:04:31,019][train_inner][INFO] - {"epoch": 365, "update": 365.0, "loss": "4.072", "ntokens": "1789.58", "nsentences": "4.95", "prob_perplexity": "40.584", "code_perplexity": "40.571", "temp": "1.86", "loss_0": "3.891", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.29934", "wps": "3924.4", "ups": "2.19", "wpb": "1789.6", "bsz": "5", "num_updates": "14600", "lr": "0.000228125", "gnorm": "0.763", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "6888"}
[2022-01-03 14:04:31,020][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:04:31,414][valid][INFO] - {"epoch": 365, "valid_loss": "4.087", "valid_ntokens": "790", "valid_nsentences": "2", "valid_prob_perplexity": "38.006", "valid_code_perplexity": "38.031", "valid_temp": "1.859", "valid_loss_0": "3.912", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.28608", "valid_wps": "0", "valid_wpb": "790", "valid_bsz": "2", "valid_num_updates": "14600", "valid_best_loss": "3.706"}
[2022-01-03 14:04:31,417][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 365 @ 14600 updates
[2022-01-03 14:04:31,418][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:04:35,211][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:04:35,230][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 365 @ 14600 updates, score 4.087) (writing took 3.813250405713916 seconds)
[2022-01-03 14:04:35,231][fairseq_cli.train][INFO] - end of epoch 365 (average epoch stats below)
[2022-01-03 14:04:35,243][train][INFO] - {"epoch": 365, "train_loss": "4.05", "train_ntokens": "1785.42", "train_nsentences": "4.95", "train_prob_perplexity": "40.779", "train_code_perplexity": "40.767", "train_temp": "1.859", "train_loss_0": "3.869", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.30131", "train_wps": "3929.9", "train_ups": "2.2", "train_wpb": "1785.4", "train_bsz": "5", "train_num_updates": "14600", "train_lr": "0.000228125", "train_gnorm": "0.758", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "6893"}
[2022-01-03 14:04:35,293][fairseq.trainer][INFO] - begin training epoch 366
[2022-01-03 14:04:35,294][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:04:49,161][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:04:49,536][valid][INFO] - {"epoch": 366, "valid_loss": "4.224", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "41.178", "valid_code_perplexity": "41.209", "valid_temp": "1.859", "valid_loss_0": "4.044", "valid_loss_1": "0.135", "valid_loss_2": "0.045", "valid_accuracy": "0.26966", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "14640", "valid_best_loss": "3.706"}
[2022-01-03 14:04:49,539][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 366 @ 14640 updates
[2022-01-03 14:04:49,540][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:04:53,459][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:04:53,487][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 366 @ 14640 updates, score 4.224) (writing took 3.947714641690254 seconds)
[2022-01-03 14:04:53,487][fairseq_cli.train][INFO] - end of epoch 366 (average epoch stats below)
[2022-01-03 14:04:53,500][train][INFO] - {"epoch": 366, "train_loss": "4.099", "train_ntokens": "1799.88", "train_nsentences": "4.95", "train_prob_perplexity": "40.807", "train_code_perplexity": "40.785", "train_temp": "1.859", "train_loss_0": "3.92", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29698", "train_wps": "3946.1", "train_ups": "2.19", "train_wpb": "1799.9", "train_bsz": "5", "train_num_updates": "14640", "train_lr": "0.00022875", "train_gnorm": "0.765", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6911"}
[2022-01-03 14:04:53,561][fairseq.trainer][INFO] - begin training epoch 367
[2022-01-03 14:04:53,562][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:05:07,544][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:05:08,034][valid][INFO] - {"epoch": 367, "valid_loss": "4.138", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "39.34", "valid_code_perplexity": "39.257", "valid_temp": "1.858", "valid_loss_0": "3.955", "valid_loss_1": "0.135", "valid_loss_2": "0.047", "valid_accuracy": "0.26562", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "14680", "valid_best_loss": "3.706"}
[2022-01-03 14:05:08,035][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 367 @ 14680 updates
[2022-01-03 14:05:08,036][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:05:11,727][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:05:11,755][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 367 @ 14680 updates, score 4.138) (writing took 3.720059740357101 seconds)
[2022-01-03 14:05:11,756][fairseq_cli.train][INFO] - end of epoch 367 (average epoch stats below)
[2022-01-03 14:05:11,769][train][INFO] - {"epoch": 367, "train_loss": "4.095", "train_ntokens": "1806.15", "train_nsentences": "4.95", "train_prob_perplexity": "40.473", "train_code_perplexity": "40.459", "train_temp": "1.859", "train_loss_0": "3.915", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.29775", "train_wps": "3957.5", "train_ups": "2.19", "train_wpb": "1806.2", "train_bsz": "5", "train_num_updates": "14680", "train_lr": "0.000229375", "train_gnorm": "0.781", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "6929"}
[2022-01-03 14:05:11,826][fairseq.trainer][INFO] - begin training epoch 368
[2022-01-03 14:05:11,826][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:05:25,721][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:05:26,196][valid][INFO] - {"epoch": 368, "valid_loss": "4.312", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "37.139", "valid_code_perplexity": "37.196", "valid_temp": "1.858", "valid_loss_0": "4.129", "valid_loss_1": "0.136", "valid_loss_2": "0.047", "valid_accuracy": "0.26517", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "14720", "valid_best_loss": "3.706"}
[2022-01-03 14:05:26,198][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 368 @ 14720 updates
[2022-01-03 14:05:26,199][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:05:29,891][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:05:29,918][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 368 @ 14720 updates, score 4.312) (writing took 3.7197474846616387 seconds)
[2022-01-03 14:05:29,918][fairseq_cli.train][INFO] - end of epoch 368 (average epoch stats below)
[2022-01-03 14:05:29,931][train][INFO] - {"epoch": 368, "train_loss": "4.102", "train_ntokens": "1792.42", "train_nsentences": "4.95", "train_prob_perplexity": "41.054", "train_code_perplexity": "41.043", "train_temp": "1.858", "train_loss_0": "3.923", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29417", "train_wps": "3950.3", "train_ups": "2.2", "train_wpb": "1792.4", "train_bsz": "5", "train_num_updates": "14720", "train_lr": "0.00023", "train_gnorm": "0.745", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "6947"}
[2022-01-03 14:05:29,972][fairseq.trainer][INFO] - begin training epoch 369
[2022-01-03 14:05:29,973][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:05:43,884][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:05:44,289][valid][INFO] - {"epoch": 369, "valid_loss": "4.205", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "41.607", "valid_code_perplexity": "41.594", "valid_temp": "1.858", "valid_loss_0": "4.027", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.28141", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "14760", "valid_best_loss": "3.706"}
[2022-01-03 14:05:44,292][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 369 @ 14760 updates
[2022-01-03 14:05:44,293][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:05:48,235][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:05:48,265][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 369 @ 14760 updates, score 4.205) (writing took 3.972475867718458 seconds)
[2022-01-03 14:05:48,265][fairseq_cli.train][INFO] - end of epoch 369 (average epoch stats below)
[2022-01-03 14:05:48,277][train][INFO] - {"epoch": 369, "train_loss": "4.059", "train_ntokens": "1797.35", "train_nsentences": "4.95", "train_prob_perplexity": "40.738", "train_code_perplexity": "40.716", "train_temp": "1.858", "train_loss_0": "3.88", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.3024", "train_wps": "3921.3", "train_ups": "2.18", "train_wpb": "1797.3", "train_bsz": "5", "train_num_updates": "14760", "train_lr": "0.000230625", "train_gnorm": "0.741", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "6966"}
[2022-01-03 14:05:48,336][fairseq.trainer][INFO] - begin training epoch 370
[2022-01-03 14:05:48,337][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:06:02,359][train_inner][INFO] - {"epoch": 370, "update": 370.0, "loss": "4.079", "ntokens": "1797.42", "nsentences": "4.95", "prob_perplexity": "40.75", "code_perplexity": "40.735", "temp": "1.858", "loss_0": "3.899", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.29925", "wps": "3936.2", "ups": "2.19", "wpb": "1797.4", "bsz": "5", "num_updates": "14800", "lr": "0.00023125", "gnorm": "0.759", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "6980"}
[2022-01-03 14:06:02,360][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:06:02,765][valid][INFO] - {"epoch": 370, "valid_loss": "4.409", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "39.737", "valid_code_perplexity": "39.683", "valid_temp": "1.857", "valid_loss_0": "4.228", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.243", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "14800", "valid_best_loss": "3.706"}
[2022-01-03 14:06:02,768][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 370 @ 14800 updates
[2022-01-03 14:06:02,769][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:06:06,446][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:06:06,474][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 370 @ 14800 updates, score 4.409) (writing took 3.7061405144631863 seconds)
[2022-01-03 14:06:06,475][fairseq_cli.train][INFO] - end of epoch 370 (average epoch stats below)
[2022-01-03 14:06:06,487][train][INFO] - {"epoch": 370, "train_loss": "4.039", "train_ntokens": "1791.3", "train_nsentences": "4.95", "train_prob_perplexity": "40.678", "train_code_perplexity": "40.673", "train_temp": "1.858", "train_loss_0": "3.857", "train_loss_1": "0.135", "train_loss_2": "0.047", "train_accuracy": "0.30499", "train_wps": "3937.5", "train_ups": "2.2", "train_wpb": "1791.3", "train_bsz": "5", "train_num_updates": "14800", "train_lr": "0.00023125", "train_gnorm": "0.762", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "6984"}
[2022-01-03 14:06:06,549][fairseq.trainer][INFO] - begin training epoch 371
[2022-01-03 14:06:06,550][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:06:20,523][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:06:20,931][valid][INFO] - {"epoch": 371, "valid_loss": "4.06", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "39.357", "valid_code_perplexity": "39.344", "valid_temp": "1.857", "valid_loss_0": "3.886", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.29501", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "14840", "valid_best_loss": "3.706"}
[2022-01-03 14:06:20,934][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 371 @ 14840 updates
[2022-01-03 14:06:20,934][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:06:24,613][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:06:24,633][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 371 @ 14840 updates, score 4.06) (writing took 3.6988779893144965 seconds)
[2022-01-03 14:06:24,633][fairseq_cli.train][INFO] - end of epoch 371 (average epoch stats below)
[2022-01-03 14:06:24,646][train][INFO] - {"epoch": 371, "train_loss": "4.083", "train_ntokens": "1791.42", "train_nsentences": "4.95", "train_prob_perplexity": "41", "train_code_perplexity": "40.988", "train_temp": "1.857", "train_loss_0": "3.902", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.2969", "train_wps": "3948.9", "train_ups": "2.2", "train_wpb": "1791.4", "train_bsz": "5", "train_num_updates": "14840", "train_lr": "0.000231875", "train_gnorm": "0.734", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.7", "train_wall": "7002"}
[2022-01-03 14:06:24,690][fairseq.trainer][INFO] - begin training epoch 372
[2022-01-03 14:06:24,691][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:06:38,578][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:06:38,975][valid][INFO] - {"epoch": 372, "valid_loss": "4.378", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "34.989", "valid_code_perplexity": "34.913", "valid_temp": "1.857", "valid_loss_0": "4.194", "valid_loss_1": "0.136", "valid_loss_2": "0.047", "valid_accuracy": "0.28099", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "14880", "valid_best_loss": "3.706"}
[2022-01-03 14:06:38,979][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 372 @ 14880 updates
[2022-01-03 14:06:38,979][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:06:42,896][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:06:42,924][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 372 @ 14880 updates, score 4.378) (writing took 3.945311289280653 seconds)
[2022-01-03 14:06:42,924][fairseq_cli.train][INFO] - end of epoch 372 (average epoch stats below)
[2022-01-03 14:06:42,936][train][INFO] - {"epoch": 372, "train_loss": "4.062", "train_ntokens": "1777.8", "train_nsentences": "4.95", "train_prob_perplexity": "40.313", "train_code_perplexity": "40.299", "train_temp": "1.857", "train_loss_0": "3.882", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.30328", "train_wps": "3890.4", "train_ups": "2.19", "train_wpb": "1777.8", "train_bsz": "5", "train_num_updates": "14880", "train_lr": "0.0002325", "train_gnorm": "0.761", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "7020"}
[2022-01-03 14:06:43,010][fairseq.trainer][INFO] - begin training epoch 373
[2022-01-03 14:06:43,011][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:06:56,896][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:06:57,298][valid][INFO] - {"epoch": 373, "valid_loss": "4.183", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "37.142", "valid_code_perplexity": "37.034", "valid_temp": "1.856", "valid_loss_0": "4.007", "valid_loss_1": "0.136", "valid_loss_2": "0.04", "valid_accuracy": "0.29112", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "14920", "valid_best_loss": "3.706"}
[2022-01-03 14:06:57,301][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 373 @ 14920 updates
[2022-01-03 14:06:57,302][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:07:01,062][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:07:01,082][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 373 @ 14920 updates, score 4.183) (writing took 3.780999002046883 seconds)
[2022-01-03 14:07:01,082][fairseq_cli.train][INFO] - end of epoch 373 (average epoch stats below)
[2022-01-03 14:07:01,095][train][INFO] - {"epoch": 373, "train_loss": "4.115", "train_ntokens": "1821.08", "train_nsentences": "4.95", "train_prob_perplexity": "40.826", "train_code_perplexity": "40.818", "train_temp": "1.856", "train_loss_0": "3.936", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29838", "train_wps": "4014.3", "train_ups": "2.2", "train_wpb": "1821.1", "train_bsz": "5", "train_num_updates": "14920", "train_lr": "0.000233125", "train_gnorm": "0.744", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "7038"}
[2022-01-03 14:07:01,139][fairseq.trainer][INFO] - begin training epoch 374
[2022-01-03 14:07:01,140][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:07:14,996][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:07:15,386][valid][INFO] - {"epoch": 374, "valid_loss": "4.231", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "40.238", "valid_code_perplexity": "40.24", "valid_temp": "1.856", "valid_loss_0": "4.052", "valid_loss_1": "0.135", "valid_loss_2": "0.044", "valid_accuracy": "0.27514", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "14960", "valid_best_loss": "3.706"}
[2022-01-03 14:07:15,389][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 374 @ 14960 updates
[2022-01-03 14:07:15,390][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:07:19,293][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:07:19,318][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 374 @ 14960 updates, score 4.231) (writing took 3.929654016159475 seconds)
[2022-01-03 14:07:19,319][fairseq_cli.train][INFO] - end of epoch 374 (average epoch stats below)
[2022-01-03 14:07:19,332][train][INFO] - {"epoch": 374, "train_loss": "4.085", "train_ntokens": "1795.55", "train_nsentences": "4.95", "train_prob_perplexity": "41.178", "train_code_perplexity": "41.163", "train_temp": "1.856", "train_loss_0": "3.905", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.29825", "train_wps": "3941.1", "train_ups": "2.19", "train_wpb": "1795.5", "train_bsz": "5", "train_num_updates": "14960", "train_lr": "0.00023375", "train_gnorm": "0.768", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7057"}
[2022-01-03 14:07:19,398][fairseq.trainer][INFO] - begin training epoch 375
[2022-01-03 14:07:19,398][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:07:33,336][train_inner][INFO] - {"epoch": 375, "update": 375.0, "loss": "4.084", "ntokens": "1792.97", "nsentences": "4.95", "prob_perplexity": "40.731", "code_perplexity": "40.718", "temp": "1.856", "loss_0": "3.903", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.29967", "wps": "3942.1", "ups": "2.2", "wpb": "1793", "bsz": "5", "num_updates": "15000", "lr": "0.000234375", "gnorm": "0.751", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "7071"}
[2022-01-03 14:07:33,337][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:07:33,753][valid][INFO] - {"epoch": 375, "valid_loss": "3.954", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "36.688", "valid_code_perplexity": "36.623", "valid_temp": "1.855", "valid_loss_0": "3.773", "valid_loss_1": "0.136", "valid_loss_2": "0.045", "valid_accuracy": "0.32891", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "15000", "valid_best_loss": "3.706"}
[2022-01-03 14:07:33,756][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 375 @ 15000 updates
[2022-01-03 14:07:33,757][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:07:37,504][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:07:37,532][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 375 @ 15000 updates, score 3.954) (writing took 3.7760214610025287 seconds)
[2022-01-03 14:07:37,532][fairseq_cli.train][INFO] - end of epoch 375 (average epoch stats below)
[2022-01-03 14:07:37,545][train][INFO] - {"epoch": 375, "train_loss": "4.072", "train_ntokens": "1779", "train_nsentences": "4.95", "train_prob_perplexity": "40.341", "train_code_perplexity": "40.325", "train_temp": "1.856", "train_loss_0": "3.891", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.30159", "train_wps": "3909.8", "train_ups": "2.2", "train_wpb": "1779", "train_bsz": "5", "train_num_updates": "15000", "train_lr": "0.000234375", "train_gnorm": "0.749", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "7075"}
[2022-01-03 14:07:37,601][fairseq.trainer][INFO] - begin training epoch 376
[2022-01-03 14:07:37,602][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:07:51,638][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:07:52,029][valid][INFO] - {"epoch": 376, "valid_loss": "4.157", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "40.2", "valid_code_perplexity": "40.19", "valid_temp": "1.855", "valid_loss_0": "3.978", "valid_loss_1": "0.135", "valid_loss_2": "0.044", "valid_accuracy": "0.29971", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "15040", "valid_best_loss": "3.706"}
[2022-01-03 14:07:52,032][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 376 @ 15040 updates
[2022-01-03 14:07:52,033][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:07:55,757][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:07:55,784][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 376 @ 15040 updates, score 4.157) (writing took 3.752193670719862 seconds)
[2022-01-03 14:07:55,784][fairseq_cli.train][INFO] - end of epoch 376 (average epoch stats below)
[2022-01-03 14:07:55,797][train][INFO] - {"epoch": 376, "train_loss": "4.069", "train_ntokens": "1799.7", "train_nsentences": "4.95", "train_prob_perplexity": "41.009", "train_code_perplexity": "40.998", "train_temp": "1.855", "train_loss_0": "3.888", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.29942", "train_wps": "3946.9", "train_ups": "2.19", "train_wpb": "1799.7", "train_bsz": "5", "train_num_updates": "15040", "train_lr": "0.000235", "train_gnorm": "0.735", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "7093"}
[2022-01-03 14:07:55,853][fairseq.trainer][INFO] - begin training epoch 377
[2022-01-03 14:07:55,854][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:08:09,872][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:08:10,277][valid][INFO] - {"epoch": 377, "valid_loss": "4.425", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "40.285", "valid_code_perplexity": "40.263", "valid_temp": "1.855", "valid_loss_0": "4.244", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.24324", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "15080", "valid_best_loss": "3.706"}
[2022-01-03 14:08:10,281][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 377 @ 15080 updates
[2022-01-03 14:08:10,283][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:08:14,008][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:08:14,037][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 377 @ 15080 updates, score 4.425) (writing took 3.755911970511079 seconds)
[2022-01-03 14:08:14,038][fairseq_cli.train][INFO] - end of epoch 377 (average epoch stats below)
[2022-01-03 14:08:14,050][train][INFO] - {"epoch": 377, "train_loss": "4.066", "train_ntokens": "1761.45", "train_nsentences": "4.95", "train_prob_perplexity": "41.134", "train_code_perplexity": "41.103", "train_temp": "1.855", "train_loss_0": "3.887", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29937", "train_wps": "3862.6", "train_ups": "2.19", "train_wpb": "1761.5", "train_bsz": "5", "train_num_updates": "15080", "train_lr": "0.000235625", "train_gnorm": "0.751", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7111"}
[2022-01-03 14:08:14,130][fairseq.trainer][INFO] - begin training epoch 378
[2022-01-03 14:08:14,131][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:08:28,002][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:08:28,398][valid][INFO] - {"epoch": 378, "valid_loss": "4.021", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "38.393", "valid_code_perplexity": "38.483", "valid_temp": "1.854", "valid_loss_0": "3.843", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.30056", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "15120", "valid_best_loss": "3.706"}
[2022-01-03 14:08:28,400][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 378 @ 15120 updates
[2022-01-03 14:08:28,401][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:08:32,319][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:08:32,339][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 378 @ 15120 updates, score 4.021) (writing took 3.9386817812919617 seconds)
[2022-01-03 14:08:32,339][fairseq_cli.train][INFO] - end of epoch 378 (average epoch stats below)
[2022-01-03 14:08:32,351][train][INFO] - {"epoch": 378, "train_loss": "4.075", "train_ntokens": "1793.95", "train_nsentences": "4.95", "train_prob_perplexity": "41.1", "train_code_perplexity": "41.08", "train_temp": "1.855", "train_loss_0": "3.895", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29933", "train_wps": "3923.6", "train_ups": "2.19", "train_wpb": "1794", "train_bsz": "5", "train_num_updates": "15120", "train_lr": "0.00023625", "train_gnorm": "0.76", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.8", "train_wall": "7130"}
[2022-01-03 14:08:32,399][fairseq.trainer][INFO] - begin training epoch 379
[2022-01-03 14:08:32,399][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:08:46,370][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:08:46,910][valid][INFO] - {"epoch": 379, "valid_loss": "4.404", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "42.285", "valid_code_perplexity": "42.334", "valid_temp": "1.854", "valid_loss_0": "4.227", "valid_loss_1": "0.135", "valid_loss_2": "0.042", "valid_accuracy": "0.25482", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "15160", "valid_best_loss": "3.706"}
[2022-01-03 14:08:46,915][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 379 @ 15160 updates
[2022-01-03 14:08:46,916][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:08:50,564][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:08:50,590][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 379 @ 15160 updates, score 4.404) (writing took 3.6755305007100105 seconds)
[2022-01-03 14:08:50,591][fairseq_cli.train][INFO] - end of epoch 379 (average epoch stats below)
[2022-01-03 14:08:50,604][train][INFO] - {"epoch": 379, "train_loss": "4.087", "train_ntokens": "1803.33", "train_nsentences": "4.95", "train_prob_perplexity": "41.394", "train_code_perplexity": "41.374", "train_temp": "1.854", "train_loss_0": "3.908", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29731", "train_wps": "3954.8", "train_ups": "2.19", "train_wpb": "1803.3", "train_bsz": "5", "train_num_updates": "15160", "train_lr": "0.000236875", "train_gnorm": "0.836", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7148"}
[2022-01-03 14:08:50,673][fairseq.trainer][INFO] - begin training epoch 380
[2022-01-03 14:08:50,674][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:09:04,685][train_inner][INFO] - {"epoch": 380, "update": 380.0, "loss": "4.071", "ntokens": "1788.89", "nsentences": "4.95", "prob_perplexity": "41.215", "code_perplexity": "41.194", "temp": "1.855", "loss_0": "3.892", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.2994", "wps": "3917.2", "ups": "2.19", "wpb": "1788.9", "bsz": "5", "num_updates": "15200", "lr": "0.0002375", "gnorm": "0.761", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "7162"}
[2022-01-03 14:09:04,686][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:09:05,086][valid][INFO] - {"epoch": 380, "valid_loss": "4.07", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "38.567", "valid_code_perplexity": "38.526", "valid_temp": "1.854", "valid_loss_0": "3.897", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.29528", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "15200", "valid_best_loss": "3.706"}
[2022-01-03 14:09:05,088][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 380 @ 15200 updates
[2022-01-03 14:09:05,089][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:09:08,791][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:09:08,820][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 380 @ 15200 updates, score 4.07) (writing took 3.731051472015679 seconds)
[2022-01-03 14:09:08,820][fairseq_cli.train][INFO] - end of epoch 380 (average epoch stats below)
[2022-01-03 14:09:08,833][train][INFO] - {"epoch": 380, "train_loss": "4.06", "train_ntokens": "1786.03", "train_nsentences": "4.95", "train_prob_perplexity": "41.438", "train_code_perplexity": "41.413", "train_temp": "1.854", "train_loss_0": "3.884", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.30159", "train_wps": "3921.8", "train_ups": "2.2", "train_wpb": "1786", "train_bsz": "5", "train_num_updates": "15200", "train_lr": "0.0002375", "train_gnorm": "0.725", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7166"}
[2022-01-03 14:09:08,879][fairseq.trainer][INFO] - begin training epoch 381
[2022-01-03 14:09:08,879][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:09:22,720][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:09:23,123][valid][INFO] - {"epoch": 381, "valid_loss": "4.072", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "41.087", "valid_code_perplexity": "41.103", "valid_temp": "1.853", "valid_loss_0": "3.899", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.28962", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "15240", "valid_best_loss": "3.706"}
[2022-01-03 14:09:23,126][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 381 @ 15240 updates
[2022-01-03 14:09:23,127][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:09:27,019][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:09:27,046][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 381 @ 15240 updates, score 4.072) (writing took 3.9194452492520213 seconds)
[2022-01-03 14:09:27,046][fairseq_cli.train][INFO] - end of epoch 381 (average epoch stats below)
[2022-01-03 14:09:27,058][train][INFO] - {"epoch": 381, "train_loss": "4.062", "train_ntokens": "1793.03", "train_nsentences": "4.95", "train_prob_perplexity": "40.881", "train_code_perplexity": "40.859", "train_temp": "1.853", "train_loss_0": "3.882", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29856", "train_wps": "3937.9", "train_ups": "2.2", "train_wpb": "1793", "train_bsz": "5", "train_num_updates": "15240", "train_lr": "0.000238125", "train_gnorm": "0.735", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7184"}
[2022-01-03 14:09:27,142][fairseq.trainer][INFO] - begin training epoch 382
[2022-01-03 14:09:27,143][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:09:41,074][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:09:41,471][valid][INFO] - {"epoch": 382, "valid_loss": "4.258", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "39.221", "valid_code_perplexity": "39.265", "valid_temp": "1.853", "valid_loss_0": "4.074", "valid_loss_1": "0.135", "valid_loss_2": "0.048", "valid_accuracy": "0.2888", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "15280", "valid_best_loss": "3.706"}
[2022-01-03 14:09:41,474][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 382 @ 15280 updates
[2022-01-03 14:09:41,475][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:09:45,233][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:09:45,261][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 382 @ 15280 updates, score 4.258) (writing took 3.7865547789260745 seconds)
[2022-01-03 14:09:45,261][fairseq_cli.train][INFO] - end of epoch 382 (average epoch stats below)
[2022-01-03 14:09:45,274][train][INFO] - {"epoch": 382, "train_loss": "4.056", "train_ntokens": "1793.15", "train_nsentences": "4.95", "train_prob_perplexity": "41.102", "train_code_perplexity": "41.079", "train_temp": "1.853", "train_loss_0": "3.877", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.3049", "train_wps": "3940.4", "train_ups": "2.2", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "15280", "train_lr": "0.00023875", "train_gnorm": "0.761", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "7203"}
[2022-01-03 14:09:45,323][fairseq.trainer][INFO] - begin training epoch 383
[2022-01-03 14:09:45,324][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:09:59,296][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:09:59,679][valid][INFO] - {"epoch": 383, "valid_loss": "4.046", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "39.75", "valid_code_perplexity": "39.725", "valid_temp": "1.853", "valid_loss_0": "3.866", "valid_loss_1": "0.135", "valid_loss_2": "0.044", "valid_accuracy": "0.30311", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "15320", "valid_best_loss": "3.706"}
[2022-01-03 14:09:59,682][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 383 @ 15320 updates
[2022-01-03 14:09:59,682][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:10:03,453][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:10:03,472][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 383 @ 15320 updates, score 4.046) (writing took 3.790624011307955 seconds)
[2022-01-03 14:10:03,473][fairseq_cli.train][INFO] - end of epoch 383 (average epoch stats below)
[2022-01-03 14:10:03,485][train][INFO] - {"epoch": 383, "train_loss": "4.092", "train_ntokens": "1798.15", "train_nsentences": "4.95", "train_prob_perplexity": "41.014", "train_code_perplexity": "40.991", "train_temp": "1.853", "train_loss_0": "3.91", "train_loss_1": "0.135", "train_loss_2": "0.047", "train_accuracy": "0.2979", "train_wps": "3952.2", "train_ups": "2.2", "train_wpb": "1798.2", "train_bsz": "5", "train_num_updates": "15320", "train_lr": "0.000239375", "train_gnorm": "0.772", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7221"}
[2022-01-03 14:10:03,527][fairseq.trainer][INFO] - begin training epoch 384
[2022-01-03 14:10:03,528][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:10:17,549][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:10:17,952][valid][INFO] - {"epoch": 384, "valid_loss": "4.156", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "36.672", "valid_code_perplexity": "36.666", "valid_temp": "1.852", "valid_loss_0": "3.977", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.30217", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "15360", "valid_best_loss": "3.706"}
[2022-01-03 14:10:17,955][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 384 @ 15360 updates
[2022-01-03 14:10:17,956][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:10:21,709][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:10:21,737][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 384 @ 15360 updates, score 4.156) (writing took 3.7823519743978977 seconds)
[2022-01-03 14:10:21,738][fairseq_cli.train][INFO] - end of epoch 384 (average epoch stats below)
[2022-01-03 14:10:21,751][train][INFO] - {"epoch": 384, "train_loss": "4.076", "train_ntokens": "1796.15", "train_nsentences": "4.95", "train_prob_perplexity": "41.596", "train_code_perplexity": "41.578", "train_temp": "1.852", "train_loss_0": "3.897", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29915", "train_wps": "3936.2", "train_ups": "2.19", "train_wpb": "1796.2", "train_bsz": "5", "train_num_updates": "15360", "train_lr": "0.00024", "train_gnorm": "0.717", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7239"}
[2022-01-03 14:10:21,829][fairseq.trainer][INFO] - begin training epoch 385
[2022-01-03 14:10:21,830][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:10:35,722][train_inner][INFO] - {"epoch": 385, "update": 385.0, "loss": "4.065", "ntokens": "1795.55", "nsentences": "4.95", "prob_perplexity": "41.163", "code_perplexity": "41.143", "temp": "1.853", "loss_0": "3.886", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.30047", "wps": "3945.2", "ups": "2.2", "wpb": "1795.5", "bsz": "5", "num_updates": "15400", "lr": "0.000240625", "gnorm": "0.749", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "7253"}
[2022-01-03 14:10:35,723][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:10:36,134][valid][INFO] - {"epoch": 385, "valid_loss": "4.026", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "37.124", "valid_code_perplexity": "37.109", "valid_temp": "1.852", "valid_loss_0": "3.846", "valid_loss_1": "0.136", "valid_loss_2": "0.044", "valid_accuracy": "0.3026", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "15400", "valid_best_loss": "3.706"}
[2022-01-03 14:10:36,139][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 385 @ 15400 updates
[2022-01-03 14:10:36,140][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:10:39,948][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:10:39,976][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 385 @ 15400 updates, score 4.026) (writing took 3.8366805529221892 seconds)
[2022-01-03 14:10:39,976][fairseq_cli.train][INFO] - end of epoch 385 (average epoch stats below)
[2022-01-03 14:10:39,989][train][INFO] - {"epoch": 385, "train_loss": "4.04", "train_ntokens": "1797.28", "train_nsentences": "4.95", "train_prob_perplexity": "41.221", "train_code_perplexity": "41.206", "train_temp": "1.852", "train_loss_0": "3.862", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.30185", "train_wps": "3944.6", "train_ups": "2.19", "train_wpb": "1797.3", "train_bsz": "5", "train_num_updates": "15400", "train_lr": "0.000240625", "train_gnorm": "0.76", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7257"}
[2022-01-03 14:10:40,070][fairseq.trainer][INFO] - begin training epoch 386
[2022-01-03 14:10:40,071][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:10:53,969][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:10:54,373][valid][INFO] - {"epoch": 386, "valid_loss": "4.237", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "40.049", "valid_code_perplexity": "40.029", "valid_temp": "1.851", "valid_loss_0": "4.057", "valid_loss_1": "0.135", "valid_loss_2": "0.046", "valid_accuracy": "0.26243", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "15440", "valid_best_loss": "3.706"}
[2022-01-03 14:10:54,375][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 386 @ 15440 updates
[2022-01-03 14:10:54,376][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:10:58,722][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:10:58,742][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 386 @ 15440 updates, score 4.237) (writing took 4.3667047917842865 seconds)
[2022-01-03 14:10:58,743][fairseq_cli.train][INFO] - end of epoch 386 (average epoch stats below)
[2022-01-03 14:10:58,755][train][INFO] - {"epoch": 386, "train_loss": "4.094", "train_ntokens": "1788.88", "train_nsentences": "4.95", "train_prob_perplexity": "41.535", "train_code_perplexity": "41.523", "train_temp": "1.852", "train_loss_0": "3.915", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29451", "train_wps": "3815.6", "train_ups": "2.13", "train_wpb": "1788.9", "train_bsz": "5", "train_num_updates": "15440", "train_lr": "0.00024125", "train_gnorm": "0.753", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7276"}
[2022-01-03 14:10:58,800][fairseq.trainer][INFO] - begin training epoch 387
[2022-01-03 14:10:58,801][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:11:12,517][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:11:12,913][valid][INFO] - {"epoch": 387, "valid_loss": "4.285", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "40.552", "valid_code_perplexity": "40.554", "valid_temp": "1.851", "valid_loss_0": "4.109", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.25733", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "15480", "valid_best_loss": "3.706"}
[2022-01-03 14:11:12,916][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 387 @ 15480 updates
[2022-01-03 14:11:12,916][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:11:16,809][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:11:16,834][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 387 @ 15480 updates, score 4.285) (writing took 3.9183569764718413 seconds)
[2022-01-03 14:11:16,834][fairseq_cli.train][INFO] - end of epoch 387 (average epoch stats below)
[2022-01-03 14:11:16,846][train][INFO] - {"epoch": 387, "train_loss": "4.076", "train_ntokens": "1788.85", "train_nsentences": "4.95", "train_prob_perplexity": "41.874", "train_code_perplexity": "41.862", "train_temp": "1.851", "train_loss_0": "3.894", "train_loss_1": "0.135", "train_loss_2": "0.047", "train_accuracy": "0.30201", "train_wps": "3957.7", "train_ups": "2.21", "train_wpb": "1788.8", "train_bsz": "5", "train_num_updates": "15480", "train_lr": "0.000241875", "train_gnorm": "0.731", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "7294"}
[2022-01-03 14:11:16,913][fairseq.trainer][INFO] - begin training epoch 388
[2022-01-03 14:11:16,913][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:11:30,779][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:11:31,180][valid][INFO] - {"epoch": 388, "valid_loss": "4.269", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "40.52", "valid_code_perplexity": "40.492", "valid_temp": "1.851", "valid_loss_0": "4.095", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.26776", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "15520", "valid_best_loss": "3.706"}
[2022-01-03 14:11:31,183][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 388 @ 15520 updates
[2022-01-03 14:11:31,184][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:11:35,016][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:11:35,044][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 388 @ 15520 updates, score 4.269) (writing took 3.8610550416633487 seconds)
[2022-01-03 14:11:35,045][fairseq_cli.train][INFO] - end of epoch 388 (average epoch stats below)
[2022-01-03 14:11:35,058][train][INFO] - {"epoch": 388, "train_loss": "4.106", "train_ntokens": "1802.92", "train_nsentences": "4.95", "train_prob_perplexity": "41.116", "train_code_perplexity": "41.096", "train_temp": "1.851", "train_loss_0": "3.927", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29592", "train_wps": "3962.8", "train_ups": "2.2", "train_wpb": "1802.9", "train_bsz": "5", "train_num_updates": "15520", "train_lr": "0.0002425", "train_gnorm": "0.736", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "7312"}
[2022-01-03 14:11:35,138][fairseq.trainer][INFO] - begin training epoch 389
[2022-01-03 14:11:35,139][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:11:49,105][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:11:49,503][valid][INFO] - {"epoch": 389, "valid_loss": "3.998", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "39.895", "valid_code_perplexity": "39.793", "valid_temp": "1.85", "valid_loss_0": "3.821", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.30159", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "15560", "valid_best_loss": "3.706"}
[2022-01-03 14:11:49,506][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 389 @ 15560 updates
[2022-01-03 14:11:49,507][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:11:53,201][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:11:53,220][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 389 @ 15560 updates, score 3.998) (writing took 3.7140567740425467 seconds)
[2022-01-03 14:11:53,220][fairseq_cli.train][INFO] - end of epoch 389 (average epoch stats below)
[2022-01-03 14:11:53,233][train][INFO] - {"epoch": 389, "train_loss": "4.119", "train_ntokens": "1796.2", "train_nsentences": "4.95", "train_prob_perplexity": "41.018", "train_code_perplexity": "41.009", "train_temp": "1.85", "train_loss_0": "3.939", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.2931", "train_wps": "3956", "train_ups": "2.2", "train_wpb": "1796.2", "train_bsz": "5", "train_num_updates": "15560", "train_lr": "0.000243125", "train_gnorm": "0.76", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7331"}
[2022-01-03 14:11:53,278][fairseq.trainer][INFO] - begin training epoch 390
[2022-01-03 14:11:53,279][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:12:07,213][train_inner][INFO] - {"epoch": 390, "update": 390.0, "loss": "4.093", "ntokens": "1792.47", "nsentences": "4.95", "prob_perplexity": "41.446", "code_perplexity": "41.43", "temp": "1.851", "loss_0": "3.914", "loss_1": "0.135", "loss_2": "0.045", "accuracy": "0.29705", "wps": "3918.9", "ups": "2.19", "wpb": "1792.5", "bsz": "5", "num_updates": "15600", "lr": "0.00024375", "gnorm": "0.752", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "7345"}
[2022-01-03 14:12:07,214][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:12:07,609][valid][INFO] - {"epoch": 390, "valid_loss": "4.071", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "41.112", "valid_code_perplexity": "41.136", "valid_temp": "1.85", "valid_loss_0": "3.894", "valid_loss_1": "0.135", "valid_loss_2": "0.042", "valid_accuracy": "0.29226", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "15600", "valid_best_loss": "3.706"}
[2022-01-03 14:12:07,612][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 390 @ 15600 updates
[2022-01-03 14:12:07,613][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:12:11,564][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:12:11,591][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 390 @ 15600 updates, score 4.071) (writing took 3.9787122858688235 seconds)
[2022-01-03 14:12:11,592][fairseq_cli.train][INFO] - end of epoch 390 (average epoch stats below)
[2022-01-03 14:12:11,604][train][INFO] - {"epoch": 390, "train_loss": "4.072", "train_ntokens": "1785.5", "train_nsentences": "4.95", "train_prob_perplexity": "41.687", "train_code_perplexity": "41.66", "train_temp": "1.85", "train_loss_0": "3.894", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.29975", "train_wps": "3890.2", "train_ups": "2.18", "train_wpb": "1785.5", "train_bsz": "5", "train_num_updates": "15600", "train_lr": "0.00024375", "train_gnorm": "0.781", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "7349"}
[2022-01-03 14:12:11,676][fairseq.trainer][INFO] - begin training epoch 391
[2022-01-03 14:12:11,677][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:12:25,651][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:12:26,048][valid][INFO] - {"epoch": 391, "valid_loss": "4.128", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "39.611", "valid_code_perplexity": "39.628", "valid_temp": "1.85", "valid_loss_0": "3.945", "valid_loss_1": "0.135", "valid_loss_2": "0.047", "valid_accuracy": "0.27941", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "15640", "valid_best_loss": "3.706"}
[2022-01-03 14:12:26,051][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 391 @ 15640 updates
[2022-01-03 14:12:26,052][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:12:29,791][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:12:29,819][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 391 @ 15640 updates, score 4.128) (writing took 3.7683191085234284 seconds)
[2022-01-03 14:12:29,820][fairseq_cli.train][INFO] - end of epoch 391 (average epoch stats below)
[2022-01-03 14:12:29,833][train][INFO] - {"epoch": 391, "train_loss": "4.018", "train_ntokens": "1784.85", "train_nsentences": "4.95", "train_prob_perplexity": "41.667", "train_code_perplexity": "41.655", "train_temp": "1.85", "train_loss_0": "3.839", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.30511", "train_wps": "3919.4", "train_ups": "2.2", "train_wpb": "1784.8", "train_bsz": "5", "train_num_updates": "15640", "train_lr": "0.000244375", "train_gnorm": "0.726", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7367"}
[2022-01-03 14:12:29,910][fairseq.trainer][INFO] - begin training epoch 392
[2022-01-03 14:12:29,911][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:12:43,814][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:12:44,204][valid][INFO] - {"epoch": 392, "valid_loss": "4.156", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "37.312", "valid_code_perplexity": "37.319", "valid_temp": "1.849", "valid_loss_0": "3.977", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.3013", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "15680", "valid_best_loss": "3.706"}
[2022-01-03 14:12:44,207][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 392 @ 15680 updates
[2022-01-03 14:12:44,208][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:12:48,144][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:12:48,173][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 392 @ 15680 updates, score 4.156) (writing took 3.9661462493240833 seconds)
[2022-01-03 14:12:48,173][fairseq_cli.train][INFO] - end of epoch 392 (average epoch stats below)
[2022-01-03 14:12:48,187][train][INFO] - {"epoch": 392, "train_loss": "4.043", "train_ntokens": "1782.6", "train_nsentences": "4.95", "train_prob_perplexity": "41.314", "train_code_perplexity": "41.293", "train_temp": "1.849", "train_loss_0": "3.862", "train_loss_1": "0.135", "train_loss_2": "0.046", "train_accuracy": "0.30659", "train_wps": "3887.7", "train_ups": "2.18", "train_wpb": "1782.6", "train_bsz": "5", "train_num_updates": "15680", "train_lr": "0.000245", "train_gnorm": "0.698", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7386"}
[2022-01-03 14:12:48,267][fairseq.trainer][INFO] - begin training epoch 393
[2022-01-03 14:12:48,268][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:13:02,109][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:13:02,500][valid][INFO] - {"epoch": 393, "valid_loss": "3.975", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "38.923", "valid_code_perplexity": "38.931", "valid_temp": "1.849", "valid_loss_0": "3.799", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.31044", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "15720", "valid_best_loss": "3.706"}
[2022-01-03 14:13:02,503][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 393 @ 15720 updates
[2022-01-03 14:13:02,503][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:13:06,410][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:13:06,422][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 393 @ 15720 updates, score 3.975) (writing took 3.9196371203288436 seconds)
[2022-01-03 14:13:06,423][fairseq_cli.train][INFO] - end of epoch 393 (average epoch stats below)
[2022-01-03 14:13:06,436][train][INFO] - {"epoch": 393, "train_loss": "4.049", "train_ntokens": "1787", "train_nsentences": "4.95", "train_prob_perplexity": "41.09", "train_code_perplexity": "41.059", "train_temp": "1.849", "train_loss_0": "3.871", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.30409", "train_wps": "3919.7", "train_ups": "2.19", "train_wpb": "1787", "train_bsz": "5", "train_num_updates": "15720", "train_lr": "0.000245625", "train_gnorm": "0.726", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7404"}
[2022-01-03 14:13:06,523][fairseq.trainer][INFO] - begin training epoch 394
[2022-01-03 14:13:06,523][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:13:20,400][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:13:20,803][valid][INFO] - {"epoch": 394, "valid_loss": "4.055", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "41.745", "valid_code_perplexity": "41.724", "valid_temp": "1.848", "valid_loss_0": "3.878", "valid_loss_1": "0.135", "valid_loss_2": "0.042", "valid_accuracy": "0.29973", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "15760", "valid_best_loss": "3.706"}
[2022-01-03 14:13:20,805][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 394 @ 15760 updates
[2022-01-03 14:13:20,806][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:13:24,711][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:13:24,740][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 394 @ 15760 updates, score 4.055) (writing took 3.9345454052090645 seconds)
[2022-01-03 14:13:24,740][fairseq_cli.train][INFO] - end of epoch 394 (average epoch stats below)
[2022-01-03 14:13:24,755][train][INFO] - {"epoch": 394, "train_loss": "4.037", "train_ntokens": "1802.15", "train_nsentences": "4.95", "train_prob_perplexity": "41.287", "train_code_perplexity": "41.254", "train_temp": "1.849", "train_loss_0": "3.857", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.30258", "train_wps": "3938.2", "train_ups": "2.19", "train_wpb": "1802.2", "train_bsz": "5", "train_num_updates": "15760", "train_lr": "0.00024625", "train_gnorm": "0.76", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "7422"}
[2022-01-03 14:13:24,836][fairseq.trainer][INFO] - begin training epoch 395
[2022-01-03 14:13:24,837][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:13:38,791][train_inner][INFO] - {"epoch": 395, "update": 395.0, "loss": "4.035", "ntokens": "1788.65", "nsentences": "4.95", "prob_perplexity": "41.39", "code_perplexity": "41.365", "temp": "1.849", "loss_0": "3.856", "loss_1": "0.135", "loss_2": "0.044", "accuracy": "0.30494", "wps": "3906.8", "ups": "2.18", "wpb": "1788.7", "bsz": "5", "num_updates": "15800", "lr": "0.000246875", "gnorm": "0.728", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "7436"}
[2022-01-03 14:13:38,792][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:13:39,187][valid][INFO] - {"epoch": 395, "valid_loss": "4.136", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "40.775", "valid_code_perplexity": "40.606", "valid_temp": "1.848", "valid_loss_0": "3.962", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.29708", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "15800", "valid_best_loss": "3.706"}
[2022-01-03 14:13:39,190][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 395 @ 15800 updates
[2022-01-03 14:13:39,191][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:13:42,833][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:13:42,864][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 395 @ 15800 updates, score 4.136) (writing took 3.674387606792152 seconds)
[2022-01-03 14:13:42,865][fairseq_cli.train][INFO] - end of epoch 395 (average epoch stats below)
[2022-01-03 14:13:42,877][train][INFO] - {"epoch": 395, "train_loss": "4.031", "train_ntokens": "1786.65", "train_nsentences": "4.95", "train_prob_perplexity": "41.593", "train_code_perplexity": "41.565", "train_temp": "1.848", "train_loss_0": "3.853", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.30636", "train_wps": "3946.3", "train_ups": "2.21", "train_wpb": "1786.7", "train_bsz": "5", "train_num_updates": "15800", "train_lr": "0.000246875", "train_gnorm": "0.732", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7440"}
[2022-01-03 14:13:42,955][fairseq.trainer][INFO] - begin training epoch 396
[2022-01-03 14:13:42,955][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:13:56,838][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:13:57,245][valid][INFO] - {"epoch": 396, "valid_loss": "4.144", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "36.54", "valid_code_perplexity": "36.495", "valid_temp": "1.848", "valid_loss_0": "3.965", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.29867", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "15840", "valid_best_loss": "3.706"}
[2022-01-03 14:13:57,249][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 396 @ 15840 updates
[2022-01-03 14:13:57,250][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:14:01,070][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:14:01,098][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 396 @ 15840 updates, score 4.144) (writing took 3.848648295737803 seconds)
[2022-01-03 14:14:01,098][fairseq_cli.train][INFO] - end of epoch 396 (average epoch stats below)
[2022-01-03 14:14:01,111][train][INFO] - {"epoch": 396, "train_loss": "4.084", "train_ntokens": "1802.22", "train_nsentences": "4.95", "train_prob_perplexity": "40.986", "train_code_perplexity": "40.964", "train_temp": "1.848", "train_loss_0": "3.908", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.29992", "train_wps": "3956.3", "train_ups": "2.2", "train_wpb": "1802.2", "train_bsz": "5", "train_num_updates": "15840", "train_lr": "0.0002475", "train_gnorm": "0.724", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "7459"}
[2022-01-03 14:14:01,175][fairseq.trainer][INFO] - begin training epoch 397
[2022-01-03 14:14:01,176][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:14:15,101][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:14:15,503][valid][INFO] - {"epoch": 397, "valid_loss": "3.978", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "38.653", "valid_code_perplexity": "38.602", "valid_temp": "1.847", "valid_loss_0": "3.801", "valid_loss_1": "0.136", "valid_loss_2": "0.041", "valid_accuracy": "0.28684", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "15880", "valid_best_loss": "3.706"}
[2022-01-03 14:14:15,506][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 397 @ 15880 updates
[2022-01-03 14:14:15,506][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:14:19,318][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:14:19,346][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 397 @ 15880 updates, score 3.978) (writing took 3.839934932999313 seconds)
[2022-01-03 14:14:19,346][fairseq_cli.train][INFO] - end of epoch 397 (average epoch stats below)
[2022-01-03 14:14:19,359][train][INFO] - {"epoch": 397, "train_loss": "4.056", "train_ntokens": "1789.83", "train_nsentences": "4.95", "train_prob_perplexity": "41.425", "train_code_perplexity": "41.408", "train_temp": "1.848", "train_loss_0": "3.879", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.30064", "train_wps": "3926.1", "train_ups": "2.19", "train_wpb": "1789.8", "train_bsz": "5", "train_num_updates": "15880", "train_lr": "0.000248125", "train_gnorm": "0.715", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7477"}
[2022-01-03 14:14:19,439][fairseq.trainer][INFO] - begin training epoch 398
[2022-01-03 14:14:19,440][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:14:33,433][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:14:33,829][valid][INFO] - {"epoch": 398, "valid_loss": "3.957", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "39.249", "valid_code_perplexity": "39.302", "valid_temp": "1.847", "valid_loss_0": "3.778", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.3183", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "15920", "valid_best_loss": "3.706"}
[2022-01-03 14:14:33,832][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 398 @ 15920 updates
[2022-01-03 14:14:33,832][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:14:37,523][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:14:37,550][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 398 @ 15920 updates, score 3.957) (writing took 3.718223669566214 seconds)
[2022-01-03 14:14:37,551][fairseq_cli.train][INFO] - end of epoch 398 (average epoch stats below)
[2022-01-03 14:14:37,564][train][INFO] - {"epoch": 398, "train_loss": "4.087", "train_ntokens": "1788.62", "train_nsentences": "4.95", "train_prob_perplexity": "41.568", "train_code_perplexity": "41.551", "train_temp": "1.847", "train_loss_0": "3.908", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.29957", "train_wps": "3932.9", "train_ups": "2.2", "train_wpb": "1788.6", "train_bsz": "5", "train_num_updates": "15920", "train_lr": "0.00024875", "train_gnorm": "0.715", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "7495"}
[2022-01-03 14:14:37,617][fairseq.trainer][INFO] - begin training epoch 399
[2022-01-03 14:14:37,618][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:14:51,527][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:14:51,920][valid][INFO] - {"epoch": 399, "valid_loss": "4.266", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "39.918", "valid_code_perplexity": "39.806", "valid_temp": "1.847", "valid_loss_0": "4.092", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.25651", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "15960", "valid_best_loss": "3.706"}
[2022-01-03 14:14:51,923][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 399 @ 15960 updates
[2022-01-03 14:14:51,924][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:14:55,840][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:14:55,860][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 399 @ 15960 updates, score 4.266) (writing took 3.9365261560305953 seconds)
[2022-01-03 14:14:55,860][fairseq_cli.train][INFO] - end of epoch 399 (average epoch stats below)
[2022-01-03 14:14:55,873][train][INFO] - {"epoch": 399, "train_loss": "4.094", "train_ntokens": "1797.95", "train_nsentences": "4.95", "train_prob_perplexity": "41.733", "train_code_perplexity": "41.718", "train_temp": "1.847", "train_loss_0": "3.915", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.296", "train_wps": "3930.7", "train_ups": "2.19", "train_wpb": "1798", "train_bsz": "5", "train_num_updates": "15960", "train_lr": "0.000249375", "train_gnorm": "0.723", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "7513"}
[2022-01-03 14:14:55,917][fairseq.trainer][INFO] - begin training epoch 400
[2022-01-03 14:14:55,918][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:15:09,925][train_inner][INFO] - {"epoch": 400, "update": 400.0, "loss": "4.075", "ntokens": "1794.15", "nsentences": "4.95", "prob_perplexity": "41.407", "code_perplexity": "41.391", "temp": "1.847", "loss_0": "3.897", "loss_1": "0.135", "loss_2": "0.043", "accuracy": "0.29963", "wps": "3937.9", "ups": "2.19", "wpb": "1794.2", "bsz": "5", "num_updates": "16000", "lr": "0.00025", "gnorm": "0.72", "clip": "0", "train_wall": "68", "gb_free": "6.6", "wall": "7527"}
[2022-01-03 14:15:09,926][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:15:10,327][valid][INFO] - {"epoch": 400, "valid_loss": "3.793", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "38.981", "valid_code_perplexity": "38.93", "valid_temp": "1.846", "valid_loss_0": "3.613", "valid_loss_1": "0.135", "valid_loss_2": "0.044", "valid_accuracy": "0.32015", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "16000", "valid_best_loss": "3.706"}
[2022-01-03 14:15:10,330][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 400 @ 16000 updates
[2022-01-03 14:15:10,331][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:15:14,070][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:15:14,089][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 400 @ 16000 updates, score 3.793) (writing took 3.759149936027825 seconds)
[2022-01-03 14:15:14,090][fairseq_cli.train][INFO] - end of epoch 400 (average epoch stats below)
[2022-01-03 14:15:14,102][train][INFO] - {"epoch": 400, "train_loss": "4.054", "train_ntokens": "1792.12", "train_nsentences": "4.95", "train_prob_perplexity": "41.323", "train_code_perplexity": "41.313", "train_temp": "1.846", "train_loss_0": "3.876", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.30203", "train_wps": "3935", "train_ups": "2.2", "train_wpb": "1792.1", "train_bsz": "5", "train_num_updates": "16000", "train_lr": "0.00025", "train_gnorm": "0.721", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "7531"}
[2022-01-03 14:15:14,150][fairseq.trainer][INFO] - begin training epoch 401
[2022-01-03 14:15:14,151][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:15:28,088][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:15:28,486][valid][INFO] - {"epoch": 401, "valid_loss": "4.445", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "40.577", "valid_code_perplexity": "40.559", "valid_temp": "1.846", "valid_loss_0": "4.266", "valid_loss_1": "0.135", "valid_loss_2": "0.044", "valid_accuracy": "0.24017", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "16040", "valid_best_loss": "3.706"}
[2022-01-03 14:15:28,489][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 401 @ 16040 updates
[2022-01-03 14:15:28,490][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:15:32,419][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:15:32,439][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 401 @ 16040 updates, score 4.445) (writing took 3.949693715199828 seconds)
[2022-01-03 14:15:32,439][fairseq_cli.train][INFO] - end of epoch 401 (average epoch stats below)
[2022-01-03 14:15:32,452][train][INFO] - {"epoch": 401, "train_loss": "4.06", "train_ntokens": "1809.97", "train_nsentences": "4.95", "train_prob_perplexity": "41.786", "train_code_perplexity": "41.772", "train_temp": "1.846", "train_loss_0": "3.882", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.30009", "train_wps": "3948.1", "train_ups": "2.18", "train_wpb": "1810", "train_bsz": "5", "train_num_updates": "16040", "train_lr": "0.000250625", "train_gnorm": "0.722", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7550"}
[2022-01-03 14:15:32,511][fairseq.trainer][INFO] - begin training epoch 402
[2022-01-03 14:15:32,511][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:15:46,376][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:15:46,781][valid][INFO] - {"epoch": 402, "valid_loss": "4.181", "valid_ntokens": "800", "valid_nsentences": "2", "valid_prob_perplexity": "42.697", "valid_code_perplexity": "42.701", "valid_temp": "1.846", "valid_loss_0": "4.005", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.25375", "valid_wps": "0", "valid_wpb": "800", "valid_bsz": "2", "valid_num_updates": "16080", "valid_best_loss": "3.706"}
[2022-01-03 14:15:46,784][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 402 @ 16080 updates
[2022-01-03 14:15:46,784][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:15:50,669][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:15:50,698][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 402 @ 16080 updates, score 4.181) (writing took 3.914379413239658 seconds)
[2022-01-03 14:15:50,699][fairseq_cli.train][INFO] - end of epoch 402 (average epoch stats below)
[2022-01-03 14:15:50,712][train][INFO] - {"epoch": 402, "train_loss": "4.057", "train_ntokens": "1790.25", "train_nsentences": "4.95", "train_prob_perplexity": "41.706", "train_code_perplexity": "41.692", "train_temp": "1.846", "train_loss_0": "3.877", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.30205", "train_wps": "3924.5", "train_ups": "2.19", "train_wpb": "1790.2", "train_bsz": "5", "train_num_updates": "16080", "train_lr": "0.00025125", "train_gnorm": "0.78", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "7568"}
[2022-01-03 14:15:50,794][fairseq.trainer][INFO] - begin training epoch 403
[2022-01-03 14:15:50,794][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:16:04,800][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:16:05,198][valid][INFO] - {"epoch": 403, "valid_loss": "4.162", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "37.502", "valid_code_perplexity": "37.472", "valid_temp": "1.845", "valid_loss_0": "3.98", "valid_loss_1": "0.136", "valid_loss_2": "0.046", "valid_accuracy": "0.31129", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "16120", "valid_best_loss": "3.706"}
[2022-01-03 14:16:05,202][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 403 @ 16120 updates
[2022-01-03 14:16:05,203][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:16:08,864][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:16:08,891][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 403 @ 16120 updates, score 4.162) (writing took 3.689168341457844 seconds)
[2022-01-03 14:16:08,892][fairseq_cli.train][INFO] - end of epoch 403 (average epoch stats below)
[2022-01-03 14:16:08,904][train][INFO] - {"epoch": 403, "train_loss": "4.045", "train_ntokens": "1790.22", "train_nsentences": "4.95", "train_prob_perplexity": "41.769", "train_code_perplexity": "41.747", "train_temp": "1.845", "train_loss_0": "3.871", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.30285", "train_wps": "3938.9", "train_ups": "2.2", "train_wpb": "1790.2", "train_bsz": "5", "train_num_updates": "16120", "train_lr": "0.000251875", "train_gnorm": "0.712", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.8", "train_wall": "7586"}
[2022-01-03 14:16:08,974][fairseq.trainer][INFO] - begin training epoch 404
[2022-01-03 14:16:08,975][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:16:22,936][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:16:23,402][valid][INFO] - {"epoch": 404, "valid_loss": "4.055", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "40.537", "valid_code_perplexity": "40.494", "valid_temp": "1.845", "valid_loss_0": "3.881", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.27632", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "16160", "valid_best_loss": "3.706"}
[2022-01-03 14:16:23,404][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 404 @ 16160 updates
[2022-01-03 14:16:23,404][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:16:27,069][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:16:27,091][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 404 @ 16160 updates, score 4.055) (writing took 3.687151382677257 seconds)
[2022-01-03 14:16:27,091][fairseq_cli.train][INFO] - end of epoch 404 (average epoch stats below)
[2022-01-03 14:16:27,104][train][INFO] - {"epoch": 404, "train_loss": "4.081", "train_ntokens": "1792.53", "train_nsentences": "4.95", "train_prob_perplexity": "41.946", "train_code_perplexity": "41.921", "train_temp": "1.845", "train_loss_0": "3.902", "train_loss_1": "0.135", "train_loss_2": "0.045", "train_accuracy": "0.29669", "train_wps": "3942.4", "train_ups": "2.2", "train_wpb": "1792.5", "train_bsz": "5", "train_num_updates": "16160", "train_lr": "0.0002525", "train_gnorm": "0.709", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7605"}
[2022-01-03 14:16:27,149][fairseq.trainer][INFO] - begin training epoch 405
[2022-01-03 14:16:27,150][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:16:40,955][train_inner][INFO] - {"epoch": 405, "update": 405.0, "loss": "4.062", "ntokens": "1795.34", "nsentences": "4.95", "prob_perplexity": "41.793", "code_perplexity": "41.774", "temp": "1.845", "loss_0": "3.884", "loss_1": "0.135", "loss_2": "0.043", "accuracy": "0.30046", "wps": "3945", "ups": "2.2", "wpb": "1795.3", "bsz": "5", "num_updates": "16200", "lr": "0.000253125", "gnorm": "0.726", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "7618"}
[2022-01-03 14:16:40,956][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:16:41,373][valid][INFO] - {"epoch": 405, "valid_loss": "4.133", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "34.885", "valid_code_perplexity": "34.813", "valid_temp": "1.844", "valid_loss_0": "3.951", "valid_loss_1": "0.136", "valid_loss_2": "0.045", "valid_accuracy": "0.32391", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "16200", "valid_best_loss": "3.706"}
[2022-01-03 14:16:41,376][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 405 @ 16200 updates
[2022-01-03 14:16:41,377][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:16:45,272][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:16:45,298][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 405 @ 16200 updates, score 4.133) (writing took 3.9215092482045293 seconds)
[2022-01-03 14:16:45,298][fairseq_cli.train][INFO] - end of epoch 405 (average epoch stats below)
[2022-01-03 14:16:45,311][train][INFO] - {"epoch": 405, "train_loss": "4.067", "train_ntokens": "1793.7", "train_nsentences": "4.95", "train_prob_perplexity": "41.757", "train_code_perplexity": "41.737", "train_temp": "1.845", "train_loss_0": "3.89", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.30062", "train_wps": "3943.4", "train_ups": "2.2", "train_wpb": "1793.7", "train_bsz": "5", "train_num_updates": "16200", "train_lr": "0.000253125", "train_gnorm": "0.708", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "7623"}
[2022-01-03 14:16:45,367][fairseq.trainer][INFO] - begin training epoch 406
[2022-01-03 14:16:45,368][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:16:59,283][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:16:59,677][valid][INFO] - {"epoch": 406, "valid_loss": "4.064", "valid_ntokens": "700", "valid_nsentences": "2", "valid_prob_perplexity": "39.989", "valid_code_perplexity": "39.851", "valid_temp": "1.844", "valid_loss_0": "3.886", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.31571", "valid_wps": "0", "valid_wpb": "700", "valid_bsz": "2", "valid_num_updates": "16240", "valid_best_loss": "3.706"}
[2022-01-03 14:16:59,680][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 406 @ 16240 updates
[2022-01-03 14:16:59,681][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:17:03,599][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:17:03,628][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 406 @ 16240 updates, score 4.064) (writing took 3.9476298922672868 seconds)
[2022-01-03 14:17:03,628][fairseq_cli.train][INFO] - end of epoch 406 (average epoch stats below)
[2022-01-03 14:17:03,640][train][INFO] - {"epoch": 406, "train_loss": "4.042", "train_ntokens": "1792.95", "train_nsentences": "4.95", "train_prob_perplexity": "42.153", "train_code_perplexity": "42.137", "train_temp": "1.844", "train_loss_0": "3.866", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.30234", "train_wps": "3915.2", "train_ups": "2.18", "train_wpb": "1793", "train_bsz": "5", "train_num_updates": "16240", "train_lr": "0.00025375", "train_gnorm": "0.721", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7641"}
[2022-01-03 14:17:03,685][fairseq.trainer][INFO] - begin training epoch 407
[2022-01-03 14:17:03,685][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:17:17,639][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:17:18,044][valid][INFO] - {"epoch": 407, "valid_loss": "4.097", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "41.806", "valid_code_perplexity": "41.78", "valid_temp": "1.844", "valid_loss_0": "3.92", "valid_loss_1": "0.135", "valid_loss_2": "0.042", "valid_accuracy": "0.28451", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "16280", "valid_best_loss": "3.706"}
[2022-01-03 14:17:18,047][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 407 @ 16280 updates
[2022-01-03 14:17:18,048][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:17:21,749][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:17:21,777][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 407 @ 16280 updates, score 4.097) (writing took 3.7302040373906493 seconds)
[2022-01-03 14:17:21,778][fairseq_cli.train][INFO] - end of epoch 407 (average epoch stats below)
[2022-01-03 14:17:21,790][train][INFO] - {"epoch": 407, "train_loss": "4.026", "train_ntokens": "1798.3", "train_nsentences": "4.95", "train_prob_perplexity": "41.915", "train_code_perplexity": "41.894", "train_temp": "1.844", "train_loss_0": "3.85", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.30459", "train_wps": "3966", "train_ups": "2.21", "train_wpb": "1798.3", "train_bsz": "5", "train_num_updates": "16280", "train_lr": "0.000254375", "train_gnorm": "0.723", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7659"}
[2022-01-03 14:17:21,846][fairseq.trainer][INFO] - begin training epoch 408
[2022-01-03 14:17:21,846][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:17:35,773][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:17:36,173][valid][INFO] - {"epoch": 408, "valid_loss": "3.779", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "39.127", "valid_code_perplexity": "39.113", "valid_temp": "1.843", "valid_loss_0": "3.604", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.3445", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "16320", "valid_best_loss": "3.706"}
[2022-01-03 14:17:36,176][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 408 @ 16320 updates
[2022-01-03 14:17:36,177][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:17:40,015][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:17:40,043][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 408 @ 16320 updates, score 3.779) (writing took 3.866949704475701 seconds)
[2022-01-03 14:17:40,044][fairseq_cli.train][INFO] - end of epoch 408 (average epoch stats below)
[2022-01-03 14:17:40,056][train][INFO] - {"epoch": 408, "train_loss": "4.045", "train_ntokens": "1800.62", "train_nsentences": "4.95", "train_prob_perplexity": "41.595", "train_code_perplexity": "41.574", "train_temp": "1.843", "train_loss_0": "3.87", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.30416", "train_wps": "3945.8", "train_ups": "2.19", "train_wpb": "1800.6", "train_bsz": "5", "train_num_updates": "16320", "train_lr": "0.000255", "train_gnorm": "0.691", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7677"}
[2022-01-03 14:17:40,133][fairseq.trainer][INFO] - begin training epoch 409
[2022-01-03 14:17:40,133][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:17:54,145][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:17:54,570][valid][INFO] - {"epoch": 409, "valid_loss": "4.118", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "41.334", "valid_code_perplexity": "41.298", "valid_temp": "1.843", "valid_loss_0": "3.94", "valid_loss_1": "0.135", "valid_loss_2": "0.042", "valid_accuracy": "0.29178", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "16360", "valid_best_loss": "3.706"}
[2022-01-03 14:17:54,573][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 409 @ 16360 updates
[2022-01-03 14:17:54,574][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:17:58,308][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:17:58,335][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 409 @ 16360 updates, score 4.118) (writing took 3.762159368954599 seconds)
[2022-01-03 14:17:58,336][fairseq_cli.train][INFO] - end of epoch 409 (average epoch stats below)
[2022-01-03 14:17:58,349][train][INFO] - {"epoch": 409, "train_loss": "4.058", "train_ntokens": "1793.55", "train_nsentences": "4.95", "train_prob_perplexity": "41.692", "train_code_perplexity": "41.675", "train_temp": "1.843", "train_loss_0": "3.882", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.29946", "train_wps": "3924.7", "train_ups": "2.19", "train_wpb": "1793.5", "train_bsz": "5", "train_num_updates": "16360", "train_lr": "0.000255625", "train_gnorm": "0.731", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "7696"}
[2022-01-03 14:17:58,423][fairseq.trainer][INFO] - begin training epoch 410
[2022-01-03 14:17:58,424][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:18:12,488][train_inner][INFO] - {"epoch": 410, "update": 410.0, "loss": "4.042", "ntokens": "1795.38", "nsentences": "4.95", "prob_perplexity": "41.798", "code_perplexity": "41.78", "temp": "1.843", "loss_0": "3.865", "loss_1": "0.135", "loss_2": "0.042", "accuracy": "0.3027", "wps": "3923.5", "ups": "2.19", "wpb": "1795.4", "bsz": "5", "num_updates": "16400", "lr": "0.00025625", "gnorm": "0.716", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "7710"}
[2022-01-03 14:18:12,488][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:18:12,891][valid][INFO] - {"epoch": 410, "valid_loss": "4.173", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "39.693", "valid_code_perplexity": "39.781", "valid_temp": "1.843", "valid_loss_0": "3.997", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.27168", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "16400", "valid_best_loss": "3.706"}
[2022-01-03 14:18:12,894][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 410 @ 16400 updates
[2022-01-03 14:18:12,895][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:18:16,812][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:18:16,841][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 410 @ 16400 updates, score 4.173) (writing took 3.9463266879320145 seconds)
[2022-01-03 14:18:16,841][fairseq_cli.train][INFO] - end of epoch 410 (average epoch stats below)
[2022-01-03 14:18:16,854][train][INFO] - {"epoch": 410, "train_loss": "4.038", "train_ntokens": "1791.47", "train_nsentences": "4.95", "train_prob_perplexity": "41.633", "train_code_perplexity": "41.619", "train_temp": "1.843", "train_loss_0": "3.859", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.30292", "train_wps": "3875", "train_ups": "2.16", "train_wpb": "1791.5", "train_bsz": "5", "train_num_updates": "16400", "train_lr": "0.00025625", "train_gnorm": "0.713", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7714"}
[2022-01-03 14:18:16,932][fairseq.trainer][INFO] - begin training epoch 411
[2022-01-03 14:18:16,933][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:18:30,896][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:18:31,305][valid][INFO] - {"epoch": 411, "valid_loss": "4.175", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "37.785", "valid_code_perplexity": "37.66", "valid_temp": "1.842", "valid_loss_0": "3.998", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.29328", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "16440", "valid_best_loss": "3.706"}
[2022-01-03 14:18:31,308][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 411 @ 16440 updates
[2022-01-03 14:18:31,309][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:18:35,015][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:18:35,043][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 411 @ 16440 updates, score 4.175) (writing took 3.7347799381241202 seconds)
[2022-01-03 14:18:35,044][fairseq_cli.train][INFO] - end of epoch 411 (average epoch stats below)
[2022-01-03 14:18:35,056][train][INFO] - {"epoch": 411, "train_loss": "4.061", "train_ntokens": "1783.65", "train_nsentences": "4.95", "train_prob_perplexity": "41.497", "train_code_perplexity": "41.471", "train_temp": "1.842", "train_loss_0": "3.882", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.30157", "train_wps": "3922.2", "train_ups": "2.2", "train_wpb": "1783.7", "train_bsz": "5", "train_num_updates": "16440", "train_lr": "0.000256875", "train_gnorm": "0.7", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7732"}
[2022-01-03 14:18:35,110][fairseq.trainer][INFO] - begin training epoch 412
[2022-01-03 14:18:35,110][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:18:49,140][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:18:49,532][valid][INFO] - {"epoch": 412, "valid_loss": "3.959", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "40.364", "valid_code_perplexity": "40.36", "valid_temp": "1.842", "valid_loss_0": "3.786", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.30822", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "16480", "valid_best_loss": "3.706"}
[2022-01-03 14:18:49,535][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 412 @ 16480 updates
[2022-01-03 14:18:49,536][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:18:53,252][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:18:53,281][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 412 @ 16480 updates, score 3.959) (writing took 3.746233446523547 seconds)
[2022-01-03 14:18:53,281][fairseq_cli.train][INFO] - end of epoch 412 (average epoch stats below)
[2022-01-03 14:18:53,295][train][INFO] - {"epoch": 412, "train_loss": "4.038", "train_ntokens": "1784.5", "train_nsentences": "4.95", "train_prob_perplexity": "41.525", "train_code_perplexity": "41.507", "train_temp": "1.842", "train_loss_0": "3.861", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.30461", "train_wps": "3916.6", "train_ups": "2.19", "train_wpb": "1784.5", "train_bsz": "5", "train_num_updates": "16480", "train_lr": "0.0002575", "train_gnorm": "0.681", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "7751"}
[2022-01-03 14:18:53,374][fairseq.trainer][INFO] - begin training epoch 413
[2022-01-03 14:18:53,375][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:19:07,290][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:19:07,708][valid][INFO] - {"epoch": 413, "valid_loss": "4.379", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "40.975", "valid_code_perplexity": "40.894", "valid_temp": "1.841", "valid_loss_0": "4.204", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.2395", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "16520", "valid_best_loss": "3.706"}
[2022-01-03 14:19:07,715][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 413 @ 16520 updates
[2022-01-03 14:19:07,716][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:19:11,508][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:19:11,537][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 413 @ 16520 updates, score 4.379) (writing took 3.822549800388515 seconds)
[2022-01-03 14:19:11,538][fairseq_cli.train][INFO] - end of epoch 413 (average epoch stats below)
[2022-01-03 14:19:11,550][train][INFO] - {"epoch": 413, "train_loss": "4.066", "train_ntokens": "1788.08", "train_nsentences": "4.95", "train_prob_perplexity": "41.695", "train_code_perplexity": "41.671", "train_temp": "1.842", "train_loss_0": "3.889", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.30211", "train_wps": "3920.6", "train_ups": "2.19", "train_wpb": "1788.1", "train_bsz": "5", "train_num_updates": "16520", "train_lr": "0.000258125", "train_gnorm": "0.701", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7769"}
[2022-01-03 14:19:11,626][fairseq.trainer][INFO] - begin training epoch 414
[2022-01-03 14:19:11,627][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:19:25,642][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:19:26,043][valid][INFO] - {"epoch": 414, "valid_loss": "3.72", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "40.384", "valid_code_perplexity": "40.389", "valid_temp": "1.841", "valid_loss_0": "3.545", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.33152", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "16560", "valid_best_loss": "3.706"}
[2022-01-03 14:19:26,046][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 414 @ 16560 updates
[2022-01-03 14:19:26,047][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:19:29,742][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:19:29,770][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 414 @ 16560 updates, score 3.72) (writing took 3.7238367162644863 seconds)
[2022-01-03 14:19:29,770][fairseq_cli.train][INFO] - end of epoch 414 (average epoch stats below)
[2022-01-03 14:19:29,783][train][INFO] - {"epoch": 414, "train_loss": "4.022", "train_ntokens": "1786.05", "train_nsentences": "4.95", "train_prob_perplexity": "41.658", "train_code_perplexity": "41.636", "train_temp": "1.841", "train_loss_0": "3.846", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.306", "train_wps": "3921", "train_ups": "2.2", "train_wpb": "1786", "train_bsz": "5", "train_num_updates": "16560", "train_lr": "0.00025875", "train_gnorm": "0.677", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "7787"}
[2022-01-03 14:19:29,856][fairseq.trainer][INFO] - begin training epoch 415
[2022-01-03 14:19:29,857][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:19:43,711][train_inner][INFO] - {"epoch": 415, "update": 415.0, "loss": "4.049", "ntokens": "1786.53", "nsentences": "4.95", "prob_perplexity": "41.624", "code_perplexity": "41.603", "temp": "1.842", "loss_0": "3.872", "loss_1": "0.135", "loss_2": "0.042", "accuracy": "0.30283", "wps": "3917.3", "ups": "2.19", "wpb": "1786.5", "bsz": "5", "num_updates": "16600", "lr": "0.000259375", "gnorm": "0.688", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "7801"}
[2022-01-03 14:19:43,712][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:19:44,119][valid][INFO] - {"epoch": 415, "valid_loss": "4.176", "valid_ntokens": "680", "valid_nsentences": "2", "valid_prob_perplexity": "42.049", "valid_code_perplexity": "42.057", "valid_temp": "1.841", "valid_loss_0": "3.998", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.29412", "valid_wps": "0", "valid_wpb": "680", "valid_bsz": "2", "valid_num_updates": "16600", "valid_best_loss": "3.706"}
[2022-01-03 14:19:44,122][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 415 @ 16600 updates
[2022-01-03 14:19:44,123][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:19:48,089][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:19:48,109][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 415 @ 16600 updates, score 4.176) (writing took 3.987259435467422 seconds)
[2022-01-03 14:19:48,110][fairseq_cli.train][INFO] - end of epoch 415 (average epoch stats below)
[2022-01-03 14:19:48,122][train][INFO] - {"epoch": 415, "train_loss": "4.058", "train_ntokens": "1790.35", "train_nsentences": "4.95", "train_prob_perplexity": "41.745", "train_code_perplexity": "41.731", "train_temp": "1.841", "train_loss_0": "3.881", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.29989", "train_wps": "3907.6", "train_ups": "2.18", "train_wpb": "1790.3", "train_bsz": "5", "train_num_updates": "16600", "train_lr": "0.000259375", "train_gnorm": "0.682", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7806"}
[2022-01-03 14:19:48,194][fairseq.trainer][INFO] - begin training epoch 416
[2022-01-03 14:19:48,195][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:20:02,159][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:20:02,562][valid][INFO] - {"epoch": 416, "valid_loss": "4.352", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "40.654", "valid_code_perplexity": "40.615", "valid_temp": "1.84", "valid_loss_0": "4.178", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.27657", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "16640", "valid_best_loss": "3.706"}
[2022-01-03 14:20:02,565][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 416 @ 16640 updates
[2022-01-03 14:20:02,566][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:20:06,332][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:20:06,360][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 416 @ 16640 updates, score 4.352) (writing took 3.794316497631371 seconds)
[2022-01-03 14:20:06,360][fairseq_cli.train][INFO] - end of epoch 416 (average epoch stats below)
[2022-01-03 14:20:06,373][train][INFO] - {"epoch": 416, "train_loss": "4.034", "train_ntokens": "1796.95", "train_nsentences": "4.95", "train_prob_perplexity": "42.195", "train_code_perplexity": "42.185", "train_temp": "1.841", "train_loss_0": "3.859", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.30191", "train_wps": "3941.2", "train_ups": "2.19", "train_wpb": "1797", "train_bsz": "5", "train_num_updates": "16640", "train_lr": "0.00026", "train_gnorm": "0.741", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "7824"}
[2022-01-03 14:20:06,426][fairseq.trainer][INFO] - begin training epoch 417
[2022-01-03 14:20:06,427][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:20:20,384][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:20:20,780][valid][INFO] - {"epoch": 417, "valid_loss": "4.332", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "42.307", "valid_code_perplexity": "42.25", "valid_temp": "1.84", "valid_loss_0": "4.154", "valid_loss_1": "0.135", "valid_loss_2": "0.043", "valid_accuracy": "0.26225", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "16680", "valid_best_loss": "3.706"}
[2022-01-03 14:20:20,783][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 417 @ 16680 updates
[2022-01-03 14:20:20,784][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:20:24,752][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:20:24,781][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 417 @ 16680 updates, score 4.332) (writing took 3.997793878428638 seconds)
[2022-01-03 14:20:24,781][fairseq_cli.train][INFO] - end of epoch 417 (average epoch stats below)
[2022-01-03 14:20:24,794][train][INFO] - {"epoch": 417, "train_loss": "4.075", "train_ntokens": "1787.53", "train_nsentences": "4.95", "train_prob_perplexity": "41.713", "train_code_perplexity": "41.701", "train_temp": "1.84", "train_loss_0": "3.896", "train_loss_1": "0.135", "train_loss_2": "0.044", "train_accuracy": "0.30018", "train_wps": "3884.2", "train_ups": "2.17", "train_wpb": "1787.5", "train_bsz": "5", "train_num_updates": "16680", "train_lr": "0.000260625", "train_gnorm": "0.692", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "7842"}
[2022-01-03 14:20:24,875][fairseq.trainer][INFO] - begin training epoch 418
[2022-01-03 14:20:24,876][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:20:38,739][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:20:39,146][valid][INFO] - {"epoch": 418, "valid_loss": "3.99", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "40.94", "valid_code_perplexity": "40.813", "valid_temp": "1.84", "valid_loss_0": "3.815", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.30226", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "16720", "valid_best_loss": "3.706"}
[2022-01-03 14:20:39,148][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 418 @ 16720 updates
[2022-01-03 14:20:39,149][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:20:42,809][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:20:42,828][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 418 @ 16720 updates, score 3.99) (writing took 3.6799067109823227 seconds)
[2022-01-03 14:20:42,828][fairseq_cli.train][INFO] - end of epoch 418 (average epoch stats below)
[2022-01-03 14:20:42,841][train][INFO] - {"epoch": 418, "train_loss": "4.026", "train_ntokens": "1777.3", "train_nsentences": "4.95", "train_prob_perplexity": "42.224", "train_code_perplexity": "42.201", "train_temp": "1.84", "train_loss_0": "3.85", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.30347", "train_wps": "3942", "train_ups": "2.22", "train_wpb": "1777.3", "train_bsz": "5", "train_num_updates": "16720", "train_lr": "0.00026125", "train_gnorm": "0.742", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7860"}
[2022-01-03 14:20:42,886][fairseq.trainer][INFO] - begin training epoch 419
[2022-01-03 14:20:42,886][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:20:56,903][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:20:57,331][valid][INFO] - {"epoch": 419, "valid_loss": "4.155", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "41.273", "valid_code_perplexity": "41.226", "valid_temp": "1.839", "valid_loss_0": "3.978", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.27204", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "16760", "valid_best_loss": "3.706"}
[2022-01-03 14:20:57,334][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 419 @ 16760 updates
[2022-01-03 14:20:57,335][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:21:01,061][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:21:01,091][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 419 @ 16760 updates, score 4.155) (writing took 3.757149183191359 seconds)
[2022-01-03 14:21:01,092][fairseq_cli.train][INFO] - end of epoch 419 (average epoch stats below)
[2022-01-03 14:21:01,105][train][INFO] - {"epoch": 419, "train_loss": "4.046", "train_ntokens": "1785.25", "train_nsentences": "4.95", "train_prob_perplexity": "42.175", "train_code_perplexity": "42.156", "train_temp": "1.839", "train_loss_0": "3.871", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.29996", "train_wps": "3912.7", "train_ups": "2.19", "train_wpb": "1785.2", "train_bsz": "5", "train_num_updates": "16760", "train_lr": "0.000261875", "train_gnorm": "0.714", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "7879"}
[2022-01-03 14:21:01,182][fairseq.trainer][INFO] - begin training epoch 420
[2022-01-03 14:21:01,183][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:21:15,151][train_inner][INFO] - {"epoch": 420, "update": 420.0, "loss": "4.052", "ntokens": "1787.42", "nsentences": "4.95", "prob_perplexity": "42.102", "code_perplexity": "42.086", "temp": "1.84", "loss_0": "3.876", "loss_1": "0.135", "loss_2": "0.041", "accuracy": "0.30047", "wps": "3910.1", "ups": "2.19", "wpb": "1787.4", "bsz": "5", "num_updates": "16800", "lr": "0.0002625", "gnorm": "0.715", "clip": "0", "train_wall": "68", "gb_free": "5.4", "wall": "7893"}
[2022-01-03 14:21:15,152][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:21:15,644][valid][INFO] - {"epoch": 420, "valid_loss": "3.977", "valid_ntokens": "676", "valid_nsentences": "2", "valid_prob_perplexity": "41.409", "valid_code_perplexity": "41.4", "valid_temp": "1.839", "valid_loss_0": "3.802", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.30473", "valid_wps": "0", "valid_wpb": "676", "valid_bsz": "2", "valid_num_updates": "16800", "valid_best_loss": "3.706"}
[2022-01-03 14:21:15,648][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 420 @ 16800 updates
[2022-01-03 14:21:15,649][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:21:19,332][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:21:19,351][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 420 @ 16800 updates, score 3.977) (writing took 3.70309725869447 seconds)
[2022-01-03 14:21:19,351][fairseq_cli.train][INFO] - end of epoch 420 (average epoch stats below)
[2022-01-03 14:21:19,365][train][INFO] - {"epoch": 420, "train_loss": "4.078", "train_ntokens": "1790.08", "train_nsentences": "4.95", "train_prob_perplexity": "42.204", "train_code_perplexity": "42.188", "train_temp": "1.839", "train_loss_0": "3.903", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.29687", "train_wps": "3924.1", "train_ups": "2.19", "train_wpb": "1790.1", "train_bsz": "5", "train_num_updates": "16800", "train_lr": "0.0002625", "train_gnorm": "0.688", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "7897"}
[2022-01-03 14:21:19,438][fairseq.trainer][INFO] - begin training epoch 421
[2022-01-03 14:21:19,438][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:21:33,353][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:21:33,767][valid][INFO] - {"epoch": 421, "valid_loss": "4.223", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "41.658", "valid_code_perplexity": "41.624", "valid_temp": "1.839", "valid_loss_0": "4.048", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.26913", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "16840", "valid_best_loss": "3.706"}
[2022-01-03 14:21:33,769][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 421 @ 16840 updates
[2022-01-03 14:21:33,770][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:21:37,562][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:21:37,592][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 421 @ 16840 updates, score 4.223) (writing took 3.8229235503822565 seconds)
[2022-01-03 14:21:37,593][fairseq_cli.train][INFO] - end of epoch 421 (average epoch stats below)
[2022-01-03 14:21:37,605][train][INFO] - {"epoch": 421, "train_loss": "4.034", "train_ntokens": "1788.97", "train_nsentences": "4.95", "train_prob_perplexity": "42.012", "train_code_perplexity": "41.992", "train_temp": "1.839", "train_loss_0": "3.858", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.3032", "train_wps": "3925.9", "train_ups": "2.19", "train_wpb": "1789", "train_bsz": "5", "train_num_updates": "16840", "train_lr": "0.000263125", "train_gnorm": "0.755", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7915"}
[2022-01-03 14:21:37,683][fairseq.trainer][INFO] - begin training epoch 422
[2022-01-03 14:21:37,684][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:21:51,589][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:21:52,069][valid][INFO] - {"epoch": 422, "valid_loss": "4.196", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "41.535", "valid_code_perplexity": "41.414", "valid_temp": "1.838", "valid_loss_0": "4.022", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.29972", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "16880", "valid_best_loss": "3.706"}
[2022-01-03 14:21:52,071][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 422 @ 16880 updates
[2022-01-03 14:21:52,071][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:21:55,798][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:21:55,825][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 422 @ 16880 updates, score 4.196) (writing took 3.7545015746727586 seconds)
[2022-01-03 14:21:55,826][fairseq_cli.train][INFO] - end of epoch 422 (average epoch stats below)
[2022-01-03 14:21:55,838][train][INFO] - {"epoch": 422, "train_loss": "4.017", "train_ntokens": "1789.33", "train_nsentences": "4.95", "train_prob_perplexity": "42.531", "train_code_perplexity": "42.496", "train_temp": "1.838", "train_loss_0": "3.841", "train_loss_1": "0.135", "train_loss_2": "0.042", "train_accuracy": "0.30418", "train_wps": "3928.1", "train_ups": "2.2", "train_wpb": "1789.3", "train_bsz": "5", "train_num_updates": "16880", "train_lr": "0.00026375", "train_gnorm": "0.694", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7933"}
[2022-01-03 14:21:55,917][fairseq.trainer][INFO] - begin training epoch 423
[2022-01-03 14:21:55,918][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:22:09,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:22:10,167][valid][INFO] - {"epoch": 423, "valid_loss": "4.115", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "42.704", "valid_code_perplexity": "42.714", "valid_temp": "1.838", "valid_loss_0": "3.942", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.29315", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "16920", "valid_best_loss": "3.706"}
[2022-01-03 14:22:10,168][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 423 @ 16920 updates
[2022-01-03 14:22:10,169][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:22:14,100][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:22:14,128][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 423 @ 16920 updates, score 4.115) (writing took 3.959569212049246 seconds)
[2022-01-03 14:22:14,129][fairseq_cli.train][INFO] - end of epoch 423 (average epoch stats below)
[2022-01-03 14:22:14,141][train][INFO] - {"epoch": 423, "train_loss": "4.042", "train_ntokens": "1786.03", "train_nsentences": "4.95", "train_prob_perplexity": "42.376", "train_code_perplexity": "42.36", "train_temp": "1.838", "train_loss_0": "3.868", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.30305", "train_wps": "3906", "train_ups": "2.19", "train_wpb": "1786", "train_bsz": "5", "train_num_updates": "16920", "train_lr": "0.000264375", "train_gnorm": "0.686", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "7952"}
[2022-01-03 14:22:14,181][fairseq.trainer][INFO] - begin training epoch 424
[2022-01-03 14:22:14,182][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:22:27,965][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:22:28,461][valid][INFO] - {"epoch": 424, "valid_loss": "3.995", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "40.982", "valid_code_perplexity": "41.029", "valid_temp": "1.837", "valid_loss_0": "3.82", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.30295", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "16960", "valid_best_loss": "3.706"}
[2022-01-03 14:22:28,463][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 424 @ 16960 updates
[2022-01-03 14:22:28,464][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:22:32,364][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:22:32,393][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 424 @ 16960 updates, score 3.995) (writing took 3.9301328593865037 seconds)
[2022-01-03 14:22:32,394][fairseq_cli.train][INFO] - end of epoch 424 (average epoch stats below)
[2022-01-03 14:22:32,406][train][INFO] - {"epoch": 424, "train_loss": "4.014", "train_ntokens": "1792.83", "train_nsentences": "4.95", "train_prob_perplexity": "42.818", "train_code_perplexity": "42.805", "train_temp": "1.838", "train_loss_0": "3.837", "train_loss_1": "0.135", "train_loss_2": "0.043", "train_accuracy": "0.30545", "train_wps": "3928.9", "train_ups": "2.19", "train_wpb": "1792.8", "train_bsz": "5", "train_num_updates": "16960", "train_lr": "0.000265", "train_gnorm": "0.676", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7970"}
[2022-01-03 14:22:32,461][fairseq.trainer][INFO] - begin training epoch 425
[2022-01-03 14:22:32,462][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:22:46,392][train_inner][INFO] - {"epoch": 425, "update": 425.0, "loss": "4.02", "ntokens": "1792.15", "nsentences": "4.95", "prob_perplexity": "42.388", "code_perplexity": "42.368", "temp": "1.838", "loss_0": "3.844", "loss_1": "0.135", "loss_2": "0.041", "accuracy": "0.30474", "wps": "3929", "ups": "2.19", "wpb": "1792.2", "bsz": "5", "num_updates": "17000", "lr": "0.000265625", "gnorm": "0.709", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "7984"}
[2022-01-03 14:22:46,393][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:22:46,790][valid][INFO] - {"epoch": 425, "valid_loss": "4.144", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "40.462", "valid_code_perplexity": "40.436", "valid_temp": "1.837", "valid_loss_0": "3.973", "valid_loss_1": "0.135", "valid_loss_2": "0.036", "valid_accuracy": "0.27423", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "17000", "valid_best_loss": "3.706"}
[2022-01-03 14:22:46,793][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 425 @ 17000 updates
[2022-01-03 14:22:46,794][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:22:50,531][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:22:50,550][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 425 @ 17000 updates, score 4.144) (writing took 3.757237263955176 seconds)
[2022-01-03 14:22:50,551][fairseq_cli.train][INFO] - end of epoch 425 (average epoch stats below)
[2022-01-03 14:22:50,563][train][INFO] - {"epoch": 425, "train_loss": "3.993", "train_ntokens": "1803.62", "train_nsentences": "4.95", "train_prob_perplexity": "42.204", "train_code_perplexity": "42.186", "train_temp": "1.837", "train_loss_0": "3.819", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.30778", "train_wps": "3976.2", "train_ups": "2.2", "train_wpb": "1803.6", "train_bsz": "5", "train_num_updates": "17000", "train_lr": "0.000265625", "train_gnorm": "0.733", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "7988"}
[2022-01-03 14:22:50,604][fairseq.trainer][INFO] - begin training epoch 426
[2022-01-03 14:22:50,605][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:23:04,548][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:23:04,948][valid][INFO] - {"epoch": 426, "valid_loss": "4.007", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "41.157", "valid_code_perplexity": "41.259", "valid_temp": "1.837", "valid_loss_0": "3.832", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.29726", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "17040", "valid_best_loss": "3.706"}
[2022-01-03 14:23:04,951][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 426 @ 17040 updates
[2022-01-03 14:23:04,951][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:23:08,871][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:23:08,890][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 426 @ 17040 updates, score 4.007) (writing took 3.939541478641331 seconds)
[2022-01-03 14:23:08,891][fairseq_cli.train][INFO] - end of epoch 426 (average epoch stats below)
[2022-01-03 14:23:08,903][train][INFO] - {"epoch": 426, "train_loss": "4.048", "train_ntokens": "1785.92", "train_nsentences": "4.95", "train_prob_perplexity": "42.482", "train_code_perplexity": "42.457", "train_temp": "1.837", "train_loss_0": "3.873", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.29968", "train_wps": "3897.9", "train_ups": "2.18", "train_wpb": "1785.9", "train_bsz": "5", "train_num_updates": "17040", "train_lr": "0.00026625", "train_gnorm": "0.699", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "8006"}
[2022-01-03 14:23:08,944][fairseq.trainer][INFO] - begin training epoch 427
[2022-01-03 14:23:08,945][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:23:22,728][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:23:23,136][valid][INFO] - {"epoch": 427, "valid_loss": "3.785", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "39.944", "valid_code_perplexity": "39.866", "valid_temp": "1.836", "valid_loss_0": "3.609", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.32656", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "17080", "valid_best_loss": "3.706"}
[2022-01-03 14:23:23,139][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 427 @ 17080 updates
[2022-01-03 14:23:23,140][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:23:27,101][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:23:27,125][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 427 @ 17080 updates, score 3.785) (writing took 3.9861567206680775 seconds)
[2022-01-03 14:23:27,126][fairseq_cli.train][INFO] - end of epoch 427 (average epoch stats below)
[2022-01-03 14:23:27,139][train][INFO] - {"epoch": 427, "train_loss": "4.032", "train_ntokens": "1793.8", "train_nsentences": "4.95", "train_prob_perplexity": "42.424", "train_code_perplexity": "42.406", "train_temp": "1.836", "train_loss_0": "3.856", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.30335", "train_wps": "3937.4", "train_ups": "2.19", "train_wpb": "1793.8", "train_bsz": "5", "train_num_updates": "17080", "train_lr": "0.000266875", "train_gnorm": "0.705", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8025"}
[2022-01-03 14:23:27,199][fairseq.trainer][INFO] - begin training epoch 428
[2022-01-03 14:23:27,199][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:23:41,066][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:23:41,480][valid][INFO] - {"epoch": 428, "valid_loss": "4.352", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "42.132", "valid_code_perplexity": "42.129", "valid_temp": "1.836", "valid_loss_0": "4.179", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.25", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "17120", "valid_best_loss": "3.706"}
[2022-01-03 14:23:41,486][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 428 @ 17120 updates
[2022-01-03 14:23:41,488][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:23:45,317][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:23:45,326][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 428 @ 17120 updates, score 4.352) (writing took 3.839452520944178 seconds)
[2022-01-03 14:23:45,326][fairseq_cli.train][INFO] - end of epoch 428 (average epoch stats below)
[2022-01-03 14:23:45,339][train][INFO] - {"epoch": 428, "train_loss": "4.063", "train_ntokens": "1802.67", "train_nsentences": "4.95", "train_prob_perplexity": "42.355", "train_code_perplexity": "42.344", "train_temp": "1.836", "train_loss_0": "3.887", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.29702", "train_wps": "3964.6", "train_ups": "2.2", "train_wpb": "1802.7", "train_bsz": "5", "train_num_updates": "17120", "train_lr": "0.0002675", "train_gnorm": "0.725", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8043"}
[2022-01-03 14:23:45,413][fairseq.trainer][INFO] - begin training epoch 429
[2022-01-03 14:23:45,414][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:23:59,383][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:23:59,785][valid][INFO] - {"epoch": 429, "valid_loss": "3.973", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "40.404", "valid_code_perplexity": "40.363", "valid_temp": "1.836", "valid_loss_0": "3.798", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.31201", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "17160", "valid_best_loss": "3.706"}
[2022-01-03 14:23:59,788][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 429 @ 17160 updates
[2022-01-03 14:23:59,789][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:24:03,547][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:24:03,576][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 429 @ 17160 updates, score 3.973) (writing took 3.787812883965671 seconds)
[2022-01-03 14:24:03,576][fairseq_cli.train][INFO] - end of epoch 429 (average epoch stats below)
[2022-01-03 14:24:03,589][train][INFO] - {"epoch": 429, "train_loss": "4.033", "train_ntokens": "1802.28", "train_nsentences": "4.95", "train_prob_perplexity": "41.909", "train_code_perplexity": "41.878", "train_temp": "1.836", "train_loss_0": "3.86", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.3033", "train_wps": "3953", "train_ups": "2.19", "train_wpb": "1802.3", "train_bsz": "5", "train_num_updates": "17160", "train_lr": "0.000268125", "train_gnorm": "0.675", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "8061"}
[2022-01-03 14:24:03,667][fairseq.trainer][INFO] - begin training epoch 430
[2022-01-03 14:24:03,668][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:24:17,598][train_inner][INFO] - {"epoch": 430, "update": 430.0, "loss": "4.039", "ntokens": "1792.29", "nsentences": "4.95", "prob_perplexity": "42.306", "code_perplexity": "42.288", "temp": "1.836", "loss_0": "3.865", "loss_1": "0.135", "loss_2": "0.04", "accuracy": "0.30158", "wps": "3930.7", "ups": "2.19", "wpb": "1792.3", "bsz": "5", "num_updates": "17200", "lr": "0.00026875", "gnorm": "0.703", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "8075"}
[2022-01-03 14:24:17,599][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:24:17,997][valid][INFO] - {"epoch": 430, "valid_loss": "4.197", "valid_ntokens": "700", "valid_nsentences": "2", "valid_prob_perplexity": "40.149", "valid_code_perplexity": "40.131", "valid_temp": "1.835", "valid_loss_0": "4.024", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.27", "valid_wps": "0", "valid_wpb": "700", "valid_bsz": "2", "valid_num_updates": "17200", "valid_best_loss": "3.706"}
[2022-01-03 14:24:18,000][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 430 @ 17200 updates
[2022-01-03 14:24:18,001][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:24:21,782][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:24:21,809][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 430 @ 17200 updates, score 4.197) (writing took 3.8091160003095865 seconds)
[2022-01-03 14:24:21,809][fairseq_cli.train][INFO] - end of epoch 430 (average epoch stats below)
[2022-01-03 14:24:21,822][train][INFO] - {"epoch": 430, "train_loss": "4.021", "train_ntokens": "1776.78", "train_nsentences": "4.95", "train_prob_perplexity": "42.36", "train_code_perplexity": "42.353", "train_temp": "1.835", "train_loss_0": "3.847", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.30458", "train_wps": "3900.6", "train_ups": "2.2", "train_wpb": "1776.8", "train_bsz": "5", "train_num_updates": "17200", "train_lr": "0.00026875", "train_gnorm": "0.708", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8079"}
[2022-01-03 14:24:21,901][fairseq.trainer][INFO] - begin training epoch 431
[2022-01-03 14:24:21,901][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:24:35,748][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:24:36,245][valid][INFO] - {"epoch": 431, "valid_loss": "4.194", "valid_ntokens": "690", "valid_nsentences": "2", "valid_prob_perplexity": "39.704", "valid_code_perplexity": "39.704", "valid_temp": "1.835", "valid_loss_0": "4.018", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.26087", "valid_wps": "0", "valid_wpb": "690", "valid_bsz": "2", "valid_num_updates": "17240", "valid_best_loss": "3.706"}
[2022-01-03 14:24:36,247][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 431 @ 17240 updates
[2022-01-03 14:24:36,247][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:24:40,016][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:24:40,043][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 431 @ 17240 updates, score 4.194) (writing took 3.7959624202921987 seconds)
[2022-01-03 14:24:40,043][fairseq_cli.train][INFO] - end of epoch 431 (average epoch stats below)
[2022-01-03 14:24:40,056][train][INFO] - {"epoch": 431, "train_loss": "4.013", "train_ntokens": "1785.42", "train_nsentences": "4.95", "train_prob_perplexity": "42.203", "train_code_perplexity": "42.181", "train_temp": "1.835", "train_loss_0": "3.84", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.30547", "train_wps": "3919.4", "train_ups": "2.2", "train_wpb": "1785.4", "train_bsz": "5", "train_num_updates": "17240", "train_lr": "0.000269375", "train_gnorm": "0.679", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "8097"}
[2022-01-03 14:24:40,126][fairseq.trainer][INFO] - begin training epoch 432
[2022-01-03 14:24:40,127][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:24:54,040][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:24:54,462][valid][INFO] - {"epoch": 432, "valid_loss": "4.095", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "41.987", "valid_code_perplexity": "41.971", "valid_temp": "1.834", "valid_loss_0": "3.921", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.27851", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "17280", "valid_best_loss": "3.706"}
[2022-01-03 14:24:54,465][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 432 @ 17280 updates
[2022-01-03 14:24:54,465][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:24:58,265][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:24:58,293][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 432 @ 17280 updates, score 4.095) (writing took 3.8277839329093695 seconds)
[2022-01-03 14:24:58,293][fairseq_cli.train][INFO] - end of epoch 432 (average epoch stats below)
[2022-01-03 14:24:58,306][train][INFO] - {"epoch": 432, "train_loss": "4.041", "train_ntokens": "1786.2", "train_nsentences": "4.95", "train_prob_perplexity": "42.466", "train_code_perplexity": "42.449", "train_temp": "1.835", "train_loss_0": "3.865", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.29883", "train_wps": "3917.8", "train_ups": "2.19", "train_wpb": "1786.2", "train_bsz": "5", "train_num_updates": "17280", "train_lr": "0.00027", "train_gnorm": "0.678", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8116"}
[2022-01-03 14:24:58,381][fairseq.trainer][INFO] - begin training epoch 433
[2022-01-03 14:24:58,382][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:25:12,161][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:25:12,548][valid][INFO] - {"epoch": 433, "valid_loss": "4.112", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "42.948", "valid_code_perplexity": "42.944", "valid_temp": "1.834", "valid_loss_0": "3.937", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.30139", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "17320", "valid_best_loss": "3.706"}
[2022-01-03 14:25:12,550][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 433 @ 17320 updates
[2022-01-03 14:25:12,551][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:25:16,447][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:25:16,472][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 433 @ 17320 updates, score 4.112) (writing took 3.922194706276059 seconds)
[2022-01-03 14:25:16,473][fairseq_cli.train][INFO] - end of epoch 433 (average epoch stats below)
[2022-01-03 14:25:16,487][train][INFO] - {"epoch": 433, "train_loss": "4.056", "train_ntokens": "1802.65", "train_nsentences": "4.95", "train_prob_perplexity": "42.681", "train_code_perplexity": "42.645", "train_temp": "1.834", "train_loss_0": "3.881", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.29931", "train_wps": "3969.1", "train_ups": "2.2", "train_wpb": "1802.7", "train_bsz": "5", "train_num_updates": "17320", "train_lr": "0.000270625", "train_gnorm": "0.723", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "8134"}
[2022-01-03 14:25:16,556][fairseq.trainer][INFO] - begin training epoch 434
[2022-01-03 14:25:16,556][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:25:30,433][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:25:30,826][valid][INFO] - {"epoch": 434, "valid_loss": "3.971", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "41.103", "valid_code_perplexity": "40.97", "valid_temp": "1.834", "valid_loss_0": "3.798", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.29634", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "17360", "valid_best_loss": "3.706"}
[2022-01-03 14:25:30,830][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 434 @ 17360 updates
[2022-01-03 14:25:30,831][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:25:34,731][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:25:34,759][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 434 @ 17360 updates, score 3.971) (writing took 3.928841656073928 seconds)
[2022-01-03 14:25:34,759][fairseq_cli.train][INFO] - end of epoch 434 (average epoch stats below)
[2022-01-03 14:25:34,772][train][INFO] - {"epoch": 434, "train_loss": "4.029", "train_ntokens": "1796.53", "train_nsentences": "4.95", "train_prob_perplexity": "42.324", "train_code_perplexity": "42.303", "train_temp": "1.834", "train_loss_0": "3.853", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.30626", "train_wps": "3932.8", "train_ups": "2.19", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "17360", "train_lr": "0.00027125", "train_gnorm": "0.671", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8152"}
[2022-01-03 14:25:34,853][fairseq.trainer][INFO] - begin training epoch 435
[2022-01-03 14:25:34,854][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:25:48,728][train_inner][INFO] - {"epoch": 435, "update": 435.0, "loss": "4.035", "ntokens": "1792.32", "nsentences": "4.95", "prob_perplexity": "42.512", "code_perplexity": "42.487", "temp": "1.834", "loss_0": "3.86", "loss_1": "0.135", "loss_2": "0.04", "accuracy": "0.30211", "wps": "3934.1", "ups": "2.19", "wpb": "1792.3", "bsz": "5", "num_updates": "17400", "lr": "0.000271875", "gnorm": "0.686", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "8166"}
[2022-01-03 14:25:48,729][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:25:49,119][valid][INFO] - {"epoch": 435, "valid_loss": "3.922", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "43.008", "valid_code_perplexity": "42.991", "valid_temp": "1.833", "valid_loss_0": "3.749", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.31768", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "17400", "valid_best_loss": "3.706"}
[2022-01-03 14:25:49,121][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 435 @ 17400 updates
[2022-01-03 14:25:49,122][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:25:52,909][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:25:52,937][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 435 @ 17400 updates, score 3.922) (writing took 3.8154833475127816 seconds)
[2022-01-03 14:25:52,937][fairseq_cli.train][INFO] - end of epoch 435 (average epoch stats below)
[2022-01-03 14:25:52,950][train][INFO] - {"epoch": 435, "train_loss": "4.034", "train_ntokens": "1790.8", "train_nsentences": "4.95", "train_prob_perplexity": "42.89", "train_code_perplexity": "42.859", "train_temp": "1.834", "train_loss_0": "3.86", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.30069", "train_wps": "3943.4", "train_ups": "2.2", "train_wpb": "1790.8", "train_bsz": "5", "train_num_updates": "17400", "train_lr": "0.000271875", "train_gnorm": "0.681", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "8170"}
[2022-01-03 14:25:53,022][fairseq.trainer][INFO] - begin training epoch 436
[2022-01-03 14:25:53,023][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:26:07,061][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:26:07,455][valid][INFO] - {"epoch": 436, "valid_loss": "4.054", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "38.068", "valid_code_perplexity": "37.971", "valid_temp": "1.833", "valid_loss_0": "3.876", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.34906", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "17440", "valid_best_loss": "3.706"}
[2022-01-03 14:26:07,458][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 436 @ 17440 updates
[2022-01-03 14:26:07,459][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:26:11,156][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:26:11,185][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 436 @ 17440 updates, score 4.054) (writing took 3.726733660325408 seconds)
[2022-01-03 14:26:11,185][fairseq_cli.train][INFO] - end of epoch 436 (average epoch stats below)
[2022-01-03 14:26:11,198][train][INFO] - {"epoch": 436, "train_loss": "4.013", "train_ntokens": "1775.33", "train_nsentences": "4.95", "train_prob_perplexity": "43.081", "train_code_perplexity": "43.06", "train_temp": "1.833", "train_loss_0": "3.841", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.30145", "train_wps": "3894.2", "train_ups": "2.19", "train_wpb": "1775.3", "train_bsz": "5", "train_num_updates": "17440", "train_lr": "0.0002725", "train_gnorm": "0.663", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8189"}
[2022-01-03 14:26:11,275][fairseq.trainer][INFO] - begin training epoch 437
[2022-01-03 14:26:11,276][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:26:25,231][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:26:25,638][valid][INFO] - {"epoch": 437, "valid_loss": "3.959", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "42.641", "valid_code_perplexity": "42.581", "valid_temp": "1.833", "valid_loss_0": "3.786", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.27719", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "17480", "valid_best_loss": "3.706"}
[2022-01-03 14:26:25,642][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 437 @ 17480 updates
[2022-01-03 14:26:25,643][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:26:29,391][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:26:29,419][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 437 @ 17480 updates, score 3.959) (writing took 3.776861419901252 seconds)
[2022-01-03 14:26:29,419][fairseq_cli.train][INFO] - end of epoch 437 (average epoch stats below)
[2022-01-03 14:26:29,432][train][INFO] - {"epoch": 437, "train_loss": "4.044", "train_ntokens": "1800.15", "train_nsentences": "4.95", "train_prob_perplexity": "42.386", "train_code_perplexity": "42.367", "train_temp": "1.833", "train_loss_0": "3.87", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.30096", "train_wps": "3951.7", "train_ups": "2.2", "train_wpb": "1800.2", "train_bsz": "5", "train_num_updates": "17480", "train_lr": "0.000273125", "train_gnorm": "0.673", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "8207"}
[2022-01-03 14:26:29,509][fairseq.trainer][INFO] - begin training epoch 438
[2022-01-03 14:26:29,510][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:26:43,512][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:26:43,927][valid][INFO] - {"epoch": 438, "valid_loss": "4.12", "valid_ntokens": "696", "valid_nsentences": "2", "valid_prob_perplexity": "37.513", "valid_code_perplexity": "37.485", "valid_temp": "1.832", "valid_loss_0": "3.945", "valid_loss_1": "0.136", "valid_loss_2": "0.039", "valid_accuracy": "0.31609", "valid_wps": "0", "valid_wpb": "696", "valid_bsz": "2", "valid_num_updates": "17520", "valid_best_loss": "3.706"}
[2022-01-03 14:26:43,931][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 438 @ 17520 updates
[2022-01-03 14:26:43,932][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:26:47,625][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:26:47,652][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 438 @ 17520 updates, score 4.12) (writing took 3.721525453031063 seconds)
[2022-01-03 14:26:47,653][fairseq_cli.train][INFO] - end of epoch 438 (average epoch stats below)
[2022-01-03 14:26:47,666][train][INFO] - {"epoch": 438, "train_loss": "3.997", "train_ntokens": "1779.65", "train_nsentences": "4.95", "train_prob_perplexity": "43.081", "train_code_perplexity": "43.061", "train_temp": "1.832", "train_loss_0": "3.823", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.30444", "train_wps": "3906.8", "train_ups": "2.2", "train_wpb": "1779.7", "train_bsz": "5", "train_num_updates": "17520", "train_lr": "0.00027375", "train_gnorm": "0.666", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8225"}
[2022-01-03 14:26:47,729][fairseq.trainer][INFO] - begin training epoch 439
[2022-01-03 14:26:47,730][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:27:01,486][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:27:01,895][valid][INFO] - {"epoch": 439, "valid_loss": "4.098", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "40.455", "valid_code_perplexity": "40.472", "valid_temp": "1.832", "valid_loss_0": "3.921", "valid_loss_1": "0.135", "valid_loss_2": "0.042", "valid_accuracy": "0.28611", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "17560", "valid_best_loss": "3.706"}
[2022-01-03 14:27:01,898][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 439 @ 17560 updates
[2022-01-03 14:27:01,899][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:27:05,814][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:27:05,840][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 439 @ 17560 updates, score 4.098) (writing took 3.9419836280867457 seconds)
[2022-01-03 14:27:05,841][fairseq_cli.train][INFO] - end of epoch 439 (average epoch stats below)
[2022-01-03 14:27:05,853][train][INFO] - {"epoch": 439, "train_loss": "4.046", "train_ntokens": "1778.67", "train_nsentences": "4.95", "train_prob_perplexity": "42.774", "train_code_perplexity": "42.755", "train_temp": "1.832", "train_loss_0": "3.873", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.29774", "train_wps": "3914.6", "train_ups": "2.2", "train_wpb": "1778.7", "train_bsz": "5", "train_num_updates": "17560", "train_lr": "0.000274375", "train_gnorm": "0.693", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8243"}
[2022-01-03 14:27:05,902][fairseq.trainer][INFO] - begin training epoch 440
[2022-01-03 14:27:05,902][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:27:19,870][train_inner][INFO] - {"epoch": 440, "update": 440.0, "loss": "4.03", "ntokens": "1784.15", "nsentences": "4.95", "prob_perplexity": "42.871", "code_perplexity": "42.851", "temp": "1.832", "loss_0": "3.856", "loss_1": "0.135", "loss_2": "0.039", "accuracy": "0.30073", "wps": "3915.6", "ups": "2.19", "wpb": "1784.2", "bsz": "5", "num_updates": "17600", "lr": "0.000275", "gnorm": "0.674", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "8257"}
[2022-01-03 14:27:19,871][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:27:20,285][valid][INFO] - {"epoch": 440, "valid_loss": "3.966", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "41.454", "valid_code_perplexity": "41.369", "valid_temp": "1.832", "valid_loss_0": "3.791", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.30808", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "17600", "valid_best_loss": "3.706"}
[2022-01-03 14:27:20,287][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 440 @ 17600 updates
[2022-01-03 14:27:20,288][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:27:23,986][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:27:24,012][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 440 @ 17600 updates, score 3.966) (writing took 3.72432744782418 seconds)
[2022-01-03 14:27:24,012][fairseq_cli.train][INFO] - end of epoch 440 (average epoch stats below)
[2022-01-03 14:27:24,025][train][INFO] - {"epoch": 440, "train_loss": "4.048", "train_ntokens": "1786.95", "train_nsentences": "4.95", "train_prob_perplexity": "43.036", "train_code_perplexity": "43.012", "train_temp": "1.832", "train_loss_0": "3.875", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.29907", "train_wps": "3936.2", "train_ups": "2.2", "train_wpb": "1787", "train_bsz": "5", "train_num_updates": "17600", "train_lr": "0.000275", "train_gnorm": "0.676", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8261"}
[2022-01-03 14:27:24,097][fairseq.trainer][INFO] - begin training epoch 441
[2022-01-03 14:27:24,098][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:27:38,038][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:27:38,432][valid][INFO] - {"epoch": 441, "valid_loss": "4.147", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "42.255", "valid_code_perplexity": "42.237", "valid_temp": "1.831", "valid_loss_0": "3.976", "valid_loss_1": "0.135", "valid_loss_2": "0.036", "valid_accuracy": "0.28912", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "17640", "valid_best_loss": "3.706"}
[2022-01-03 14:27:38,434][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 441 @ 17640 updates
[2022-01-03 14:27:38,435][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:27:42,259][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:27:42,286][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 441 @ 17640 updates, score 4.147) (writing took 3.8520457027480006 seconds)
[2022-01-03 14:27:42,287][fairseq_cli.train][INFO] - end of epoch 441 (average epoch stats below)
[2022-01-03 14:27:42,299][train][INFO] - {"epoch": 441, "train_loss": "4.021", "train_ntokens": "1791.1", "train_nsentences": "4.95", "train_prob_perplexity": "43.173", "train_code_perplexity": "43.145", "train_temp": "1.831", "train_loss_0": "3.848", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.30449", "train_wps": "3923.1", "train_ups": "2.19", "train_wpb": "1791.1", "train_bsz": "5", "train_num_updates": "17640", "train_lr": "0.000275625", "train_gnorm": "0.687", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "8280"}
[2022-01-03 14:27:42,369][fairseq.trainer][INFO] - begin training epoch 442
[2022-01-03 14:27:42,370][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:27:56,363][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:27:56,821][valid][INFO] - {"epoch": 442, "valid_loss": "4.029", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "40.319", "valid_code_perplexity": "40.315", "valid_temp": "1.831", "valid_loss_0": "3.854", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.31974", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "17680", "valid_best_loss": "3.706"}
[2022-01-03 14:27:56,825][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 442 @ 17680 updates
[2022-01-03 14:27:56,826][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:28:00,634][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:28:00,662][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 442 @ 17680 updates, score 4.029) (writing took 3.8374276077374816 seconds)
[2022-01-03 14:28:00,663][fairseq_cli.train][INFO] - end of epoch 442 (average epoch stats below)
[2022-01-03 14:28:00,676][train][INFO] - {"epoch": 442, "train_loss": "4.037", "train_ntokens": "1805.03", "train_nsentences": "4.95", "train_prob_perplexity": "42.605", "train_code_perplexity": "42.592", "train_temp": "1.831", "train_loss_0": "3.863", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.30501", "train_wps": "3931.7", "train_ups": "2.18", "train_wpb": "1805", "train_bsz": "5", "train_num_updates": "17680", "train_lr": "0.00027625", "train_gnorm": "0.712", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8298"}
[2022-01-03 14:28:00,731][fairseq.trainer][INFO] - begin training epoch 443
[2022-01-03 14:28:00,732][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:28:14,727][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:28:15,140][valid][INFO] - {"epoch": 443, "valid_loss": "3.932", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "42.758", "valid_code_perplexity": "42.658", "valid_temp": "1.83", "valid_loss_0": "3.76", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.28792", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "17720", "valid_best_loss": "3.706"}
[2022-01-03 14:28:15,143][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 443 @ 17720 updates
[2022-01-03 14:28:15,144][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:28:19,029][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:28:19,057][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 443 @ 17720 updates, score 3.932) (writing took 3.913807477802038 seconds)
[2022-01-03 14:28:19,057][fairseq_cli.train][INFO] - end of epoch 443 (average epoch stats below)
[2022-01-03 14:28:19,070][train][INFO] - {"epoch": 443, "train_loss": "4.007", "train_ntokens": "1786.6", "train_nsentences": "4.95", "train_prob_perplexity": "42.215", "train_code_perplexity": "42.19", "train_temp": "1.831", "train_loss_0": "3.832", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.3092", "train_wps": "3887.8", "train_ups": "2.18", "train_wpb": "1786.6", "train_bsz": "5", "train_num_updates": "17720", "train_lr": "0.000276875", "train_gnorm": "0.681", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "8316"}
[2022-01-03 14:28:19,145][fairseq.trainer][INFO] - begin training epoch 444
[2022-01-03 14:28:19,145][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:28:32,939][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:28:33,340][valid][INFO] - {"epoch": 444, "valid_loss": "4.209", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "39.688", "valid_code_perplexity": "39.636", "valid_temp": "1.83", "valid_loss_0": "4.038", "valid_loss_1": "0.135", "valid_loss_2": "0.037", "valid_accuracy": "0.28825", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "17760", "valid_best_loss": "3.706"}
[2022-01-03 14:28:33,343][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 444 @ 17760 updates
[2022-01-03 14:28:33,344][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:28:37,229][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:28:37,257][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 444 @ 17760 updates, score 4.209) (writing took 3.9142699046060443 seconds)
[2022-01-03 14:28:37,258][fairseq_cli.train][INFO] - end of epoch 444 (average epoch stats below)
[2022-01-03 14:28:37,270][train][INFO] - {"epoch": 444, "train_loss": "4.024", "train_ntokens": "1798.3", "train_nsentences": "4.95", "train_prob_perplexity": "43.014", "train_code_perplexity": "42.996", "train_temp": "1.83", "train_loss_0": "3.849", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.30444", "train_wps": "3955.1", "train_ups": "2.2", "train_wpb": "1798.3", "train_bsz": "5", "train_num_updates": "17760", "train_lr": "0.0002775", "train_gnorm": "0.672", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8335"}
[2022-01-03 14:28:37,352][fairseq.trainer][INFO] - begin training epoch 445
[2022-01-03 14:28:37,353][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:28:51,228][train_inner][INFO] - {"epoch": 445, "update": 445.0, "loss": "4.026", "ntokens": "1793.86", "nsentences": "4.95", "prob_perplexity": "42.671", "code_perplexity": "42.65", "temp": "1.831", "loss_0": "3.853", "loss_1": "0.135", "loss_2": "0.039", "accuracy": "0.30533", "wps": "3927.7", "ups": "2.19", "wpb": "1793.9", "bsz": "5", "num_updates": "17800", "lr": "0.000278125", "gnorm": "0.682", "clip": "0", "train_wall": "67", "gb_free": "5.4", "wall": "8349"}
[2022-01-03 14:28:51,229][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:28:51,640][valid][INFO] - {"epoch": 445, "valid_loss": "3.966", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "35.619", "valid_code_perplexity": "35.608", "valid_temp": "1.83", "valid_loss_0": "3.786", "valid_loss_1": "0.136", "valid_loss_2": "0.044", "valid_accuracy": "0.33241", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "17800", "valid_best_loss": "3.706"}
[2022-01-03 14:28:51,646][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 445 @ 17800 updates
[2022-01-03 14:28:51,647][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:28:55,463][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:28:55,490][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 445 @ 17800 updates, score 3.966) (writing took 3.8445369359105825 seconds)
[2022-01-03 14:28:55,491][fairseq_cli.train][INFO] - end of epoch 445 (average epoch stats below)
[2022-01-03 14:28:55,504][train][INFO] - {"epoch": 445, "train_loss": "4.044", "train_ntokens": "1788.25", "train_nsentences": "4.95", "train_prob_perplexity": "42.346", "train_code_perplexity": "42.326", "train_temp": "1.83", "train_loss_0": "3.871", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.30352", "train_wps": "3925.7", "train_ups": "2.2", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "17800", "train_lr": "0.000278125", "train_gnorm": "0.66", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "8353"}
[2022-01-03 14:28:55,578][fairseq.trainer][INFO] - begin training epoch 446
[2022-01-03 14:28:55,579][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:29:09,621][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:29:10,022][valid][INFO] - {"epoch": 446, "valid_loss": "4.097", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "40.996", "valid_code_perplexity": "40.998", "valid_temp": "1.829", "valid_loss_0": "3.924", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.28831", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "17840", "valid_best_loss": "3.706"}
[2022-01-03 14:29:10,026][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 446 @ 17840 updates
[2022-01-03 14:29:10,027][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:29:13,712][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:29:13,740][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 446 @ 17840 updates, score 4.097) (writing took 3.7142627025023103 seconds)
[2022-01-03 14:29:13,741][fairseq_cli.train][INFO] - end of epoch 446 (average epoch stats below)
[2022-01-03 14:29:13,754][train][INFO] - {"epoch": 446, "train_loss": "4.049", "train_ntokens": "1783.58", "train_nsentences": "4.95", "train_prob_perplexity": "42.201", "train_code_perplexity": "42.182", "train_temp": "1.83", "train_loss_0": "3.873", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.30031", "train_wps": "3912", "train_ups": "2.19", "train_wpb": "1783.6", "train_bsz": "5", "train_num_updates": "17840", "train_lr": "0.00027875", "train_gnorm": "0.667", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "8371"}
[2022-01-03 14:29:13,830][fairseq.trainer][INFO] - begin training epoch 447
[2022-01-03 14:29:13,831][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:29:27,747][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:29:28,152][valid][INFO] - {"epoch": 447, "valid_loss": "4.1", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "41.769", "valid_code_perplexity": "41.71", "valid_temp": "1.829", "valid_loss_0": "3.927", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.27885", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "17880", "valid_best_loss": "3.706"}
[2022-01-03 14:29:28,155][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 447 @ 17880 updates
[2022-01-03 14:29:28,156][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:29:31,939][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:29:31,967][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 447 @ 17880 updates, score 4.1) (writing took 3.812213941477239 seconds)
[2022-01-03 14:29:31,968][fairseq_cli.train][INFO] - end of epoch 447 (average epoch stats below)
[2022-01-03 14:29:31,981][train][INFO] - {"epoch": 447, "train_loss": "4.045", "train_ntokens": "1795.15", "train_nsentences": "4.95", "train_prob_perplexity": "42.386", "train_code_perplexity": "42.376", "train_temp": "1.829", "train_loss_0": "3.87", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.29893", "train_wps": "3942.3", "train_ups": "2.2", "train_wpb": "1795.2", "train_bsz": "5", "train_num_updates": "17880", "train_lr": "0.000279375", "train_gnorm": "0.661", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "8389"}
[2022-01-03 14:29:32,055][fairseq.trainer][INFO] - begin training epoch 448
[2022-01-03 14:29:32,056][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:29:45,917][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:29:46,319][valid][INFO] - {"epoch": 448, "valid_loss": "4.187", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "41.687", "valid_code_perplexity": "41.611", "valid_temp": "1.829", "valid_loss_0": "4.015", "valid_loss_1": "0.135", "valid_loss_2": "0.037", "valid_accuracy": "0.27674", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "17920", "valid_best_loss": "3.706"}
[2022-01-03 14:29:46,321][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 448 @ 17920 updates
[2022-01-03 14:29:46,322][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:29:50,277][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:29:50,297][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 448 @ 17920 updates, score 4.187) (writing took 3.975782411172986 seconds)
[2022-01-03 14:29:50,297][fairseq_cli.train][INFO] - end of epoch 448 (average epoch stats below)
[2022-01-03 14:29:50,309][train][INFO] - {"epoch": 448, "train_loss": "4.07", "train_ntokens": "1827.22", "train_nsentences": "4.95", "train_prob_perplexity": "42.108", "train_code_perplexity": "42.077", "train_temp": "1.829", "train_loss_0": "3.895", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.29679", "train_wps": "3990.4", "train_ups": "2.18", "train_wpb": "1827.2", "train_bsz": "5", "train_num_updates": "17920", "train_lr": "0.00028", "train_gnorm": "0.688", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "8408"}
[2022-01-03 14:29:50,353][fairseq.trainer][INFO] - begin training epoch 449
[2022-01-03 14:29:50,353][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:30:04,284][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:30:04,688][valid][INFO] - {"epoch": 449, "valid_loss": "4.223", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "41.492", "valid_code_perplexity": "41.572", "valid_temp": "1.828", "valid_loss_0": "4.049", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.27717", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "17960", "valid_best_loss": "3.706"}
[2022-01-03 14:30:04,691][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 449 @ 17960 updates
[2022-01-03 14:30:04,692][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:30:08,479][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:30:08,499][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 449 @ 17960 updates, score 4.223) (writing took 3.807675240561366 seconds)
[2022-01-03 14:30:08,499][fairseq_cli.train][INFO] - end of epoch 449 (average epoch stats below)
[2022-01-03 14:30:08,512][train][INFO] - {"epoch": 449, "train_loss": "4.043", "train_ntokens": "1783.97", "train_nsentences": "4.95", "train_prob_perplexity": "42.745", "train_code_perplexity": "42.724", "train_temp": "1.828", "train_loss_0": "3.87", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.29985", "train_wps": "3923.1", "train_ups": "2.2", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "17960", "train_lr": "0.000280625", "train_gnorm": "0.662", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "8426"}
[2022-01-03 14:30:08,568][fairseq.trainer][INFO] - begin training epoch 450
[2022-01-03 14:30:08,568][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:30:22,448][train_inner][INFO] - {"epoch": 450, "update": 450.0, "loss": "4.051", "ntokens": "1795.14", "nsentences": "4.95", "prob_perplexity": "42.436", "code_perplexity": "42.415", "temp": "1.829", "loss_0": "3.877", "loss_1": "0.135", "loss_2": "0.04", "accuracy": "0.29939", "wps": "3936.4", "ups": "2.19", "wpb": "1795.1", "bsz": "5", "num_updates": "18000", "lr": "0.00028125", "gnorm": "0.671", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "8440"}
[2022-01-03 14:30:22,449][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:30:22,966][valid][INFO] - {"epoch": 450, "valid_loss": "3.939", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "36.531", "valid_code_perplexity": "36.482", "valid_temp": "1.828", "valid_loss_0": "3.76", "valid_loss_1": "0.136", "valid_loss_2": "0.043", "valid_accuracy": "0.32231", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "18000", "valid_best_loss": "3.706"}
[2022-01-03 14:30:22,968][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 450 @ 18000 updates
[2022-01-03 14:30:22,969][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:30:26,856][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:30:26,883][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 450 @ 18000 updates, score 3.939) (writing took 3.9150096969679 seconds)
[2022-01-03 14:30:26,884][fairseq_cli.train][INFO] - end of epoch 450 (average epoch stats below)
[2022-01-03 14:30:26,897][train][INFO] - {"epoch": 450, "train_loss": "4.049", "train_ntokens": "1785.78", "train_nsentences": "4.95", "train_prob_perplexity": "42.741", "train_code_perplexity": "42.715", "train_temp": "1.828", "train_loss_0": "3.875", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.30112", "train_wps": "3888", "train_ups": "2.18", "train_wpb": "1785.8", "train_bsz": "5", "train_num_updates": "18000", "train_lr": "0.00028125", "train_gnorm": "0.676", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8444"}
[2022-01-03 14:30:26,974][fairseq.trainer][INFO] - begin training epoch 451
[2022-01-03 14:30:26,975][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:30:40,823][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:30:41,246][valid][INFO] - {"epoch": 451, "valid_loss": "3.956", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "41.347", "valid_code_perplexity": "41.377", "valid_temp": "1.828", "valid_loss_0": "3.781", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.33201", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "18040", "valid_best_loss": "3.706"}
[2022-01-03 14:30:41,251][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 451 @ 18040 updates
[2022-01-03 14:30:41,252][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:30:44,982][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:30:45,009][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 451 @ 18040 updates, score 3.956) (writing took 3.7577366773039103 seconds)
[2022-01-03 14:30:45,009][fairseq_cli.train][INFO] - end of epoch 451 (average epoch stats below)
[2022-01-03 14:30:45,023][train][INFO] - {"epoch": 451, "train_loss": "4.039", "train_ntokens": "1801.8", "train_nsentences": "4.95", "train_prob_perplexity": "42.66", "train_code_perplexity": "42.645", "train_temp": "1.828", "train_loss_0": "3.863", "train_loss_1": "0.135", "train_loss_2": "0.041", "train_accuracy": "0.30002", "train_wps": "3979.2", "train_ups": "2.21", "train_wpb": "1801.8", "train_bsz": "5", "train_num_updates": "18040", "train_lr": "0.000281875", "train_gnorm": "0.664", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "8462"}
[2022-01-03 14:30:45,082][fairseq.trainer][INFO] - begin training epoch 452
[2022-01-03 14:30:45,083][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:30:59,025][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:30:59,410][valid][INFO] - {"epoch": 452, "valid_loss": "4.108", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "38.928", "valid_code_perplexity": "38.863", "valid_temp": "1.827", "valid_loss_0": "3.934", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.30679", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "18080", "valid_best_loss": "3.706"}
[2022-01-03 14:30:59,413][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 452 @ 18080 updates
[2022-01-03 14:30:59,414][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:31:03,232][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:31:03,259][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 452 @ 18080 updates, score 4.108) (writing took 3.845944452099502 seconds)
[2022-01-03 14:31:03,260][fairseq_cli.train][INFO] - end of epoch 452 (average epoch stats below)
[2022-01-03 14:31:03,273][train][INFO] - {"epoch": 452, "train_loss": "4.034", "train_ntokens": "1805.15", "train_nsentences": "4.95", "train_prob_perplexity": "42.546", "train_code_perplexity": "42.521", "train_temp": "1.827", "train_loss_0": "3.86", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.30374", "train_wps": "3959.2", "train_ups": "2.19", "train_wpb": "1805.2", "train_bsz": "5", "train_num_updates": "18080", "train_lr": "0.0002825", "train_gnorm": "0.653", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8481"}
[2022-01-03 14:31:03,350][fairseq.trainer][INFO] - begin training epoch 453
[2022-01-03 14:31:03,351][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:31:17,333][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:31:17,835][valid][INFO] - {"epoch": 453, "valid_loss": "3.856", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "41.953", "valid_code_perplexity": "41.896", "valid_temp": "1.827", "valid_loss_0": "3.682", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.32297", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "18120", "valid_best_loss": "3.706"}
[2022-01-03 14:31:17,836][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 453 @ 18120 updates
[2022-01-03 14:31:17,837][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:31:21,486][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:31:21,512][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 453 @ 18120 updates, score 3.856) (writing took 3.6755977254360914 seconds)
[2022-01-03 14:31:21,512][fairseq_cli.train][INFO] - end of epoch 453 (average epoch stats below)
[2022-01-03 14:31:21,525][train][INFO] - {"epoch": 453, "train_loss": "3.999", "train_ntokens": "1782.95", "train_nsentences": "4.95", "train_prob_perplexity": "42.767", "train_code_perplexity": "42.752", "train_temp": "1.827", "train_loss_0": "3.826", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.30602", "train_wps": "3910", "train_ups": "2.19", "train_wpb": "1783", "train_bsz": "5", "train_num_updates": "18120", "train_lr": "0.000283125", "train_gnorm": "0.658", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8499"}
[2022-01-03 14:31:21,574][fairseq.trainer][INFO] - begin training epoch 454
[2022-01-03 14:31:21,575][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:31:35,476][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:31:35,876][valid][INFO] - {"epoch": 454, "valid_loss": "4.174", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "40.957", "valid_code_perplexity": "40.951", "valid_temp": "1.826", "valid_loss_0": "3.999", "valid_loss_1": "0.135", "valid_loss_2": "0.04", "valid_accuracy": "0.29491", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "18160", "valid_best_loss": "3.706"}
[2022-01-03 14:31:35,880][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 454 @ 18160 updates
[2022-01-03 14:31:35,880][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:31:39,819][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:31:39,845][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 454 @ 18160 updates, score 4.174) (writing took 3.9650002187117934 seconds)
[2022-01-03 14:31:39,845][fairseq_cli.train][INFO] - end of epoch 454 (average epoch stats below)
[2022-01-03 14:31:39,858][train][INFO] - {"epoch": 454, "train_loss": "4.038", "train_ntokens": "1786.53", "train_nsentences": "4.95", "train_prob_perplexity": "43.056", "train_code_perplexity": "43.03", "train_temp": "1.827", "train_loss_0": "3.863", "train_loss_1": "0.135", "train_loss_2": "0.04", "train_accuracy": "0.29995", "train_wps": "3900.7", "train_ups": "2.18", "train_wpb": "1786.5", "train_bsz": "5", "train_num_updates": "18160", "train_lr": "0.00028375", "train_gnorm": "0.665", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8517"}
[2022-01-03 14:31:39,913][fairseq.trainer][INFO] - begin training epoch 455
[2022-01-03 14:31:39,914][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:31:53,730][train_inner][INFO] - {"epoch": 455, "update": 455.0, "loss": "4.032", "ntokens": "1793.53", "nsentences": "4.95", "prob_perplexity": "42.921", "code_perplexity": "42.9", "temp": "1.827", "loss_0": "3.858", "loss_1": "0.135", "loss_2": "0.039", "accuracy": "0.30177", "wps": "3930.2", "ups": "2.19", "wpb": "1793.5", "bsz": "5", "num_updates": "18200", "lr": "0.000284375", "gnorm": "0.665", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "8531"}
[2022-01-03 14:31:53,731][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:31:54,174][valid][INFO] - {"epoch": 455, "valid_loss": "4.212", "valid_ntokens": "814", "valid_nsentences": "2", "valid_prob_perplexity": "39.089", "valid_code_perplexity": "39.009", "valid_temp": "1.826", "valid_loss_0": "4.04", "valid_loss_1": "0.135", "valid_loss_2": "0.036", "valid_accuracy": "0.2801", "valid_wps": "0", "valid_wpb": "814", "valid_bsz": "2", "valid_num_updates": "18200", "valid_best_loss": "3.706"}
[2022-01-03 14:31:54,177][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 455 @ 18200 updates
[2022-01-03 14:31:54,178][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:31:58,042][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:31:58,070][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 455 @ 18200 updates, score 4.212) (writing took 3.893596710637212 seconds)
[2022-01-03 14:31:58,071][fairseq_cli.train][INFO] - end of epoch 455 (average epoch stats below)
[2022-01-03 14:31:58,084][train][INFO] - {"epoch": 455, "train_loss": "4.049", "train_ntokens": "1791.22", "train_nsentences": "4.95", "train_prob_perplexity": "43.576", "train_code_perplexity": "43.551", "train_temp": "1.826", "train_loss_0": "3.878", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.2991", "train_wps": "3933.8", "train_ups": "2.2", "train_wpb": "1791.2", "train_bsz": "5", "train_num_updates": "18200", "train_lr": "0.000284375", "train_gnorm": "0.683", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8535"}
[2022-01-03 14:31:58,160][fairseq.trainer][INFO] - begin training epoch 456
[2022-01-03 14:31:58,161][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:32:12,015][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:32:12,550][valid][INFO] - {"epoch": 456, "valid_loss": "3.887", "valid_ntokens": "790", "valid_nsentences": "2", "valid_prob_perplexity": "40.941", "valid_code_perplexity": "40.99", "valid_temp": "1.826", "valid_loss_0": "3.717", "valid_loss_1": "0.135", "valid_loss_2": "0.035", "valid_accuracy": "0.31013", "valid_wps": "0", "valid_wpb": "790", "valid_bsz": "2", "valid_num_updates": "18240", "valid_best_loss": "3.706"}
[2022-01-03 14:32:12,551][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 456 @ 18240 updates
[2022-01-03 14:32:12,552][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:32:16,216][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:32:16,235][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 456 @ 18240 updates, score 3.887) (writing took 3.683927219361067 seconds)
[2022-01-03 14:32:16,236][fairseq_cli.train][INFO] - end of epoch 456 (average epoch stats below)
[2022-01-03 14:32:16,248][train][INFO] - {"epoch": 456, "train_loss": "4.045", "train_ntokens": "1796.15", "train_nsentences": "4.95", "train_prob_perplexity": "43.129", "train_code_perplexity": "43.104", "train_temp": "1.826", "train_loss_0": "3.872", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.29929", "train_wps": "3958.1", "train_ups": "2.2", "train_wpb": "1796.2", "train_bsz": "5", "train_num_updates": "18240", "train_lr": "0.000285", "train_gnorm": "0.643", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8554"}
[2022-01-03 14:32:16,299][fairseq.trainer][INFO] - begin training epoch 457
[2022-01-03 14:32:16,299][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:32:30,128][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:32:30,529][valid][INFO] - {"epoch": 457, "valid_loss": "3.656", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "40.134", "valid_code_perplexity": "40.123", "valid_temp": "1.825", "valid_loss_0": "3.488", "valid_loss_1": "0.135", "valid_loss_2": "0.033", "valid_accuracy": "0.3519", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "18280", "valid_best_loss": "3.656"}
[2022-01-03 14:32:30,532][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 457 @ 18280 updates
[2022-01-03 14:32:30,533][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 14:32:34,445][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 14:32:40,945][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 457 @ 18280 updates, score 3.656) (writing took 10.413384049199522 seconds)
[2022-01-03 14:32:40,946][fairseq_cli.train][INFO] - end of epoch 457 (average epoch stats below)
[2022-01-03 14:32:40,958][train][INFO] - {"epoch": 457, "train_loss": "4.038", "train_ntokens": "1787.65", "train_nsentences": "4.95", "train_prob_perplexity": "42.877", "train_code_perplexity": "42.846", "train_temp": "1.825", "train_loss_0": "3.864", "train_loss_1": "0.135", "train_loss_2": "0.039", "train_accuracy": "0.29951", "train_wps": "2895.2", "train_ups": "1.62", "train_wpb": "1787.7", "train_bsz": "5", "train_num_updates": "18280", "train_lr": "0.000285625", "train_gnorm": "0.659", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "8578"}
[2022-01-03 14:32:41,035][fairseq.trainer][INFO] - begin training epoch 458
[2022-01-03 14:32:41,035][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:32:54,799][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:32:55,200][valid][INFO] - {"epoch": 458, "valid_loss": "4.284", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "42.22", "valid_code_perplexity": "42.249", "valid_temp": "1.825", "valid_loss_0": "4.115", "valid_loss_1": "0.135", "valid_loss_2": "0.034", "valid_accuracy": "0.27147", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "18320", "valid_best_loss": "3.656"}
[2022-01-03 14:32:55,203][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 458 @ 18320 updates
[2022-01-03 14:32:55,204][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:32:59,150][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:32:59,171][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 458 @ 18320 updates, score 4.284) (writing took 3.9679296938702464 seconds)
[2022-01-03 14:32:59,172][fairseq_cli.train][INFO] - end of epoch 458 (average epoch stats below)
[2022-01-03 14:32:59,185][train][INFO] - {"epoch": 458, "train_loss": "4.017", "train_ntokens": "1791.42", "train_nsentences": "4.95", "train_prob_perplexity": "43.617", "train_code_perplexity": "43.585", "train_temp": "1.825", "train_loss_0": "3.845", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.3023", "train_wps": "3934.3", "train_ups": "2.2", "train_wpb": "1791.4", "train_bsz": "5", "train_num_updates": "18320", "train_lr": "0.00028625", "train_gnorm": "0.655", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "8597"}
[2022-01-03 14:32:59,255][fairseq.trainer][INFO] - begin training epoch 459
[2022-01-03 14:32:59,256][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:33:13,075][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:33:13,475][valid][INFO] - {"epoch": 459, "valid_loss": "4.048", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "41.289", "valid_code_perplexity": "41.226", "valid_temp": "1.825", "valid_loss_0": "3.879", "valid_loss_1": "0.135", "valid_loss_2": "0.034", "valid_accuracy": "0.26762", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "18360", "valid_best_loss": "3.656"}
[2022-01-03 14:33:13,479][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 459 @ 18360 updates
[2022-01-03 14:33:13,480][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:33:17,426][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:33:17,455][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 459 @ 18360 updates, score 4.048) (writing took 3.976005570963025 seconds)
[2022-01-03 14:33:17,455][fairseq_cli.train][INFO] - end of epoch 459 (average epoch stats below)
[2022-01-03 14:33:17,468][train][INFO] - {"epoch": 459, "train_loss": "3.991", "train_ntokens": "1785.55", "train_nsentences": "4.95", "train_prob_perplexity": "43.039", "train_code_perplexity": "43.021", "train_temp": "1.825", "train_loss_0": "3.82", "train_loss_1": "0.135", "train_loss_2": "0.037", "train_accuracy": "0.30432", "train_wps": "3909.2", "train_ups": "2.19", "train_wpb": "1785.5", "train_bsz": "5", "train_num_updates": "18360", "train_lr": "0.000286875", "train_gnorm": "0.687", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "8615"}
[2022-01-03 14:33:17,527][fairseq.trainer][INFO] - begin training epoch 460
[2022-01-03 14:33:17,528][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:33:31,530][train_inner][INFO] - {"epoch": 460, "update": 460.0, "loss": "4.019", "ntokens": "1789.46", "nsentences": "4.95", "prob_perplexity": "43.12", "code_perplexity": "43.092", "temp": "1.825", "loss_0": "3.847", "loss_1": "0.135", "loss_2": "0.038", "accuracy": "0.30241", "wps": "3659.9", "ups": "2.05", "wpb": "1789.5", "bsz": "5", "num_updates": "18400", "lr": "0.0002875", "gnorm": "0.663", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "8629"}
[2022-01-03 14:33:31,531][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:33:31,904][valid][INFO] - {"epoch": 460, "valid_loss": "4.204", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "42.052", "valid_code_perplexity": "42.07", "valid_temp": "1.824", "valid_loss_0": "4.032", "valid_loss_1": "0.135", "valid_loss_2": "0.037", "valid_accuracy": "0.28608", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "18400", "valid_best_loss": "3.656"}
[2022-01-03 14:33:31,908][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 460 @ 18400 updates
[2022-01-03 14:33:31,910][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:33:35,644][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:33:35,670][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 460 @ 18400 updates, score 4.204) (writing took 3.7620716309174895 seconds)
[2022-01-03 14:33:35,671][fairseq_cli.train][INFO] - end of epoch 460 (average epoch stats below)
[2022-01-03 14:33:35,684][train][INFO] - {"epoch": 460, "train_loss": "4.006", "train_ntokens": "1786.55", "train_nsentences": "4.95", "train_prob_perplexity": "42.937", "train_code_perplexity": "42.906", "train_temp": "1.824", "train_loss_0": "3.833", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.30667", "train_wps": "3925.9", "train_ups": "2.2", "train_wpb": "1786.5", "train_bsz": "5", "train_num_updates": "18400", "train_lr": "0.0002875", "train_gnorm": "0.669", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "8633"}
[2022-01-03 14:33:35,755][fairseq.trainer][INFO] - begin training epoch 461
[2022-01-03 14:33:35,756][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:33:49,671][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:33:50,163][valid][INFO] - {"epoch": 461, "valid_loss": "4.187", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "40.957", "valid_code_perplexity": "41.033", "valid_temp": "1.824", "valid_loss_0": "4.019", "valid_loss_1": "0.135", "valid_loss_2": "0.033", "valid_accuracy": "0.27973", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "18440", "valid_best_loss": "3.656"}
[2022-01-03 14:33:50,165][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 461 @ 18440 updates
[2022-01-03 14:33:50,165][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:33:53,844][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:33:53,863][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 461 @ 18440 updates, score 4.187) (writing took 3.697739388793707 seconds)
[2022-01-03 14:33:53,863][fairseq_cli.train][INFO] - end of epoch 461 (average epoch stats below)
[2022-01-03 14:33:53,875][train][INFO] - {"epoch": 461, "train_loss": "4.017", "train_ntokens": "1805.88", "train_nsentences": "4.95", "train_prob_perplexity": "43.569", "train_code_perplexity": "43.535", "train_temp": "1.824", "train_loss_0": "3.843", "train_loss_1": "0.134", "train_loss_2": "0.039", "train_accuracy": "0.30069", "train_wps": "3973.5", "train_ups": "2.2", "train_wpb": "1805.9", "train_bsz": "5", "train_num_updates": "18440", "train_lr": "0.000288125", "train_gnorm": "0.663", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "8651"}
[2022-01-03 14:33:53,923][fairseq.trainer][INFO] - begin training epoch 462
[2022-01-03 14:33:53,924][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:34:07,792][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:34:08,209][valid][INFO] - {"epoch": 462, "valid_loss": "3.945", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "41.827", "valid_code_perplexity": "41.669", "valid_temp": "1.823", "valid_loss_0": "3.775", "valid_loss_1": "0.135", "valid_loss_2": "0.035", "valid_accuracy": "0.2875", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "18480", "valid_best_loss": "3.656"}
[2022-01-03 14:34:08,214][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 462 @ 18480 updates
[2022-01-03 14:34:08,216][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:34:12,149][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:34:12,177][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 462 @ 18480 updates, score 3.945) (writing took 3.962501565925777 seconds)
[2022-01-03 14:34:12,177][fairseq_cli.train][INFO] - end of epoch 462 (average epoch stats below)
[2022-01-03 14:34:12,190][train][INFO] - {"epoch": 462, "train_loss": "4.001", "train_ntokens": "1786.97", "train_nsentences": "4.95", "train_prob_perplexity": "43.174", "train_code_perplexity": "43.156", "train_temp": "1.824", "train_loss_0": "3.828", "train_loss_1": "0.135", "train_loss_2": "0.038", "train_accuracy": "0.3072", "train_wps": "3905.5", "train_ups": "2.19", "train_wpb": "1787", "train_bsz": "5", "train_num_updates": "18480", "train_lr": "0.00028875", "train_gnorm": "0.669", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "8670"}
[2022-01-03 14:34:12,264][fairseq.trainer][INFO] - begin training epoch 463
[2022-01-03 14:34:12,265][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:34:26,177][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:34:26,644][valid][INFO] - {"epoch": 463, "valid_loss": "4.094", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "35.811", "valid_code_perplexity": "35.771", "valid_temp": "1.823", "valid_loss_0": "3.921", "valid_loss_1": "0.136", "valid_loss_2": "0.037", "valid_accuracy": "0.3011", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "18520", "valid_best_loss": "3.656"}
[2022-01-03 14:34:26,646][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 463 @ 18520 updates
[2022-01-03 14:34:26,646][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:34:30,639][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:34:30,659][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 463 @ 18520 updates, score 4.094) (writing took 4.013065464794636 seconds)
[2022-01-03 14:34:30,659][fairseq_cli.train][INFO] - end of epoch 463 (average epoch stats below)
[2022-01-03 14:34:30,671][train][INFO] - {"epoch": 463, "train_loss": "3.998", "train_ntokens": "1797.92", "train_nsentences": "4.95", "train_prob_perplexity": "42.733", "train_code_perplexity": "42.704", "train_temp": "1.823", "train_loss_0": "3.827", "train_loss_1": "0.135", "train_loss_2": "0.036", "train_accuracy": "0.30745", "train_wps": "3893.8", "train_ups": "2.17", "train_wpb": "1797.9", "train_bsz": "5", "train_num_updates": "18520", "train_lr": "0.000289375", "train_gnorm": "0.662", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8688"}
[2022-01-03 14:34:30,725][fairseq.trainer][INFO] - begin training epoch 464
[2022-01-03 14:34:30,726][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:34:44,657][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:34:45,145][valid][INFO] - {"epoch": 464, "valid_loss": "3.978", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "41.668", "valid_code_perplexity": "41.684", "valid_temp": "1.823", "valid_loss_0": "3.808", "valid_loss_1": "0.135", "valid_loss_2": "0.035", "valid_accuracy": "0.29645", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "18560", "valid_best_loss": "3.656"}
[2022-01-03 14:34:45,147][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 464 @ 18560 updates
[2022-01-03 14:34:45,148][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:34:48,882][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:34:48,902][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 464 @ 18560 updates, score 3.978) (writing took 3.755061692558229 seconds)
[2022-01-03 14:34:48,903][fairseq_cli.train][INFO] - end of epoch 464 (average epoch stats below)
[2022-01-03 14:34:48,915][train][INFO] - {"epoch": 464, "train_loss": "4.01", "train_ntokens": "1803.88", "train_nsentences": "4.95", "train_prob_perplexity": "43.231", "train_code_perplexity": "43.21", "train_temp": "1.823", "train_loss_0": "3.838", "train_loss_1": "0.135", "train_loss_2": "0.037", "train_accuracy": "0.30328", "train_wps": "3957.8", "train_ups": "2.19", "train_wpb": "1803.9", "train_bsz": "5", "train_num_updates": "18560", "train_lr": "0.00029", "train_gnorm": "0.669", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8706"}
[2022-01-03 14:34:48,959][fairseq.trainer][INFO] - begin training epoch 465
[2022-01-03 14:34:48,959][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:35:02,833][train_inner][INFO] - {"epoch": 465, "update": 465.0, "loss": "4.01", "ntokens": "1799.08", "nsentences": "4.95", "prob_perplexity": "43.253", "code_perplexity": "43.229", "temp": "1.823", "loss_0": "3.838", "loss_1": "0.135", "loss_2": "0.038", "accuracy": "0.30382", "wps": "3941.4", "ups": "2.19", "wpb": "1799.1", "bsz": "5", "num_updates": "18600", "lr": "0.000290625", "gnorm": "0.664", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "8720"}
[2022-01-03 14:35:02,834][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:35:03,243][valid][INFO] - {"epoch": 465, "valid_loss": "4.288", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "41.898", "valid_code_perplexity": "41.839", "valid_temp": "1.822", "valid_loss_0": "4.117", "valid_loss_1": "0.135", "valid_loss_2": "0.036", "valid_accuracy": "0.26448", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "18600", "valid_best_loss": "3.656"}
[2022-01-03 14:35:03,247][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 465 @ 18600 updates
[2022-01-03 14:35:03,248][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:35:07,158][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:35:07,185][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 465 @ 18600 updates, score 4.288) (writing took 3.9380206763744354 seconds)
[2022-01-03 14:35:07,185][fairseq_cli.train][INFO] - end of epoch 465 (average epoch stats below)
[2022-01-03 14:35:07,198][train][INFO] - {"epoch": 465, "train_loss": "4.026", "train_ntokens": "1800.75", "train_nsentences": "4.95", "train_prob_perplexity": "43.556", "train_code_perplexity": "43.54", "train_temp": "1.823", "train_loss_0": "3.853", "train_loss_1": "0.134", "train_loss_2": "0.038", "train_accuracy": "0.30054", "train_wps": "3942.5", "train_ups": "2.19", "train_wpb": "1800.8", "train_bsz": "5", "train_num_updates": "18600", "train_lr": "0.000290625", "train_gnorm": "0.659", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "8725"}
[2022-01-03 14:35:07,271][fairseq.trainer][INFO] - begin training epoch 466
[2022-01-03 14:35:07,272][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:35:21,265][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:35:21,681][valid][INFO] - {"epoch": 466, "valid_loss": "4.233", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "42.463", "valid_code_perplexity": "42.28", "valid_temp": "1.822", "valid_loss_0": "4.061", "valid_loss_1": "0.135", "valid_loss_2": "0.037", "valid_accuracy": "0.27183", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "18640", "valid_best_loss": "3.656"}
[2022-01-03 14:35:21,684][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 466 @ 18640 updates
[2022-01-03 14:35:21,685][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:35:25,347][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:35:25,375][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 466 @ 18640 updates, score 4.233) (writing took 3.6911851540207863 seconds)
[2022-01-03 14:35:25,376][fairseq_cli.train][INFO] - end of epoch 466 (average epoch stats below)
[2022-01-03 14:35:25,388][train][INFO] - {"epoch": 466, "train_loss": "4.01", "train_ntokens": "1796.33", "train_nsentences": "4.95", "train_prob_perplexity": "44.094", "train_code_perplexity": "44.07", "train_temp": "1.822", "train_loss_0": "3.838", "train_loss_1": "0.134", "train_loss_2": "0.038", "train_accuracy": "0.30224", "train_wps": "3952.9", "train_ups": "2.2", "train_wpb": "1796.3", "train_bsz": "5", "train_num_updates": "18640", "train_lr": "0.00029125", "train_gnorm": "0.654", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "7.2", "train_wall": "8743"}
[2022-01-03 14:35:25,465][fairseq.trainer][INFO] - begin training epoch 467
[2022-01-03 14:35:25,466][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:35:39,319][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:35:39,718][valid][INFO] - {"epoch": 467, "valid_loss": "3.941", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "42.888", "valid_code_perplexity": "42.715", "valid_temp": "1.822", "valid_loss_0": "3.768", "valid_loss_1": "0.135", "valid_loss_2": "0.038", "valid_accuracy": "0.30886", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "18680", "valid_best_loss": "3.656"}
[2022-01-03 14:35:39,721][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 467 @ 18680 updates
[2022-01-03 14:35:39,722][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:35:43,689][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:35:43,718][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 467 @ 18680 updates, score 3.941) (writing took 3.996706551872194 seconds)
[2022-01-03 14:35:43,719][fairseq_cli.train][INFO] - end of epoch 467 (average epoch stats below)
[2022-01-03 14:35:43,731][train][INFO] - {"epoch": 467, "train_loss": "4.021", "train_ntokens": "1808", "train_nsentences": "4.95", "train_prob_perplexity": "43.534", "train_code_perplexity": "43.51", "train_temp": "1.822", "train_loss_0": "3.849", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.29913", "train_wps": "3945.4", "train_ups": "2.18", "train_wpb": "1808", "train_bsz": "5", "train_num_updates": "18680", "train_lr": "0.000291875", "train_gnorm": "0.666", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "8761"}
[2022-01-03 14:35:43,811][fairseq.trainer][INFO] - begin training epoch 468
[2022-01-03 14:35:43,812][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:35:57,712][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:35:58,125][valid][INFO] - {"epoch": 468, "valid_loss": "4.14", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "42.484", "valid_code_perplexity": "42.443", "valid_temp": "1.821", "valid_loss_0": "3.971", "valid_loss_1": "0.135", "valid_loss_2": "0.034", "valid_accuracy": "0.31048", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "18720", "valid_best_loss": "3.656"}
[2022-01-03 14:35:58,127][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 468 @ 18720 updates
[2022-01-03 14:35:58,128][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:36:01,921][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:36:01,948][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 468 @ 18720 updates, score 4.14) (writing took 3.8214206928387284 seconds)
[2022-01-03 14:36:01,949][fairseq_cli.train][INFO] - end of epoch 468 (average epoch stats below)
[2022-01-03 14:36:01,962][train][INFO] - {"epoch": 468, "train_loss": "4.007", "train_ntokens": "1805.35", "train_nsentences": "4.95", "train_prob_perplexity": "43.818", "train_code_perplexity": "43.804", "train_temp": "1.821", "train_loss_0": "3.836", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30361", "train_wps": "3963.9", "train_ups": "2.2", "train_wpb": "1805.3", "train_bsz": "5", "train_num_updates": "18720", "train_lr": "0.0002925", "train_gnorm": "0.645", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.8", "train_wall": "8779"}
[2022-01-03 14:36:02,015][fairseq.trainer][INFO] - begin training epoch 469
[2022-01-03 14:36:02,016][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:36:15,833][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:36:16,251][valid][INFO] - {"epoch": 469, "valid_loss": "4.04", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "41.136", "valid_code_perplexity": "41.166", "valid_temp": "1.821", "valid_loss_0": "3.869", "valid_loss_1": "0.135", "valid_loss_2": "0.035", "valid_accuracy": "0.30161", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "18760", "valid_best_loss": "3.656"}
[2022-01-03 14:36:16,254][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 469 @ 18760 updates
[2022-01-03 14:36:16,255][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:36:20,212][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:36:20,241][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 469 @ 18760 updates, score 4.04) (writing took 3.9870283138006926 seconds)
[2022-01-03 14:36:20,242][fairseq_cli.train][INFO] - end of epoch 469 (average epoch stats below)
[2022-01-03 14:36:20,254][train][INFO] - {"epoch": 469, "train_loss": "3.983", "train_ntokens": "1785.78", "train_nsentences": "4.95", "train_prob_perplexity": "43.369", "train_code_perplexity": "43.359", "train_temp": "1.821", "train_loss_0": "3.812", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30425", "train_wps": "3907.6", "train_ups": "2.19", "train_wpb": "1785.8", "train_bsz": "5", "train_num_updates": "18760", "train_lr": "0.000293125", "train_gnorm": "0.661", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "8798"}
[2022-01-03 14:36:20,332][fairseq.trainer][INFO] - begin training epoch 470
[2022-01-03 14:36:20,333][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:36:34,317][train_inner][INFO] - {"epoch": 470, "update": 470.0, "loss": "4.005", "ntokens": "1794.14", "nsentences": "4.95", "prob_perplexity": "43.614", "code_perplexity": "43.596", "temp": "1.821", "loss_0": "3.834", "loss_1": "0.134", "loss_2": "0.037", "accuracy": "0.30281", "wps": "3922.8", "ups": "2.19", "wpb": "1794.1", "bsz": "5", "num_updates": "18800", "lr": "0.00029375", "gnorm": "0.653", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "8812"}
[2022-01-03 14:36:34,318][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:36:34,718][valid][INFO] - {"epoch": 470, "valid_loss": "3.906", "valid_ntokens": "696", "valid_nsentences": "2", "valid_prob_perplexity": "42.1", "valid_code_perplexity": "42.076", "valid_temp": "1.821", "valid_loss_0": "3.739", "valid_loss_1": "0.135", "valid_loss_2": "0.032", "valid_accuracy": "0.33046", "valid_wps": "0", "valid_wpb": "696", "valid_bsz": "2", "valid_num_updates": "18800", "valid_best_loss": "3.656"}
[2022-01-03 14:36:34,722][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 470 @ 18800 updates
[2022-01-03 14:36:34,723][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:36:38,482][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:36:38,511][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 470 @ 18800 updates, score 3.906) (writing took 3.789226216264069 seconds)
[2022-01-03 14:36:38,511][fairseq_cli.train][INFO] - end of epoch 470 (average epoch stats below)
[2022-01-03 14:36:38,524][train][INFO] - {"epoch": 470, "train_loss": "4.004", "train_ntokens": "1775.25", "train_nsentences": "4.95", "train_prob_perplexity": "43.254", "train_code_perplexity": "43.237", "train_temp": "1.821", "train_loss_0": "3.833", "train_loss_1": "0.135", "train_loss_2": "0.037", "train_accuracy": "0.30489", "train_wps": "3889.4", "train_ups": "2.19", "train_wpb": "1775.2", "train_bsz": "5", "train_num_updates": "18800", "train_lr": "0.00029375", "train_gnorm": "0.639", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8816"}
[2022-01-03 14:36:38,607][fairseq.trainer][INFO] - begin training epoch 471
[2022-01-03 14:36:38,608][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:36:52,488][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:36:52,887][valid][INFO] - {"epoch": 471, "valid_loss": "4.032", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "38.726", "valid_code_perplexity": "38.657", "valid_temp": "1.82", "valid_loss_0": "3.855", "valid_loss_1": "0.136", "valid_loss_2": "0.042", "valid_accuracy": "0.29921", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "18840", "valid_best_loss": "3.656"}
[2022-01-03 14:36:52,890][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 471 @ 18840 updates
[2022-01-03 14:36:52,891][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:36:56,771][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:36:56,779][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 471 @ 18840 updates, score 4.032) (writing took 3.8893633438274264 seconds)
[2022-01-03 14:36:56,780][fairseq_cli.train][INFO] - end of epoch 471 (average epoch stats below)
[2022-01-03 14:36:56,792][train][INFO] - {"epoch": 471, "train_loss": "4.004", "train_ntokens": "1795.03", "train_nsentences": "4.95", "train_prob_perplexity": "43.818", "train_code_perplexity": "43.792", "train_temp": "1.82", "train_loss_0": "3.833", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30469", "train_wps": "3933.1", "train_ups": "2.19", "train_wpb": "1795", "train_bsz": "5", "train_num_updates": "18840", "train_lr": "0.000294375", "train_gnorm": "0.658", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "8834"}
[2022-01-03 14:36:56,876][fairseq.trainer][INFO] - begin training epoch 472
[2022-01-03 14:36:56,877][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:37:10,733][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:37:11,417][valid][INFO] - {"epoch": 472, "valid_loss": "4.348", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "40.76", "valid_code_perplexity": "40.69", "valid_temp": "1.82", "valid_loss_0": "4.178", "valid_loss_1": "0.135", "valid_loss_2": "0.035", "valid_accuracy": "0.26819", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "18880", "valid_best_loss": "3.656"}
[2022-01-03 14:37:11,419][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 472 @ 18880 updates
[2022-01-03 14:37:11,420][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:37:15,161][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:37:15,193][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 472 @ 18880 updates, score 4.348) (writing took 3.77372760605067 seconds)
[2022-01-03 14:37:15,194][fairseq_cli.train][INFO] - end of epoch 472 (average epoch stats below)
[2022-01-03 14:37:15,207][train][INFO] - {"epoch": 472, "train_loss": "3.964", "train_ntokens": "1767.85", "train_nsentences": "4.95", "train_prob_perplexity": "43.6", "train_code_perplexity": "43.575", "train_temp": "1.82", "train_loss_0": "3.793", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30861", "train_wps": "3842.8", "train_ups": "2.17", "train_wpb": "1767.8", "train_bsz": "5", "train_num_updates": "18880", "train_lr": "0.000295", "train_gnorm": "0.64", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "8853"}
[2022-01-03 14:37:15,280][fairseq.trainer][INFO] - begin training epoch 473
[2022-01-03 14:37:15,281][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:37:29,209][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:37:29,705][valid][INFO] - {"epoch": 473, "valid_loss": "4.204", "valid_ntokens": "802", "valid_nsentences": "2", "valid_prob_perplexity": "41.329", "valid_code_perplexity": "41.297", "valid_temp": "1.819", "valid_loss_0": "4.032", "valid_loss_1": "0.135", "valid_loss_2": "0.037", "valid_accuracy": "0.28055", "valid_wps": "0", "valid_wpb": "802", "valid_bsz": "2", "valid_num_updates": "18920", "valid_best_loss": "3.656"}
[2022-01-03 14:37:29,706][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 473 @ 18920 updates
[2022-01-03 14:37:29,707][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:37:33,626][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:37:33,637][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 473 @ 18920 updates, score 4.204) (writing took 3.9310136772692204 seconds)
[2022-01-03 14:37:33,638][fairseq_cli.train][INFO] - end of epoch 473 (average epoch stats below)
[2022-01-03 14:37:33,651][train][INFO] - {"epoch": 473, "train_loss": "4.024", "train_ntokens": "1802.58", "train_nsentences": "4.95", "train_prob_perplexity": "44.078", "train_code_perplexity": "44.066", "train_temp": "1.82", "train_loss_0": "3.852", "train_loss_1": "0.134", "train_loss_2": "0.038", "train_accuracy": "0.30175", "train_wps": "3912.1", "train_ups": "2.17", "train_wpb": "1802.6", "train_bsz": "5", "train_num_updates": "18920", "train_lr": "0.000295625", "train_gnorm": "0.645", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "8871"}
[2022-01-03 14:37:33,724][fairseq.trainer][INFO] - begin training epoch 474
[2022-01-03 14:37:33,725][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:37:47,534][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:37:48,023][valid][INFO] - {"epoch": 474, "valid_loss": "4.016", "valid_ntokens": "706", "valid_nsentences": "2", "valid_prob_perplexity": "41.337", "valid_code_perplexity": "41.135", "valid_temp": "1.819", "valid_loss_0": "3.845", "valid_loss_1": "0.135", "valid_loss_2": "0.036", "valid_accuracy": "0.28612", "valid_wps": "0", "valid_wpb": "706", "valid_bsz": "2", "valid_num_updates": "18960", "valid_best_loss": "3.656"}
[2022-01-03 14:37:48,025][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 474 @ 18960 updates
[2022-01-03 14:37:48,025][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:37:51,816][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:37:51,842][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 474 @ 18960 updates, score 4.016) (writing took 3.8174303509294987 seconds)
[2022-01-03 14:37:51,843][fairseq_cli.train][INFO] - end of epoch 474 (average epoch stats below)
[2022-01-03 14:37:51,856][train][INFO] - {"epoch": 474, "train_loss": "4.001", "train_ntokens": "1804.17", "train_nsentences": "4.95", "train_prob_perplexity": "43.339", "train_code_perplexity": "43.312", "train_temp": "1.819", "train_loss_0": "3.83", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30817", "train_wps": "3966.9", "train_ups": "2.2", "train_wpb": "1804.2", "train_bsz": "5", "train_num_updates": "18960", "train_lr": "0.00029625", "train_gnorm": "0.68", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "8889"}
[2022-01-03 14:37:51,927][fairseq.trainer][INFO] - begin training epoch 475
[2022-01-03 14:37:51,928][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:38:05,876][train_inner][INFO] - {"epoch": 475, "update": 475.0, "loss": "4.006", "ntokens": "1792.56", "nsentences": "4.95", "prob_perplexity": "43.803", "code_perplexity": "43.778", "temp": "1.82", "loss_0": "3.834", "loss_1": "0.134", "loss_2": "0.037", "accuracy": "0.30458", "wps": "3916.2", "ups": "2.18", "wpb": "1792.6", "bsz": "5", "num_updates": "19000", "lr": "0.000296875", "gnorm": "0.654", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "8903"}
[2022-01-03 14:38:05,877][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:38:06,321][valid][INFO] - {"epoch": 475, "valid_loss": "3.834", "valid_ntokens": "696", "valid_nsentences": "2", "valid_prob_perplexity": "42.672", "valid_code_perplexity": "42.486", "valid_temp": "1.819", "valid_loss_0": "3.66", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.30747", "valid_wps": "0", "valid_wpb": "696", "valid_bsz": "2", "valid_num_updates": "19000", "valid_best_loss": "3.656"}
[2022-01-03 14:38:06,323][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 475 @ 19000 updates
[2022-01-03 14:38:06,324][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:38:10,022][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:38:10,051][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 475 @ 19000 updates, score 3.834) (writing took 3.7280035400763154 seconds)
[2022-01-03 14:38:10,052][fairseq_cli.train][INFO] - end of epoch 475 (average epoch stats below)
[2022-01-03 14:38:10,064][train][INFO] - {"epoch": 475, "train_loss": "4.035", "train_ntokens": "1793.15", "train_nsentences": "4.95", "train_prob_perplexity": "44.179", "train_code_perplexity": "44.145", "train_temp": "1.819", "train_loss_0": "3.861", "train_loss_1": "0.134", "train_loss_2": "0.039", "train_accuracy": "0.29971", "train_wps": "3941.8", "train_ups": "2.2", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "19000", "train_lr": "0.000296875", "train_gnorm": "0.646", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "8907"}
[2022-01-03 14:38:10,143][fairseq.trainer][INFO] - begin training epoch 476
[2022-01-03 14:38:10,144][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:38:23,998][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:38:24,399][valid][INFO] - {"epoch": 476, "valid_loss": "4.175", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "43.33", "valid_code_perplexity": "43.266", "valid_temp": "1.818", "valid_loss_0": "4.002", "valid_loss_1": "0.135", "valid_loss_2": "0.039", "valid_accuracy": "0.29863", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "19040", "valid_best_loss": "3.656"}
[2022-01-03 14:38:24,402][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 476 @ 19040 updates
[2022-01-03 14:38:24,403][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:38:28,559][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:38:28,589][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 476 @ 19040 updates, score 4.175) (writing took 4.186312172561884 seconds)
[2022-01-03 14:38:28,589][fairseq_cli.train][INFO] - end of epoch 476 (average epoch stats below)
[2022-01-03 14:38:28,602][train][INFO] - {"epoch": 476, "train_loss": "4.008", "train_ntokens": "1799.35", "train_nsentences": "4.95", "train_prob_perplexity": "44.165", "train_code_perplexity": "44.145", "train_temp": "1.819", "train_loss_0": "3.835", "train_loss_1": "0.134", "train_loss_2": "0.039", "train_accuracy": "0.3043", "train_wps": "3885.3", "train_ups": "2.16", "train_wpb": "1799.3", "train_bsz": "5", "train_num_updates": "19040", "train_lr": "0.0002975", "train_gnorm": "0.647", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8926"}
[2022-01-03 14:38:28,675][fairseq.trainer][INFO] - begin training epoch 477
[2022-01-03 14:38:28,676][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:38:42,636][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:38:43,040][valid][INFO] - {"epoch": 477, "valid_loss": "4.043", "valid_ntokens": "804", "valid_nsentences": "2", "valid_prob_perplexity": "43.202", "valid_code_perplexity": "43.258", "valid_temp": "1.818", "valid_loss_0": "3.875", "valid_loss_1": "0.135", "valid_loss_2": "0.033", "valid_accuracy": "0.27985", "valid_wps": "0", "valid_wpb": "804", "valid_bsz": "2", "valid_num_updates": "19080", "valid_best_loss": "3.656"}
[2022-01-03 14:38:43,043][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 477 @ 19080 updates
[2022-01-03 14:38:43,043][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:38:46,968][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:38:46,997][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 477 @ 19080 updates, score 4.043) (writing took 3.9542866060510278 seconds)
[2022-01-03 14:38:46,997][fairseq_cli.train][INFO] - end of epoch 477 (average epoch stats below)
[2022-01-03 14:38:47,010][train][INFO] - {"epoch": 477, "train_loss": "4.011", "train_ntokens": "1785.28", "train_nsentences": "4.95", "train_prob_perplexity": "44.634", "train_code_perplexity": "44.619", "train_temp": "1.818", "train_loss_0": "3.84", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30275", "train_wps": "3881.9", "train_ups": "2.17", "train_wpb": "1785.3", "train_bsz": "5", "train_num_updates": "19080", "train_lr": "0.000298125", "train_gnorm": "0.682", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "8944"}
[2022-01-03 14:38:47,068][fairseq.trainer][INFO] - begin training epoch 478
[2022-01-03 14:38:47,069][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:39:00,880][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:39:01,295][valid][INFO] - {"epoch": 478, "valid_loss": "3.987", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "43.076", "valid_code_perplexity": "42.967", "valid_temp": "1.818", "valid_loss_0": "3.819", "valid_loss_1": "0.135", "valid_loss_2": "0.034", "valid_accuracy": "0.28493", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "19120", "valid_best_loss": "3.656"}
[2022-01-03 14:39:01,299][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 478 @ 19120 updates
[2022-01-03 14:39:01,300][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:39:05,186][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:39:05,206][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 478 @ 19120 updates, score 3.987) (writing took 3.9062654841691256 seconds)
[2022-01-03 14:39:05,206][fairseq_cli.train][INFO] - end of epoch 478 (average epoch stats below)
[2022-01-03 14:39:05,218][train][INFO] - {"epoch": 478, "train_loss": "4.007", "train_ntokens": "1803.67", "train_nsentences": "4.95", "train_prob_perplexity": "44.046", "train_code_perplexity": "44.027", "train_temp": "1.818", "train_loss_0": "3.838", "train_loss_1": "0.134", "train_loss_2": "0.034", "train_accuracy": "0.30272", "train_wps": "3964.9", "train_ups": "2.2", "train_wpb": "1803.7", "train_bsz": "5", "train_num_updates": "19120", "train_lr": "0.00029875", "train_gnorm": "0.659", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8963"}
[2022-01-03 14:39:05,267][fairseq.trainer][INFO] - begin training epoch 479
[2022-01-03 14:39:05,267][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:39:19,155][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:39:19,551][valid][INFO] - {"epoch": 479, "valid_loss": "4.261", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "43.863", "valid_code_perplexity": "43.831", "valid_temp": "1.817", "valid_loss_0": "4.093", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.23747", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "19160", "valid_best_loss": "3.656"}
[2022-01-03 14:39:19,554][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 479 @ 19160 updates
[2022-01-03 14:39:19,554][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:39:23,488][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:39:23,516][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 479 @ 19160 updates, score 4.261) (writing took 3.9627453815191984 seconds)
[2022-01-03 14:39:23,517][fairseq_cli.train][INFO] - end of epoch 479 (average epoch stats below)
[2022-01-03 14:39:23,529][train][INFO] - {"epoch": 479, "train_loss": "3.97", "train_ntokens": "1788.1", "train_nsentences": "4.95", "train_prob_perplexity": "44.409", "train_code_perplexity": "44.38", "train_temp": "1.817", "train_loss_0": "3.8", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30653", "train_wps": "3908.7", "train_ups": "2.19", "train_wpb": "1788.1", "train_bsz": "5", "train_num_updates": "19160", "train_lr": "0.000299375", "train_gnorm": "0.635", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "8981"}
[2022-01-03 14:39:23,608][fairseq.trainer][INFO] - begin training epoch 480
[2022-01-03 14:39:23,609][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:39:37,618][train_inner][INFO] - {"epoch": 480, "update": 480.0, "loss": "3.993", "ntokens": "1791.5", "nsentences": "4.95", "prob_perplexity": "44.425", "code_perplexity": "44.404", "temp": "1.818", "loss_0": "3.822", "loss_1": "0.134", "loss_2": "0.036", "accuracy": "0.30517", "wps": "3906", "ups": "2.18", "wpb": "1791.5", "bsz": "5", "num_updates": "19200", "lr": "0.0003", "gnorm": "0.66", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "8995"}
[2022-01-03 14:39:37,619][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:39:38,010][valid][INFO] - {"epoch": 480, "valid_loss": "3.952", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "43.274", "valid_code_perplexity": "43.251", "valid_temp": "1.817", "valid_loss_0": "3.783", "valid_loss_1": "0.135", "valid_loss_2": "0.035", "valid_accuracy": "0.30141", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "19200", "valid_best_loss": "3.656"}
[2022-01-03 14:39:38,013][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 480 @ 19200 updates
[2022-01-03 14:39:38,014][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:39:41,706][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:39:41,724][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 480 @ 19200 updates, score 3.952) (writing took 3.71064932923764 seconds)
[2022-01-03 14:39:41,724][fairseq_cli.train][INFO] - end of epoch 480 (average epoch stats below)
[2022-01-03 14:39:41,737][train][INFO] - {"epoch": 480, "train_loss": "3.968", "train_ntokens": "1781.1", "train_nsentences": "4.95", "train_prob_perplexity": "44.868", "train_code_perplexity": "44.847", "train_temp": "1.817", "train_loss_0": "3.798", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30958", "train_wps": "3915.5", "train_ups": "2.2", "train_wpb": "1781.1", "train_bsz": "5", "train_num_updates": "19200", "train_lr": "0.0003", "train_gnorm": "0.678", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "8999"}
[2022-01-03 14:39:41,789][fairseq.trainer][INFO] - begin training epoch 481
[2022-01-03 14:39:41,789][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:39:55,882][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:39:56,296][valid][INFO] - {"epoch": 481, "valid_loss": "4.22", "valid_ntokens": "802", "valid_nsentences": "2", "valid_prob_perplexity": "40.323", "valid_code_perplexity": "40.51", "valid_temp": "1.817", "valid_loss_0": "4.048", "valid_loss_1": "0.135", "valid_loss_2": "0.036", "valid_accuracy": "0.27805", "valid_wps": "0", "valid_wpb": "802", "valid_bsz": "2", "valid_num_updates": "19240", "valid_best_loss": "3.656"}
[2022-01-03 14:39:56,300][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 481 @ 19240 updates
[2022-01-03 14:39:56,300][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:39:59,966][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:39:59,991][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 481 @ 19240 updates, score 4.22) (writing took 3.6918095611035824 seconds)
[2022-01-03 14:39:59,992][fairseq_cli.train][INFO] - end of epoch 481 (average epoch stats below)
[2022-01-03 14:40:00,005][train][INFO] - {"epoch": 481, "train_loss": "4.017", "train_ntokens": "1797.05", "train_nsentences": "4.95", "train_prob_perplexity": "44.606", "train_code_perplexity": "44.589", "train_temp": "1.817", "train_loss_0": "3.847", "train_loss_1": "0.134", "train_loss_2": "0.035", "train_accuracy": "0.30177", "train_wps": "3937.7", "train_ups": "2.19", "train_wpb": "1797", "train_bsz": "5", "train_num_updates": "19240", "train_lr": "0.000300625", "train_gnorm": "0.636", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9017"}
[2022-01-03 14:40:00,076][fairseq.trainer][INFO] - begin training epoch 482
[2022-01-03 14:40:00,077][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:40:14,005][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:40:14,400][valid][INFO] - {"epoch": 482, "valid_loss": "4.011", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "44.306", "valid_code_perplexity": "44.236", "valid_temp": "1.816", "valid_loss_0": "3.844", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.30882", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "19280", "valid_best_loss": "3.656"}
[2022-01-03 14:40:14,403][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 482 @ 19280 updates
[2022-01-03 14:40:14,404][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:40:18,199][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:40:18,224][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 482 @ 19280 updates, score 4.011) (writing took 3.820915427058935 seconds)
[2022-01-03 14:40:18,224][fairseq_cli.train][INFO] - end of epoch 482 (average epoch stats below)
[2022-01-03 14:40:18,237][train][INFO] - {"epoch": 482, "train_loss": "3.986", "train_ntokens": "1790.72", "train_nsentences": "4.95", "train_prob_perplexity": "44.615", "train_code_perplexity": "44.596", "train_temp": "1.816", "train_loss_0": "3.816", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30785", "train_wps": "3931.5", "train_ups": "2.2", "train_wpb": "1790.7", "train_bsz": "5", "train_num_updates": "19280", "train_lr": "0.00030125", "train_gnorm": "0.654", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9036"}
[2022-01-03 14:40:18,287][fairseq.trainer][INFO] - begin training epoch 483
[2022-01-03 14:40:18,288][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:40:32,331][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:40:32,738][valid][INFO] - {"epoch": 483, "valid_loss": "4.013", "valid_ntokens": "820", "valid_nsentences": "2", "valid_prob_perplexity": "43.749", "valid_code_perplexity": "43.742", "valid_temp": "1.816", "valid_loss_0": "3.845", "valid_loss_1": "0.134", "valid_loss_2": "0.034", "valid_accuracy": "0.2939", "valid_wps": "0", "valid_wpb": "820", "valid_bsz": "2", "valid_num_updates": "19320", "valid_best_loss": "3.656"}
[2022-01-03 14:40:32,742][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 483 @ 19320 updates
[2022-01-03 14:40:32,743][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:40:36,472][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:40:36,501][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 483 @ 19320 updates, score 4.013) (writing took 3.7587090833112597 seconds)
[2022-01-03 14:40:36,501][fairseq_cli.train][INFO] - end of epoch 483 (average epoch stats below)
[2022-01-03 14:40:36,514][train][INFO] - {"epoch": 483, "train_loss": "3.981", "train_ntokens": "1782.05", "train_nsentences": "4.95", "train_prob_perplexity": "45.24", "train_code_perplexity": "45.213", "train_temp": "1.816", "train_loss_0": "3.811", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30471", "train_wps": "3902.9", "train_ups": "2.19", "train_wpb": "1782", "train_bsz": "5", "train_num_updates": "19320", "train_lr": "0.000301875", "train_gnorm": "0.626", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "9054"}
[2022-01-03 14:40:36,587][fairseq.trainer][INFO] - begin training epoch 484
[2022-01-03 14:40:36,588][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:40:50,406][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:40:50,900][valid][INFO] - {"epoch": 484, "valid_loss": "3.948", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "44.367", "valid_code_perplexity": "44.34", "valid_temp": "1.815", "valid_loss_0": "3.777", "valid_loss_1": "0.134", "valid_loss_2": "0.037", "valid_accuracy": "0.30623", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "19360", "valid_best_loss": "3.656"}
[2022-01-03 14:40:50,902][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 484 @ 19360 updates
[2022-01-03 14:40:50,902][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:40:54,735][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:40:54,764][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 484 @ 19360 updates, score 3.948) (writing took 3.8620851011946797 seconds)
[2022-01-03 14:40:54,764][fairseq_cli.train][INFO] - end of epoch 484 (average epoch stats below)
[2022-01-03 14:40:54,777][train][INFO] - {"epoch": 484, "train_loss": "3.994", "train_ntokens": "1797.75", "train_nsentences": "4.95", "train_prob_perplexity": "44.396", "train_code_perplexity": "44.378", "train_temp": "1.816", "train_loss_0": "3.823", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30662", "train_wps": "3940.2", "train_ups": "2.19", "train_wpb": "1797.8", "train_bsz": "5", "train_num_updates": "19360", "train_lr": "0.0003025", "train_gnorm": "0.661", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "9072"}
[2022-01-03 14:40:54,839][fairseq.trainer][INFO] - begin training epoch 485
[2022-01-03 14:40:54,840][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:41:08,727][train_inner][INFO] - {"epoch": 485, "update": 485.0, "loss": "3.99", "ntokens": "1789.94", "nsentences": "4.95", "prob_perplexity": "44.709", "code_perplexity": "44.687", "temp": "1.816", "loss_0": "3.82", "loss_1": "0.134", "loss_2": "0.036", "accuracy": "0.30552", "wps": "3929.8", "ups": "2.2", "wpb": "1789.9", "bsz": "5", "num_updates": "19400", "lr": "0.000303125", "gnorm": "0.643", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "9086"}
[2022-01-03 14:41:08,727][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:41:09,124][valid][INFO] - {"epoch": 485, "valid_loss": "3.961", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "42.696", "valid_code_perplexity": "42.521", "valid_temp": "1.815", "valid_loss_0": "3.791", "valid_loss_1": "0.135", "valid_loss_2": "0.035", "valid_accuracy": "0.32838", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "19400", "valid_best_loss": "3.656"}
[2022-01-03 14:41:09,127][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 485 @ 19400 updates
[2022-01-03 14:41:09,128][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:41:12,933][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:41:12,962][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 485 @ 19400 updates, score 3.961) (writing took 3.8344226367771626 seconds)
[2022-01-03 14:41:12,962][fairseq_cli.train][INFO] - end of epoch 485 (average epoch stats below)
[2022-01-03 14:41:12,975][train][INFO] - {"epoch": 485, "train_loss": "3.973", "train_ntokens": "1782.12", "train_nsentences": "4.95", "train_prob_perplexity": "44.686", "train_code_perplexity": "44.662", "train_temp": "1.815", "train_loss_0": "3.801", "train_loss_1": "0.134", "train_loss_2": "0.038", "train_accuracy": "0.30666", "train_wps": "3919.9", "train_ups": "2.2", "train_wpb": "1782.1", "train_bsz": "5", "train_num_updates": "19400", "train_lr": "0.000303125", "train_gnorm": "0.638", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "9090"}
[2022-01-03 14:41:13,047][fairseq.trainer][INFO] - begin training epoch 486
[2022-01-03 14:41:13,047][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:41:26,958][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:41:27,354][valid][INFO] - {"epoch": 486, "valid_loss": "4.087", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "45.549", "valid_code_perplexity": "45.434", "valid_temp": "1.815", "valid_loss_0": "3.918", "valid_loss_1": "0.134", "valid_loss_2": "0.035", "valid_accuracy": "0.28767", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "19440", "valid_best_loss": "3.656"}
[2022-01-03 14:41:27,357][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 486 @ 19440 updates
[2022-01-03 14:41:27,358][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:41:31,161][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:41:31,190][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 486 @ 19440 updates, score 4.087) (writing took 3.8326800912618637 seconds)
[2022-01-03 14:41:31,190][fairseq_cli.train][INFO] - end of epoch 486 (average epoch stats below)
[2022-01-03 14:41:31,203][train][INFO] - {"epoch": 486, "train_loss": "3.998", "train_ntokens": "1791.25", "train_nsentences": "4.95", "train_prob_perplexity": "44.717", "train_code_perplexity": "44.694", "train_temp": "1.815", "train_loss_0": "3.827", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30234", "train_wps": "3933.5", "train_ups": "2.2", "train_wpb": "1791.2", "train_bsz": "5", "train_num_updates": "19440", "train_lr": "0.00030375", "train_gnorm": "0.627", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9109"}
[2022-01-03 14:41:31,249][fairseq.trainer][INFO] - begin training epoch 487
[2022-01-03 14:41:31,250][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:41:45,240][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:41:45,639][valid][INFO] - {"epoch": 487, "valid_loss": "3.968", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "44.013", "valid_code_perplexity": "43.98", "valid_temp": "1.814", "valid_loss_0": "3.799", "valid_loss_1": "0.134", "valid_loss_2": "0.035", "valid_accuracy": "0.31476", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "19480", "valid_best_loss": "3.656"}
[2022-01-03 14:41:45,642][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 487 @ 19480 updates
[2022-01-03 14:41:45,643][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:41:49,414][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:41:49,441][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 487 @ 19480 updates, score 3.968) (writing took 3.7984306598082185 seconds)
[2022-01-03 14:41:49,441][fairseq_cli.train][INFO] - end of epoch 487 (average epoch stats below)
[2022-01-03 14:41:49,454][train][INFO] - {"epoch": 487, "train_loss": "4.019", "train_ntokens": "1799.17", "train_nsentences": "4.95", "train_prob_perplexity": "45.506", "train_code_perplexity": "45.476", "train_temp": "1.815", "train_loss_0": "3.849", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.29784", "train_wps": "3946", "train_ups": "2.19", "train_wpb": "1799.2", "train_bsz": "5", "train_num_updates": "19480", "train_lr": "0.000304375", "train_gnorm": "0.628", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "9127"}
[2022-01-03 14:41:49,529][fairseq.trainer][INFO] - begin training epoch 488
[2022-01-03 14:41:49,530][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:42:03,543][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:42:03,951][valid][INFO] - {"epoch": 488, "valid_loss": "4.152", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "44.491", "valid_code_perplexity": "44.495", "valid_temp": "1.814", "valid_loss_0": "3.985", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.27865", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "19520", "valid_best_loss": "3.656"}
[2022-01-03 14:42:03,955][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 488 @ 19520 updates
[2022-01-03 14:42:03,956][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:42:07,651][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:42:07,681][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 488 @ 19520 updates, score 4.152) (writing took 3.7260905569419265 seconds)
[2022-01-03 14:42:07,681][fairseq_cli.train][INFO] - end of epoch 488 (average epoch stats below)
[2022-01-03 14:42:07,694][train][INFO] - {"epoch": 488, "train_loss": "4.002", "train_ntokens": "1782.83", "train_nsentences": "4.95", "train_prob_perplexity": "45.909", "train_code_perplexity": "45.898", "train_temp": "1.814", "train_loss_0": "3.834", "train_loss_1": "0.134", "train_loss_2": "0.034", "train_accuracy": "0.29933", "train_wps": "3912.5", "train_ups": "2.19", "train_wpb": "1782.8", "train_bsz": "5", "train_num_updates": "19520", "train_lr": "0.000305", "train_gnorm": "0.635", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9145"}
[2022-01-03 14:42:07,771][fairseq.trainer][INFO] - begin training epoch 489
[2022-01-03 14:42:07,772][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:42:21,506][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:42:21,906][valid][INFO] - {"epoch": 489, "valid_loss": "3.884", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "43.895", "valid_code_perplexity": "43.907", "valid_temp": "1.814", "valid_loss_0": "3.712", "valid_loss_1": "0.134", "valid_loss_2": "0.037", "valid_accuracy": "0.33006", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "19560", "valid_best_loss": "3.656"}
[2022-01-03 14:42:21,909][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 489 @ 19560 updates
[2022-01-03 14:42:21,909][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:42:25,881][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:42:25,910][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 489 @ 19560 updates, score 3.884) (writing took 4.001226341351867 seconds)
[2022-01-03 14:42:25,910][fairseq_cli.train][INFO] - end of epoch 489 (average epoch stats below)
[2022-01-03 14:42:25,924][train][INFO] - {"epoch": 489, "train_loss": "3.969", "train_ntokens": "1783.12", "train_nsentences": "4.95", "train_prob_perplexity": "45.521", "train_code_perplexity": "45.504", "train_temp": "1.814", "train_loss_0": "3.798", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30597", "train_wps": "3915.4", "train_ups": "2.2", "train_wpb": "1783.1", "train_bsz": "5", "train_num_updates": "19560", "train_lr": "0.000305625", "train_gnorm": "0.639", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "9163"}
[2022-01-03 14:42:26,014][fairseq.trainer][INFO] - begin training epoch 490
[2022-01-03 14:42:26,015][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:42:39,881][train_inner][INFO] - {"epoch": 490, "update": 490.0, "loss": "3.994", "ntokens": "1788.92", "nsentences": "4.95", "prob_perplexity": "45.496", "code_perplexity": "45.476", "temp": "1.814", "loss_0": "3.824", "loss_1": "0.134", "loss_2": "0.036", "accuracy": "0.30222", "wps": "3925.6", "ups": "2.19", "wpb": "1788.9", "bsz": "5", "num_updates": "19600", "lr": "0.00030625", "gnorm": "0.641", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "9177"}
[2022-01-03 14:42:39,882][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:42:40,283][valid][INFO] - {"epoch": 490, "valid_loss": "4.125", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "44.1", "valid_code_perplexity": "43.911", "valid_temp": "1.813", "valid_loss_0": "3.954", "valid_loss_1": "0.134", "valid_loss_2": "0.037", "valid_accuracy": "0.29545", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "19600", "valid_best_loss": "3.656"}
[2022-01-03 14:42:40,286][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 490 @ 19600 updates
[2022-01-03 14:42:40,286][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:42:44,024][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:42:44,047][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 490 @ 19600 updates, score 4.125) (writing took 3.7607332123443484 seconds)
[2022-01-03 14:42:44,047][fairseq_cli.train][INFO] - end of epoch 490 (average epoch stats below)
[2022-01-03 14:42:44,060][train][INFO] - {"epoch": 490, "train_loss": "3.982", "train_ntokens": "1788.25", "train_nsentences": "4.95", "train_prob_perplexity": "45.826", "train_code_perplexity": "45.81", "train_temp": "1.813", "train_loss_0": "3.811", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30565", "train_wps": "3946.8", "train_ups": "2.21", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "19600", "train_lr": "0.00030625", "train_gnorm": "0.678", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "9181"}
[2022-01-03 14:42:44,130][fairseq.trainer][INFO] - begin training epoch 491
[2022-01-03 14:42:44,131][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:42:58,007][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:42:58,417][valid][INFO] - {"epoch": 491, "valid_loss": "4.326", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "45.921", "valid_code_perplexity": "45.884", "valid_temp": "1.813", "valid_loss_0": "4.155", "valid_loss_1": "0.134", "valid_loss_2": "0.037", "valid_accuracy": "0.24795", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "19640", "valid_best_loss": "3.656"}
[2022-01-03 14:42:58,420][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 491 @ 19640 updates
[2022-01-03 14:42:58,421][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:43:02,377][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:43:02,405][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 491 @ 19640 updates, score 4.326) (writing took 3.984850900247693 seconds)
[2022-01-03 14:43:02,406][fairseq_cli.train][INFO] - end of epoch 491 (average epoch stats below)
[2022-01-03 14:43:02,418][train][INFO] - {"epoch": 491, "train_loss": "4.007", "train_ntokens": "1778.22", "train_nsentences": "4.95", "train_prob_perplexity": "45.534", "train_code_perplexity": "45.507", "train_temp": "1.813", "train_loss_0": "3.838", "train_loss_1": "0.134", "train_loss_2": "0.035", "train_accuracy": "0.3028", "train_wps": "3877.1", "train_ups": "2.18", "train_wpb": "1778.2", "train_bsz": "5", "train_num_updates": "19640", "train_lr": "0.000306875", "train_gnorm": "0.645", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9200"}
[2022-01-03 14:43:02,495][fairseq.trainer][INFO] - begin training epoch 492
[2022-01-03 14:43:02,496][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:43:16,460][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:43:16,868][valid][INFO] - {"epoch": 492, "valid_loss": "4.221", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "45.674", "valid_code_perplexity": "45.576", "valid_temp": "1.813", "valid_loss_0": "4.053", "valid_loss_1": "0.134", "valid_loss_2": "0.035", "valid_accuracy": "0.27676", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "19680", "valid_best_loss": "3.656"}
[2022-01-03 14:43:16,872][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 492 @ 19680 updates
[2022-01-03 14:43:16,873][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:43:20,569][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:43:20,588][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 492 @ 19680 updates, score 4.221) (writing took 3.7163617815822363 seconds)
[2022-01-03 14:43:20,589][fairseq_cli.train][INFO] - end of epoch 492 (average epoch stats below)
[2022-01-03 14:43:20,602][train][INFO] - {"epoch": 492, "train_loss": "3.994", "train_ntokens": "1799.72", "train_nsentences": "4.95", "train_prob_perplexity": "45.69", "train_code_perplexity": "45.665", "train_temp": "1.813", "train_loss_0": "3.824", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30435", "train_wps": "3961.9", "train_ups": "2.2", "train_wpb": "1799.7", "train_bsz": "5", "train_num_updates": "19680", "train_lr": "0.0003075", "train_gnorm": "0.639", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9218"}
[2022-01-03 14:43:20,649][fairseq.trainer][INFO] - begin training epoch 493
[2022-01-03 14:43:20,649][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:43:34,627][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:43:35,026][valid][INFO] - {"epoch": 493, "valid_loss": "3.777", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "44.899", "valid_code_perplexity": "44.855", "valid_temp": "1.812", "valid_loss_0": "3.606", "valid_loss_1": "0.134", "valid_loss_2": "0.037", "valid_accuracy": "0.33898", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "19720", "valid_best_loss": "3.656"}
[2022-01-03 14:43:35,029][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 493 @ 19720 updates
[2022-01-03 14:43:35,030][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:43:38,908][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:43:38,935][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 493 @ 19720 updates, score 3.777) (writing took 3.9059288669377565 seconds)
[2022-01-03 14:43:38,936][fairseq_cli.train][INFO] - end of epoch 493 (average epoch stats below)
[2022-01-03 14:43:38,948][train][INFO] - {"epoch": 493, "train_loss": "3.959", "train_ntokens": "1792.92", "train_nsentences": "4.95", "train_prob_perplexity": "45.579", "train_code_perplexity": "45.553", "train_temp": "1.812", "train_loss_0": "3.79", "train_loss_1": "0.134", "train_loss_2": "0.035", "train_accuracy": "0.30729", "train_wps": "3911.8", "train_ups": "2.18", "train_wpb": "1792.9", "train_bsz": "5", "train_num_updates": "19720", "train_lr": "0.000308125", "train_gnorm": "0.628", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "9236"}
[2022-01-03 14:43:39,010][fairseq.trainer][INFO] - begin training epoch 494
[2022-01-03 14:43:39,011][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:43:52,994][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:43:53,475][valid][INFO] - {"epoch": 494, "valid_loss": "4.115", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "41.489", "valid_code_perplexity": "41.289", "valid_temp": "1.812", "valid_loss_0": "3.939", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.30054", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "19760", "valid_best_loss": "3.656"}
[2022-01-03 14:43:53,476][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 494 @ 19760 updates
[2022-01-03 14:43:53,477][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:43:57,101][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:43:57,127][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 494 @ 19760 updates, score 4.115) (writing took 3.6508649373427033 seconds)
[2022-01-03 14:43:57,128][fairseq_cli.train][INFO] - end of epoch 494 (average epoch stats below)
[2022-01-03 14:43:57,141][train][INFO] - {"epoch": 494, "train_loss": "4.036", "train_ntokens": "1791.25", "train_nsentences": "4.95", "train_prob_perplexity": "45.22", "train_code_perplexity": "45.194", "train_temp": "1.812", "train_loss_0": "3.865", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.298", "train_wps": "3941.2", "train_ups": "2.2", "train_wpb": "1791.2", "train_bsz": "5", "train_num_updates": "19760", "train_lr": "0.00030875", "train_gnorm": "0.62", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9255"}
[2022-01-03 14:43:57,218][fairseq.trainer][INFO] - begin training epoch 495
[2022-01-03 14:43:57,219][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:44:11,147][train_inner][INFO] - {"epoch": 495, "update": 495.0, "loss": "4.002", "ntokens": "1792.79", "nsentences": "4.95", "prob_perplexity": "45.575", "code_perplexity": "45.55", "temp": "1.812", "loss_0": "3.833", "loss_1": "0.134", "loss_2": "0.036", "accuracy": "0.30255", "wps": "3929.3", "ups": "2.19", "wpb": "1792.8", "bsz": "5", "num_updates": "19800", "lr": "0.000309375", "gnorm": "0.631", "clip": "0", "train_wall": "68", "gb_free": "9.8", "wall": "9269"}
[2022-01-03 14:44:11,148][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:44:11,575][valid][INFO] - {"epoch": 495, "valid_loss": "4.305", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "45.463", "valid_code_perplexity": "45.397", "valid_temp": "1.811", "valid_loss_0": "4.136", "valid_loss_1": "0.134", "valid_loss_2": "0.035", "valid_accuracy": "0.26795", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "19800", "valid_best_loss": "3.656"}
[2022-01-03 14:44:11,578][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 495 @ 19800 updates
[2022-01-03 14:44:11,579][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:44:15,361][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:44:15,389][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 495 @ 19800 updates, score 4.305) (writing took 3.8109659291803837 seconds)
[2022-01-03 14:44:15,389][fairseq_cli.train][INFO] - end of epoch 495 (average epoch stats below)
[2022-01-03 14:44:15,403][train][INFO] - {"epoch": 495, "train_loss": "4.017", "train_ntokens": "1801.83", "train_nsentences": "4.95", "train_prob_perplexity": "45.853", "train_code_perplexity": "45.829", "train_temp": "1.812", "train_loss_0": "3.846", "train_loss_1": "0.134", "train_loss_2": "0.037", "train_accuracy": "0.30031", "train_wps": "3949.6", "train_ups": "2.19", "train_wpb": "1801.8", "train_bsz": "5", "train_num_updates": "19800", "train_lr": "0.000309375", "train_gnorm": "0.622", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.8", "train_wall": "9273"}
[2022-01-03 14:44:15,477][fairseq.trainer][INFO] - begin training epoch 496
[2022-01-03 14:44:15,478][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:44:29,540][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:44:30,017][valid][INFO] - {"epoch": 496, "valid_loss": "4.057", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "45.295", "valid_code_perplexity": "45.253", "valid_temp": "1.811", "valid_loss_0": "3.89", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.29471", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "19840", "valid_best_loss": "3.656"}
[2022-01-03 14:44:30,019][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 496 @ 19840 updates
[2022-01-03 14:44:30,019][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:44:33,639][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:44:33,671][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 496 @ 19840 updates, score 4.057) (writing took 3.6520561603829265 seconds)
[2022-01-03 14:44:33,671][fairseq_cli.train][INFO] - end of epoch 496 (average epoch stats below)
[2022-01-03 14:44:33,697][train][INFO] - {"epoch": 496, "train_loss": "3.995", "train_ntokens": "1805.3", "train_nsentences": "4.95", "train_prob_perplexity": "46.852", "train_code_perplexity": "46.836", "train_temp": "1.811", "train_loss_0": "3.827", "train_loss_1": "0.134", "train_loss_2": "0.035", "train_accuracy": "0.30221", "train_wps": "3952.9", "train_ups": "2.19", "train_wpb": "1805.3", "train_bsz": "5", "train_num_updates": "19840", "train_lr": "0.00031", "train_gnorm": "0.622", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "9291"}
[2022-01-03 14:44:33,781][fairseq.trainer][INFO] - begin training epoch 497
[2022-01-03 14:44:33,782][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:44:47,649][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:44:48,146][valid][INFO] - {"epoch": 497, "valid_loss": "4.441", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "45.791", "valid_code_perplexity": "45.699", "valid_temp": "1.811", "valid_loss_0": "4.274", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.22739", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "19880", "valid_best_loss": "3.656"}
[2022-01-03 14:44:48,148][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 497 @ 19880 updates
[2022-01-03 14:44:48,148][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:44:51,832][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:44:51,860][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 497 @ 19880 updates, score 4.441) (writing took 3.7125572618097067 seconds)
[2022-01-03 14:44:51,861][fairseq_cli.train][INFO] - end of epoch 497 (average epoch stats below)
[2022-01-03 14:44:51,873][train][INFO] - {"epoch": 497, "train_loss": "3.983", "train_ntokens": "1785.3", "train_nsentences": "4.95", "train_prob_perplexity": "46.483", "train_code_perplexity": "46.456", "train_temp": "1.811", "train_loss_0": "3.815", "train_loss_1": "0.134", "train_loss_2": "0.035", "train_accuracy": "0.30345", "train_wps": "3931.7", "train_ups": "2.2", "train_wpb": "1785.3", "train_bsz": "5", "train_num_updates": "19880", "train_lr": "0.000310625", "train_gnorm": "0.652", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "9309"}
[2022-01-03 14:44:51,947][fairseq.trainer][INFO] - begin training epoch 498
[2022-01-03 14:44:51,948][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:45:05,880][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:45:06,291][valid][INFO] - {"epoch": 498, "valid_loss": "3.803", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "43.751", "valid_code_perplexity": "43.812", "valid_temp": "1.81", "valid_loss_0": "3.634", "valid_loss_1": "0.134", "valid_loss_2": "0.034", "valid_accuracy": "0.31793", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "19920", "valid_best_loss": "3.656"}
[2022-01-03 14:45:06,295][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 498 @ 19920 updates
[2022-01-03 14:45:06,296][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:45:10,090][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:45:10,119][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 498 @ 19920 updates, score 3.803) (writing took 3.823433564044535 seconds)
[2022-01-03 14:45:10,119][fairseq_cli.train][INFO] - end of epoch 498 (average epoch stats below)
[2022-01-03 14:45:10,132][train][INFO] - {"epoch": 498, "train_loss": "3.97", "train_ntokens": "1796.03", "train_nsentences": "4.95", "train_prob_perplexity": "46.812", "train_code_perplexity": "46.795", "train_temp": "1.811", "train_loss_0": "3.8", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30861", "train_wps": "3937.4", "train_ups": "2.19", "train_wpb": "1796", "train_bsz": "5", "train_num_updates": "19920", "train_lr": "0.00031125", "train_gnorm": "0.626", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "9328"}
[2022-01-03 14:45:10,212][fairseq.trainer][INFO] - begin training epoch 499
[2022-01-03 14:45:10,213][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:45:24,086][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:45:24,483][valid][INFO] - {"epoch": 499, "valid_loss": "3.911", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "40.069", "valid_code_perplexity": "40.025", "valid_temp": "1.81", "valid_loss_0": "3.734", "valid_loss_1": "0.135", "valid_loss_2": "0.041", "valid_accuracy": "0.31641", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "19960", "valid_best_loss": "3.656"}
[2022-01-03 14:45:24,486][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 499 @ 19960 updates
[2022-01-03 14:45:24,487][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:45:28,441][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:45:28,471][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 499 @ 19960 updates, score 3.911) (writing took 3.9850822892040014 seconds)
[2022-01-03 14:45:28,471][fairseq_cli.train][INFO] - end of epoch 499 (average epoch stats below)
[2022-01-03 14:45:28,484][train][INFO] - {"epoch": 499, "train_loss": "3.985", "train_ntokens": "1787.47", "train_nsentences": "4.95", "train_prob_perplexity": "46.546", "train_code_perplexity": "46.526", "train_temp": "1.81", "train_loss_0": "3.815", "train_loss_1": "0.134", "train_loss_2": "0.036", "train_accuracy": "0.30498", "train_wps": "3898.7", "train_ups": "2.18", "train_wpb": "1787.5", "train_bsz": "5", "train_num_updates": "19960", "train_lr": "0.000311875", "train_gnorm": "0.633", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "9346"}
[2022-01-03 14:45:28,564][fairseq.trainer][INFO] - begin training epoch 500
[2022-01-03 14:45:28,565][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:45:42,417][train_inner][INFO] - {"epoch": 500, "update": 500.0, "loss": "3.987", "ntokens": "1793.78", "nsentences": "4.95", "prob_perplexity": "46.841", "code_perplexity": "46.82", "temp": "1.811", "loss_0": "3.818", "loss_1": "0.134", "loss_2": "0.035", "accuracy": "0.30379", "wps": "3931.2", "ups": "2.19", "wpb": "1793.8", "bsz": "5", "num_updates": "20000", "lr": "0.0003125", "gnorm": "0.633", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "9360"}
[2022-01-03 14:45:42,420][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:45:42,827][valid][INFO] - {"epoch": 500, "valid_loss": "3.952", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "44.785", "valid_code_perplexity": "44.722", "valid_temp": "1.81", "valid_loss_0": "3.785", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.31356", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "20000", "valid_best_loss": "3.656"}
[2022-01-03 14:45:42,832][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 500 @ 20000 updates
[2022-01-03 14:45:42,833][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:45:46,641][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:45:46,668][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 500 @ 20000 updates, score 3.952) (writing took 3.8365699257701635 seconds)
[2022-01-03 14:45:46,669][fairseq_cli.train][INFO] - end of epoch 500 (average epoch stats below)
[2022-01-03 14:45:46,682][train][INFO] - {"epoch": 500, "train_loss": "4", "train_ntokens": "1794.8", "train_nsentences": "4.95", "train_prob_perplexity": "47.511", "train_code_perplexity": "47.488", "train_temp": "1.81", "train_loss_0": "3.831", "train_loss_1": "0.134", "train_loss_2": "0.035", "train_accuracy": "0.29971", "train_wps": "3947.9", "train_ups": "2.2", "train_wpb": "1794.8", "train_bsz": "5", "train_num_updates": "20000", "train_lr": "0.0003125", "train_gnorm": "0.63", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "9364"}
[2022-01-03 14:45:46,754][fairseq.trainer][INFO] - begin training epoch 501
[2022-01-03 14:45:46,755][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:46:00,661][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:46:01,067][valid][INFO] - {"epoch": 501, "valid_loss": "4.032", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "45.514", "valid_code_perplexity": "45.521", "valid_temp": "1.809", "valid_loss_0": "3.866", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.27676", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "20040", "valid_best_loss": "3.656"}
[2022-01-03 14:46:01,070][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 501 @ 20040 updates
[2022-01-03 14:46:01,071][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:46:04,872][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:46:04,899][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 501 @ 20040 updates, score 4.032) (writing took 3.8285718020051718 seconds)
[2022-01-03 14:46:04,899][fairseq_cli.train][INFO] - end of epoch 501 (average epoch stats below)
[2022-01-03 14:46:04,912][train][INFO] - {"epoch": 501, "train_loss": "3.962", "train_ntokens": "1795.72", "train_nsentences": "4.95", "train_prob_perplexity": "47.105", "train_code_perplexity": "47.067", "train_temp": "1.809", "train_loss_0": "3.794", "train_loss_1": "0.134", "train_loss_2": "0.034", "train_accuracy": "0.30425", "train_wps": "3942.9", "train_ups": "2.2", "train_wpb": "1795.7", "train_bsz": "5", "train_num_updates": "20040", "train_lr": "0.000313125", "train_gnorm": "0.636", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "9382"}
[2022-01-03 14:46:04,989][fairseq.trainer][INFO] - begin training epoch 502
[2022-01-03 14:46:04,990][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:46:18,849][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:46:19,270][valid][INFO] - {"epoch": 502, "valid_loss": "3.981", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "45.319", "valid_code_perplexity": "45.177", "valid_temp": "1.809", "valid_loss_0": "3.815", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.30343", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "20080", "valid_best_loss": "3.656"}
[2022-01-03 14:46:19,275][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 502 @ 20080 updates
[2022-01-03 14:46:19,277][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:46:23,353][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:46:23,382][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 502 @ 20080 updates, score 3.981) (writing took 4.10618247743696 seconds)
[2022-01-03 14:46:23,382][fairseq_cli.train][INFO] - end of epoch 502 (average epoch stats below)
[2022-01-03 14:46:23,395][train][INFO] - {"epoch": 502, "train_loss": "4.02", "train_ntokens": "1796", "train_nsentences": "4.95", "train_prob_perplexity": "47.068", "train_code_perplexity": "47.034", "train_temp": "1.809", "train_loss_0": "3.853", "train_loss_1": "0.134", "train_loss_2": "0.033", "train_accuracy": "0.29795", "train_wps": "3889.5", "train_ups": "2.17", "train_wpb": "1796", "train_bsz": "5", "train_num_updates": "20080", "train_lr": "0.00031375", "train_gnorm": "0.606", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "9401"}
[2022-01-03 14:46:23,467][fairseq.trainer][INFO] - begin training epoch 503
[2022-01-03 14:46:23,468][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:46:37,436][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:46:37,842][valid][INFO] - {"epoch": 503, "valid_loss": "4.398", "valid_ntokens": "798", "valid_nsentences": "2", "valid_prob_perplexity": "46.021", "valid_code_perplexity": "46.021", "valid_temp": "1.809", "valid_loss_0": "4.231", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.22682", "valid_wps": "0", "valid_wpb": "798", "valid_bsz": "2", "valid_num_updates": "20120", "valid_best_loss": "3.656"}
[2022-01-03 14:46:37,846][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 503 @ 20120 updates
[2022-01-03 14:46:37,847][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:46:41,546][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:46:41,571][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 503 @ 20120 updates, score 4.398) (writing took 3.7254489697515965 seconds)
[2022-01-03 14:46:41,572][fairseq_cli.train][INFO] - end of epoch 503 (average epoch stats below)
[2022-01-03 14:46:41,584][train][INFO] - {"epoch": 503, "train_loss": "4.005", "train_ntokens": "1790.75", "train_nsentences": "4.95", "train_prob_perplexity": "46.764", "train_code_perplexity": "46.738", "train_temp": "1.809", "train_loss_0": "3.838", "train_loss_1": "0.134", "train_loss_2": "0.034", "train_accuracy": "0.30018", "train_wps": "3940.7", "train_ups": "2.2", "train_wpb": "1790.8", "train_bsz": "5", "train_num_updates": "20120", "train_lr": "0.000314375", "train_gnorm": "0.633", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9419"}
[2022-01-03 14:46:41,657][fairseq.trainer][INFO] - begin training epoch 504
[2022-01-03 14:46:41,658][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:46:55,573][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:46:55,981][valid][INFO] - {"epoch": 504, "valid_loss": "4.037", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "47.414", "valid_code_perplexity": "47.489", "valid_temp": "1.808", "valid_loss_0": "3.873", "valid_loss_1": "0.134", "valid_loss_2": "0.031", "valid_accuracy": "0.29045", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "20160", "valid_best_loss": "3.656"}
[2022-01-03 14:46:55,986][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 504 @ 20160 updates
[2022-01-03 14:46:55,987][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:47:00,025][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:47:00,054][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 504 @ 20160 updates, score 4.037) (writing took 4.0674205012619495 seconds)
[2022-01-03 14:47:00,054][fairseq_cli.train][INFO] - end of epoch 504 (average epoch stats below)
[2022-01-03 14:47:00,067][train][INFO] - {"epoch": 504, "train_loss": "3.973", "train_ntokens": "1810.38", "train_nsentences": "4.95", "train_prob_perplexity": "47.729", "train_code_perplexity": "47.696", "train_temp": "1.808", "train_loss_0": "3.806", "train_loss_1": "0.134", "train_loss_2": "0.033", "train_accuracy": "0.30269", "train_wps": "3920.7", "train_ups": "2.17", "train_wpb": "1810.4", "train_bsz": "5", "train_num_updates": "20160", "train_lr": "0.000315", "train_gnorm": "0.641", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9437"}
[2022-01-03 14:47:00,121][fairseq.trainer][INFO] - begin training epoch 505
[2022-01-03 14:47:00,122][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:47:14,118][train_inner][INFO] - {"epoch": 505, "update": 505.0, "loss": "3.992", "ntokens": "1799.46", "nsentences": "4.95", "prob_perplexity": "47.247", "code_perplexity": "47.214", "temp": "1.809", "loss_0": "3.825", "loss_1": "0.134", "loss_2": "0.034", "accuracy": "0.30113", "wps": "3925.2", "ups": "2.18", "wpb": "1799.5", "bsz": "5", "num_updates": "20200", "lr": "0.000315625", "gnorm": "0.631", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "9452"}
[2022-01-03 14:47:14,119][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:47:14,509][valid][INFO] - {"epoch": 505, "valid_loss": "3.836", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "45.462", "valid_code_perplexity": "45.301", "valid_temp": "1.808", "valid_loss_0": "3.671", "valid_loss_1": "0.134", "valid_loss_2": "0.031", "valid_accuracy": "0.30052", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "20200", "valid_best_loss": "3.656"}
[2022-01-03 14:47:14,512][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 505 @ 20200 updates
[2022-01-03 14:47:14,513][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:47:18,209][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:47:18,238][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 505 @ 20200 updates, score 3.836) (writing took 3.7256527189165354 seconds)
[2022-01-03 14:47:18,238][fairseq_cli.train][INFO] - end of epoch 505 (average epoch stats below)
[2022-01-03 14:47:18,252][train][INFO] - {"epoch": 505, "train_loss": "3.999", "train_ntokens": "1804.47", "train_nsentences": "4.95", "train_prob_perplexity": "47.568", "train_code_perplexity": "47.534", "train_temp": "1.808", "train_loss_0": "3.832", "train_loss_1": "0.134", "train_loss_2": "0.034", "train_accuracy": "0.30054", "train_wps": "3972.1", "train_ups": "2.2", "train_wpb": "1804.5", "train_bsz": "5", "train_num_updates": "20200", "train_lr": "0.000315625", "train_gnorm": "0.637", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9456"}
[2022-01-03 14:47:18,311][fairseq.trainer][INFO] - begin training epoch 506
[2022-01-03 14:47:18,312][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:47:32,353][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:47:32,745][valid][INFO] - {"epoch": 506, "valid_loss": "4.142", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "47.185", "valid_code_perplexity": "47.275", "valid_temp": "1.808", "valid_loss_0": "3.975", "valid_loss_1": "0.134", "valid_loss_2": "0.034", "valid_accuracy": "0.30758", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "20240", "valid_best_loss": "3.656"}
[2022-01-03 14:47:32,748][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 506 @ 20240 updates
[2022-01-03 14:47:32,749][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:47:36,466][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:47:36,494][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 506 @ 20240 updates, score 4.142) (writing took 3.745953164063394 seconds)
[2022-01-03 14:47:36,495][fairseq_cli.train][INFO] - end of epoch 506 (average epoch stats below)
[2022-01-03 14:47:36,507][train][INFO] - {"epoch": 506, "train_loss": "4.003", "train_ntokens": "1792.08", "train_nsentences": "4.95", "train_prob_perplexity": "47.532", "train_code_perplexity": "47.506", "train_temp": "1.808", "train_loss_0": "3.834", "train_loss_1": "0.134", "train_loss_2": "0.035", "train_accuracy": "0.29872", "train_wps": "3929.5", "train_ups": "2.19", "train_wpb": "1792.1", "train_bsz": "5", "train_num_updates": "20240", "train_lr": "0.00031625", "train_gnorm": "0.632", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9474"}
[2022-01-03 14:47:36,580][fairseq.trainer][INFO] - begin training epoch 507
[2022-01-03 14:47:36,580][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:47:50,576][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:47:50,992][valid][INFO] - {"epoch": 507, "valid_loss": "3.998", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "46.144", "valid_code_perplexity": "46.08", "valid_temp": "1.807", "valid_loss_0": "3.829", "valid_loss_1": "0.134", "valid_loss_2": "0.035", "valid_accuracy": "0.30491", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "20280", "valid_best_loss": "3.656"}
[2022-01-03 14:47:50,996][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 507 @ 20280 updates
[2022-01-03 14:47:50,997][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:47:54,726][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:47:54,755][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 507 @ 20280 updates, score 3.998) (writing took 3.7589021418243647 seconds)
[2022-01-03 14:47:54,756][fairseq_cli.train][INFO] - end of epoch 507 (average epoch stats below)
[2022-01-03 14:47:54,769][train][INFO] - {"epoch": 507, "train_loss": "3.98", "train_ntokens": "1753.35", "train_nsentences": "4.95", "train_prob_perplexity": "48.133", "train_code_perplexity": "48.096", "train_temp": "1.807", "train_loss_0": "3.812", "train_loss_1": "0.133", "train_loss_2": "0.035", "train_accuracy": "0.30571", "train_wps": "3843.1", "train_ups": "2.19", "train_wpb": "1753.3", "train_bsz": "5", "train_num_updates": "20280", "train_lr": "0.000316875", "train_gnorm": "0.633", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9492"}
[2022-01-03 14:47:54,850][fairseq.trainer][INFO] - begin training epoch 508
[2022-01-03 14:47:54,851][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:48:08,839][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:48:09,240][valid][INFO] - {"epoch": 508, "valid_loss": "4.006", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "47.277", "valid_code_perplexity": "47.257", "valid_temp": "1.807", "valid_loss_0": "3.84", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.30284", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "20320", "valid_best_loss": "3.656"}
[2022-01-03 14:48:09,242][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 508 @ 20320 updates
[2022-01-03 14:48:09,243][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:48:13,000][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:48:13,028][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 508 @ 20320 updates, score 4.006) (writing took 3.7856667013838887 seconds)
[2022-01-03 14:48:13,029][fairseq_cli.train][INFO] - end of epoch 508 (average epoch stats below)
[2022-01-03 14:48:13,042][train][INFO] - {"epoch": 508, "train_loss": "3.96", "train_ntokens": "1791.67", "train_nsentences": "4.95", "train_prob_perplexity": "48.063", "train_code_perplexity": "48.035", "train_temp": "1.807", "train_loss_0": "3.792", "train_loss_1": "0.133", "train_loss_2": "0.035", "train_accuracy": "0.30618", "train_wps": "3924.9", "train_ups": "2.19", "train_wpb": "1791.7", "train_bsz": "5", "train_num_updates": "20320", "train_lr": "0.0003175", "train_gnorm": "0.609", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9510"}
[2022-01-03 14:48:13,116][fairseq.trainer][INFO] - begin training epoch 509
[2022-01-03 14:48:13,117][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:48:26,967][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:48:27,382][valid][INFO] - {"epoch": 509, "valid_loss": "4.219", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "43.432", "valid_code_perplexity": "43.347", "valid_temp": "1.806", "valid_loss_0": "4.048", "valid_loss_1": "0.134", "valid_loss_2": "0.036", "valid_accuracy": "0.26786", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "20360", "valid_best_loss": "3.656"}
[2022-01-03 14:48:27,385][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 509 @ 20360 updates
[2022-01-03 14:48:27,386][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:48:31,312][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:48:31,342][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 509 @ 20360 updates, score 4.219) (writing took 3.9566673981025815 seconds)
[2022-01-03 14:48:31,342][fairseq_cli.train][INFO] - end of epoch 509 (average epoch stats below)
[2022-01-03 14:48:31,356][train][INFO] - {"epoch": 509, "train_loss": "3.993", "train_ntokens": "1804.9", "train_nsentences": "4.95", "train_prob_perplexity": "47.889", "train_code_perplexity": "47.869", "train_temp": "1.807", "train_loss_0": "3.824", "train_loss_1": "0.133", "train_loss_2": "0.035", "train_accuracy": "0.30207", "train_wps": "3945", "train_ups": "2.19", "train_wpb": "1804.9", "train_bsz": "5", "train_num_updates": "20360", "train_lr": "0.000318125", "train_gnorm": "0.616", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9529"}
[2022-01-03 14:48:31,435][fairseq.trainer][INFO] - begin training epoch 510
[2022-01-03 14:48:31,435][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:48:45,404][train_inner][INFO] - {"epoch": 510, "update": 510.0, "loss": "3.986", "ntokens": "1786.78", "nsentences": "4.95", "prob_perplexity": "47.869", "code_perplexity": "47.841", "temp": "1.807", "loss_0": "3.817", "loss_1": "0.133", "loss_2": "0.035", "accuracy": "0.3032", "wps": "3915.3", "ups": "2.19", "wpb": "1786.8", "bsz": "5", "num_updates": "20400", "lr": "0.00031875", "gnorm": "0.624", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "9543"}
[2022-01-03 14:48:45,405][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:48:45,807][valid][INFO] - {"epoch": 510, "valid_loss": "4.187", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "47.022", "valid_code_perplexity": "47.02", "valid_temp": "1.806", "valid_loss_0": "4.019", "valid_loss_1": "0.134", "valid_loss_2": "0.034", "valid_accuracy": "0.2839", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "20400", "valid_best_loss": "3.656"}
[2022-01-03 14:48:45,811][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 510 @ 20400 updates
[2022-01-03 14:48:45,812][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:48:49,498][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:48:49,527][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 510 @ 20400 updates, score 4.187) (writing took 3.715999448671937 seconds)
[2022-01-03 14:48:49,528][fairseq_cli.train][INFO] - end of epoch 510 (average epoch stats below)
[2022-01-03 14:48:49,540][train][INFO] - {"epoch": 510, "train_loss": "3.993", "train_ntokens": "1791.88", "train_nsentences": "4.95", "train_prob_perplexity": "47.727", "train_code_perplexity": "47.7", "train_temp": "1.806", "train_loss_0": "3.824", "train_loss_1": "0.134", "train_loss_2": "0.035", "train_accuracy": "0.3034", "train_wps": "3944.2", "train_ups": "2.2", "train_wpb": "1791.9", "train_bsz": "5", "train_num_updates": "20400", "train_lr": "0.00031875", "train_gnorm": "0.628", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "9547"}
[2022-01-03 14:48:49,588][fairseq.trainer][INFO] - begin training epoch 511
[2022-01-03 14:48:49,589][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:49:03,585][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:49:04,068][valid][INFO] - {"epoch": 511, "valid_loss": "3.951", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "47.883", "valid_code_perplexity": "47.835", "valid_temp": "1.806", "valid_loss_0": "3.784", "valid_loss_1": "0.133", "valid_loss_2": "0.033", "valid_accuracy": "0.2945", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "20440", "valid_best_loss": "3.656"}
[2022-01-03 14:49:04,070][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 511 @ 20440 updates
[2022-01-03 14:49:04,070][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:49:07,870][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:49:07,890][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 511 @ 20440 updates, score 3.951) (writing took 3.8195674987509847 seconds)
[2022-01-03 14:49:07,890][fairseq_cli.train][INFO] - end of epoch 511 (average epoch stats below)
[2022-01-03 14:49:07,902][train][INFO] - {"epoch": 511, "train_loss": "3.966", "train_ntokens": "1774.62", "train_nsentences": "4.95", "train_prob_perplexity": "48.076", "train_code_perplexity": "48.061", "train_temp": "1.806", "train_loss_0": "3.798", "train_loss_1": "0.133", "train_loss_2": "0.035", "train_accuracy": "0.3069", "train_wps": "3868.4", "train_ups": "2.18", "train_wpb": "1774.6", "train_bsz": "5", "train_num_updates": "20440", "train_lr": "0.000319375", "train_gnorm": "0.62", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9565"}
[2022-01-03 14:49:07,942][fairseq.trainer][INFO] - begin training epoch 512
[2022-01-03 14:49:07,942][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:49:21,852][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:49:22,344][valid][INFO] - {"epoch": 512, "valid_loss": "4.162", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "43.808", "valid_code_perplexity": "43.824", "valid_temp": "1.805", "valid_loss_0": "3.991", "valid_loss_1": "0.134", "valid_loss_2": "0.036", "valid_accuracy": "0.26446", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "20480", "valid_best_loss": "3.656"}
[2022-01-03 14:49:22,346][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 512 @ 20480 updates
[2022-01-03 14:49:22,347][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:49:26,009][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:49:26,038][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 512 @ 20480 updates, score 4.162) (writing took 3.6917509213089943 seconds)
[2022-01-03 14:49:26,039][fairseq_cli.train][INFO] - end of epoch 512 (average epoch stats below)
[2022-01-03 14:49:26,052][train][INFO] - {"epoch": 512, "train_loss": "3.927", "train_ntokens": "1774.12", "train_nsentences": "4.95", "train_prob_perplexity": "48.574", "train_code_perplexity": "48.541", "train_temp": "1.806", "train_loss_0": "3.76", "train_loss_1": "0.133", "train_loss_2": "0.034", "train_accuracy": "0.31008", "train_wps": "3912.9", "train_ups": "2.21", "train_wpb": "1774.1", "train_bsz": "5", "train_num_updates": "20480", "train_lr": "0.00032", "train_gnorm": "0.612", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9583"}
[2022-01-03 14:49:26,132][fairseq.trainer][INFO] - begin training epoch 513
[2022-01-03 14:49:26,132][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:49:39,927][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:49:40,420][valid][INFO] - {"epoch": 513, "valid_loss": "3.984", "valid_ntokens": "690", "valid_nsentences": "2", "valid_prob_perplexity": "46.615", "valid_code_perplexity": "46.622", "valid_temp": "1.805", "valid_loss_0": "3.818", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.29565", "valid_wps": "0", "valid_wpb": "690", "valid_bsz": "2", "valid_num_updates": "20520", "valid_best_loss": "3.656"}
[2022-01-03 14:49:40,422][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 513 @ 20520 updates
[2022-01-03 14:49:40,422][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:49:44,235][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:49:44,255][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 513 @ 20520 updates, score 3.984) (writing took 3.832739402540028 seconds)
[2022-01-03 14:49:44,255][fairseq_cli.train][INFO] - end of epoch 513 (average epoch stats below)
[2022-01-03 14:49:44,268][train][INFO] - {"epoch": 513, "train_loss": "4.002", "train_ntokens": "1798.72", "train_nsentences": "4.95", "train_prob_perplexity": "47.68", "train_code_perplexity": "47.639", "train_temp": "1.805", "train_loss_0": "3.835", "train_loss_1": "0.134", "train_loss_2": "0.034", "train_accuracy": "0.3026", "train_wps": "3952.6", "train_ups": "2.2", "train_wpb": "1798.7", "train_bsz": "5", "train_num_updates": "20520", "train_lr": "0.000320625", "train_gnorm": "0.601", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9602"}
[2022-01-03 14:49:44,310][fairseq.trainer][INFO] - begin training epoch 514
[2022-01-03 14:49:44,310][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:49:58,174][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:49:58,595][valid][INFO] - {"epoch": 514, "valid_loss": "4.058", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "48.216", "valid_code_perplexity": "48.084", "valid_temp": "1.805", "valid_loss_0": "3.893", "valid_loss_1": "0.133", "valid_loss_2": "0.031", "valid_accuracy": "0.30357", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "20560", "valid_best_loss": "3.656"}
[2022-01-03 14:49:58,598][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 514 @ 20560 updates
[2022-01-03 14:49:58,599][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:50:02,528][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:50:02,557][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 514 @ 20560 updates, score 4.058) (writing took 3.958393959328532 seconds)
[2022-01-03 14:50:02,557][fairseq_cli.train][INFO] - end of epoch 514 (average epoch stats below)
[2022-01-03 14:50:02,570][train][INFO] - {"epoch": 514, "train_loss": "3.994", "train_ntokens": "1790.17", "train_nsentences": "4.95", "train_prob_perplexity": "49", "train_code_perplexity": "48.971", "train_temp": "1.805", "train_loss_0": "3.827", "train_loss_1": "0.133", "train_loss_2": "0.034", "train_accuracy": "0.30253", "train_wps": "3915.2", "train_ups": "2.19", "train_wpb": "1790.2", "train_bsz": "5", "train_num_updates": "20560", "train_lr": "0.00032125", "train_gnorm": "0.637", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "9620"}
[2022-01-03 14:50:02,650][fairseq.trainer][INFO] - begin training epoch 515
[2022-01-03 14:50:02,651][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:50:16,554][train_inner][INFO] - {"epoch": 515, "update": 515.0, "loss": "3.966", "ntokens": "1788.65", "nsentences": "4.95", "prob_perplexity": "48.489", "code_perplexity": "48.461", "temp": "1.805", "loss_0": "3.799", "loss_1": "0.133", "loss_2": "0.034", "accuracy": "0.30556", "wps": "3925.2", "ups": "2.19", "wpb": "1788.7", "bsz": "5", "num_updates": "20600", "lr": "0.000321875", "gnorm": "0.614", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "9634"}
[2022-01-03 14:50:16,554][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:50:16,953][valid][INFO] - {"epoch": 515, "valid_loss": "3.997", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "47.073", "valid_code_perplexity": "47.103", "valid_temp": "1.804", "valid_loss_0": "3.834", "valid_loss_1": "0.134", "valid_loss_2": "0.03", "valid_accuracy": "0.2791", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "20600", "valid_best_loss": "3.656"}
[2022-01-03 14:50:16,956][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 515 @ 20600 updates
[2022-01-03 14:50:16,957][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:50:20,728][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:50:20,756][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 515 @ 20600 updates, score 3.997) (writing took 3.800340344198048 seconds)
[2022-01-03 14:50:20,757][fairseq_cli.train][INFO] - end of epoch 515 (average epoch stats below)
[2022-01-03 14:50:20,769][train][INFO] - {"epoch": 515, "train_loss": "3.941", "train_ntokens": "1805.6", "train_nsentences": "4.95", "train_prob_perplexity": "49.115", "train_code_perplexity": "49.091", "train_temp": "1.804", "train_loss_0": "3.775", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30574", "train_wps": "3971.2", "train_ups": "2.2", "train_wpb": "1805.6", "train_bsz": "5", "train_num_updates": "20600", "train_lr": "0.000321875", "train_gnorm": "0.601", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9638"}
[2022-01-03 14:50:20,807][fairseq.trainer][INFO] - begin training epoch 516
[2022-01-03 14:50:20,808][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:50:34,663][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:50:35,052][valid][INFO] - {"epoch": 516, "valid_loss": "3.947", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "47.243", "valid_code_perplexity": "47.225", "valid_temp": "1.804", "valid_loss_0": "3.78", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.29156", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "20640", "valid_best_loss": "3.656"}
[2022-01-03 14:50:35,056][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 516 @ 20640 updates
[2022-01-03 14:50:35,057][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:50:38,961][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:50:38,987][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 516 @ 20640 updates, score 3.947) (writing took 3.9307612562552094 seconds)
[2022-01-03 14:50:38,987][fairseq_cli.train][INFO] - end of epoch 516 (average epoch stats below)
[2022-01-03 14:50:39,000][train][INFO] - {"epoch": 516, "train_loss": "4.019", "train_ntokens": "1778.6", "train_nsentences": "4.95", "train_prob_perplexity": "48.774", "train_code_perplexity": "48.721", "train_temp": "1.804", "train_loss_0": "3.853", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.29785", "train_wps": "3905.2", "train_ups": "2.2", "train_wpb": "1778.6", "train_bsz": "5", "train_num_updates": "20640", "train_lr": "0.0003225", "train_gnorm": "0.621", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9656"}
[2022-01-03 14:50:39,055][fairseq.trainer][INFO] - begin training epoch 517
[2022-01-03 14:50:39,056][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:50:52,965][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:50:53,374][valid][INFO] - {"epoch": 517, "valid_loss": "3.809", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "46.056", "valid_code_perplexity": "46.002", "valid_temp": "1.804", "valid_loss_0": "3.643", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.31267", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "20680", "valid_best_loss": "3.656"}
[2022-01-03 14:50:53,377][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 517 @ 20680 updates
[2022-01-03 14:50:53,378][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:50:57,190][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:50:57,219][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 517 @ 20680 updates, score 3.809) (writing took 3.8417692445218563 seconds)
[2022-01-03 14:50:57,219][fairseq_cli.train][INFO] - end of epoch 517 (average epoch stats below)
[2022-01-03 14:50:57,232][train][INFO] - {"epoch": 517, "train_loss": "3.993", "train_ntokens": "1804.45", "train_nsentences": "4.95", "train_prob_perplexity": "48.537", "train_code_perplexity": "48.508", "train_temp": "1.804", "train_loss_0": "3.826", "train_loss_1": "0.133", "train_loss_2": "0.034", "train_accuracy": "0.29876", "train_wps": "3961.6", "train_ups": "2.2", "train_wpb": "1804.5", "train_bsz": "5", "train_num_updates": "20680", "train_lr": "0.000323125", "train_gnorm": "0.612", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9675"}
[2022-01-03 14:50:57,317][fairseq.trainer][INFO] - begin training epoch 518
[2022-01-03 14:50:57,318][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:51:11,141][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:51:11,544][valid][INFO] - {"epoch": 518, "valid_loss": "4.015", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "43.526", "valid_code_perplexity": "43.534", "valid_temp": "1.803", "valid_loss_0": "3.847", "valid_loss_1": "0.134", "valid_loss_2": "0.034", "valid_accuracy": "0.28184", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "20720", "valid_best_loss": "3.656"}
[2022-01-03 14:51:11,547][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 518 @ 20720 updates
[2022-01-03 14:51:11,548][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:51:15,730][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:51:15,748][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 518 @ 20720 updates, score 4.015) (writing took 4.201006667688489 seconds)
[2022-01-03 14:51:15,749][fairseq_cli.train][INFO] - end of epoch 518 (average epoch stats below)
[2022-01-03 14:51:15,762][train][INFO] - {"epoch": 518, "train_loss": "3.951", "train_ntokens": "1782.85", "train_nsentences": "4.95", "train_prob_perplexity": "48.301", "train_code_perplexity": "48.264", "train_temp": "1.803", "train_loss_0": "3.785", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30737", "train_wps": "3851.3", "train_ups": "2.16", "train_wpb": "1782.8", "train_bsz": "5", "train_num_updates": "20720", "train_lr": "0.00032375", "train_gnorm": "0.611", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9693"}
[2022-01-03 14:51:15,800][fairseq.trainer][INFO] - begin training epoch 519
[2022-01-03 14:51:15,800][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:51:29,681][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:51:30,077][valid][INFO] - {"epoch": 519, "valid_loss": "4.245", "valid_ntokens": "816", "valid_nsentences": "2", "valid_prob_perplexity": "47.756", "valid_code_perplexity": "47.747", "valid_temp": "1.803", "valid_loss_0": "4.078", "valid_loss_1": "0.134", "valid_loss_2": "0.034", "valid_accuracy": "0.27328", "valid_wps": "0", "valid_wpb": "816", "valid_bsz": "2", "valid_num_updates": "20760", "valid_best_loss": "3.656"}
[2022-01-03 14:51:30,079][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 519 @ 20760 updates
[2022-01-03 14:51:30,080][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:51:34,064][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:51:34,092][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 519 @ 20760 updates, score 4.245) (writing took 4.013023503124714 seconds)
[2022-01-03 14:51:34,093][fairseq_cli.train][INFO] - end of epoch 519 (average epoch stats below)
[2022-01-03 14:51:34,105][train][INFO] - {"epoch": 519, "train_loss": "3.979", "train_ntokens": "1788.15", "train_nsentences": "4.95", "train_prob_perplexity": "48.366", "train_code_perplexity": "48.333", "train_temp": "1.803", "train_loss_0": "3.813", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30252", "train_wps": "3902", "train_ups": "2.18", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "20760", "train_lr": "0.000324375", "train_gnorm": "0.625", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9712"}
[2022-01-03 14:51:34,182][fairseq.trainer][INFO] - begin training epoch 520
[2022-01-03 14:51:34,183][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:51:48,020][train_inner][INFO] - {"epoch": 520, "update": 520.0, "loss": "3.981", "ntokens": "1790.97", "nsentences": "4.95", "prob_perplexity": "48.601", "code_perplexity": "48.564", "temp": "1.803", "loss_0": "3.815", "loss_1": "0.133", "loss_2": "0.033", "accuracy": "0.30206", "wps": "3916.7", "ups": "2.19", "wpb": "1791", "bsz": "5", "num_updates": "20800", "lr": "0.000325", "gnorm": "0.619", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "9725"}
[2022-01-03 14:51:48,021][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:51:48,420][valid][INFO] - {"epoch": 520, "valid_loss": "3.736", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "47.61", "valid_code_perplexity": "47.542", "valid_temp": "1.802", "valid_loss_0": "3.571", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.32895", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "20800", "valid_best_loss": "3.656"}
[2022-01-03 14:51:48,422][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 520 @ 20800 updates
[2022-01-03 14:51:48,423][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:51:52,325][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:51:52,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 520 @ 20800 updates, score 3.736) (writing took 3.9221140099689364 seconds)
[2022-01-03 14:51:52,345][fairseq_cli.train][INFO] - end of epoch 520 (average epoch stats below)
[2022-01-03 14:51:52,357][train][INFO] - {"epoch": 520, "train_loss": "3.964", "train_ntokens": "1800.83", "train_nsentences": "4.95", "train_prob_perplexity": "49.026", "train_code_perplexity": "48.992", "train_temp": "1.803", "train_loss_0": "3.799", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30382", "train_wps": "3949.3", "train_ups": "2.19", "train_wpb": "1800.8", "train_bsz": "5", "train_num_updates": "20800", "train_lr": "0.000325", "train_gnorm": "0.627", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9730"}
[2022-01-03 14:51:52,398][fairseq.trainer][INFO] - begin training epoch 521
[2022-01-03 14:51:52,398][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:52:06,355][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:52:06,762][valid][INFO] - {"epoch": 521, "valid_loss": "3.916", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "45.633", "valid_code_perplexity": "45.519", "valid_temp": "1.802", "valid_loss_0": "3.752", "valid_loss_1": "0.134", "valid_loss_2": "0.031", "valid_accuracy": "0.3044", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "20840", "valid_best_loss": "3.656"}
[2022-01-03 14:52:06,766][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 521 @ 20840 updates
[2022-01-03 14:52:06,767][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:52:10,550][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:52:10,578][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 521 @ 20840 updates, score 3.916) (writing took 3.812358535826206 seconds)
[2022-01-03 14:52:10,578][fairseq_cli.train][INFO] - end of epoch 521 (average epoch stats below)
[2022-01-03 14:52:10,591][train][INFO] - {"epoch": 521, "train_loss": "3.958", "train_ntokens": "1794.08", "train_nsentences": "4.95", "train_prob_perplexity": "49.037", "train_code_perplexity": "49.007", "train_temp": "1.802", "train_loss_0": "3.793", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30208", "train_wps": "3938.4", "train_ups": "2.2", "train_wpb": "1794.1", "train_bsz": "5", "train_num_updates": "20840", "train_lr": "0.000325625", "train_gnorm": "0.604", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9748"}
[2022-01-03 14:52:10,671][fairseq.trainer][INFO] - begin training epoch 522
[2022-01-03 14:52:10,672][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:52:24,754][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:52:25,234][valid][INFO] - {"epoch": 522, "valid_loss": "3.98", "valid_ntokens": "688", "valid_nsentences": "2", "valid_prob_perplexity": "47.983", "valid_code_perplexity": "47.995", "valid_temp": "1.802", "valid_loss_0": "3.812", "valid_loss_1": "0.133", "valid_loss_2": "0.034", "valid_accuracy": "0.30523", "valid_wps": "0", "valid_wpb": "688", "valid_bsz": "2", "valid_num_updates": "20880", "valid_best_loss": "3.656"}
[2022-01-03 14:52:25,236][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 522 @ 20880 updates
[2022-01-03 14:52:25,237][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:52:28,955][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:52:28,984][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 522 @ 20880 updates, score 3.98) (writing took 3.747660960070789 seconds)
[2022-01-03 14:52:28,984][fairseq_cli.train][INFO] - end of epoch 522 (average epoch stats below)
[2022-01-03 14:52:28,997][train][INFO] - {"epoch": 522, "train_loss": "3.987", "train_ntokens": "1791.15", "train_nsentences": "4.95", "train_prob_perplexity": "48.998", "train_code_perplexity": "48.971", "train_temp": "1.802", "train_loss_0": "3.821", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.30182", "train_wps": "3895.3", "train_ups": "2.17", "train_wpb": "1791.2", "train_bsz": "5", "train_num_updates": "20880", "train_lr": "0.00032625", "train_gnorm": "0.609", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "9766"}
[2022-01-03 14:52:29,058][fairseq.trainer][INFO] - begin training epoch 523
[2022-01-03 14:52:29,059][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:52:42,991][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:52:43,394][valid][INFO] - {"epoch": 523, "valid_loss": "3.815", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "47.827", "valid_code_perplexity": "47.772", "valid_temp": "1.801", "valid_loss_0": "3.647", "valid_loss_1": "0.133", "valid_loss_2": "0.034", "valid_accuracy": "0.35027", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "20920", "valid_best_loss": "3.656"}
[2022-01-03 14:52:43,397][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 523 @ 20920 updates
[2022-01-03 14:52:43,398][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:52:47,460][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:52:47,480][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 523 @ 20920 updates, score 3.815) (writing took 4.083130342885852 seconds)
[2022-01-03 14:52:47,481][fairseq_cli.train][INFO] - end of epoch 523 (average epoch stats below)
[2022-01-03 14:52:47,493][train][INFO] - {"epoch": 523, "train_loss": "3.934", "train_ntokens": "1784.7", "train_nsentences": "4.95", "train_prob_perplexity": "48.799", "train_code_perplexity": "48.758", "train_temp": "1.802", "train_loss_0": "3.768", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.30595", "train_wps": "3862.2", "train_ups": "2.16", "train_wpb": "1784.7", "train_bsz": "5", "train_num_updates": "20920", "train_lr": "0.000326875", "train_gnorm": "0.622", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "9785"}
[2022-01-03 14:52:47,542][fairseq.trainer][INFO] - begin training epoch 524
[2022-01-03 14:52:47,543][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:53:01,449][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:53:01,849][valid][INFO] - {"epoch": 524, "valid_loss": "4.137", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "49.484", "valid_code_perplexity": "49.342", "valid_temp": "1.801", "valid_loss_0": "3.974", "valid_loss_1": "0.133", "valid_loss_2": "0.03", "valid_accuracy": "0.2863", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "20960", "valid_best_loss": "3.656"}
[2022-01-03 14:53:01,852][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 524 @ 20960 updates
[2022-01-03 14:53:01,852][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:53:05,794][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:53:05,822][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 524 @ 20960 updates, score 4.137) (writing took 3.9703741697594523 seconds)
[2022-01-03 14:53:05,823][fairseq_cli.train][INFO] - end of epoch 524 (average epoch stats below)
[2022-01-03 14:53:05,835][train][INFO] - {"epoch": 524, "train_loss": "3.961", "train_ntokens": "1811.47", "train_nsentences": "4.95", "train_prob_perplexity": "49.493", "train_code_perplexity": "49.457", "train_temp": "1.801", "train_loss_0": "3.794", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.30445", "train_wps": "3953.1", "train_ups": "2.18", "train_wpb": "1811.5", "train_bsz": "5", "train_num_updates": "20960", "train_lr": "0.0003275", "train_gnorm": "0.633", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9803"}
[2022-01-03 14:53:05,914][fairseq.trainer][INFO] - begin training epoch 525
[2022-01-03 14:53:05,915][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:53:19,838][train_inner][INFO] - {"epoch": 525, "update": 525.0, "loss": "3.959", "ntokens": "1796.38", "nsentences": "4.95", "prob_perplexity": "49.221", "code_perplexity": "49.185", "temp": "1.802", "loss_0": "3.793", "loss_1": "0.133", "loss_2": "0.032", "accuracy": "0.30378", "wps": "3913.5", "ups": "2.18", "wpb": "1796.4", "bsz": "5", "num_updates": "21000", "lr": "0.000328125", "gnorm": "0.614", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "9817"}
[2022-01-03 14:53:19,839][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:53:20,229][valid][INFO] - {"epoch": 525, "valid_loss": "3.857", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "41.548", "valid_code_perplexity": "41.463", "valid_temp": "1.801", "valid_loss_0": "3.689", "valid_loss_1": "0.135", "valid_loss_2": "0.033", "valid_accuracy": "0.31301", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "21000", "valid_best_loss": "3.656"}
[2022-01-03 14:53:20,232][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 525 @ 21000 updates
[2022-01-03 14:53:20,233][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:53:23,974][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:53:24,002][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 525 @ 21000 updates, score 3.857) (writing took 3.769163033924997 seconds)
[2022-01-03 14:53:24,002][fairseq_cli.train][INFO] - end of epoch 525 (average epoch stats below)
[2022-01-03 14:53:24,015][train][INFO] - {"epoch": 525, "train_loss": "3.953", "train_ntokens": "1800.5", "train_nsentences": "4.95", "train_prob_perplexity": "49.776", "train_code_perplexity": "49.735", "train_temp": "1.801", "train_loss_0": "3.788", "train_loss_1": "0.133", "train_loss_2": "0.031", "train_accuracy": "0.3046", "train_wps": "3964.3", "train_ups": "2.2", "train_wpb": "1800.5", "train_bsz": "5", "train_num_updates": "21000", "train_lr": "0.000328125", "train_gnorm": "0.604", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "9821"}
[2022-01-03 14:53:24,090][fairseq.trainer][INFO] - begin training epoch 526
[2022-01-03 14:53:24,091][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:53:38,048][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:53:38,444][valid][INFO] - {"epoch": 526, "valid_loss": "3.923", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "49.051", "valid_code_perplexity": "49.062", "valid_temp": "1.8", "valid_loss_0": "3.76", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.2962", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "21040", "valid_best_loss": "3.656"}
[2022-01-03 14:53:38,447][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 526 @ 21040 updates
[2022-01-03 14:53:38,447][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:53:42,221][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:53:42,248][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 526 @ 21040 updates, score 3.923) (writing took 3.801170510239899 seconds)
[2022-01-03 14:53:42,248][fairseq_cli.train][INFO] - end of epoch 526 (average epoch stats below)
[2022-01-03 14:53:42,263][train][INFO] - {"epoch": 526, "train_loss": "3.967", "train_ntokens": "1781.5", "train_nsentences": "4.95", "train_prob_perplexity": "49.747", "train_code_perplexity": "49.704", "train_temp": "1.8", "train_loss_0": "3.801", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.30328", "train_wps": "3908.2", "train_ups": "2.19", "train_wpb": "1781.5", "train_bsz": "5", "train_num_updates": "21040", "train_lr": "0.00032875", "train_gnorm": "0.654", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "9840"}
[2022-01-03 14:53:42,312][fairseq.trainer][INFO] - begin training epoch 527
[2022-01-03 14:53:42,313][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:53:56,153][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:53:56,632][valid][INFO] - {"epoch": 527, "valid_loss": "3.675", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "48.088", "valid_code_perplexity": "48.112", "valid_temp": "1.8", "valid_loss_0": "3.513", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.34555", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "21080", "valid_best_loss": "3.656"}
[2022-01-03 14:53:56,634][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 527 @ 21080 updates
[2022-01-03 14:53:56,635][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:54:00,555][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:54:00,583][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 527 @ 21080 updates, score 3.675) (writing took 3.948711607605219 seconds)
[2022-01-03 14:54:00,584][fairseq_cli.train][INFO] - end of epoch 527 (average epoch stats below)
[2022-01-03 14:54:00,596][train][INFO] - {"epoch": 527, "train_loss": "3.992", "train_ntokens": "1822.92", "train_nsentences": "4.95", "train_prob_perplexity": "49.539", "train_code_perplexity": "49.509", "train_temp": "1.8", "train_loss_0": "3.827", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.29797", "train_wps": "3980", "train_ups": "2.18", "train_wpb": "1822.9", "train_bsz": "5", "train_num_updates": "21080", "train_lr": "0.000329375", "train_gnorm": "0.597", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "9858"}
[2022-01-03 14:54:00,673][fairseq.trainer][INFO] - begin training epoch 528
[2022-01-03 14:54:00,673][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:54:14,739][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:54:15,142][valid][INFO] - {"epoch": 528, "valid_loss": "3.812", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "49.247", "valid_code_perplexity": "49.168", "valid_temp": "1.8", "valid_loss_0": "3.646", "valid_loss_1": "0.133", "valid_loss_2": "0.033", "valid_accuracy": "0.31077", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "21120", "valid_best_loss": "3.656"}
[2022-01-03 14:54:15,147][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 528 @ 21120 updates
[2022-01-03 14:54:15,148][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:54:18,812][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:54:18,842][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 528 @ 21120 updates, score 3.812) (writing took 3.6946444623172283 seconds)
[2022-01-03 14:54:18,842][fairseq_cli.train][INFO] - end of epoch 528 (average epoch stats below)
[2022-01-03 14:54:18,854][train][INFO] - {"epoch": 528, "train_loss": "3.956", "train_ntokens": "1791.5", "train_nsentences": "4.95", "train_prob_perplexity": "49.507", "train_code_perplexity": "49.479", "train_temp": "1.8", "train_loss_0": "3.791", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30444", "train_wps": "3927.5", "train_ups": "2.19", "train_wpb": "1791.5", "train_bsz": "5", "train_num_updates": "21120", "train_lr": "0.00033", "train_gnorm": "0.605", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9876"}
[2022-01-03 14:54:18,912][fairseq.trainer][INFO] - begin training epoch 529
[2022-01-03 14:54:18,913][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:54:32,780][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:54:33,192][valid][INFO] - {"epoch": 529, "valid_loss": "3.945", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "49.262", "valid_code_perplexity": "49.236", "valid_temp": "1.799", "valid_loss_0": "3.779", "valid_loss_1": "0.133", "valid_loss_2": "0.032", "valid_accuracy": "0.30481", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "21160", "valid_best_loss": "3.656"}
[2022-01-03 14:54:33,196][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 529 @ 21160 updates
[2022-01-03 14:54:33,197][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:54:37,251][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:54:37,278][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 529 @ 21160 updates, score 3.945) (writing took 4.0822477620095015 seconds)
[2022-01-03 14:54:37,279][fairseq_cli.train][INFO] - end of epoch 529 (average epoch stats below)
[2022-01-03 14:54:37,292][train][INFO] - {"epoch": 529, "train_loss": "4.038", "train_ntokens": "1807.65", "train_nsentences": "4.95", "train_prob_perplexity": "49.384", "train_code_perplexity": "49.356", "train_temp": "1.799", "train_loss_0": "3.873", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.29273", "train_wps": "3924.5", "train_ups": "2.17", "train_wpb": "1807.7", "train_bsz": "5", "train_num_updates": "21160", "train_lr": "0.000330625", "train_gnorm": "0.652", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "9895"}
[2022-01-03 14:54:37,364][fairseq.trainer][INFO] - begin training epoch 530
[2022-01-03 14:54:37,365][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:54:51,432][train_inner][INFO] - {"epoch": 530, "update": 530.0, "loss": "3.992", "ntokens": "1800.91", "nsentences": "4.95", "prob_perplexity": "49.462", "code_perplexity": "49.429", "temp": "1.8", "loss_0": "3.826", "loss_1": "0.133", "loss_2": "0.032", "accuracy": "0.2992", "wps": "3932.9", "ups": "2.18", "wpb": "1800.9", "bsz": "5", "num_updates": "21200", "lr": "0.00033125", "gnorm": "0.628", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "9909"}
[2022-01-03 14:54:51,433][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:54:51,840][valid][INFO] - {"epoch": 530, "valid_loss": "4.159", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "47.293", "valid_code_perplexity": "47.022", "valid_temp": "1.799", "valid_loss_0": "3.993", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.2726", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "21200", "valid_best_loss": "3.656"}
[2022-01-03 14:54:51,844][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 530 @ 21200 updates
[2022-01-03 14:54:51,845][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:54:55,800][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:54:55,829][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 530 @ 21200 updates, score 4.159) (writing took 3.9848671555519104 seconds)
[2022-01-03 14:54:55,829][fairseq_cli.train][INFO] - end of epoch 530 (average epoch stats below)
[2022-01-03 14:54:55,842][train][INFO] - {"epoch": 530, "train_loss": "4.006", "train_ntokens": "1801", "train_nsentences": "4.95", "train_prob_perplexity": "49.133", "train_code_perplexity": "49.096", "train_temp": "1.799", "train_loss_0": "3.839", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.29767", "train_wps": "3886.3", "train_ups": "2.16", "train_wpb": "1801", "train_bsz": "5", "train_num_updates": "21200", "train_lr": "0.00033125", "train_gnorm": "0.63", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "9913"}
[2022-01-03 14:54:55,918][fairseq.trainer][INFO] - begin training epoch 531
[2022-01-03 14:54:55,919][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:55:09,797][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:55:10,210][valid][INFO] - {"epoch": 531, "valid_loss": "4.136", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "48.44", "valid_code_perplexity": "48.389", "valid_temp": "1.798", "valid_loss_0": "3.972", "valid_loss_1": "0.133", "valid_loss_2": "0.03", "valid_accuracy": "0.27322", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "21240", "valid_best_loss": "3.656"}
[2022-01-03 14:55:10,214][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 531 @ 21240 updates
[2022-01-03 14:55:10,215][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:55:14,128][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:55:14,155][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 531 @ 21240 updates, score 4.136) (writing took 3.9408732652664185 seconds)
[2022-01-03 14:55:14,155][fairseq_cli.train][INFO] - end of epoch 531 (average epoch stats below)
[2022-01-03 14:55:14,167][train][INFO] - {"epoch": 531, "train_loss": "3.959", "train_ntokens": "1791.88", "train_nsentences": "4.95", "train_prob_perplexity": "49.429", "train_code_perplexity": "49.384", "train_temp": "1.799", "train_loss_0": "3.792", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.3032", "train_wps": "3913.8", "train_ups": "2.18", "train_wpb": "1791.9", "train_bsz": "5", "train_num_updates": "21240", "train_lr": "0.000331875", "train_gnorm": "0.603", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9932"}
[2022-01-03 14:55:14,238][fairseq.trainer][INFO] - begin training epoch 532
[2022-01-03 14:55:14,239][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:55:28,022][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:55:28,435][valid][INFO] - {"epoch": 532, "valid_loss": "4.281", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "49.189", "valid_code_perplexity": "49.25", "valid_temp": "1.798", "valid_loss_0": "4.115", "valid_loss_1": "0.133", "valid_loss_2": "0.033", "valid_accuracy": "0.25421", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "21280", "valid_best_loss": "3.656"}
[2022-01-03 14:55:28,440][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 532 @ 21280 updates
[2022-01-03 14:55:28,441][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:55:32,371][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:55:32,399][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 532 @ 21280 updates, score 4.281) (writing took 3.9592384276911616 seconds)
[2022-01-03 14:55:32,400][fairseq_cli.train][INFO] - end of epoch 532 (average epoch stats below)
[2022-01-03 14:55:32,412][train][INFO] - {"epoch": 532, "train_loss": "3.962", "train_ntokens": "1798.5", "train_nsentences": "4.95", "train_prob_perplexity": "48.935", "train_code_perplexity": "48.893", "train_temp": "1.798", "train_loss_0": "3.796", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.30292", "train_wps": "3945.8", "train_ups": "2.19", "train_wpb": "1798.5", "train_bsz": "5", "train_num_updates": "21280", "train_lr": "0.0003325", "train_gnorm": "0.606", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9950"}
[2022-01-03 14:55:32,487][fairseq.trainer][INFO] - begin training epoch 533
[2022-01-03 14:55:32,488][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:55:46,327][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:55:46,723][valid][INFO] - {"epoch": 533, "valid_loss": "4.385", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "50.891", "valid_code_perplexity": "50.892", "valid_temp": "1.798", "valid_loss_0": "4.221", "valid_loss_1": "0.133", "valid_loss_2": "0.031", "valid_accuracy": "0.26331", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "21320", "valid_best_loss": "3.656"}
[2022-01-03 14:55:46,727][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 533 @ 21320 updates
[2022-01-03 14:55:46,727][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:55:50,678][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:55:50,706][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 533 @ 21320 updates, score 4.385) (writing took 3.9795248648151755 seconds)
[2022-01-03 14:55:50,707][fairseq_cli.train][INFO] - end of epoch 533 (average epoch stats below)
[2022-01-03 14:55:50,719][train][INFO] - {"epoch": 533, "train_loss": "3.98", "train_ntokens": "1796.5", "train_nsentences": "4.95", "train_prob_perplexity": "50.002", "train_code_perplexity": "49.958", "train_temp": "1.798", "train_loss_0": "3.814", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.29889", "train_wps": "3928", "train_ups": "2.19", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "21320", "train_lr": "0.000333125", "train_gnorm": "0.607", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "9968"}
[2022-01-03 14:55:50,796][fairseq.trainer][INFO] - begin training epoch 534
[2022-01-03 14:55:50,797][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:56:04,646][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:56:05,050][valid][INFO] - {"epoch": 534, "valid_loss": "3.964", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "48.367", "valid_code_perplexity": "48.123", "valid_temp": "1.797", "valid_loss_0": "3.796", "valid_loss_1": "0.133", "valid_loss_2": "0.034", "valid_accuracy": "0.28299", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "21360", "valid_best_loss": "3.656"}
[2022-01-03 14:56:05,053][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 534 @ 21360 updates
[2022-01-03 14:56:05,054][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:56:08,950][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:56:08,976][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 534 @ 21360 updates, score 3.964) (writing took 3.923064425587654 seconds)
[2022-01-03 14:56:08,977][fairseq_cli.train][INFO] - end of epoch 534 (average epoch stats below)
[2022-01-03 14:56:08,990][train][INFO] - {"epoch": 534, "train_loss": "3.959", "train_ntokens": "1779.5", "train_nsentences": "4.95", "train_prob_perplexity": "50.032", "train_code_perplexity": "49.993", "train_temp": "1.798", "train_loss_0": "3.794", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30084", "train_wps": "3898.6", "train_ups": "2.19", "train_wpb": "1779.5", "train_bsz": "5", "train_num_updates": "21360", "train_lr": "0.00033375", "train_gnorm": "0.613", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "9986"}
[2022-01-03 14:56:09,068][fairseq.trainer][INFO] - begin training epoch 535
[2022-01-03 14:56:09,069][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:56:22,813][train_inner][INFO] - {"epoch": 535, "update": 535.0, "loss": "3.965", "ntokens": "1792.82", "nsentences": "4.95", "prob_perplexity": "49.707", "code_perplexity": "49.664", "temp": "1.798", "loss_0": "3.8", "loss_1": "0.133", "loss_2": "0.033", "accuracy": "0.30156", "wps": "3924.4", "ups": "2.19", "wpb": "1792.8", "bsz": "5", "num_updates": "21400", "lr": "0.000334375", "gnorm": "0.606", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "10000"}
[2022-01-03 14:56:22,814][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:56:23,212][valid][INFO] - {"epoch": 535, "valid_loss": "4.006", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "49.497", "valid_code_perplexity": "49.28", "valid_temp": "1.797", "valid_loss_0": "3.839", "valid_loss_1": "0.133", "valid_loss_2": "0.033", "valid_accuracy": "0.26538", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "21400", "valid_best_loss": "3.656"}
[2022-01-03 14:56:23,216][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 535 @ 21400 updates
[2022-01-03 14:56:23,216][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:56:27,143][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:56:27,171][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 535 @ 21400 updates, score 4.006) (writing took 3.9549081083387136 seconds)
[2022-01-03 14:56:27,171][fairseq_cli.train][INFO] - end of epoch 535 (average epoch stats below)
[2022-01-03 14:56:27,184][train][INFO] - {"epoch": 535, "train_loss": "3.966", "train_ntokens": "1797.7", "train_nsentences": "4.95", "train_prob_perplexity": "50.138", "train_code_perplexity": "50.093", "train_temp": "1.797", "train_loss_0": "3.801", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30194", "train_wps": "3955", "train_ups": "2.2", "train_wpb": "1797.7", "train_bsz": "5", "train_num_updates": "21400", "train_lr": "0.000334375", "train_gnorm": "0.601", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "10005"}
[2022-01-03 14:56:27,257][fairseq.trainer][INFO] - begin training epoch 536
[2022-01-03 14:56:27,258][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:56:41,285][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:56:41,677][valid][INFO] - {"epoch": 536, "valid_loss": "3.781", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "49.095", "valid_code_perplexity": "49.032", "valid_temp": "1.797", "valid_loss_0": "3.617", "valid_loss_1": "0.133", "valid_loss_2": "0.031", "valid_accuracy": "0.32461", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "21440", "valid_best_loss": "3.656"}
[2022-01-03 14:56:41,680][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 536 @ 21440 updates
[2022-01-03 14:56:41,681][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:56:45,356][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:56:45,385][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 536 @ 21440 updates, score 3.781) (writing took 3.704718578606844 seconds)
[2022-01-03 14:56:45,385][fairseq_cli.train][INFO] - end of epoch 536 (average epoch stats below)
[2022-01-03 14:56:45,398][train][INFO] - {"epoch": 536, "train_loss": "3.943", "train_ntokens": "1789.33", "train_nsentences": "4.95", "train_prob_perplexity": "50.004", "train_code_perplexity": "49.987", "train_temp": "1.797", "train_loss_0": "3.776", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.30474", "train_wps": "3932.3", "train_ups": "2.2", "train_wpb": "1789.3", "train_bsz": "5", "train_num_updates": "21440", "train_lr": "0.000335", "train_gnorm": "0.599", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "10023"}
[2022-01-03 14:56:45,477][fairseq.trainer][INFO] - begin training epoch 537
[2022-01-03 14:56:45,478][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:56:59,479][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:56:59,885][valid][INFO] - {"epoch": 537, "valid_loss": "3.911", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "49.769", "valid_code_perplexity": "49.702", "valid_temp": "1.796", "valid_loss_0": "3.745", "valid_loss_1": "0.133", "valid_loss_2": "0.033", "valid_accuracy": "0.31351", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "21480", "valid_best_loss": "3.656"}
[2022-01-03 14:56:59,888][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 537 @ 21480 updates
[2022-01-03 14:56:59,890][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:57:03,569][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:57:03,595][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 537 @ 21480 updates, score 3.911) (writing took 3.7063648588955402 seconds)
[2022-01-03 14:57:03,595][fairseq_cli.train][INFO] - end of epoch 537 (average epoch stats below)
[2022-01-03 14:57:03,608][train][INFO] - {"epoch": 537, "train_loss": "3.953", "train_ntokens": "1795.42", "train_nsentences": "4.95", "train_prob_perplexity": "50.117", "train_code_perplexity": "50.064", "train_temp": "1.797", "train_loss_0": "3.788", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30166", "train_wps": "3946.7", "train_ups": "2.2", "train_wpb": "1795.4", "train_bsz": "5", "train_num_updates": "21480", "train_lr": "0.000335625", "train_gnorm": "0.612", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10041"}
[2022-01-03 14:57:03,687][fairseq.trainer][INFO] - begin training epoch 538
[2022-01-03 14:57:03,688][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:57:17,721][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:57:18,260][valid][INFO] - {"epoch": 538, "valid_loss": "4.18", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "45.174", "valid_code_perplexity": "45.193", "valid_temp": "1.796", "valid_loss_0": "4.013", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.30112", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "21520", "valid_best_loss": "3.656"}
[2022-01-03 14:57:18,261][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 538 @ 21520 updates
[2022-01-03 14:57:18,262][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:57:21,825][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:57:21,853][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 538 @ 21520 updates, score 4.18) (writing took 3.59176586009562 seconds)
[2022-01-03 14:57:21,854][fairseq_cli.train][INFO] - end of epoch 538 (average epoch stats below)
[2022-01-03 14:57:21,866][train][INFO] - {"epoch": 538, "train_loss": "4.003", "train_ntokens": "1814.33", "train_nsentences": "4.95", "train_prob_perplexity": "50.506", "train_code_perplexity": "50.466", "train_temp": "1.796", "train_loss_0": "3.838", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.29536", "train_wps": "3977.5", "train_ups": "2.19", "train_wpb": "1814.3", "train_bsz": "5", "train_num_updates": "21520", "train_lr": "0.00033625", "train_gnorm": "0.606", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "10059"}
[2022-01-03 14:57:21,937][fairseq.trainer][INFO] - begin training epoch 539
[2022-01-03 14:57:21,938][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:57:35,827][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:57:36,234][valid][INFO] - {"epoch": 539, "valid_loss": "4.14", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "47.321", "valid_code_perplexity": "47.194", "valid_temp": "1.796", "valid_loss_0": "3.976", "valid_loss_1": "0.134", "valid_loss_2": "0.031", "valid_accuracy": "0.28283", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "21560", "valid_best_loss": "3.656"}
[2022-01-03 14:57:36,237][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 539 @ 21560 updates
[2022-01-03 14:57:36,237][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:57:40,038][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:57:40,061][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 539 @ 21560 updates, score 4.14) (writing took 3.8245059847831726 seconds)
[2022-01-03 14:57:40,062][fairseq_cli.train][INFO] - end of epoch 539 (average epoch stats below)
[2022-01-03 14:57:40,074][train][INFO] - {"epoch": 539, "train_loss": "3.965", "train_ntokens": "1791.83", "train_nsentences": "4.95", "train_prob_perplexity": "49.004", "train_code_perplexity": "48.96", "train_temp": "1.796", "train_loss_0": "3.8", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30092", "train_wps": "3939.1", "train_ups": "2.2", "train_wpb": "1791.8", "train_bsz": "5", "train_num_updates": "21560", "train_lr": "0.000336875", "train_gnorm": "0.644", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "10077"}
[2022-01-03 14:57:40,120][fairseq.trainer][INFO] - begin training epoch 540
[2022-01-03 14:57:40,121][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:57:54,168][train_inner][INFO] - {"epoch": 540, "update": 540.0, "loss": "3.963", "ntokens": "1796.32", "nsentences": "4.95", "prob_perplexity": "49.876", "code_perplexity": "49.839", "temp": "1.796", "loss_0": "3.797", "loss_1": "0.133", "loss_2": "0.033", "accuracy": "0.30125", "wps": "3933.2", "ups": "2.19", "wpb": "1796.3", "bsz": "5", "num_updates": "21600", "lr": "0.0003375", "gnorm": "0.613", "clip": "0", "train_wall": "68", "gb_free": "6.1", "wall": "10092"}
[2022-01-03 14:57:54,169][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:57:54,570][valid][INFO] - {"epoch": 540, "valid_loss": "4.185", "valid_ntokens": "812", "valid_nsentences": "2", "valid_prob_perplexity": "49.44", "valid_code_perplexity": "49.543", "valid_temp": "1.795", "valid_loss_0": "4.02", "valid_loss_1": "0.133", "valid_loss_2": "0.032", "valid_accuracy": "0.28571", "valid_wps": "0", "valid_wpb": "812", "valid_bsz": "2", "valid_num_updates": "21600", "valid_best_loss": "3.656"}
[2022-01-03 14:57:54,573][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 540 @ 21600 updates
[2022-01-03 14:57:54,574][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:57:58,317][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:57:58,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 540 @ 21600 updates, score 4.185) (writing took 3.772231119684875 seconds)
[2022-01-03 14:57:58,346][fairseq_cli.train][INFO] - end of epoch 540 (average epoch stats below)
[2022-01-03 14:57:58,359][train][INFO] - {"epoch": 540, "train_loss": "3.948", "train_ntokens": "1790.7", "train_nsentences": "4.95", "train_prob_perplexity": "49.748", "train_code_perplexity": "49.72", "train_temp": "1.795", "train_loss_0": "3.782", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.30364", "train_wps": "3920.1", "train_ups": "2.19", "train_wpb": "1790.7", "train_bsz": "5", "train_num_updates": "21600", "train_lr": "0.0003375", "train_gnorm": "0.604", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "10096"}
[2022-01-03 14:57:58,438][fairseq.trainer][INFO] - begin training epoch 541
[2022-01-03 14:57:58,439][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:58:12,399][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:58:12,796][valid][INFO] - {"epoch": 541, "valid_loss": "4.158", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "48.113", "valid_code_perplexity": "47.93", "valid_temp": "1.795", "valid_loss_0": "3.993", "valid_loss_1": "0.133", "valid_loss_2": "0.032", "valid_accuracy": "0.27701", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "21640", "valid_best_loss": "3.656"}
[2022-01-03 14:58:12,799][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 541 @ 21640 updates
[2022-01-03 14:58:12,799][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:58:16,616][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:58:16,636][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 541 @ 21640 updates, score 4.158) (writing took 3.83751676697284 seconds)
[2022-01-03 14:58:16,637][fairseq_cli.train][INFO] - end of epoch 541 (average epoch stats below)
[2022-01-03 14:58:16,649][train][INFO] - {"epoch": 541, "train_loss": "3.959", "train_ntokens": "1801.15", "train_nsentences": "4.95", "train_prob_perplexity": "49.939", "train_code_perplexity": "49.871", "train_temp": "1.795", "train_loss_0": "3.793", "train_loss_1": "0.133", "train_loss_2": "0.033", "train_accuracy": "0.30437", "train_wps": "3941.8", "train_ups": "2.19", "train_wpb": "1801.2", "train_bsz": "5", "train_num_updates": "21640", "train_lr": "0.000338125", "train_gnorm": "0.61", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10114"}
[2022-01-03 14:58:16,706][fairseq.trainer][INFO] - begin training epoch 542
[2022-01-03 14:58:16,707][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:58:30,613][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:58:31,016][valid][INFO] - {"epoch": 542, "valid_loss": "3.995", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "48.59", "valid_code_perplexity": "48.682", "valid_temp": "1.795", "valid_loss_0": "3.833", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.30274", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "21680", "valid_best_loss": "3.656"}
[2022-01-03 14:58:31,020][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 542 @ 21680 updates
[2022-01-03 14:58:31,020][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:58:34,913][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:58:34,939][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 542 @ 21680 updates, score 3.995) (writing took 3.9197058361023664 seconds)
[2022-01-03 14:58:34,940][fairseq_cli.train][INFO] - end of epoch 542 (average epoch stats below)
[2022-01-03 14:58:34,952][train][INFO] - {"epoch": 542, "train_loss": "3.976", "train_ntokens": "1787.7", "train_nsentences": "4.95", "train_prob_perplexity": "50.193", "train_code_perplexity": "50.149", "train_temp": "1.795", "train_loss_0": "3.811", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.29953", "train_wps": "3909.6", "train_ups": "2.19", "train_wpb": "1787.7", "train_bsz": "5", "train_num_updates": "21680", "train_lr": "0.00033875", "train_gnorm": "0.588", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.5", "train_wall": "10132"}
[2022-01-03 14:58:35,001][fairseq.trainer][INFO] - begin training epoch 543
[2022-01-03 14:58:35,001][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:58:49,021][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:58:49,453][valid][INFO] - {"epoch": 543, "valid_loss": "3.685", "valid_ntokens": "704", "valid_nsentences": "2", "valid_prob_perplexity": "42.687", "valid_code_perplexity": "42.582", "valid_temp": "1.794", "valid_loss_0": "3.517", "valid_loss_1": "0.135", "valid_loss_2": "0.034", "valid_accuracy": "0.37074", "valid_wps": "0", "valid_wpb": "704", "valid_bsz": "2", "valid_num_updates": "21720", "valid_best_loss": "3.656"}
[2022-01-03 14:58:49,458][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 543 @ 21720 updates
[2022-01-03 14:58:49,459][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:58:53,144][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:58:53,174][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 543 @ 21720 updates, score 3.685) (writing took 3.715921675786376 seconds)
[2022-01-03 14:58:53,174][fairseq_cli.train][INFO] - end of epoch 543 (average epoch stats below)
[2022-01-03 14:58:53,187][train][INFO] - {"epoch": 543, "train_loss": "3.957", "train_ntokens": "1787.55", "train_nsentences": "4.95", "train_prob_perplexity": "50.217", "train_code_perplexity": "50.18", "train_temp": "1.794", "train_loss_0": "3.793", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30391", "train_wps": "3923.9", "train_ups": "2.2", "train_wpb": "1787.5", "train_bsz": "5", "train_num_updates": "21720", "train_lr": "0.000339375", "train_gnorm": "0.605", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10151"}
[2022-01-03 14:58:53,264][fairseq.trainer][INFO] - begin training epoch 544
[2022-01-03 14:58:53,265][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:59:07,087][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:59:07,498][valid][INFO] - {"epoch": 544, "valid_loss": "3.972", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "48.838", "valid_code_perplexity": "48.814", "valid_temp": "1.794", "valid_loss_0": "3.808", "valid_loss_1": "0.133", "valid_loss_2": "0.03", "valid_accuracy": "0.29675", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "21760", "valid_best_loss": "3.656"}
[2022-01-03 14:59:07,503][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 544 @ 21760 updates
[2022-01-03 14:59:07,504][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:59:11,474][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:59:11,503][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 544 @ 21760 updates, score 3.972) (writing took 4.000835061073303 seconds)
[2022-01-03 14:59:11,504][fairseq_cli.train][INFO] - end of epoch 544 (average epoch stats below)
[2022-01-03 14:59:11,517][train][INFO] - {"epoch": 544, "train_loss": "3.917", "train_ntokens": "1774.05", "train_nsentences": "4.95", "train_prob_perplexity": "49.796", "train_code_perplexity": "49.761", "train_temp": "1.794", "train_loss_0": "3.753", "train_loss_1": "0.133", "train_loss_2": "0.031", "train_accuracy": "0.3105", "train_wps": "3874.2", "train_ups": "2.18", "train_wpb": "1774", "train_bsz": "5", "train_num_updates": "21760", "train_lr": "0.00034", "train_gnorm": "0.602", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "10169"}
[2022-01-03 14:59:11,598][fairseq.trainer][INFO] - begin training epoch 545
[2022-01-03 14:59:11,599][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:59:25,574][train_inner][INFO] - {"epoch": 545, "update": 545.0, "loss": "3.954", "ntokens": "1789.4", "nsentences": "4.95", "prob_perplexity": "50.102", "code_perplexity": "50.06", "temp": "1.794", "loss_0": "3.79", "loss_1": "0.133", "loss_2": "0.032", "accuracy": "0.30422", "wps": "3915.8", "ups": "2.19", "wpb": "1789.4", "bsz": "5", "num_updates": "21800", "lr": "0.000340625", "gnorm": "0.602", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "10183"}
[2022-01-03 14:59:25,575][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:59:26,047][valid][INFO] - {"epoch": 545, "valid_loss": "4.305", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "50.167", "valid_code_perplexity": "50.168", "valid_temp": "1.793", "valid_loss_0": "4.14", "valid_loss_1": "0.133", "valid_loss_2": "0.032", "valid_accuracy": "0.24459", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "21800", "valid_best_loss": "3.656"}
[2022-01-03 14:59:26,048][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 545 @ 21800 updates
[2022-01-03 14:59:26,049][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:59:29,672][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:59:29,699][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 545 @ 21800 updates, score 4.305) (writing took 3.6505044708028436 seconds)
[2022-01-03 14:59:29,699][fairseq_cli.train][INFO] - end of epoch 545 (average epoch stats below)
[2022-01-03 14:59:29,713][train][INFO] - {"epoch": 545, "train_loss": "3.962", "train_ntokens": "1796.58", "train_nsentences": "4.95", "train_prob_perplexity": "50.364", "train_code_perplexity": "50.338", "train_temp": "1.794", "train_loss_0": "3.797", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30284", "train_wps": "3952.4", "train_ups": "2.2", "train_wpb": "1796.6", "train_bsz": "5", "train_num_updates": "21800", "train_lr": "0.000340625", "train_gnorm": "0.606", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "10187"}
[2022-01-03 14:59:29,791][fairseq.trainer][INFO] - begin training epoch 546
[2022-01-03 14:59:29,791][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 14:59:43,637][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 14:59:44,033][valid][INFO] - {"epoch": 546, "valid_loss": "4.268", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "49.259", "valid_code_perplexity": "49.236", "valid_temp": "1.793", "valid_loss_0": "4.108", "valid_loss_1": "0.133", "valid_loss_2": "0.027", "valid_accuracy": "0.25648", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "21840", "valid_best_loss": "3.656"}
[2022-01-03 14:59:44,037][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 546 @ 21840 updates
[2022-01-03 14:59:44,038][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:59:47,989][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 14:59:48,016][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 546 @ 21840 updates, score 4.268) (writing took 3.978842245414853 seconds)
[2022-01-03 14:59:48,016][fairseq_cli.train][INFO] - end of epoch 546 (average epoch stats below)
[2022-01-03 14:59:48,029][train][INFO] - {"epoch": 546, "train_loss": "3.998", "train_ntokens": "1798.08", "train_nsentences": "4.95", "train_prob_perplexity": "50.934", "train_code_perplexity": "50.894", "train_temp": "1.793", "train_loss_0": "3.835", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.29589", "train_wps": "3929.5", "train_ups": "2.19", "train_wpb": "1798.1", "train_bsz": "5", "train_num_updates": "21840", "train_lr": "0.00034125", "train_gnorm": "0.594", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10205"}
[2022-01-03 14:59:48,078][fairseq.trainer][INFO] - begin training epoch 547
[2022-01-03 14:59:48,079][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:00:01,818][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:00:02,212][valid][INFO] - {"epoch": 547, "valid_loss": "4.358", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "49.801", "valid_code_perplexity": "49.778", "valid_temp": "1.793", "valid_loss_0": "4.195", "valid_loss_1": "0.133", "valid_loss_2": "0.03", "valid_accuracy": "0.2467", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "21880", "valid_best_loss": "3.656"}
[2022-01-03 15:00:02,215][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 547 @ 21880 updates
[2022-01-03 15:00:02,216][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:00:06,141][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:00:06,168][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 547 @ 21880 updates, score 4.358) (writing took 3.9529375303536654 seconds)
[2022-01-03 15:00:06,169][fairseq_cli.train][INFO] - end of epoch 547 (average epoch stats below)
[2022-01-03 15:00:06,181][train][INFO] - {"epoch": 547, "train_loss": "3.938", "train_ntokens": "1786.3", "train_nsentences": "4.95", "train_prob_perplexity": "50.523", "train_code_perplexity": "50.472", "train_temp": "1.793", "train_loss_0": "3.773", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30685", "train_wps": "3939", "train_ups": "2.21", "train_wpb": "1786.3", "train_bsz": "5", "train_num_updates": "21880", "train_lr": "0.000341875", "train_gnorm": "0.617", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "10224"}
[2022-01-03 15:00:06,258][fairseq.trainer][INFO] - begin training epoch 548
[2022-01-03 15:00:06,259][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:00:20,132][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:00:20,575][valid][INFO] - {"epoch": 548, "valid_loss": "3.967", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "48.984", "valid_code_perplexity": "48.918", "valid_temp": "1.792", "valid_loss_0": "3.806", "valid_loss_1": "0.133", "valid_loss_2": "0.028", "valid_accuracy": "0.29054", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "21920", "valid_best_loss": "3.656"}
[2022-01-03 15:00:20,577][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 548 @ 21920 updates
[2022-01-03 15:00:20,578][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:00:24,341][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:00:24,371][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 548 @ 21920 updates, score 3.967) (writing took 3.7936993138864636 seconds)
[2022-01-03 15:00:24,371][fairseq_cli.train][INFO] - end of epoch 548 (average epoch stats below)
[2022-01-03 15:00:24,384][train][INFO] - {"epoch": 548, "train_loss": "3.94", "train_ntokens": "1786.72", "train_nsentences": "4.95", "train_prob_perplexity": "50.499", "train_code_perplexity": "50.452", "train_temp": "1.793", "train_loss_0": "3.777", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.30185", "train_wps": "3929.1", "train_ups": "2.2", "train_wpb": "1786.7", "train_bsz": "5", "train_num_updates": "21920", "train_lr": "0.0003425", "train_gnorm": "0.604", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10242"}
[2022-01-03 15:00:24,472][fairseq.trainer][INFO] - begin training epoch 549
[2022-01-03 15:00:24,473][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:00:38,448][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:00:38,840][valid][INFO] - {"epoch": 549, "valid_loss": "4.112", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "45.132", "valid_code_perplexity": "45.058", "valid_temp": "1.792", "valid_loss_0": "3.948", "valid_loss_1": "0.134", "valid_loss_2": "0.031", "valid_accuracy": "0.28189", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "21960", "valid_best_loss": "3.656"}
[2022-01-03 15:00:38,845][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 549 @ 21960 updates
[2022-01-03 15:00:38,847][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:00:42,542][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:00:42,560][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 549 @ 21960 updates, score 4.112) (writing took 3.714149234816432 seconds)
[2022-01-03 15:00:42,560][fairseq_cli.train][INFO] - end of epoch 549 (average epoch stats below)
[2022-01-03 15:00:42,573][train][INFO] - {"epoch": 549, "train_loss": "3.949", "train_ntokens": "1814.03", "train_nsentences": "4.95", "train_prob_perplexity": "50.557", "train_code_perplexity": "50.496", "train_temp": "1.792", "train_loss_0": "3.787", "train_loss_1": "0.133", "train_loss_2": "0.029", "train_accuracy": "0.30135", "train_wps": "3992.2", "train_ups": "2.2", "train_wpb": "1814", "train_bsz": "5", "train_num_updates": "21960", "train_lr": "0.000343125", "train_gnorm": "0.594", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10260"}
[2022-01-03 15:00:42,622][fairseq.trainer][INFO] - begin training epoch 550
[2022-01-03 15:00:42,623][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:00:56,581][train_inner][INFO] - {"epoch": 550, "update": 550.0, "loss": "3.96", "ntokens": "1797.6", "nsentences": "4.95", "prob_perplexity": "50.523", "code_perplexity": "50.473", "temp": "1.793", "loss_0": "3.797", "loss_1": "0.133", "loss_2": "0.03", "accuracy": "0.30076", "wps": "3951", "ups": "2.2", "wpb": "1797.6", "bsz": "5", "num_updates": "22000", "lr": "0.00034375", "gnorm": "0.601", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "10274"}
[2022-01-03 15:00:56,582][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:00:56,980][valid][INFO] - {"epoch": 550, "valid_loss": "3.838", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "48.767", "valid_code_perplexity": "48.662", "valid_temp": "1.792", "valid_loss_0": "3.676", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.32338", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "22000", "valid_best_loss": "3.656"}
[2022-01-03 15:00:56,984][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 550 @ 22000 updates
[2022-01-03 15:00:56,986][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:01:00,921][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:01:00,949][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 550 @ 22000 updates, score 3.838) (writing took 3.964795290492475 seconds)
[2022-01-03 15:01:00,950][fairseq_cli.train][INFO] - end of epoch 550 (average epoch stats below)
[2022-01-03 15:01:00,962][train][INFO] - {"epoch": 550, "train_loss": "3.975", "train_ntokens": "1802.88", "train_nsentences": "4.95", "train_prob_perplexity": "50.102", "train_code_perplexity": "50.052", "train_temp": "1.792", "train_loss_0": "3.812", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.29794", "train_wps": "3924.2", "train_ups": "2.18", "train_wpb": "1802.9", "train_bsz": "5", "train_num_updates": "22000", "train_lr": "0.00034375", "train_gnorm": "0.598", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10278"}
[2022-01-03 15:01:01,037][fairseq.trainer][INFO] - begin training epoch 551
[2022-01-03 15:01:01,038][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:01:14,982][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:01:15,387][valid][INFO] - {"epoch": 551, "valid_loss": "3.959", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "49.772", "valid_code_perplexity": "49.713", "valid_temp": "1.791", "valid_loss_0": "3.799", "valid_loss_1": "0.133", "valid_loss_2": "0.027", "valid_accuracy": "0.29656", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "22040", "valid_best_loss": "3.656"}
[2022-01-03 15:01:15,390][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 551 @ 22040 updates
[2022-01-03 15:01:15,390][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:01:19,082][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:01:19,083][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 551 @ 22040 updates, score 3.959) (writing took 3.6930913534015417 seconds)
[2022-01-03 15:01:19,083][fairseq_cli.train][INFO] - end of epoch 551 (average epoch stats below)
[2022-01-03 15:01:19,095][train][INFO] - {"epoch": 551, "train_loss": "3.94", "train_ntokens": "1791.4", "train_nsentences": "4.95", "train_prob_perplexity": "50.276", "train_code_perplexity": "50.214", "train_temp": "1.791", "train_loss_0": "3.777", "train_loss_1": "0.133", "train_loss_2": "0.029", "train_accuracy": "0.30391", "train_wps": "3954.4", "train_ups": "2.21", "train_wpb": "1791.4", "train_bsz": "5", "train_num_updates": "22040", "train_lr": "0.000344375", "train_gnorm": "0.612", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "10296"}
[2022-01-03 15:01:19,131][fairseq.trainer][INFO] - begin training epoch 552
[2022-01-03 15:01:19,132][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:01:33,114][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:01:33,531][valid][INFO] - {"epoch": 552, "valid_loss": "3.499", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "48.889", "valid_code_perplexity": "49.028", "valid_temp": "1.791", "valid_loss_0": "3.336", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.36022", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "22080", "valid_best_loss": "3.499"}
[2022-01-03 15:01:33,534][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 552 @ 22080 updates
[2022-01-03 15:01:33,534][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 15:01:37,420][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 15:01:48,816][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 552 @ 22080 updates, score 3.499) (writing took 15.282057541422546 seconds)
[2022-01-03 15:01:48,816][fairseq_cli.train][INFO] - end of epoch 552 (average epoch stats below)
[2022-01-03 15:01:48,830][train][INFO] - {"epoch": 552, "train_loss": "3.965", "train_ntokens": "1797.58", "train_nsentences": "4.95", "train_prob_perplexity": "51.254", "train_code_perplexity": "51.216", "train_temp": "1.791", "train_loss_0": "3.802", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.29999", "train_wps": "2419.3", "train_ups": "1.35", "train_wpb": "1797.6", "train_bsz": "5", "train_num_updates": "22080", "train_lr": "0.000345", "train_gnorm": "0.608", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "10326"}
[2022-01-03 15:01:48,907][fairseq.trainer][INFO] - begin training epoch 553
[2022-01-03 15:01:48,908][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:02:02,613][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:02:03,026][valid][INFO] - {"epoch": 553, "valid_loss": "4.032", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "45.552", "valid_code_perplexity": "45.614", "valid_temp": "1.791", "valid_loss_0": "3.869", "valid_loss_1": "0.134", "valid_loss_2": "0.029", "valid_accuracy": "0.26729", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "22120", "valid_best_loss": "3.499"}
[2022-01-03 15:02:03,030][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 553 @ 22120 updates
[2022-01-03 15:02:03,031][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:02:07,133][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:02:07,158][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 553 @ 22120 updates, score 4.032) (writing took 4.128265778534114 seconds)
[2022-01-03 15:02:07,159][fairseq_cli.train][INFO] - end of epoch 553 (average epoch stats below)
[2022-01-03 15:02:07,171][train][INFO] - {"epoch": 553, "train_loss": "3.91", "train_ntokens": "1803.1", "train_nsentences": "4.95", "train_prob_perplexity": "50.693", "train_code_perplexity": "50.661", "train_temp": "1.791", "train_loss_0": "3.748", "train_loss_1": "0.133", "train_loss_2": "0.029", "train_accuracy": "0.30796", "train_wps": "3934.9", "train_ups": "2.18", "train_wpb": "1803.1", "train_bsz": "5", "train_num_updates": "22120", "train_lr": "0.000345625", "train_gnorm": "0.587", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "10345"}
[2022-01-03 15:02:07,245][fairseq.trainer][INFO] - begin training epoch 554
[2022-01-03 15:02:07,246][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:02:21,061][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:02:21,462][valid][INFO] - {"epoch": 554, "valid_loss": "3.903", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "49.2", "valid_code_perplexity": "49.172", "valid_temp": "1.79", "valid_loss_0": "3.741", "valid_loss_1": "0.133", "valid_loss_2": "0.028", "valid_accuracy": "0.3137", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "22160", "valid_best_loss": "3.499"}
[2022-01-03 15:02:21,466][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 554 @ 22160 updates
[2022-01-03 15:02:21,466][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:02:25,430][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:02:25,459][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 554 @ 22160 updates, score 3.903) (writing took 3.9937948687002063 seconds)
[2022-01-03 15:02:25,460][fairseq_cli.train][INFO] - end of epoch 554 (average epoch stats below)
[2022-01-03 15:02:25,472][train][INFO] - {"epoch": 554, "train_loss": "3.948", "train_ntokens": "1782.55", "train_nsentences": "4.95", "train_prob_perplexity": "50.382", "train_code_perplexity": "50.332", "train_temp": "1.79", "train_loss_0": "3.786", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.30277", "train_wps": "3898.7", "train_ups": "2.19", "train_wpb": "1782.5", "train_bsz": "5", "train_num_updates": "22160", "train_lr": "0.00034625", "train_gnorm": "0.6", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10363"}
[2022-01-03 15:02:25,529][fairseq.trainer][INFO] - begin training epoch 555
[2022-01-03 15:02:25,530][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:02:39,342][train_inner][INFO] - {"epoch": 555, "update": 555.0, "loss": "3.938", "ntokens": "1791.42", "nsentences": "4.95", "prob_perplexity": "50.772", "code_perplexity": "50.725", "temp": "1.791", "loss_0": "3.776", "loss_1": "0.133", "loss_2": "0.029", "accuracy": "0.30439", "wps": "3487.1", "ups": "1.95", "wpb": "1791.4", "bsz": "5", "num_updates": "22200", "lr": "0.000346875", "gnorm": "0.601", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "10377"}
[2022-01-03 15:02:39,342][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:02:39,751][valid][INFO] - {"epoch": 555, "valid_loss": "4.085", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "49.142", "valid_code_perplexity": "49.169", "valid_temp": "1.79", "valid_loss_0": "3.921", "valid_loss_1": "0.133", "valid_loss_2": "0.031", "valid_accuracy": "0.25204", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "22200", "valid_best_loss": "3.499"}
[2022-01-03 15:02:39,755][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 555 @ 22200 updates
[2022-01-03 15:02:39,756][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:02:43,671][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:02:43,699][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 555 @ 22200 updates, score 4.085) (writing took 3.9440736081451178 seconds)
[2022-01-03 15:02:43,700][fairseq_cli.train][INFO] - end of epoch 555 (average epoch stats below)
[2022-01-03 15:02:43,712][train][INFO] - {"epoch": 555, "train_loss": "3.93", "train_ntokens": "1782.5", "train_nsentences": "4.95", "train_prob_perplexity": "51.255", "train_code_perplexity": "51.204", "train_temp": "1.79", "train_loss_0": "3.768", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.30731", "train_wps": "3911.7", "train_ups": "2.19", "train_wpb": "1782.5", "train_bsz": "5", "train_num_updates": "22200", "train_lr": "0.000346875", "train_gnorm": "0.598", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10381"}
[2022-01-03 15:02:43,768][fairseq.trainer][INFO] - begin training epoch 556
[2022-01-03 15:02:43,768][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:02:57,668][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:02:58,068][valid][INFO] - {"epoch": 556, "valid_loss": "4.178", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "49.952", "valid_code_perplexity": "49.922", "valid_temp": "1.79", "valid_loss_0": "4.016", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.27953", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "22240", "valid_best_loss": "3.499"}
[2022-01-03 15:02:58,071][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 556 @ 22240 updates
[2022-01-03 15:02:58,072][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:03:01,862][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:03:01,887][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 556 @ 22240 updates, score 4.178) (writing took 3.816305230371654 seconds)
[2022-01-03 15:03:01,888][fairseq_cli.train][INFO] - end of epoch 556 (average epoch stats below)
[2022-01-03 15:03:01,900][train][INFO] - {"epoch": 556, "train_loss": "3.944", "train_ntokens": "1787.62", "train_nsentences": "4.95", "train_prob_perplexity": "50.882", "train_code_perplexity": "50.834", "train_temp": "1.79", "train_loss_0": "3.781", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.30503", "train_wps": "3934.1", "train_ups": "2.2", "train_wpb": "1787.6", "train_bsz": "5", "train_num_updates": "22240", "train_lr": "0.0003475", "train_gnorm": "0.594", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "10399"}
[2022-01-03 15:03:01,947][fairseq.trainer][INFO] - begin training epoch 557
[2022-01-03 15:03:01,948][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:03:15,804][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:03:16,224][valid][INFO] - {"epoch": 557, "valid_loss": "3.992", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "46.506", "valid_code_perplexity": "46.426", "valid_temp": "1.789", "valid_loss_0": "3.828", "valid_loss_1": "0.134", "valid_loss_2": "0.03", "valid_accuracy": "0.29467", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "22280", "valid_best_loss": "3.499"}
[2022-01-03 15:03:16,229][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 557 @ 22280 updates
[2022-01-03 15:03:16,231][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:03:20,189][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:03:20,219][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 557 @ 22280 updates, score 3.992) (writing took 3.9895860319957137 seconds)
[2022-01-03 15:03:20,220][fairseq_cli.train][INFO] - end of epoch 557 (average epoch stats below)
[2022-01-03 15:03:20,233][train][INFO] - {"epoch": 557, "train_loss": "3.933", "train_ntokens": "1798.45", "train_nsentences": "4.95", "train_prob_perplexity": "51.496", "train_code_perplexity": "51.457", "train_temp": "1.789", "train_loss_0": "3.77", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.3046", "train_wps": "3926.8", "train_ups": "2.18", "train_wpb": "1798.5", "train_bsz": "5", "train_num_updates": "22280", "train_lr": "0.000348125", "train_gnorm": "0.604", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10418"}
[2022-01-03 15:03:20,317][fairseq.trainer][INFO] - begin training epoch 558
[2022-01-03 15:03:20,317][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:03:34,233][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:03:34,641][valid][INFO] - {"epoch": 558, "valid_loss": "3.839", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "49.446", "valid_code_perplexity": "49.458", "valid_temp": "1.789", "valid_loss_0": "3.673", "valid_loss_1": "0.133", "valid_loss_2": "0.032", "valid_accuracy": "0.31882", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "22320", "valid_best_loss": "3.499"}
[2022-01-03 15:03:34,644][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 558 @ 22320 updates
[2022-01-03 15:03:34,645][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:03:38,392][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:03:38,415][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 558 @ 22320 updates, score 3.839) (writing took 3.7708885380998254 seconds)
[2022-01-03 15:03:38,415][fairseq_cli.train][INFO] - end of epoch 558 (average epoch stats below)
[2022-01-03 15:03:38,428][train][INFO] - {"epoch": 558, "train_loss": "3.938", "train_ntokens": "1776.25", "train_nsentences": "4.95", "train_prob_perplexity": "51.112", "train_code_perplexity": "51.05", "train_temp": "1.789", "train_loss_0": "3.774", "train_loss_1": "0.133", "train_loss_2": "0.031", "train_accuracy": "0.30601", "train_wps": "3907.7", "train_ups": "2.2", "train_wpb": "1776.2", "train_bsz": "5", "train_num_updates": "22320", "train_lr": "0.00034875", "train_gnorm": "0.573", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10436"}
[2022-01-03 15:03:38,481][fairseq.trainer][INFO] - begin training epoch 559
[2022-01-03 15:03:38,482][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:03:52,403][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:03:52,806][valid][INFO] - {"epoch": 559, "valid_loss": "3.959", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "47.137", "valid_code_perplexity": "47.008", "valid_temp": "1.788", "valid_loss_0": "3.795", "valid_loss_1": "0.134", "valid_loss_2": "0.03", "valid_accuracy": "0.30585", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "22360", "valid_best_loss": "3.499"}
[2022-01-03 15:03:52,809][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 559 @ 22360 updates
[2022-01-03 15:03:52,810][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:03:56,604][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:03:56,632][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 559 @ 22360 updates, score 3.959) (writing took 3.822710933163762 seconds)
[2022-01-03 15:03:56,632][fairseq_cli.train][INFO] - end of epoch 559 (average epoch stats below)
[2022-01-03 15:03:56,645][train][INFO] - {"epoch": 559, "train_loss": "3.932", "train_ntokens": "1796.53", "train_nsentences": "4.95", "train_prob_perplexity": "50.86", "train_code_perplexity": "50.802", "train_temp": "1.789", "train_loss_0": "3.769", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.30679", "train_wps": "3947.5", "train_ups": "2.2", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "22360", "train_lr": "0.000349375", "train_gnorm": "0.58", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "10454"}
[2022-01-03 15:03:56,716][fairseq.trainer][INFO] - begin training epoch 560
[2022-01-03 15:03:56,717][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:04:10,464][train_inner][INFO] - {"epoch": 560, "update": 560.0, "loss": "3.939", "ntokens": "1789.15", "nsentences": "4.95", "prob_perplexity": "51.12", "code_perplexity": "51.07", "temp": "1.789", "loss_0": "3.776", "loss_1": "0.133", "loss_2": "0.03", "accuracy": "0.30561", "wps": "3927.5", "ups": "2.2", "wpb": "1789.2", "bsz": "5", "num_updates": "22400", "lr": "0.00035", "gnorm": "0.594", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "10468"}
[2022-01-03 15:04:10,465][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:04:10,860][valid][INFO] - {"epoch": 560, "valid_loss": "4.001", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "46.91", "valid_code_perplexity": "46.736", "valid_temp": "1.788", "valid_loss_0": "3.836", "valid_loss_1": "0.134", "valid_loss_2": "0.031", "valid_accuracy": "0.30612", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "22400", "valid_best_loss": "3.499"}
[2022-01-03 15:04:10,863][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 560 @ 22400 updates
[2022-01-03 15:04:10,864][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:04:14,755][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:04:14,774][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 560 @ 22400 updates, score 4.001) (writing took 3.911371788010001 seconds)
[2022-01-03 15:04:14,775][fairseq_cli.train][INFO] - end of epoch 560 (average epoch stats below)
[2022-01-03 15:04:14,787][train][INFO] - {"epoch": 560, "train_loss": "3.948", "train_ntokens": "1786.92", "train_nsentences": "4.95", "train_prob_perplexity": "51.251", "train_code_perplexity": "51.206", "train_temp": "1.788", "train_loss_0": "3.785", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.30565", "train_wps": "3942.4", "train_ups": "2.21", "train_wpb": "1786.9", "train_bsz": "5", "train_num_updates": "22400", "train_lr": "0.00035", "train_gnorm": "0.62", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "10472"}
[2022-01-03 15:04:14,831][fairseq.trainer][INFO] - begin training epoch 561
[2022-01-03 15:04:14,832][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:04:28,754][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:04:29,238][valid][INFO] - {"epoch": 561, "valid_loss": "3.764", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "43.154", "valid_code_perplexity": "43.03", "valid_temp": "1.788", "valid_loss_0": "3.596", "valid_loss_1": "0.135", "valid_loss_2": "0.034", "valid_accuracy": "0.31467", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "22440", "valid_best_loss": "3.499"}
[2022-01-03 15:04:29,240][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 561 @ 22440 updates
[2022-01-03 15:04:29,241][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:04:32,992][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:04:33,022][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 561 @ 22440 updates, score 3.764) (writing took 3.781645502895117 seconds)
[2022-01-03 15:04:33,022][fairseq_cli.train][INFO] - end of epoch 561 (average epoch stats below)
[2022-01-03 15:04:33,035][train][INFO] - {"epoch": 561, "train_loss": "3.944", "train_ntokens": "1787.7", "train_nsentences": "4.95", "train_prob_perplexity": "51.338", "train_code_perplexity": "51.297", "train_temp": "1.788", "train_loss_0": "3.779", "train_loss_1": "0.133", "train_loss_2": "0.032", "train_accuracy": "0.30324", "train_wps": "3921.5", "train_ups": "2.19", "train_wpb": "1787.7", "train_bsz": "5", "train_num_updates": "22440", "train_lr": "0.000350625", "train_gnorm": "0.592", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10490"}
[2022-01-03 15:04:33,116][fairseq.trainer][INFO] - begin training epoch 562
[2022-01-03 15:04:33,117][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:04:46,894][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:04:47,290][valid][INFO] - {"epoch": 562, "valid_loss": "4.137", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "43.656", "valid_code_perplexity": "43.427", "valid_temp": "1.787", "valid_loss_0": "3.969", "valid_loss_1": "0.134", "valid_loss_2": "0.033", "valid_accuracy": "0.27249", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "22480", "valid_best_loss": "3.499"}
[2022-01-03 15:04:47,293][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 562 @ 22480 updates
[2022-01-03 15:04:47,294][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:04:51,216][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:04:51,245][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 562 @ 22480 updates, score 4.137) (writing took 3.9516002889722586 seconds)
[2022-01-03 15:04:51,245][fairseq_cli.train][INFO] - end of epoch 562 (average epoch stats below)
[2022-01-03 15:04:51,258][train][INFO] - {"epoch": 562, "train_loss": "3.971", "train_ntokens": "1806.1", "train_nsentences": "4.95", "train_prob_perplexity": "51.984", "train_code_perplexity": "51.913", "train_temp": "1.788", "train_loss_0": "3.808", "train_loss_1": "0.133", "train_loss_2": "0.031", "train_accuracy": "0.29832", "train_wps": "3967.3", "train_ups": "2.2", "train_wpb": "1806.1", "train_bsz": "5", "train_num_updates": "22480", "train_lr": "0.00035125", "train_gnorm": "0.598", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "10509"}
[2022-01-03 15:04:51,338][fairseq.trainer][INFO] - begin training epoch 563
[2022-01-03 15:04:51,338][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:05:05,156][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:05:05,551][valid][INFO] - {"epoch": 563, "valid_loss": "4.056", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "52.34", "valid_code_perplexity": "52.465", "valid_temp": "1.787", "valid_loss_0": "3.893", "valid_loss_1": "0.132", "valid_loss_2": "0.03", "valid_accuracy": "0.28426", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "22520", "valid_best_loss": "3.499"}
[2022-01-03 15:05:05,554][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 563 @ 22520 updates
[2022-01-03 15:05:05,554][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:05:09,499][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:05:09,526][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 563 @ 22520 updates, score 4.056) (writing took 3.9719736501574516 seconds)
[2022-01-03 15:05:09,526][fairseq_cli.train][INFO] - end of epoch 563 (average epoch stats below)
[2022-01-03 15:05:09,539][train][INFO] - {"epoch": 563, "train_loss": "3.921", "train_ntokens": "1789.42", "train_nsentences": "4.95", "train_prob_perplexity": "51.833", "train_code_perplexity": "51.79", "train_temp": "1.787", "train_loss_0": "3.758", "train_loss_1": "0.133", "train_loss_2": "0.031", "train_accuracy": "0.3042", "train_wps": "3918.1", "train_ups": "2.19", "train_wpb": "1789.4", "train_bsz": "5", "train_num_updates": "22520", "train_lr": "0.000351875", "train_gnorm": "0.586", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "10527"}
[2022-01-03 15:05:09,609][fairseq.trainer][INFO] - begin training epoch 564
[2022-01-03 15:05:09,610][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:05:23,464][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:05:23,879][valid][INFO] - {"epoch": 564, "valid_loss": "3.854", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "50.052", "valid_code_perplexity": "49.94", "valid_temp": "1.787", "valid_loss_0": "3.693", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.33657", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "22560", "valid_best_loss": "3.499"}
[2022-01-03 15:05:23,882][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 564 @ 22560 updates
[2022-01-03 15:05:23,883][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:05:27,772][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:05:27,801][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 564 @ 22560 updates, score 3.854) (writing took 3.918958039022982 seconds)
[2022-01-03 15:05:27,801][fairseq_cli.train][INFO] - end of epoch 564 (average epoch stats below)
[2022-01-03 15:05:27,814][train][INFO] - {"epoch": 564, "train_loss": "3.966", "train_ntokens": "1794.42", "train_nsentences": "4.95", "train_prob_perplexity": "51.353", "train_code_perplexity": "51.268", "train_temp": "1.787", "train_loss_0": "3.803", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.29869", "train_wps": "3930.3", "train_ups": "2.19", "train_wpb": "1794.4", "train_bsz": "5", "train_num_updates": "22560", "train_lr": "0.0003525", "train_gnorm": "0.59", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10545"}
[2022-01-03 15:05:27,890][fairseq.trainer][INFO] - begin training epoch 565
[2022-01-03 15:05:27,891][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:05:41,846][train_inner][INFO] - {"epoch": 565, "update": 565.0, "loss": "3.944", "ntokens": "1796.44", "nsentences": "4.95", "prob_perplexity": "51.59", "code_perplexity": "51.528", "temp": "1.787", "loss_0": "3.78", "loss_1": "0.133", "loss_2": "0.031", "accuracy": "0.30241", "wps": "3932.3", "ups": "2.19", "wpb": "1796.4", "bsz": "5", "num_updates": "22600", "lr": "0.000353125", "gnorm": "0.591", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "10559"}
[2022-01-03 15:05:41,847][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:05:42,247][valid][INFO] - {"epoch": 565, "valid_loss": "3.984", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "48.599", "valid_code_perplexity": "48.509", "valid_temp": "1.786", "valid_loss_0": "3.825", "valid_loss_1": "0.133", "valid_loss_2": "0.026", "valid_accuracy": "0.28075", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "22600", "valid_best_loss": "3.499"}
[2022-01-03 15:05:42,250][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 565 @ 22600 updates
[2022-01-03 15:05:42,251][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:05:46,051][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:05:46,081][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 565 @ 22600 updates, score 3.984) (writing took 3.830595364794135 seconds)
[2022-01-03 15:05:46,081][fairseq_cli.train][INFO] - end of epoch 565 (average epoch stats below)
[2022-01-03 15:05:46,094][train][INFO] - {"epoch": 565, "train_loss": "3.915", "train_ntokens": "1804.55", "train_nsentences": "4.95", "train_prob_perplexity": "51.442", "train_code_perplexity": "51.372", "train_temp": "1.786", "train_loss_0": "3.754", "train_loss_1": "0.133", "train_loss_2": "0.029", "train_accuracy": "0.30761", "train_wps": "3951.4", "train_ups": "2.19", "train_wpb": "1804.5", "train_bsz": "5", "train_num_updates": "22600", "train_lr": "0.000353125", "train_gnorm": "0.588", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "10563"}
[2022-01-03 15:05:46,139][fairseq.trainer][INFO] - begin training epoch 566
[2022-01-03 15:05:46,140][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:06:00,052][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:06:00,447][valid][INFO] - {"epoch": 566, "valid_loss": "4.476", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "51.088", "valid_code_perplexity": "51.135", "valid_temp": "1.786", "valid_loss_0": "4.313", "valid_loss_1": "0.133", "valid_loss_2": "0.03", "valid_accuracy": "0.24482", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "22640", "valid_best_loss": "3.499"}
[2022-01-03 15:06:00,449][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 566 @ 22640 updates
[2022-01-03 15:06:00,450][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:06:04,260][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:06:04,289][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 566 @ 22640 updates, score 4.476) (writing took 3.839576745405793 seconds)
[2022-01-03 15:06:04,289][fairseq_cli.train][INFO] - end of epoch 566 (average epoch stats below)
[2022-01-03 15:06:04,302][train][INFO] - {"epoch": 566, "train_loss": "3.954", "train_ntokens": "1803.1", "train_nsentences": "4.95", "train_prob_perplexity": "51.715", "train_code_perplexity": "51.68", "train_temp": "1.786", "train_loss_0": "3.792", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.30262", "train_wps": "3963.9", "train_ups": "2.2", "train_wpb": "1803.1", "train_bsz": "5", "train_num_updates": "22640", "train_lr": "0.00035375", "train_gnorm": "0.585", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "10582"}
[2022-01-03 15:06:04,353][fairseq.trainer][INFO] - begin training epoch 567
[2022-01-03 15:06:04,353][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:06:18,247][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:06:18,671][valid][INFO] - {"epoch": 567, "valid_loss": "3.888", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "46.394", "valid_code_perplexity": "46.491", "valid_temp": "1.786", "valid_loss_0": "3.722", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.30609", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "22680", "valid_best_loss": "3.499"}
[2022-01-03 15:06:18,673][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 567 @ 22680 updates
[2022-01-03 15:06:18,674][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:06:22,559][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:06:22,586][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 567 @ 22680 updates, score 3.888) (writing took 3.913194501772523 seconds)
[2022-01-03 15:06:22,587][fairseq_cli.train][INFO] - end of epoch 567 (average epoch stats below)
[2022-01-03 15:06:22,600][train][INFO] - {"epoch": 567, "train_loss": "3.952", "train_ntokens": "1787.83", "train_nsentences": "4.95", "train_prob_perplexity": "52.214", "train_code_perplexity": "52.145", "train_temp": "1.786", "train_loss_0": "3.79", "train_loss_1": "0.133", "train_loss_2": "0.029", "train_accuracy": "0.3015", "train_wps": "3911.1", "train_ups": "2.19", "train_wpb": "1787.8", "train_bsz": "5", "train_num_updates": "22680", "train_lr": "0.000354375", "train_gnorm": "0.577", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "10600"}
[2022-01-03 15:06:22,667][fairseq.trainer][INFO] - begin training epoch 568
[2022-01-03 15:06:22,668][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:06:36,507][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:06:36,918][valid][INFO] - {"epoch": 568, "valid_loss": "4.087", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "50.746", "valid_code_perplexity": "50.626", "valid_temp": "1.785", "valid_loss_0": "3.924", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.30563", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "22720", "valid_best_loss": "3.499"}
[2022-01-03 15:06:36,921][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 568 @ 22720 updates
[2022-01-03 15:06:36,922][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:06:40,851][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:06:40,880][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 568 @ 22720 updates, score 4.087) (writing took 3.959477311000228 seconds)
[2022-01-03 15:06:40,881][fairseq_cli.train][INFO] - end of epoch 568 (average epoch stats below)
[2022-01-03 15:06:40,894][train][INFO] - {"epoch": 568, "train_loss": "3.953", "train_ntokens": "1805.85", "train_nsentences": "4.95", "train_prob_perplexity": "51.952", "train_code_perplexity": "51.882", "train_temp": "1.785", "train_loss_0": "3.791", "train_loss_1": "0.133", "train_loss_2": "0.029", "train_accuracy": "0.29972", "train_wps": "3951.3", "train_ups": "2.19", "train_wpb": "1805.8", "train_bsz": "5", "train_num_updates": "22720", "train_lr": "0.000355", "train_gnorm": "0.595", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "10618"}
[2022-01-03 15:06:40,975][fairseq.trainer][INFO] - begin training epoch 569
[2022-01-03 15:06:40,976][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:06:54,910][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:06:55,309][valid][INFO] - {"epoch": 569, "valid_loss": "4.173", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "52.19", "valid_code_perplexity": "52.105", "valid_temp": "1.785", "valid_loss_0": "4.012", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.28591", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "22760", "valid_best_loss": "3.499"}
[2022-01-03 15:06:55,312][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 569 @ 22760 updates
[2022-01-03 15:06:55,313][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:06:59,076][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:06:59,105][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 569 @ 22760 updates, score 4.173) (writing took 3.7932427134364843 seconds)
[2022-01-03 15:06:59,106][fairseq_cli.train][INFO] - end of epoch 569 (average epoch stats below)
[2022-01-03 15:06:59,119][train][INFO] - {"epoch": 569, "train_loss": "3.907", "train_ntokens": "1768.92", "train_nsentences": "4.95", "train_prob_perplexity": "51.726", "train_code_perplexity": "51.642", "train_temp": "1.785", "train_loss_0": "3.744", "train_loss_1": "0.133", "train_loss_2": "0.03", "train_accuracy": "0.30886", "train_wps": "3885.2", "train_ups": "2.2", "train_wpb": "1768.9", "train_bsz": "5", "train_num_updates": "22760", "train_lr": "0.000355625", "train_gnorm": "0.602", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.7", "train_wall": "10637"}
[2022-01-03 15:06:59,198][fairseq.trainer][INFO] - begin training epoch 570
[2022-01-03 15:06:59,199][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:07:13,143][train_inner][INFO] - {"epoch": 570, "update": 570.0, "loss": "3.941", "ntokens": "1792.28", "nsentences": "4.95", "prob_perplexity": "52.114", "code_perplexity": "52.047", "temp": "1.785", "loss_0": "3.779", "loss_1": "0.133", "loss_2": "0.03", "accuracy": "0.30326", "wps": "3926.8", "ups": "2.19", "wpb": "1792.3", "bsz": "5", "num_updates": "22800", "lr": "0.00035625", "gnorm": "0.588", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "10651"}
[2022-01-03 15:07:13,143][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:07:13,560][valid][INFO] - {"epoch": 570, "valid_loss": "4.238", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "52.394", "valid_code_perplexity": "52.201", "valid_temp": "1.785", "valid_loss_0": "4.075", "valid_loss_1": "0.132", "valid_loss_2": "0.031", "valid_accuracy": "0.25066", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "22800", "valid_best_loss": "3.499"}
[2022-01-03 15:07:13,563][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 570 @ 22800 updates
[2022-01-03 15:07:13,564][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:07:17,422][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:07:17,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 570 @ 22800 updates, score 4.238) (writing took 3.889480048790574 seconds)
[2022-01-03 15:07:17,453][fairseq_cli.train][INFO] - end of epoch 570 (average epoch stats below)
[2022-01-03 15:07:17,466][train][INFO] - {"epoch": 570, "train_loss": "3.94", "train_ntokens": "1795.7", "train_nsentences": "4.95", "train_prob_perplexity": "52.961", "train_code_perplexity": "52.886", "train_temp": "1.785", "train_loss_0": "3.777", "train_loss_1": "0.132", "train_loss_2": "0.031", "train_accuracy": "0.30368", "train_wps": "3917.7", "train_ups": "2.18", "train_wpb": "1795.7", "train_bsz": "5", "train_num_updates": "22800", "train_lr": "0.00035625", "train_gnorm": "0.58", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "10655"}
[2022-01-03 15:07:17,523][fairseq.trainer][INFO] - begin training epoch 571
[2022-01-03 15:07:17,524][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:07:31,435][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:07:31,852][valid][INFO] - {"epoch": 571, "valid_loss": "3.914", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "53.108", "valid_code_perplexity": "53.038", "valid_temp": "1.784", "valid_loss_0": "3.752", "valid_loss_1": "0.132", "valid_loss_2": "0.03", "valid_accuracy": "0.292", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "22840", "valid_best_loss": "3.499"}
[2022-01-03 15:07:31,855][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 571 @ 22840 updates
[2022-01-03 15:07:31,856][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:07:35,570][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:07:35,597][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 571 @ 22840 updates, score 3.914) (writing took 3.7416485333815217 seconds)
[2022-01-03 15:07:35,597][fairseq_cli.train][INFO] - end of epoch 571 (average epoch stats below)
[2022-01-03 15:07:35,610][train][INFO] - {"epoch": 571, "train_loss": "3.923", "train_ntokens": "1791.4", "train_nsentences": "4.95", "train_prob_perplexity": "53.281", "train_code_perplexity": "53.216", "train_temp": "1.784", "train_loss_0": "3.76", "train_loss_1": "0.132", "train_loss_2": "0.031", "train_accuracy": "0.30469", "train_wps": "3952", "train_ups": "2.21", "train_wpb": "1791.4", "train_bsz": "5", "train_num_updates": "22840", "train_lr": "0.000356875", "train_gnorm": "0.599", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "10673"}
[2022-01-03 15:07:35,653][fairseq.trainer][INFO] - begin training epoch 572
[2022-01-03 15:07:35,654][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:07:49,652][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:07:50,054][valid][INFO] - {"epoch": 572, "valid_loss": "4.223", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "51.167", "valid_code_perplexity": "51.178", "valid_temp": "1.784", "valid_loss_0": "4.062", "valid_loss_1": "0.133", "valid_loss_2": "0.028", "valid_accuracy": "0.27703", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "22880", "valid_best_loss": "3.499"}
[2022-01-03 15:07:50,057][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 572 @ 22880 updates
[2022-01-03 15:07:50,057][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:07:53,839][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:07:53,866][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 572 @ 22880 updates, score 4.223) (writing took 3.8087734058499336 seconds)
[2022-01-03 15:07:53,866][fairseq_cli.train][INFO] - end of epoch 572 (average epoch stats below)
[2022-01-03 15:07:53,879][train][INFO] - {"epoch": 572, "train_loss": "3.9", "train_ntokens": "1780.45", "train_nsentences": "4.95", "train_prob_perplexity": "53.246", "train_code_perplexity": "53.188", "train_temp": "1.784", "train_loss_0": "3.738", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30716", "train_wps": "3901.1", "train_ups": "2.19", "train_wpb": "1780.5", "train_bsz": "5", "train_num_updates": "22880", "train_lr": "0.0003575", "train_gnorm": "0.624", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10691"}
[2022-01-03 15:07:53,952][fairseq.trainer][INFO] - begin training epoch 573
[2022-01-03 15:07:53,953][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:08:07,925][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:08:08,337][valid][INFO] - {"epoch": 573, "valid_loss": "3.816", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "50.52", "valid_code_perplexity": "50.529", "valid_temp": "1.783", "valid_loss_0": "3.654", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.31432", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "22920", "valid_best_loss": "3.499"}
[2022-01-03 15:08:08,340][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 573 @ 22920 updates
[2022-01-03 15:08:08,341][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:08:12,050][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:08:12,077][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 573 @ 22920 updates, score 3.816) (writing took 3.737085825763643 seconds)
[2022-01-03 15:08:12,077][fairseq_cli.train][INFO] - end of epoch 573 (average epoch stats below)
[2022-01-03 15:08:12,090][train][INFO] - {"epoch": 573, "train_loss": "3.948", "train_ntokens": "1787.78", "train_nsentences": "4.95", "train_prob_perplexity": "53.264", "train_code_perplexity": "53.211", "train_temp": "1.784", "train_loss_0": "3.787", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30009", "train_wps": "3929.5", "train_ups": "2.2", "train_wpb": "1787.8", "train_bsz": "5", "train_num_updates": "22920", "train_lr": "0.000358125", "train_gnorm": "0.583", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "10709"}
[2022-01-03 15:08:12,141][fairseq.trainer][INFO] - begin training epoch 574
[2022-01-03 15:08:12,142][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:08:26,100][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:08:26,504][valid][INFO] - {"epoch": 574, "valid_loss": "3.704", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "51.893", "valid_code_perplexity": "51.846", "valid_temp": "1.783", "valid_loss_0": "3.541", "valid_loss_1": "0.133", "valid_loss_2": "0.031", "valid_accuracy": "0.32219", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "22960", "valid_best_loss": "3.499"}
[2022-01-03 15:08:26,507][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 574 @ 22960 updates
[2022-01-03 15:08:26,508][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:08:30,316][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:08:30,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 574 @ 22960 updates, score 3.704) (writing took 3.8377183489501476 seconds)
[2022-01-03 15:08:30,345][fairseq_cli.train][INFO] - end of epoch 574 (average epoch stats below)
[2022-01-03 15:08:30,358][train][INFO] - {"epoch": 574, "train_loss": "3.917", "train_ntokens": "1781.7", "train_nsentences": "4.95", "train_prob_perplexity": "52.868", "train_code_perplexity": "52.78", "train_temp": "1.783", "train_loss_0": "3.754", "train_loss_1": "0.132", "train_loss_2": "0.03", "train_accuracy": "0.30542", "train_wps": "3903.8", "train_ups": "2.19", "train_wpb": "1781.7", "train_bsz": "5", "train_num_updates": "22960", "train_lr": "0.00035875", "train_gnorm": "0.607", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "10728"}
[2022-01-03 15:08:30,441][fairseq.trainer][INFO] - begin training epoch 575
[2022-01-03 15:08:30,442][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:08:44,382][train_inner][INFO] - {"epoch": 575, "update": 575.0, "loss": "3.929", "ntokens": "1787.5", "nsentences": "4.95", "prob_perplexity": "53.374", "code_perplexity": "53.309", "temp": "1.784", "loss_0": "3.767", "loss_1": "0.132", "loss_2": "0.03", "accuracy": "0.30344", "wps": "3918.8", "ups": "2.19", "wpb": "1787.5", "bsz": "5", "num_updates": "23000", "lr": "0.000359375", "gnorm": "0.603", "clip": "0", "train_wall": "68", "gb_free": "6.6", "wall": "10742"}
[2022-01-03 15:08:44,383][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:08:44,788][valid][INFO] - {"epoch": 575, "valid_loss": "3.849", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "51.462", "valid_code_perplexity": "51.38", "valid_temp": "1.783", "valid_loss_0": "3.689", "valid_loss_1": "0.133", "valid_loss_2": "0.027", "valid_accuracy": "0.28969", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "23000", "valid_best_loss": "3.499"}
[2022-01-03 15:08:44,790][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 575 @ 23000 updates
[2022-01-03 15:08:44,791][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:08:48,517][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:08:48,544][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 575 @ 23000 updates, score 3.849) (writing took 3.7535213166847825 seconds)
[2022-01-03 15:08:48,544][fairseq_cli.train][INFO] - end of epoch 575 (average epoch stats below)
[2022-01-03 15:08:48,557][train][INFO] - {"epoch": 575, "train_loss": "3.959", "train_ntokens": "1796.17", "train_nsentences": "4.95", "train_prob_perplexity": "54.21", "train_code_perplexity": "54.148", "train_temp": "1.783", "train_loss_0": "3.797", "train_loss_1": "0.132", "train_loss_2": "0.03", "train_accuracy": "0.29987", "train_wps": "3950.7", "train_ups": "2.2", "train_wpb": "1796.2", "train_bsz": "5", "train_num_updates": "23000", "train_lr": "0.000359375", "train_gnorm": "0.6", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "10746"}
[2022-01-03 15:08:48,627][fairseq.trainer][INFO] - begin training epoch 576
[2022-01-03 15:08:48,627][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:09:02,577][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:09:02,985][valid][INFO] - {"epoch": 576, "valid_loss": "4.248", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "51.499", "valid_code_perplexity": "51.423", "valid_temp": "1.782", "valid_loss_0": "4.087", "valid_loss_1": "0.133", "valid_loss_2": "0.028", "valid_accuracy": "0.2721", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "23040", "valid_best_loss": "3.499"}
[2022-01-03 15:09:02,990][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 576 @ 23040 updates
[2022-01-03 15:09:02,991][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:09:06,788][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:09:06,815][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 576 @ 23040 updates, score 4.248) (writing took 3.82494858186692 seconds)
[2022-01-03 15:09:06,815][fairseq_cli.train][INFO] - end of epoch 576 (average epoch stats below)
[2022-01-03 15:09:06,827][train][INFO] - {"epoch": 576, "train_loss": "3.904", "train_ntokens": "1767.53", "train_nsentences": "4.95", "train_prob_perplexity": "53.572", "train_code_perplexity": "53.474", "train_temp": "1.783", "train_loss_0": "3.742", "train_loss_1": "0.132", "train_loss_2": "0.03", "train_accuracy": "0.30728", "train_wps": "3872.4", "train_ups": "2.19", "train_wpb": "1767.5", "train_bsz": "5", "train_num_updates": "23040", "train_lr": "0.00036", "train_gnorm": "0.596", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10764"}
[2022-01-03 15:09:06,870][fairseq.trainer][INFO] - begin training epoch 577
[2022-01-03 15:09:06,870][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:09:20,887][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:09:21,387][valid][INFO] - {"epoch": 577, "valid_loss": "3.75", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "51.459", "valid_code_perplexity": "51.345", "valid_temp": "1.782", "valid_loss_0": "3.586", "valid_loss_1": "0.133", "valid_loss_2": "0.031", "valid_accuracy": "0.31501", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "23080", "valid_best_loss": "3.499"}
[2022-01-03 15:09:21,388][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 577 @ 23080 updates
[2022-01-03 15:09:21,389][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:09:25,029][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:09:25,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 577 @ 23080 updates, score 3.75) (writing took 3.6694567892700434 seconds)
[2022-01-03 15:09:25,058][fairseq_cli.train][INFO] - end of epoch 577 (average epoch stats below)
[2022-01-03 15:09:25,071][train][INFO] - {"epoch": 577, "train_loss": "3.908", "train_ntokens": "1776.12", "train_nsentences": "4.95", "train_prob_perplexity": "53.236", "train_code_perplexity": "53.143", "train_temp": "1.782", "train_loss_0": "3.747", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30893", "train_wps": "3896.9", "train_ups": "2.19", "train_wpb": "1776.1", "train_bsz": "5", "train_num_updates": "23080", "train_lr": "0.000360625", "train_gnorm": "0.591", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10782"}
[2022-01-03 15:09:25,148][fairseq.trainer][INFO] - begin training epoch 578
[2022-01-03 15:09:25,149][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:09:38,969][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:09:39,368][valid][INFO] - {"epoch": 578, "valid_loss": "3.823", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "48.519", "valid_code_perplexity": "48.31", "valid_temp": "1.782", "valid_loss_0": "3.659", "valid_loss_1": "0.133", "valid_loss_2": "0.031", "valid_accuracy": "0.33649", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "23120", "valid_best_loss": "3.499"}
[2022-01-03 15:09:39,371][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 578 @ 23120 updates
[2022-01-03 15:09:39,372][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:09:43,344][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:09:43,372][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 578 @ 23120 updates, score 3.823) (writing took 4.000868696719408 seconds)
[2022-01-03 15:09:43,373][fairseq_cli.train][INFO] - end of epoch 578 (average epoch stats below)
[2022-01-03 15:09:43,385][train][INFO] - {"epoch": 578, "train_loss": "3.934", "train_ntokens": "1804.47", "train_nsentences": "4.95", "train_prob_perplexity": "53.888", "train_code_perplexity": "53.797", "train_temp": "1.782", "train_loss_0": "3.771", "train_loss_1": "0.132", "train_loss_2": "0.031", "train_accuracy": "0.30258", "train_wps": "3943.9", "train_ups": "2.19", "train_wpb": "1804.5", "train_bsz": "5", "train_num_updates": "23120", "train_lr": "0.00036125", "train_gnorm": "0.592", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10801"}
[2022-01-03 15:09:43,463][fairseq.trainer][INFO] - begin training epoch 579
[2022-01-03 15:09:43,464][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:09:57,444][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:09:57,934][valid][INFO] - {"epoch": 579, "valid_loss": "4.417", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "53.384", "valid_code_perplexity": "53.454", "valid_temp": "1.781", "valid_loss_0": "4.256", "valid_loss_1": "0.132", "valid_loss_2": "0.029", "valid_accuracy": "0.24107", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "23160", "valid_best_loss": "3.499"}
[2022-01-03 15:09:57,936][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 579 @ 23160 updates
[2022-01-03 15:09:57,936][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:10:01,604][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:10:01,632][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 579 @ 23160 updates, score 4.417) (writing took 3.6966020660474896 seconds)
[2022-01-03 15:10:01,634][fairseq_cli.train][INFO] - end of epoch 579 (average epoch stats below)
[2022-01-03 15:10:01,648][train][INFO] - {"epoch": 579, "train_loss": "3.939", "train_ntokens": "1799.45", "train_nsentences": "4.95", "train_prob_perplexity": "53.139", "train_code_perplexity": "53.06", "train_temp": "1.781", "train_loss_0": "3.777", "train_loss_1": "0.132", "train_loss_2": "0.03", "train_accuracy": "0.30384", "train_wps": "3944.2", "train_ups": "2.19", "train_wpb": "1799.5", "train_bsz": "5", "train_num_updates": "23160", "train_lr": "0.000361875", "train_gnorm": "0.576", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "10819"}
[2022-01-03 15:10:01,718][fairseq.trainer][INFO] - begin training epoch 580
[2022-01-03 15:10:01,718][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:10:15,770][train_inner][INFO] - {"epoch": 580, "update": 580.0, "loss": "3.918", "ntokens": "1786.22", "nsentences": "4.95", "prob_perplexity": "53.65", "code_perplexity": "53.563", "temp": "1.782", "loss_0": "3.756", "loss_1": "0.132", "loss_2": "0.03", "accuracy": "0.3061", "wps": "3909.6", "ups": "2.19", "wpb": "1786.2", "bsz": "5", "num_updates": "23200", "lr": "0.0003625", "gnorm": "0.591", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "10833"}
[2022-01-03 15:10:15,771][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:10:16,176][valid][INFO] - {"epoch": 580, "valid_loss": "4.152", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "52.925", "valid_code_perplexity": "52.687", "valid_temp": "1.781", "valid_loss_0": "3.991", "valid_loss_1": "0.132", "valid_loss_2": "0.029", "valid_accuracy": "0.25543", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "23200", "valid_best_loss": "3.499"}
[2022-01-03 15:10:16,179][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 580 @ 23200 updates
[2022-01-03 15:10:16,180][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:10:19,837][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:10:19,868][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 580 @ 23200 updates, score 4.152) (writing took 3.688813202083111 seconds)
[2022-01-03 15:10:19,868][fairseq_cli.train][INFO] - end of epoch 580 (average epoch stats below)
[2022-01-03 15:10:19,881][train][INFO] - {"epoch": 580, "train_loss": "3.905", "train_ntokens": "1783.53", "train_nsentences": "4.95", "train_prob_perplexity": "54.417", "train_code_perplexity": "54.34", "train_temp": "1.781", "train_loss_0": "3.744", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30797", "train_wps": "3915.4", "train_ups": "2.2", "train_wpb": "1783.5", "train_bsz": "5", "train_num_updates": "23200", "train_lr": "0.0003625", "train_gnorm": "0.601", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "10837"}
[2022-01-03 15:10:19,952][fairseq.trainer][INFO] - begin training epoch 581
[2022-01-03 15:10:19,953][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:10:33,925][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:10:34,321][valid][INFO] - {"epoch": 581, "valid_loss": "3.721", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "46.418", "valid_code_perplexity": "46.48", "valid_temp": "1.781", "valid_loss_0": "3.558", "valid_loss_1": "0.134", "valid_loss_2": "0.029", "valid_accuracy": "0.3699", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "23240", "valid_best_loss": "3.499"}
[2022-01-03 15:10:34,324][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 581 @ 23240 updates
[2022-01-03 15:10:34,324][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:10:38,090][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:10:38,118][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 581 @ 23240 updates, score 3.721) (writing took 3.7943938272073865 seconds)
[2022-01-03 15:10:38,119][fairseq_cli.train][INFO] - end of epoch 581 (average epoch stats below)
[2022-01-03 15:10:38,131][train][INFO] - {"epoch": 581, "train_loss": "3.96", "train_ntokens": "1822.25", "train_nsentences": "4.95", "train_prob_perplexity": "54.107", "train_code_perplexity": "54.027", "train_temp": "1.781", "train_loss_0": "3.799", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30262", "train_wps": "3996.7", "train_ups": "2.19", "train_wpb": "1822.2", "train_bsz": "5", "train_num_updates": "23240", "train_lr": "0.000363125", "train_gnorm": "0.563", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10856"}
[2022-01-03 15:10:38,189][fairseq.trainer][INFO] - begin training epoch 582
[2022-01-03 15:10:38,189][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:10:52,073][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:10:52,567][valid][INFO] - {"epoch": 582, "valid_loss": "4.088", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "51.499", "valid_code_perplexity": "51.491", "valid_temp": "1.78", "valid_loss_0": "3.927", "valid_loss_1": "0.133", "valid_loss_2": "0.028", "valid_accuracy": "0.27171", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "23280", "valid_best_loss": "3.499"}
[2022-01-03 15:10:52,568][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 582 @ 23280 updates
[2022-01-03 15:10:52,569][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:10:56,616][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:10:56,642][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 582 @ 23280 updates, score 4.088) (writing took 4.073750182054937 seconds)
[2022-01-03 15:10:56,643][fairseq_cli.train][INFO] - end of epoch 582 (average epoch stats below)
[2022-01-03 15:10:56,655][train][INFO] - {"epoch": 582, "train_loss": "3.945", "train_ntokens": "1800.22", "train_nsentences": "4.95", "train_prob_perplexity": "53.665", "train_code_perplexity": "53.579", "train_temp": "1.78", "train_loss_0": "3.785", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30309", "train_wps": "3889.9", "train_ups": "2.16", "train_wpb": "1800.2", "train_bsz": "5", "train_num_updates": "23280", "train_lr": "0.00036375", "train_gnorm": "0.578", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "10874"}
[2022-01-03 15:10:56,725][fairseq.trainer][INFO] - begin training epoch 583
[2022-01-03 15:10:56,726][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:11:10,648][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:11:11,074][valid][INFO] - {"epoch": 583, "valid_loss": "4.232", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "52.378", "valid_code_perplexity": "52.224", "valid_temp": "1.78", "valid_loss_0": "4.07", "valid_loss_1": "0.132", "valid_loss_2": "0.029", "valid_accuracy": "0.24454", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "23320", "valid_best_loss": "3.499"}
[2022-01-03 15:11:11,079][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 583 @ 23320 updates
[2022-01-03 15:11:11,080][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:11:14,856][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:11:14,884][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 583 @ 23320 updates, score 4.232) (writing took 3.805650473572314 seconds)
[2022-01-03 15:11:14,885][fairseq_cli.train][INFO] - end of epoch 583 (average epoch stats below)
[2022-01-03 15:11:14,897][train][INFO] - {"epoch": 583, "train_loss": "3.918", "train_ntokens": "1796.47", "train_nsentences": "4.95", "train_prob_perplexity": "53.52", "train_code_perplexity": "53.444", "train_temp": "1.78", "train_loss_0": "3.757", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30563", "train_wps": "3941.9", "train_ups": "2.19", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "23320", "train_lr": "0.000364375", "train_gnorm": "0.612", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "10892"}
[2022-01-03 15:11:14,974][fairseq.trainer][INFO] - begin training epoch 584
[2022-01-03 15:11:14,975][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:11:28,851][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:11:29,257][valid][INFO] - {"epoch": 584, "valid_loss": "4.029", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "50.072", "valid_code_perplexity": "49.763", "valid_temp": "1.78", "valid_loss_0": "3.866", "valid_loss_1": "0.133", "valid_loss_2": "0.03", "valid_accuracy": "0.28982", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "23360", "valid_best_loss": "3.499"}
[2022-01-03 15:11:29,260][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 584 @ 23360 updates
[2022-01-03 15:11:29,261][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:11:33,108][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:11:33,136][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 584 @ 23360 updates, score 4.029) (writing took 3.8754677837714553 seconds)
[2022-01-03 15:11:33,136][fairseq_cli.train][INFO] - end of epoch 584 (average epoch stats below)
[2022-01-03 15:11:33,152][train][INFO] - {"epoch": 584, "train_loss": "3.939", "train_ntokens": "1799.5", "train_nsentences": "4.95", "train_prob_perplexity": "53.932", "train_code_perplexity": "53.854", "train_temp": "1.78", "train_loss_0": "3.777", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30321", "train_wps": "3946.5", "train_ups": "2.19", "train_wpb": "1799.5", "train_bsz": "5", "train_num_updates": "23360", "train_lr": "0.000365", "train_gnorm": "0.57", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "10911"}
[2022-01-03 15:11:33,223][fairseq.trainer][INFO] - begin training epoch 585
[2022-01-03 15:11:33,224][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:11:47,210][train_inner][INFO] - {"epoch": 585, "update": 585.0, "loss": "3.935", "ntokens": "1803.05", "nsentences": "4.95", "prob_perplexity": "53.82", "code_perplexity": "53.739", "temp": "1.78", "loss_0": "3.774", "loss_1": "0.132", "loss_2": "0.029", "accuracy": "0.30404", "wps": "3944.2", "ups": "2.19", "wpb": "1803", "bsz": "5", "num_updates": "23400", "lr": "0.000365625", "gnorm": "0.578", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "10925"}
[2022-01-03 15:11:47,211][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:11:47,616][valid][INFO] - {"epoch": 585, "valid_loss": "4.387", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "52.661", "valid_code_perplexity": "52.526", "valid_temp": "1.779", "valid_loss_0": "4.226", "valid_loss_1": "0.132", "valid_loss_2": "0.029", "valid_accuracy": "0.22382", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "23400", "valid_best_loss": "3.499"}
[2022-01-03 15:11:47,620][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 585 @ 23400 updates
[2022-01-03 15:11:47,620][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:11:51,371][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:11:51,400][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 585 @ 23400 updates, score 4.387) (writing took 3.7800217010080814 seconds)
[2022-01-03 15:11:51,400][fairseq_cli.train][INFO] - end of epoch 585 (average epoch stats below)
[2022-01-03 15:11:51,413][train][INFO] - {"epoch": 585, "train_loss": "3.912", "train_ntokens": "1796.78", "train_nsentences": "4.95", "train_prob_perplexity": "53.877", "train_code_perplexity": "53.792", "train_temp": "1.779", "train_loss_0": "3.752", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30567", "train_wps": "3938.6", "train_ups": "2.19", "train_wpb": "1796.8", "train_bsz": "5", "train_num_updates": "23400", "train_lr": "0.000365625", "train_gnorm": "0.567", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "10929"}
[2022-01-03 15:11:51,494][fairseq.trainer][INFO] - begin training epoch 586
[2022-01-03 15:11:51,494][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:12:05,425][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:12:05,848][valid][INFO] - {"epoch": 586, "valid_loss": "3.512", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "52.911", "valid_code_perplexity": "52.922", "valid_temp": "1.779", "valid_loss_0": "3.354", "valid_loss_1": "0.132", "valid_loss_2": "0.025", "valid_accuracy": "0.38493", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "23440", "valid_best_loss": "3.499"}
[2022-01-03 15:12:05,850][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 586 @ 23440 updates
[2022-01-03 15:12:05,851][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:12:09,645][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:12:09,674][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 586 @ 23440 updates, score 3.512) (writing took 3.824225563555956 seconds)
[2022-01-03 15:12:09,675][fairseq_cli.train][INFO] - end of epoch 586 (average epoch stats below)
[2022-01-03 15:12:09,687][train][INFO] - {"epoch": 586, "train_loss": "3.921", "train_ntokens": "1782.45", "train_nsentences": "4.95", "train_prob_perplexity": "53.837", "train_code_perplexity": "53.74", "train_temp": "1.779", "train_loss_0": "3.76", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30688", "train_wps": "3904.2", "train_ups": "2.19", "train_wpb": "1782.5", "train_bsz": "5", "train_num_updates": "23440", "train_lr": "0.00036625", "train_gnorm": "0.606", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "10947"}
[2022-01-03 15:12:09,760][fairseq.trainer][INFO] - begin training epoch 587
[2022-01-03 15:12:09,761][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:12:23,723][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:12:24,120][valid][INFO] - {"epoch": 587, "valid_loss": "3.565", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "51.625", "valid_code_perplexity": "51.341", "valid_temp": "1.778", "valid_loss_0": "3.406", "valid_loss_1": "0.133", "valid_loss_2": "0.027", "valid_accuracy": "0.35175", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "23480", "valid_best_loss": "3.499"}
[2022-01-03 15:12:24,122][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 587 @ 23480 updates
[2022-01-03 15:12:24,123][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:12:27,873][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:12:27,900][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 587 @ 23480 updates, score 3.565) (writing took 3.7773872101679444 seconds)
[2022-01-03 15:12:27,900][fairseq_cli.train][INFO] - end of epoch 587 (average epoch stats below)
[2022-01-03 15:12:27,912][train][INFO] - {"epoch": 587, "train_loss": "3.924", "train_ntokens": "1789.88", "train_nsentences": "4.95", "train_prob_perplexity": "54.641", "train_code_perplexity": "54.547", "train_temp": "1.779", "train_loss_0": "3.764", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30121", "train_wps": "3931", "train_ups": "2.2", "train_wpb": "1789.9", "train_bsz": "5", "train_num_updates": "23480", "train_lr": "0.000366875", "train_gnorm": "0.602", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "10965"}
[2022-01-03 15:12:27,966][fairseq.trainer][INFO] - begin training epoch 588
[2022-01-03 15:12:27,967][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:12:41,816][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:12:42,311][valid][INFO] - {"epoch": 588, "valid_loss": "3.913", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "46.411", "valid_code_perplexity": "46.243", "valid_temp": "1.778", "valid_loss_0": "3.748", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.33062", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "23520", "valid_best_loss": "3.499"}
[2022-01-03 15:12:42,312][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 588 @ 23520 updates
[2022-01-03 15:12:42,313][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:12:46,320][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:12:46,349][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 588 @ 23520 updates, score 3.913) (writing took 4.036836631596088 seconds)
[2022-01-03 15:12:46,350][fairseq_cli.train][INFO] - end of epoch 588 (average epoch stats below)
[2022-01-03 15:12:46,362][train][INFO] - {"epoch": 588, "train_loss": "3.895", "train_ntokens": "1786.62", "train_nsentences": "4.95", "train_prob_perplexity": "54.505", "train_code_perplexity": "54.419", "train_temp": "1.778", "train_loss_0": "3.735", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30706", "train_wps": "3876.1", "train_ups": "2.17", "train_wpb": "1786.6", "train_bsz": "5", "train_num_updates": "23520", "train_lr": "0.0003675", "train_gnorm": "0.572", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "10984"}
[2022-01-03 15:12:46,411][fairseq.trainer][INFO] - begin training epoch 589
[2022-01-03 15:12:46,412][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:13:00,242][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:13:00,642][valid][INFO] - {"epoch": 589, "valid_loss": "4.073", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "54.755", "valid_code_perplexity": "54.73", "valid_temp": "1.778", "valid_loss_0": "3.914", "valid_loss_1": "0.132", "valid_loss_2": "0.028", "valid_accuracy": "0.26447", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "23560", "valid_best_loss": "3.499"}
[2022-01-03 15:13:00,645][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 589 @ 23560 updates
[2022-01-03 15:13:00,646][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:13:04,383][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:13:04,402][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 589 @ 23560 updates, score 4.073) (writing took 3.757015509530902 seconds)
[2022-01-03 15:13:04,403][fairseq_cli.train][INFO] - end of epoch 589 (average epoch stats below)
[2022-01-03 15:13:04,415][train][INFO] - {"epoch": 589, "train_loss": "3.908", "train_ntokens": "1800.42", "train_nsentences": "4.95", "train_prob_perplexity": "55.457", "train_code_perplexity": "55.343", "train_temp": "1.778", "train_loss_0": "3.748", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30655", "train_wps": "3992", "train_ups": "2.22", "train_wpb": "1800.4", "train_bsz": "5", "train_num_updates": "23560", "train_lr": "0.000368125", "train_gnorm": "0.595", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "11002"}
[2022-01-03 15:13:04,469][fairseq.trainer][INFO] - begin training epoch 590
[2022-01-03 15:13:04,469][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:13:18,396][train_inner][INFO] - {"epoch": 590, "update": 590.0, "loss": "3.917", "ntokens": "1791.6", "nsentences": "4.95", "prob_perplexity": "54.76", "code_perplexity": "54.663", "temp": "1.778", "loss_0": "3.757", "loss_1": "0.132", "loss_2": "0.028", "accuracy": "0.30474", "wps": "3930", "ups": "2.19", "wpb": "1791.6", "bsz": "5", "num_updates": "23600", "lr": "0.00036875", "gnorm": "0.592", "clip": "0", "train_wall": "67", "gb_free": "5.4", "wall": "11016"}
[2022-01-03 15:13:18,397][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:13:18,898][valid][INFO] - {"epoch": 590, "valid_loss": "4.056", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "51.579", "valid_code_perplexity": "51.406", "valid_temp": "1.777", "valid_loss_0": "3.894", "valid_loss_1": "0.133", "valid_loss_2": "0.03", "valid_accuracy": "0.30965", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "23600", "valid_best_loss": "3.499"}
[2022-01-03 15:13:18,900][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 590 @ 23600 updates
[2022-01-03 15:13:18,900][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:13:22,672][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:13:22,700][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 590 @ 23600 updates, score 4.056) (writing took 3.8000382725149393 seconds)
[2022-01-03 15:13:22,700][fairseq_cli.train][INFO] - end of epoch 590 (average epoch stats below)
[2022-01-03 15:13:22,713][train][INFO] - {"epoch": 590, "train_loss": "3.939", "train_ntokens": "1798.6", "train_nsentences": "4.95", "train_prob_perplexity": "55.36", "train_code_perplexity": "55.264", "train_temp": "1.778", "train_loss_0": "3.778", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30201", "train_wps": "3934.6", "train_ups": "2.19", "train_wpb": "1798.6", "train_bsz": "5", "train_num_updates": "23600", "train_lr": "0.00036875", "train_gnorm": "0.586", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "11020"}
[2022-01-03 15:13:22,781][fairseq.trainer][INFO] - begin training epoch 591
[2022-01-03 15:13:22,782][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:13:36,649][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:13:37,147][valid][INFO] - {"epoch": 591, "valid_loss": "4.12", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "45.204", "valid_code_perplexity": "45.102", "valid_temp": "1.777", "valid_loss_0": "3.955", "valid_loss_1": "0.134", "valid_loss_2": "0.031", "valid_accuracy": "0.29923", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "23640", "valid_best_loss": "3.499"}
[2022-01-03 15:13:37,149][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 591 @ 23640 updates
[2022-01-03 15:13:37,150][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:13:40,923][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:13:40,952][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 591 @ 23640 updates, score 4.12) (writing took 3.8024901719763875 seconds)
[2022-01-03 15:13:40,952][fairseq_cli.train][INFO] - end of epoch 591 (average epoch stats below)
[2022-01-03 15:13:40,964][train][INFO] - {"epoch": 591, "train_loss": "3.894", "train_ntokens": "1775.17", "train_nsentences": "4.95", "train_prob_perplexity": "55.762", "train_code_perplexity": "55.642", "train_temp": "1.777", "train_loss_0": "3.734", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30846", "train_wps": "3893", "train_ups": "2.19", "train_wpb": "1775.2", "train_bsz": "5", "train_num_updates": "23640", "train_lr": "0.000369375", "train_gnorm": "0.565", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "11038"}
[2022-01-03 15:13:41,038][fairseq.trainer][INFO] - begin training epoch 592
[2022-01-03 15:13:41,039][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:13:54,922][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:13:55,324][valid][INFO] - {"epoch": 592, "valid_loss": "3.844", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "53.676", "valid_code_perplexity": "53.548", "valid_temp": "1.777", "valid_loss_0": "3.685", "valid_loss_1": "0.132", "valid_loss_2": "0.026", "valid_accuracy": "0.32337", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "23680", "valid_best_loss": "3.499"}
[2022-01-03 15:13:55,328][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 592 @ 23680 updates
[2022-01-03 15:13:55,329][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:13:59,239][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:13:59,268][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 592 @ 23680 updates, score 3.844) (writing took 3.94095897115767 seconds)
[2022-01-03 15:13:59,269][fairseq_cli.train][INFO] - end of epoch 592 (average epoch stats below)
[2022-01-03 15:13:59,282][train][INFO] - {"epoch": 592, "train_loss": "3.908", "train_ntokens": "1788.17", "train_nsentences": "4.95", "train_prob_perplexity": "55.289", "train_code_perplexity": "55.177", "train_temp": "1.777", "train_loss_0": "3.749", "train_loss_1": "0.132", "train_loss_2": "0.027", "train_accuracy": "0.30286", "train_wps": "3907.6", "train_ups": "2.19", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "23680", "train_lr": "0.00037", "train_gnorm": "0.564", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11057"}
[2022-01-03 15:13:59,340][fairseq.trainer][INFO] - begin training epoch 593
[2022-01-03 15:13:59,340][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:14:13,155][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:14:13,559][valid][INFO] - {"epoch": 593, "valid_loss": "3.896", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "51.666", "valid_code_perplexity": "51.564", "valid_temp": "1.776", "valid_loss_0": "3.735", "valid_loss_1": "0.133", "valid_loss_2": "0.028", "valid_accuracy": "0.3011", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "23720", "valid_best_loss": "3.499"}
[2022-01-03 15:14:13,562][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 593 @ 23720 updates
[2022-01-03 15:14:13,563][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:14:17,519][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:14:17,549][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 593 @ 23720 updates, score 3.896) (writing took 3.986109451390803 seconds)
[2022-01-03 15:14:17,549][fairseq_cli.train][INFO] - end of epoch 593 (average epoch stats below)
[2022-01-03 15:14:17,562][train][INFO] - {"epoch": 593, "train_loss": "3.936", "train_ntokens": "1796.17", "train_nsentences": "4.95", "train_prob_perplexity": "54.748", "train_code_perplexity": "54.596", "train_temp": "1.777", "train_loss_0": "3.776", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30178", "train_wps": "3933.1", "train_ups": "2.19", "train_wpb": "1796.2", "train_bsz": "5", "train_num_updates": "23720", "train_lr": "0.000370625", "train_gnorm": "0.573", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "11075"}
[2022-01-03 15:14:17,640][fairseq.trainer][INFO] - begin training epoch 594
[2022-01-03 15:14:17,641][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:14:31,464][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:14:31,871][valid][INFO] - {"epoch": 594, "valid_loss": "3.918", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "53.178", "valid_code_perplexity": "52.971", "valid_temp": "1.776", "valid_loss_0": "3.755", "valid_loss_1": "0.132", "valid_loss_2": "0.03", "valid_accuracy": "0.29526", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "23760", "valid_best_loss": "3.499"}
[2022-01-03 15:14:31,874][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 594 @ 23760 updates
[2022-01-03 15:14:31,874][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:14:35,813][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:14:35,830][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 594 @ 23760 updates, score 3.918) (writing took 3.9564873790368438 seconds)
[2022-01-03 15:14:35,831][fairseq_cli.train][INFO] - end of epoch 594 (average epoch stats below)
[2022-01-03 15:14:35,844][train][INFO] - {"epoch": 594, "train_loss": "3.947", "train_ntokens": "1788.08", "train_nsentences": "4.95", "train_prob_perplexity": "55.631", "train_code_perplexity": "55.524", "train_temp": "1.776", "train_loss_0": "3.786", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.2992", "train_wps": "3915", "train_ups": "2.19", "train_wpb": "1788.1", "train_bsz": "5", "train_num_updates": "23760", "train_lr": "0.00037125", "train_gnorm": "0.57", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "11093"}
[2022-01-03 15:14:35,881][fairseq.trainer][INFO] - begin training epoch 595
[2022-01-03 15:14:35,882][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:14:49,968][train_inner][INFO] - {"epoch": 595, "update": 595.0, "loss": "3.917", "ntokens": "1785.69", "nsentences": "4.95", "prob_perplexity": "55.426", "code_perplexity": "55.3", "temp": "1.777", "loss_0": "3.757", "loss_1": "0.132", "loss_2": "0.028", "accuracy": "0.30376", "wps": "3900.6", "ups": "2.18", "wpb": "1785.7", "bsz": "5", "num_updates": "23800", "lr": "0.000371875", "gnorm": "0.572", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "11107"}
[2022-01-03 15:14:49,969][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:14:50,437][valid][INFO] - {"epoch": 595, "valid_loss": "4.113", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "53.36", "valid_code_perplexity": "53.313", "valid_temp": "1.776", "valid_loss_0": "3.954", "valid_loss_1": "0.132", "valid_loss_2": "0.027", "valid_accuracy": "0.26839", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "23800", "valid_best_loss": "3.499"}
[2022-01-03 15:14:50,438][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 595 @ 23800 updates
[2022-01-03 15:14:50,439][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:14:54,058][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:14:54,086][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 595 @ 23800 updates, score 4.113) (writing took 3.6472729863598943 seconds)
[2022-01-03 15:14:54,086][fairseq_cli.train][INFO] - end of epoch 595 (average epoch stats below)
[2022-01-03 15:14:54,099][train][INFO] - {"epoch": 595, "train_loss": "3.898", "train_ntokens": "1780.88", "train_nsentences": "4.95", "train_prob_perplexity": "55.698", "train_code_perplexity": "55.559", "train_temp": "1.776", "train_loss_0": "3.738", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30653", "train_wps": "3904.9", "train_ups": "2.19", "train_wpb": "1780.9", "train_bsz": "5", "train_num_updates": "23800", "train_lr": "0.000371875", "train_gnorm": "0.587", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "11111"}
[2022-01-03 15:14:54,180][fairseq.trainer][INFO] - begin training epoch 596
[2022-01-03 15:14:54,181][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:15:08,236][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:15:08,645][valid][INFO] - {"epoch": 596, "valid_loss": "4.407", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "52.616", "valid_code_perplexity": "52.354", "valid_temp": "1.775", "valid_loss_0": "4.244", "valid_loss_1": "0.132", "valid_loss_2": "0.03", "valid_accuracy": "0.22506", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "23840", "valid_best_loss": "3.499"}
[2022-01-03 15:15:08,647][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 596 @ 23840 updates
[2022-01-03 15:15:08,648][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:15:12,280][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:15:12,308][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 596 @ 23840 updates, score 4.407) (writing took 3.660951022990048 seconds)
[2022-01-03 15:15:12,309][fairseq_cli.train][INFO] - end of epoch 596 (average epoch stats below)
[2022-01-03 15:15:12,323][train][INFO] - {"epoch": 596, "train_loss": "3.911", "train_ntokens": "1782.53", "train_nsentences": "4.95", "train_prob_perplexity": "55.651", "train_code_perplexity": "55.515", "train_temp": "1.775", "train_loss_0": "3.751", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30809", "train_wps": "3915.4", "train_ups": "2.2", "train_wpb": "1782.5", "train_bsz": "5", "train_num_updates": "23840", "train_lr": "0.0003725", "train_gnorm": "0.591", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11130"}
[2022-01-03 15:15:12,383][fairseq.trainer][INFO] - begin training epoch 597
[2022-01-03 15:15:12,384][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:15:26,368][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:15:26,772][valid][INFO] - {"epoch": 597, "valid_loss": "3.833", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "45.652", "valid_code_perplexity": "45.505", "valid_temp": "1.775", "valid_loss_0": "3.668", "valid_loss_1": "0.134", "valid_loss_2": "0.032", "valid_accuracy": "0.31806", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "23880", "valid_best_loss": "3.499"}
[2022-01-03 15:15:26,775][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 597 @ 23880 updates
[2022-01-03 15:15:26,775][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:15:30,480][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:15:30,508][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 597 @ 23880 updates, score 3.833) (writing took 3.7326904432848096 seconds)
[2022-01-03 15:15:30,508][fairseq_cli.train][INFO] - end of epoch 597 (average epoch stats below)
[2022-01-03 15:15:30,521][train][INFO] - {"epoch": 597, "train_loss": "3.923", "train_ntokens": "1792.47", "train_nsentences": "4.95", "train_prob_perplexity": "55.431", "train_code_perplexity": "55.306", "train_temp": "1.775", "train_loss_0": "3.763", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.30307", "train_wps": "3942.7", "train_ups": "2.2", "train_wpb": "1792.5", "train_bsz": "5", "train_num_updates": "23880", "train_lr": "0.000373125", "train_gnorm": "0.565", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11148"}
[2022-01-03 15:15:30,600][fairseq.trainer][INFO] - begin training epoch 598
[2022-01-03 15:15:30,601][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:15:44,446][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:15:44,847][valid][INFO] - {"epoch": 598, "valid_loss": "4.093", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "49.455", "valid_code_perplexity": "49.353", "valid_temp": "1.775", "valid_loss_0": "3.931", "valid_loss_1": "0.133", "valid_loss_2": "0.029", "valid_accuracy": "0.29219", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "23920", "valid_best_loss": "3.499"}
[2022-01-03 15:15:44,849][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 598 @ 23920 updates
[2022-01-03 15:15:44,850][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:15:48,895][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:15:48,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 598 @ 23920 updates, score 4.093) (writing took 4.066813409328461 seconds)
[2022-01-03 15:15:48,916][fairseq_cli.train][INFO] - end of epoch 598 (average epoch stats below)
[2022-01-03 15:15:48,929][train][INFO] - {"epoch": 598, "train_loss": "3.896", "train_ntokens": "1792.35", "train_nsentences": "4.95", "train_prob_perplexity": "55.485", "train_code_perplexity": "55.356", "train_temp": "1.775", "train_loss_0": "3.736", "train_loss_1": "0.132", "train_loss_2": "0.029", "train_accuracy": "0.30655", "train_wps": "3897.4", "train_ups": "2.17", "train_wpb": "1792.3", "train_bsz": "5", "train_num_updates": "23920", "train_lr": "0.00037375", "train_gnorm": "0.561", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11166"}
[2022-01-03 15:15:48,969][fairseq.trainer][INFO] - begin training epoch 599
[2022-01-03 15:15:48,970][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:16:03,004][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:16:03,406][valid][INFO] - {"epoch": 599, "valid_loss": "4.218", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "56.062", "valid_code_perplexity": "55.794", "valid_temp": "1.774", "valid_loss_0": "4.059", "valid_loss_1": "0.132", "valid_loss_2": "0.028", "valid_accuracy": "0.25789", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "23960", "valid_best_loss": "3.499"}
[2022-01-03 15:16:03,409][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 599 @ 23960 updates
[2022-01-03 15:16:03,410][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:16:07,145][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:16:07,170][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 599 @ 23960 updates, score 4.218) (writing took 3.7611676789820194 seconds)
[2022-01-03 15:16:07,171][fairseq_cli.train][INFO] - end of epoch 599 (average epoch stats below)
[2022-01-03 15:16:07,183][train][INFO] - {"epoch": 599, "train_loss": "3.892", "train_ntokens": "1786.6", "train_nsentences": "4.95", "train_prob_perplexity": "56.912", "train_code_perplexity": "56.784", "train_temp": "1.774", "train_loss_0": "3.733", "train_loss_1": "0.131", "train_loss_2": "0.028", "train_accuracy": "0.3053", "train_wps": "3917.5", "train_ups": "2.19", "train_wpb": "1786.6", "train_bsz": "5", "train_num_updates": "23960", "train_lr": "0.000374375", "train_gnorm": "0.576", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11185"}
[2022-01-03 15:16:07,257][fairseq.trainer][INFO] - begin training epoch 600
[2022-01-03 15:16:07,257][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:16:21,087][train_inner][INFO] - {"epoch": 600, "update": 600.0, "loss": "3.91", "ntokens": "1791.61", "nsentences": "4.95", "prob_perplexity": "56.02", "code_perplexity": "55.885", "temp": "1.775", "loss_0": "3.75", "loss_1": "0.132", "loss_2": "0.028", "accuracy": "0.30453", "wps": "3933", "ups": "2.2", "wpb": "1791.6", "bsz": "5", "num_updates": "24000", "lr": "0.000375", "gnorm": "0.573", "clip": "0", "train_wall": "68", "gb_free": "7.2", "wall": "11198"}
[2022-01-03 15:16:21,088][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:16:21,484][valid][INFO] - {"epoch": 600, "valid_loss": "4.311", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "53.7", "valid_code_perplexity": "53.373", "valid_temp": "1.774", "valid_loss_0": "4.15", "valid_loss_1": "0.132", "valid_loss_2": "0.028", "valid_accuracy": "0.23634", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "24000", "valid_best_loss": "3.499"}
[2022-01-03 15:16:21,487][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 600 @ 24000 updates
[2022-01-03 15:16:21,487][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:16:25,475][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:16:25,496][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 600 @ 24000 updates, score 4.311) (writing took 4.009078557603061 seconds)
[2022-01-03 15:16:25,496][fairseq_cli.train][INFO] - end of epoch 600 (average epoch stats below)
[2022-01-03 15:16:25,508][train][INFO] - {"epoch": 600, "train_loss": "3.927", "train_ntokens": "1804.1", "train_nsentences": "4.95", "train_prob_perplexity": "56.622", "train_code_perplexity": "56.465", "train_temp": "1.774", "train_loss_0": "3.768", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.29968", "train_wps": "3940.7", "train_ups": "2.18", "train_wpb": "1804.1", "train_bsz": "5", "train_num_updates": "24000", "train_lr": "0.000375", "train_gnorm": "0.575", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "11203"}
[2022-01-03 15:16:25,554][fairseq.trainer][INFO] - begin training epoch 601
[2022-01-03 15:16:25,554][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:16:39,418][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:16:39,814][valid][INFO] - {"epoch": 601, "valid_loss": "3.952", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "56.589", "valid_code_perplexity": "56.552", "valid_temp": "1.773", "valid_loss_0": "3.791", "valid_loss_1": "0.132", "valid_loss_2": "0.029", "valid_accuracy": "0.29342", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "24040", "valid_best_loss": "3.499"}
[2022-01-03 15:16:39,817][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 601 @ 24040 updates
[2022-01-03 15:16:39,818][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:16:43,709][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:16:43,728][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 601 @ 24040 updates, score 3.952) (writing took 3.9108138075098395 seconds)
[2022-01-03 15:16:43,729][fairseq_cli.train][INFO] - end of epoch 601 (average epoch stats below)
[2022-01-03 15:16:43,741][train][INFO] - {"epoch": 601, "train_loss": "3.907", "train_ntokens": "1779.9", "train_nsentences": "4.95", "train_prob_perplexity": "56.419", "train_code_perplexity": "56.286", "train_temp": "1.774", "train_loss_0": "3.747", "train_loss_1": "0.132", "train_loss_2": "0.028", "train_accuracy": "0.3042", "train_wps": "3907.5", "train_ups": "2.2", "train_wpb": "1779.9", "train_bsz": "5", "train_num_updates": "24040", "train_lr": "0.000375625", "train_gnorm": "0.571", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "11221"}
[2022-01-03 15:16:43,790][fairseq.trainer][INFO] - begin training epoch 602
[2022-01-03 15:16:43,790][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:16:57,677][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:16:58,078][valid][INFO] - {"epoch": 602, "valid_loss": "4.037", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "53.744", "valid_code_perplexity": "53.514", "valid_temp": "1.773", "valid_loss_0": "3.877", "valid_loss_1": "0.132", "valid_loss_2": "0.028", "valid_accuracy": "0.26738", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "24080", "valid_best_loss": "3.499"}
[2022-01-03 15:16:58,081][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 602 @ 24080 updates
[2022-01-03 15:16:58,082][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:17:01,920][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:17:01,941][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 602 @ 24080 updates, score 4.037) (writing took 3.8598262602463365 seconds)
[2022-01-03 15:17:01,941][fairseq_cli.train][INFO] - end of epoch 602 (average epoch stats below)
[2022-01-03 15:17:01,954][train][INFO] - {"epoch": 602, "train_loss": "3.881", "train_ntokens": "1792.05", "train_nsentences": "4.95", "train_prob_perplexity": "57.083", "train_code_perplexity": "56.937", "train_temp": "1.773", "train_loss_0": "3.721", "train_loss_1": "0.131", "train_loss_2": "0.029", "train_accuracy": "0.30638", "train_wps": "3938.6", "train_ups": "2.2", "train_wpb": "1792", "train_bsz": "5", "train_num_updates": "24080", "train_lr": "0.00037625", "train_gnorm": "0.583", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11239"}
[2022-01-03 15:17:02,009][fairseq.trainer][INFO] - begin training epoch 603
[2022-01-03 15:17:02,009][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:17:16,050][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:17:16,459][valid][INFO] - {"epoch": 603, "valid_loss": "4.14", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "56.94", "valid_code_perplexity": "56.665", "valid_temp": "1.773", "valid_loss_0": "3.982", "valid_loss_1": "0.131", "valid_loss_2": "0.027", "valid_accuracy": "0.26337", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "24120", "valid_best_loss": "3.499"}
[2022-01-03 15:17:16,463][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 603 @ 24120 updates
[2022-01-03 15:17:16,464][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:17:20,192][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:17:20,219][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 603 @ 24120 updates, score 4.14) (writing took 3.755818147212267 seconds)
[2022-01-03 15:17:20,219][fairseq_cli.train][INFO] - end of epoch 603 (average epoch stats below)
[2022-01-03 15:17:20,231][train][INFO] - {"epoch": 603, "train_loss": "3.94", "train_ntokens": "1803.28", "train_nsentences": "4.95", "train_prob_perplexity": "58.03", "train_code_perplexity": "57.931", "train_temp": "1.773", "train_loss_0": "3.781", "train_loss_1": "0.131", "train_loss_2": "0.028", "train_accuracy": "0.29794", "train_wps": "3949.2", "train_ups": "2.19", "train_wpb": "1803.3", "train_bsz": "5", "train_num_updates": "24120", "train_lr": "0.000376875", "train_gnorm": "0.586", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.5", "train_wall": "11258"}
[2022-01-03 15:17:20,300][fairseq.trainer][INFO] - begin training epoch 604
[2022-01-03 15:17:20,301][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:17:34,300][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:17:34,711][valid][INFO] - {"epoch": 604, "valid_loss": "3.826", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "54.654", "valid_code_perplexity": "54.537", "valid_temp": "1.772", "valid_loss_0": "3.666", "valid_loss_1": "0.132", "valid_loss_2": "0.028", "valid_accuracy": "0.30055", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "24160", "valid_best_loss": "3.499"}
[2022-01-03 15:17:34,714][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 604 @ 24160 updates
[2022-01-03 15:17:34,714][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:17:38,424][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:17:38,442][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 604 @ 24160 updates, score 3.826) (writing took 3.7284732973203063 seconds)
[2022-01-03 15:17:38,443][fairseq_cli.train][INFO] - end of epoch 604 (average epoch stats below)
[2022-01-03 15:17:38,455][train][INFO] - {"epoch": 604, "train_loss": "3.913", "train_ntokens": "1784", "train_nsentences": "4.95", "train_prob_perplexity": "57.347", "train_code_perplexity": "57.205", "train_temp": "1.773", "train_loss_0": "3.754", "train_loss_1": "0.131", "train_loss_2": "0.027", "train_accuracy": "0.30312", "train_wps": "3918.5", "train_ups": "2.2", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "24160", "train_lr": "0.0003775", "train_gnorm": "0.565", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11276"}
[2022-01-03 15:17:38,494][fairseq.trainer][INFO] - begin training epoch 605
[2022-01-03 15:17:38,495][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:17:52,359][train_inner][INFO] - {"epoch": 605, "update": 605.0, "loss": "3.915", "ntokens": "1791.88", "nsentences": "4.95", "prob_perplexity": "57.362", "code_perplexity": "57.226", "temp": "1.773", "loss_0": "3.755", "loss_1": "0.131", "loss_2": "0.028", "accuracy": "0.30218", "wps": "3927", "ups": "2.19", "wpb": "1791.9", "bsz": "5", "num_updates": "24200", "lr": "0.000378125", "gnorm": "0.574", "clip": "0", "train_wall": "68", "gb_free": "6.1", "wall": "11290"}
[2022-01-03 15:17:52,360][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:17:52,757][valid][INFO] - {"epoch": 605, "valid_loss": "3.722", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "55.334", "valid_code_perplexity": "54.709", "valid_temp": "1.772", "valid_loss_0": "3.564", "valid_loss_1": "0.132", "valid_loss_2": "0.026", "valid_accuracy": "0.33333", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "24200", "valid_best_loss": "3.499"}
[2022-01-03 15:17:52,761][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 605 @ 24200 updates
[2022-01-03 15:17:52,761][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:17:56,661][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:17:56,687][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 605 @ 24200 updates, score 3.722) (writing took 3.926765971817076 seconds)
[2022-01-03 15:17:56,688][fairseq_cli.train][INFO] - end of epoch 605 (average epoch stats below)
[2022-01-03 15:17:56,700][train][INFO] - {"epoch": 605, "train_loss": "3.932", "train_ntokens": "1800.2", "train_nsentences": "4.95", "train_prob_perplexity": "57.93", "train_code_perplexity": "57.769", "train_temp": "1.772", "train_loss_0": "3.772", "train_loss_1": "0.131", "train_loss_2": "0.029", "train_accuracy": "0.29933", "train_wps": "3949.4", "train_ups": "2.19", "train_wpb": "1800.2", "train_bsz": "5", "train_num_updates": "24200", "train_lr": "0.000378125", "train_gnorm": "0.565", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11294"}
[2022-01-03 15:17:56,768][fairseq.trainer][INFO] - begin training epoch 606
[2022-01-03 15:17:56,769][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:18:10,579][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:18:10,982][valid][INFO] - {"epoch": 606, "valid_loss": "4.186", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "56.947", "valid_code_perplexity": "56.771", "valid_temp": "1.772", "valid_loss_0": "4.027", "valid_loss_1": "0.131", "valid_loss_2": "0.028", "valid_accuracy": "0.25676", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "24240", "valid_best_loss": "3.499"}
[2022-01-03 15:18:10,984][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 606 @ 24240 updates
[2022-01-03 15:18:10,985][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:18:14,883][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:18:14,911][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 606 @ 24240 updates, score 4.186) (writing took 3.927123051136732 seconds)
[2022-01-03 15:18:14,912][fairseq_cli.train][INFO] - end of epoch 606 (average epoch stats below)
[2022-01-03 15:18:14,925][train][INFO] - {"epoch": 606, "train_loss": "3.929", "train_ntokens": "1792.42", "train_nsentences": "4.95", "train_prob_perplexity": "58.26", "train_code_perplexity": "58.046", "train_temp": "1.772", "train_loss_0": "3.771", "train_loss_1": "0.131", "train_loss_2": "0.027", "train_accuracy": "0.30096", "train_wps": "3936.9", "train_ups": "2.2", "train_wpb": "1792.4", "train_bsz": "5", "train_num_updates": "24240", "train_lr": "0.00037875", "train_gnorm": "0.577", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11312"}
[2022-01-03 15:18:15,006][fairseq.trainer][INFO] - begin training epoch 607
[2022-01-03 15:18:15,006][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:18:29,019][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:18:29,424][valid][INFO] - {"epoch": 607, "valid_loss": "4.128", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "56.85", "valid_code_perplexity": "56.445", "valid_temp": "1.771", "valid_loss_0": "3.972", "valid_loss_1": "0.131", "valid_loss_2": "0.025", "valid_accuracy": "0.25844", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "24280", "valid_best_loss": "3.499"}
[2022-01-03 15:18:29,427][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 607 @ 24280 updates
[2022-01-03 15:18:29,428][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:18:33,073][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:18:33,091][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 607 @ 24280 updates, score 4.128) (writing took 3.6643774453550577 seconds)
[2022-01-03 15:18:33,092][fairseq_cli.train][INFO] - end of epoch 607 (average epoch stats below)
[2022-01-03 15:18:33,104][train][INFO] - {"epoch": 607, "train_loss": "3.919", "train_ntokens": "1793.28", "train_nsentences": "4.95", "train_prob_perplexity": "58.651", "train_code_perplexity": "58.508", "train_temp": "1.772", "train_loss_0": "3.761", "train_loss_1": "0.131", "train_loss_2": "0.027", "train_accuracy": "0.30341", "train_wps": "3948.6", "train_ups": "2.2", "train_wpb": "1793.3", "train_bsz": "5", "train_num_updates": "24280", "train_lr": "0.000379375", "train_gnorm": "0.573", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11331"}
[2022-01-03 15:18:33,141][fairseq.trainer][INFO] - begin training epoch 608
[2022-01-03 15:18:33,142][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:18:47,058][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:18:47,461][valid][INFO] - {"epoch": 608, "valid_loss": "3.989", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "55.917", "valid_code_perplexity": "55.449", "valid_temp": "1.771", "valid_loss_0": "3.829", "valid_loss_1": "0.132", "valid_loss_2": "0.029", "valid_accuracy": "0.28686", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "24320", "valid_best_loss": "3.499"}
[2022-01-03 15:18:47,464][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 608 @ 24320 updates
[2022-01-03 15:18:47,465][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:18:51,353][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:18:51,383][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 608 @ 24320 updates, score 3.989) (writing took 3.918600461445749 seconds)
[2022-01-03 15:18:51,383][fairseq_cli.train][INFO] - end of epoch 608 (average epoch stats below)
[2022-01-03 15:18:51,396][train][INFO] - {"epoch": 608, "train_loss": "3.955", "train_ntokens": "1795.83", "train_nsentences": "4.95", "train_prob_perplexity": "57.682", "train_code_perplexity": "57.477", "train_temp": "1.771", "train_loss_0": "3.797", "train_loss_1": "0.131", "train_loss_2": "0.027", "train_accuracy": "0.29818", "train_wps": "3929.7", "train_ups": "2.19", "train_wpb": "1795.8", "train_bsz": "5", "train_num_updates": "24320", "train_lr": "0.00038", "train_gnorm": "0.593", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11349"}
[2022-01-03 15:18:51,479][fairseq.trainer][INFO] - begin training epoch 609
[2022-01-03 15:18:51,480][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:19:05,388][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:19:05,794][valid][INFO] - {"epoch": 609, "valid_loss": "3.939", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "55.828", "valid_code_perplexity": "55.454", "valid_temp": "1.771", "valid_loss_0": "3.784", "valid_loss_1": "0.132", "valid_loss_2": "0.024", "valid_accuracy": "0.30274", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "24360", "valid_best_loss": "3.499"}
[2022-01-03 15:19:05,797][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 609 @ 24360 updates
[2022-01-03 15:19:05,798][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:19:09,542][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:19:09,563][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 609 @ 24360 updates, score 3.939) (writing took 3.7653450034558773 seconds)
[2022-01-03 15:19:09,563][fairseq_cli.train][INFO] - end of epoch 609 (average epoch stats below)
[2022-01-03 15:19:09,575][train][INFO] - {"epoch": 609, "train_loss": "3.905", "train_ntokens": "1775.6", "train_nsentences": "4.95", "train_prob_perplexity": "58.629", "train_code_perplexity": "58.452", "train_temp": "1.771", "train_loss_0": "3.746", "train_loss_1": "0.131", "train_loss_2": "0.028", "train_accuracy": "0.3009", "train_wps": "3909.4", "train_ups": "2.2", "train_wpb": "1775.6", "train_bsz": "5", "train_num_updates": "24360", "train_lr": "0.000380625", "train_gnorm": "0.565", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11367"}
[2022-01-03 15:19:09,619][fairseq.trainer][INFO] - begin training epoch 610
[2022-01-03 15:19:09,619][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:19:23,446][train_inner][INFO] - {"epoch": 610, "update": 610.0, "loss": "3.924", "ntokens": "1788.43", "nsentences": "4.95", "prob_perplexity": "58.245", "code_perplexity": "58.058", "temp": "1.771", "loss_0": "3.766", "loss_1": "0.131", "loss_2": "0.027", "accuracy": "0.30143", "wps": "3927.4", "ups": "2.2", "wpb": "1788.4", "bsz": "5", "num_updates": "24400", "lr": "0.00038125", "gnorm": "0.577", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "11381"}
[2022-01-03 15:19:23,447][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:19:23,858][valid][INFO] - {"epoch": 610, "valid_loss": "3.805", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "55.826", "valid_code_perplexity": "55.691", "valid_temp": "1.77", "valid_loss_0": "3.646", "valid_loss_1": "0.132", "valid_loss_2": "0.028", "valid_accuracy": "0.30563", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "24400", "valid_best_loss": "3.499"}
[2022-01-03 15:19:23,862][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 610 @ 24400 updates
[2022-01-03 15:19:23,863][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:19:27,772][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:19:27,797][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 610 @ 24400 updates, score 3.805) (writing took 3.9356785537675023 seconds)
[2022-01-03 15:19:27,798][fairseq_cli.train][INFO] - end of epoch 610 (average epoch stats below)
[2022-01-03 15:19:27,811][train][INFO] - {"epoch": 610, "train_loss": "3.914", "train_ntokens": "1785.03", "train_nsentences": "4.95", "train_prob_perplexity": "58", "train_code_perplexity": "57.806", "train_temp": "1.77", "train_loss_0": "3.755", "train_loss_1": "0.131", "train_loss_2": "0.027", "train_accuracy": "0.30372", "train_wps": "3918.3", "train_ups": "2.2", "train_wpb": "1785", "train_bsz": "5", "train_num_updates": "24400", "train_lr": "0.00038125", "train_gnorm": "0.578", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11385"}
[2022-01-03 15:19:27,878][fairseq.trainer][INFO] - begin training epoch 611
[2022-01-03 15:19:27,879][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:19:41,883][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:19:42,331][valid][INFO] - {"epoch": 611, "valid_loss": "3.864", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "56.989", "valid_code_perplexity": "56.678", "valid_temp": "1.77", "valid_loss_0": "3.705", "valid_loss_1": "0.131", "valid_loss_2": "0.027", "valid_accuracy": "0.31794", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "24440", "valid_best_loss": "3.499"}
[2022-01-03 15:19:42,334][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 611 @ 24440 updates
[2022-01-03 15:19:42,335][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:19:46,138][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:19:46,168][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 611 @ 24440 updates, score 3.864) (writing took 3.83410138823092 seconds)
[2022-01-03 15:19:46,168][fairseq_cli.train][INFO] - end of epoch 611 (average epoch stats below)
[2022-01-03 15:19:46,182][train][INFO] - {"epoch": 611, "train_loss": "3.951", "train_ntokens": "1806.95", "train_nsentences": "4.95", "train_prob_perplexity": "59.291", "train_code_perplexity": "59.087", "train_temp": "1.77", "train_loss_0": "3.791", "train_loss_1": "0.131", "train_loss_2": "0.028", "train_accuracy": "0.29878", "train_wps": "3937.2", "train_ups": "2.18", "train_wpb": "1807", "train_bsz": "5", "train_num_updates": "24440", "train_lr": "0.000381875", "train_gnorm": "0.562", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11404"}
[2022-01-03 15:19:46,247][fairseq.trainer][INFO] - begin training epoch 612
[2022-01-03 15:19:46,247][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:20:00,174][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:20:00,571][valid][INFO] - {"epoch": 612, "valid_loss": "3.889", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "55.681", "valid_code_perplexity": "55.569", "valid_temp": "1.77", "valid_loss_0": "3.728", "valid_loss_1": "0.132", "valid_loss_2": "0.029", "valid_accuracy": "0.30287", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "24480", "valid_best_loss": "3.499"}
[2022-01-03 15:20:00,574][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 612 @ 24480 updates
[2022-01-03 15:20:00,575][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:20:04,226][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:20:04,254][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 612 @ 24480 updates, score 3.889) (writing took 3.680113152600825 seconds)
[2022-01-03 15:20:04,255][fairseq_cli.train][INFO] - end of epoch 612 (average epoch stats below)
[2022-01-03 15:20:04,267][train][INFO] - {"epoch": 612, "train_loss": "3.926", "train_ntokens": "1791.7", "train_nsentences": "4.95", "train_prob_perplexity": "59.51", "train_code_perplexity": "59.312", "train_temp": "1.77", "train_loss_0": "3.766", "train_loss_1": "0.131", "train_loss_2": "0.028", "train_accuracy": "0.30219", "train_wps": "3965.6", "train_ups": "2.21", "train_wpb": "1791.7", "train_bsz": "5", "train_num_updates": "24480", "train_lr": "0.0003825", "train_gnorm": "0.554", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11422"}
[2022-01-03 15:20:04,342][fairseq.trainer][INFO] - begin training epoch 613
[2022-01-03 15:20:04,343][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:20:18,297][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:20:18,698][valid][INFO] - {"epoch": 613, "valid_loss": "3.953", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "56.338", "valid_code_perplexity": "56.033", "valid_temp": "1.769", "valid_loss_0": "3.793", "valid_loss_1": "0.132", "valid_loss_2": "0.028", "valid_accuracy": "0.31522", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "24520", "valid_best_loss": "3.499"}
[2022-01-03 15:20:18,701][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 613 @ 24520 updates
[2022-01-03 15:20:18,702][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:20:22,448][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:20:22,475][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 613 @ 24520 updates, score 3.953) (writing took 3.774349955841899 seconds)
[2022-01-03 15:20:22,476][fairseq_cli.train][INFO] - end of epoch 613 (average epoch stats below)
[2022-01-03 15:20:22,488][train][INFO] - {"epoch": 613, "train_loss": "3.949", "train_ntokens": "1791.1", "train_nsentences": "4.95", "train_prob_perplexity": "59.079", "train_code_perplexity": "58.852", "train_temp": "1.769", "train_loss_0": "3.789", "train_loss_1": "0.131", "train_loss_2": "0.029", "train_accuracy": "0.29732", "train_wps": "3934.7", "train_ups": "2.2", "train_wpb": "1791.1", "train_bsz": "5", "train_num_updates": "24520", "train_lr": "0.000383125", "train_gnorm": "0.558", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11440"}
[2022-01-03 15:20:22,531][fairseq.trainer][INFO] - begin training epoch 614
[2022-01-03 15:20:22,532][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:20:36,448][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:20:36,862][valid][INFO] - {"epoch": 614, "valid_loss": "3.854", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "57.057", "valid_code_perplexity": "56.563", "valid_temp": "1.769", "valid_loss_0": "3.692", "valid_loss_1": "0.131", "valid_loss_2": "0.031", "valid_accuracy": "0.32027", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "24560", "valid_best_loss": "3.499"}
[2022-01-03 15:20:36,866][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 614 @ 24560 updates
[2022-01-03 15:20:36,868][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:20:40,778][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:20:40,807][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 614 @ 24560 updates, score 3.854) (writing took 3.9408306879922748 seconds)
[2022-01-03 15:20:40,808][fairseq_cli.train][INFO] - end of epoch 614 (average epoch stats below)
[2022-01-03 15:20:40,821][train][INFO] - {"epoch": 614, "train_loss": "3.926", "train_ntokens": "1792.97", "train_nsentences": "4.95", "train_prob_perplexity": "59.854", "train_code_perplexity": "59.627", "train_temp": "1.769", "train_loss_0": "3.766", "train_loss_1": "0.131", "train_loss_2": "0.03", "train_accuracy": "0.2992", "train_wps": "3914.9", "train_ups": "2.18", "train_wpb": "1793", "train_bsz": "5", "train_num_updates": "24560", "train_lr": "0.00038375", "train_gnorm": "0.581", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "11458"}
[2022-01-03 15:20:40,878][fairseq.trainer][INFO] - begin training epoch 615
[2022-01-03 15:20:40,879][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:20:54,849][train_inner][INFO] - {"epoch": 615, "update": 615.0, "loss": "3.941", "ntokens": "1795.92", "nsentences": "4.95", "prob_perplexity": "59.548", "code_perplexity": "59.33", "temp": "1.769", "loss_0": "3.782", "loss_1": "0.131", "loss_2": "0.029", "accuracy": "0.29928", "wps": "3930.3", "ups": "2.19", "wpb": "1795.9", "bsz": "5", "num_updates": "24600", "lr": "0.000384375", "gnorm": "0.569", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "11472"}
[2022-01-03 15:20:54,850][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:20:55,266][valid][INFO] - {"epoch": 615, "valid_loss": "3.853", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "57.764", "valid_code_perplexity": "57.403", "valid_temp": "1.769", "valid_loss_0": "3.695", "valid_loss_1": "0.131", "valid_loss_2": "0.027", "valid_accuracy": "0.29683", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "24600", "valid_best_loss": "3.499"}
[2022-01-03 15:20:55,270][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 615 @ 24600 updates
[2022-01-03 15:20:55,271][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:20:58,956][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:20:58,976][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 615 @ 24600 updates, score 3.853) (writing took 3.706002744846046 seconds)
[2022-01-03 15:20:58,977][fairseq_cli.train][INFO] - end of epoch 615 (average epoch stats below)
[2022-01-03 15:20:58,989][train][INFO] - {"epoch": 615, "train_loss": "3.955", "train_ntokens": "1796.9", "train_nsentences": "4.95", "train_prob_perplexity": "60.008", "train_code_perplexity": "59.77", "train_temp": "1.769", "train_loss_0": "3.796", "train_loss_1": "0.131", "train_loss_2": "0.029", "train_accuracy": "0.29892", "train_wps": "3958.8", "train_ups": "2.2", "train_wpb": "1796.9", "train_bsz": "5", "train_num_updates": "24600", "train_lr": "0.000384375", "train_gnorm": "0.589", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11476"}
[2022-01-03 15:20:59,035][fairseq.trainer][INFO] - begin training epoch 616
[2022-01-03 15:20:59,035][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:21:12,943][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:21:13,336][valid][INFO] - {"epoch": 616, "valid_loss": "3.956", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "54.074", "valid_code_perplexity": "54.069", "valid_temp": "1.768", "valid_loss_0": "3.794", "valid_loss_1": "0.132", "valid_loss_2": "0.03", "valid_accuracy": "0.29597", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "24640", "valid_best_loss": "3.499"}
[2022-01-03 15:21:13,339][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 616 @ 24640 updates
[2022-01-03 15:21:13,340][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:21:17,304][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:21:17,334][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 616 @ 24640 updates, score 3.956) (writing took 3.994401208125055 seconds)
[2022-01-03 15:21:17,334][fairseq_cli.train][INFO] - end of epoch 616 (average epoch stats below)
[2022-01-03 15:21:17,347][train][INFO] - {"epoch": 616, "train_loss": "3.911", "train_ntokens": "1802.08", "train_nsentences": "4.95", "train_prob_perplexity": "60.231", "train_code_perplexity": "59.994", "train_temp": "1.768", "train_loss_0": "3.753", "train_loss_1": "0.131", "train_loss_2": "0.028", "train_accuracy": "0.30266", "train_wps": "3929.3", "train_ups": "2.18", "train_wpb": "1802.1", "train_bsz": "5", "train_num_updates": "24640", "train_lr": "0.000385", "train_gnorm": "0.56", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "11495"}
[2022-01-03 15:21:17,402][fairseq.trainer][INFO] - begin training epoch 617
[2022-01-03 15:21:17,402][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:21:31,304][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:21:31,709][valid][INFO] - {"epoch": 617, "valid_loss": "3.795", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "58.602", "valid_code_perplexity": "58.081", "valid_temp": "1.768", "valid_loss_0": "3.635", "valid_loss_1": "0.131", "valid_loss_2": "0.028", "valid_accuracy": "0.30392", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "24680", "valid_best_loss": "3.499"}
[2022-01-03 15:21:31,712][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 617 @ 24680 updates
[2022-01-03 15:21:31,713][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:21:35,542][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:21:35,571][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 617 @ 24680 updates, score 3.795) (writing took 3.858253284357488 seconds)
[2022-01-03 15:21:35,571][fairseq_cli.train][INFO] - end of epoch 617 (average epoch stats below)
[2022-01-03 15:21:35,584][train][INFO] - {"epoch": 617, "train_loss": "3.929", "train_ntokens": "1788.38", "train_nsentences": "4.95", "train_prob_perplexity": "60.247", "train_code_perplexity": "59.958", "train_temp": "1.768", "train_loss_0": "3.77", "train_loss_1": "0.131", "train_loss_2": "0.028", "train_accuracy": "0.2995", "train_wps": "3925.3", "train_ups": "2.19", "train_wpb": "1788.4", "train_bsz": "5", "train_num_updates": "24680", "train_lr": "0.000385625", "train_gnorm": "0.584", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11513"}
[2022-01-03 15:21:35,626][fairseq.trainer][INFO] - begin training epoch 618
[2022-01-03 15:21:35,627][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:21:49,368][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:21:49,763][valid][INFO] - {"epoch": 618, "valid_loss": "3.88", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "56.869", "valid_code_perplexity": "56.862", "valid_temp": "1.767", "valid_loss_0": "3.719", "valid_loss_1": "0.131", "valid_loss_2": "0.029", "valid_accuracy": "0.31476", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "24720", "valid_best_loss": "3.499"}
[2022-01-03 15:21:49,766][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 618 @ 24720 updates
[2022-01-03 15:21:49,767][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:21:53,649][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:21:53,678][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 618 @ 24720 updates, score 3.88) (writing took 3.9113241229206324 seconds)
[2022-01-03 15:21:53,678][fairseq_cli.train][INFO] - end of epoch 618 (average epoch stats below)
[2022-01-03 15:21:53,692][train][INFO] - {"epoch": 618, "train_loss": "3.97", "train_ntokens": "1776.45", "train_nsentences": "4.95", "train_prob_perplexity": "61.597", "train_code_perplexity": "61.304", "train_temp": "1.768", "train_loss_0": "3.81", "train_loss_1": "0.13", "train_loss_2": "0.029", "train_accuracy": "0.29574", "train_wps": "3927.2", "train_ups": "2.21", "train_wpb": "1776.5", "train_bsz": "5", "train_num_updates": "24720", "train_lr": "0.00038625", "train_gnorm": "0.574", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11531"}
[2022-01-03 15:21:53,773][fairseq.trainer][INFO] - begin training epoch 619
[2022-01-03 15:21:53,774][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:22:07,764][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:22:08,191][valid][INFO] - {"epoch": 619, "valid_loss": "4.054", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "61.28", "valid_code_perplexity": "61.299", "valid_temp": "1.767", "valid_loss_0": "3.893", "valid_loss_1": "0.13", "valid_loss_2": "0.03", "valid_accuracy": "0.29813", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "24760", "valid_best_loss": "3.499"}
[2022-01-03 15:22:08,196][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 619 @ 24760 updates
[2022-01-03 15:22:08,197][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:22:12,265][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:22:12,294][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 619 @ 24760 updates, score 4.054) (writing took 4.0984598733484745 seconds)
[2022-01-03 15:22:12,295][fairseq_cli.train][INFO] - end of epoch 619 (average epoch stats below)
[2022-01-03 15:22:12,308][train][INFO] - {"epoch": 619, "train_loss": "3.886", "train_ntokens": "1784.8", "train_nsentences": "4.95", "train_prob_perplexity": "60.393", "train_code_perplexity": "60.129", "train_temp": "1.767", "train_loss_0": "3.726", "train_loss_1": "0.131", "train_loss_2": "0.029", "train_accuracy": "0.30631", "train_wps": "3837.8", "train_ups": "2.15", "train_wpb": "1784.8", "train_bsz": "5", "train_num_updates": "24760", "train_lr": "0.000386875", "train_gnorm": "0.581", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11550"}
[2022-01-03 15:22:12,389][fairseq.trainer][INFO] - begin training epoch 620
[2022-01-03 15:22:12,389][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:22:26,224][train_inner][INFO] - {"epoch": 620, "update": 620.0, "loss": "3.92", "ntokens": "1785.37", "nsentences": "4.95", "prob_perplexity": "60.821", "code_perplexity": "60.547", "temp": "1.768", "loss_0": "3.76", "loss_1": "0.131", "loss_2": "0.029", "accuracy": "0.30143", "wps": "3908.3", "ups": "2.19", "wpb": "1785.4", "bsz": "5", "num_updates": "24800", "lr": "0.0003875", "gnorm": "0.575", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "11564"}
[2022-01-03 15:22:26,224][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:22:26,634][valid][INFO] - {"epoch": 620, "valid_loss": "3.983", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "52.084", "valid_code_perplexity": "51.358", "valid_temp": "1.767", "valid_loss_0": "3.818", "valid_loss_1": "0.133", "valid_loss_2": "0.033", "valid_accuracy": "0.29704", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "24800", "valid_best_loss": "3.499"}
[2022-01-03 15:22:26,637][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 620 @ 24800 updates
[2022-01-03 15:22:26,638][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:22:30,527][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:22:30,552][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 620 @ 24800 updates, score 3.983) (writing took 3.914900477975607 seconds)
[2022-01-03 15:22:30,553][fairseq_cli.train][INFO] - end of epoch 620 (average epoch stats below)
[2022-01-03 15:22:30,565][train][INFO] - {"epoch": 620, "train_loss": "3.903", "train_ntokens": "1775.12", "train_nsentences": "4.95", "train_prob_perplexity": "61.64", "train_code_perplexity": "61.352", "train_temp": "1.767", "train_loss_0": "3.743", "train_loss_1": "0.13", "train_loss_2": "0.03", "train_accuracy": "0.30289", "train_wps": "3891.7", "train_ups": "2.19", "train_wpb": "1775.1", "train_bsz": "5", "train_num_updates": "24800", "train_lr": "0.0003875", "train_gnorm": "0.577", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11568"}
[2022-01-03 15:22:30,628][fairseq.trainer][INFO] - begin training epoch 621
[2022-01-03 15:22:30,628][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:22:44,516][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:22:44,949][valid][INFO] - {"epoch": 621, "valid_loss": "4.083", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "55.878", "valid_code_perplexity": "55.338", "valid_temp": "1.766", "valid_loss_0": "3.922", "valid_loss_1": "0.132", "valid_loss_2": "0.029", "valid_accuracy": "0.2957", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "24840", "valid_best_loss": "3.499"}
[2022-01-03 15:22:44,952][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 621 @ 24840 updates
[2022-01-03 15:22:44,952][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:22:48,751][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:22:48,779][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 621 @ 24840 updates, score 4.083) (writing took 3.8271178025752306 seconds)
[2022-01-03 15:22:48,779][fairseq_cli.train][INFO] - end of epoch 621 (average epoch stats below)
[2022-01-03 15:22:48,792][train][INFO] - {"epoch": 621, "train_loss": "3.93", "train_ntokens": "1796.7", "train_nsentences": "4.95", "train_prob_perplexity": "61.955", "train_code_perplexity": "61.624", "train_temp": "1.767", "train_loss_0": "3.771", "train_loss_1": "0.13", "train_loss_2": "0.029", "train_accuracy": "0.29863", "train_wps": "3945.8", "train_ups": "2.2", "train_wpb": "1796.7", "train_bsz": "5", "train_num_updates": "24840", "train_lr": "0.000388125", "train_gnorm": "0.564", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11586"}
[2022-01-03 15:22:48,867][fairseq.trainer][INFO] - begin training epoch 622
[2022-01-03 15:22:48,867][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:23:02,815][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:23:03,236][valid][INFO] - {"epoch": 622, "valid_loss": "3.846", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "59.747", "valid_code_perplexity": "58.941", "valid_temp": "1.766", "valid_loss_0": "3.685", "valid_loss_1": "0.131", "valid_loss_2": "0.03", "valid_accuracy": "0.30315", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "24880", "valid_best_loss": "3.499"}
[2022-01-03 15:23:03,239][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 622 @ 24880 updates
[2022-01-03 15:23:03,240][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:23:06,989][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:23:07,019][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 622 @ 24880 updates, score 3.846) (writing took 3.7794101452454925 seconds)
[2022-01-03 15:23:07,019][fairseq_cli.train][INFO] - end of epoch 622 (average epoch stats below)
[2022-01-03 15:23:07,033][train][INFO] - {"epoch": 622, "train_loss": "3.921", "train_ntokens": "1807.38", "train_nsentences": "4.95", "train_prob_perplexity": "62.306", "train_code_perplexity": "61.889", "train_temp": "1.766", "train_loss_0": "3.761", "train_loss_1": "0.13", "train_loss_2": "0.029", "train_accuracy": "0.30075", "train_wps": "3966.2", "train_ups": "2.19", "train_wpb": "1807.4", "train_bsz": "5", "train_num_updates": "24880", "train_lr": "0.00038875", "train_gnorm": "0.569", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "11604"}
[2022-01-03 15:23:07,111][fairseq.trainer][INFO] - begin training epoch 623
[2022-01-03 15:23:07,112][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:23:21,112][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:23:21,568][valid][INFO] - {"epoch": 623, "valid_loss": "3.877", "valid_ntokens": "686", "valid_nsentences": "2", "valid_prob_perplexity": "59.133", "valid_code_perplexity": "58.402", "valid_temp": "1.766", "valid_loss_0": "3.715", "valid_loss_1": "0.131", "valid_loss_2": "0.03", "valid_accuracy": "0.29738", "valid_wps": "0", "valid_wpb": "686", "valid_bsz": "2", "valid_num_updates": "24920", "valid_best_loss": "3.499"}
[2022-01-03 15:23:21,570][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 623 @ 24920 updates
[2022-01-03 15:23:21,570][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:23:25,253][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:23:25,280][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 623 @ 24920 updates, score 3.877) (writing took 3.710423283278942 seconds)
[2022-01-03 15:23:25,281][fairseq_cli.train][INFO] - end of epoch 623 (average epoch stats below)
[2022-01-03 15:23:25,294][train][INFO] - {"epoch": 623, "train_loss": "3.938", "train_ntokens": "1810.58", "train_nsentences": "4.95", "train_prob_perplexity": "62.446", "train_code_perplexity": "62.019", "train_temp": "1.766", "train_loss_0": "3.778", "train_loss_1": "0.13", "train_loss_2": "0.03", "train_accuracy": "0.29836", "train_wps": "3968.8", "train_ups": "2.19", "train_wpb": "1810.6", "train_bsz": "5", "train_num_updates": "24920", "train_lr": "0.000389375", "train_gnorm": "0.583", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "11623"}
[2022-01-03 15:23:25,378][fairseq.trainer][INFO] - begin training epoch 624
[2022-01-03 15:23:25,379][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:23:39,325][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:23:39,726][valid][INFO] - {"epoch": 624, "valid_loss": "3.811", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "60.954", "valid_code_perplexity": "60.786", "valid_temp": "1.765", "valid_loss_0": "3.65", "valid_loss_1": "0.131", "valid_loss_2": "0.031", "valid_accuracy": "0.32429", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "24960", "valid_best_loss": "3.499"}
[2022-01-03 15:23:39,729][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 624 @ 24960 updates
[2022-01-03 15:23:39,730][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:23:43,475][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:23:43,502][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 624 @ 24960 updates, score 3.811) (writing took 3.772449877113104 seconds)
[2022-01-03 15:23:43,502][fairseq_cli.train][INFO] - end of epoch 624 (average epoch stats below)
[2022-01-03 15:23:43,516][train][INFO] - {"epoch": 624, "train_loss": "3.937", "train_ntokens": "1776.08", "train_nsentences": "4.95", "train_prob_perplexity": "62.96", "train_code_perplexity": "62.493", "train_temp": "1.766", "train_loss_0": "3.775", "train_loss_1": "0.13", "train_loss_2": "0.031", "train_accuracy": "0.2991", "train_wps": "3901.8", "train_ups": "2.2", "train_wpb": "1776.1", "train_bsz": "5", "train_num_updates": "24960", "train_lr": "0.00039", "train_gnorm": "0.58", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11641"}
[2022-01-03 15:23:43,586][fairseq.trainer][INFO] - begin training epoch 625
[2022-01-03 15:23:43,587][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:23:57,505][train_inner][INFO] - {"epoch": 625, "update": 625.0, "loss": "3.937", "ntokens": "1797.96", "nsentences": "4.95", "prob_perplexity": "62.683", "code_perplexity": "62.251", "temp": "1.766", "loss_0": "3.777", "loss_1": "0.13", "loss_2": "0.03", "accuracy": "0.298", "wps": "3939.9", "ups": "2.19", "wpb": "1798", "bsz": "5", "num_updates": "25000", "lr": "0.000390625", "gnorm": "0.576", "clip": "0", "train_wall": "67", "gb_free": "5.4", "wall": "11655"}
[2022-01-03 15:23:57,506][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:23:57,914][valid][INFO] - {"epoch": 625, "valid_loss": "4.156", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "62.231", "valid_code_perplexity": "61.79", "valid_temp": "1.765", "valid_loss_0": "3.994", "valid_loss_1": "0.13", "valid_loss_2": "0.032", "valid_accuracy": "0.28016", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "25000", "valid_best_loss": "3.499"}
[2022-01-03 15:23:57,918][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 625 @ 25000 updates
[2022-01-03 15:23:57,918][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:24:01,721][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:24:01,750][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 625 @ 25000 updates, score 4.156) (writing took 3.832292689010501 seconds)
[2022-01-03 15:24:01,750][fairseq_cli.train][INFO] - end of epoch 625 (average epoch stats below)
[2022-01-03 15:24:01,763][train][INFO] - {"epoch": 625, "train_loss": "3.96", "train_ntokens": "1799.1", "train_nsentences": "4.95", "train_prob_perplexity": "63.75", "train_code_perplexity": "63.231", "train_temp": "1.765", "train_loss_0": "3.8", "train_loss_1": "0.13", "train_loss_2": "0.031", "train_accuracy": "0.29313", "train_wps": "3946.6", "train_ups": "2.19", "train_wpb": "1799.1", "train_bsz": "5", "train_num_updates": "25000", "train_lr": "0.000390625", "train_gnorm": "0.583", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "11659"}
[2022-01-03 15:24:01,842][fairseq.trainer][INFO] - begin training epoch 626
[2022-01-03 15:24:01,843][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:24:15,890][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:24:16,298][valid][INFO] - {"epoch": 626, "valid_loss": "3.949", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "58.785", "valid_code_perplexity": "58.133", "valid_temp": "1.765", "valid_loss_0": "3.789", "valid_loss_1": "0.131", "valid_loss_2": "0.029", "valid_accuracy": "0.30697", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "25040", "valid_best_loss": "3.499"}
[2022-01-03 15:24:16,301][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 626 @ 25040 updates
[2022-01-03 15:24:16,302][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:24:19,991][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:24:20,019][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 626 @ 25040 updates, score 3.949) (writing took 3.71814242284745 seconds)
[2022-01-03 15:24:20,019][fairseq_cli.train][INFO] - end of epoch 626 (average epoch stats below)
[2022-01-03 15:24:20,032][train][INFO] - {"epoch": 626, "train_loss": "3.908", "train_ntokens": "1779.5", "train_nsentences": "4.95", "train_prob_perplexity": "63.951", "train_code_perplexity": "63.377", "train_temp": "1.765", "train_loss_0": "3.748", "train_loss_1": "0.13", "train_loss_2": "0.031", "train_accuracy": "0.30232", "train_wps": "3898.9", "train_ups": "2.19", "train_wpb": "1779.5", "train_bsz": "5", "train_num_updates": "25040", "train_lr": "0.00039125", "train_gnorm": "0.574", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11677"}
[2022-01-03 15:24:20,076][fairseq.trainer][INFO] - begin training epoch 627
[2022-01-03 15:24:20,076][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:24:33,838][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:24:34,248][valid][INFO] - {"epoch": 627, "valid_loss": "3.874", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "59.578", "valid_code_perplexity": "58.615", "valid_temp": "1.764", "valid_loss_0": "3.713", "valid_loss_1": "0.131", "valid_loss_2": "0.031", "valid_accuracy": "0.29061", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "25080", "valid_best_loss": "3.499"}
[2022-01-03 15:24:34,250][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 627 @ 25080 updates
[2022-01-03 15:24:34,251][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:24:38,145][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:24:38,173][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 627 @ 25080 updates, score 3.874) (writing took 3.9222773779183626 seconds)
[2022-01-03 15:24:38,173][fairseq_cli.train][INFO] - end of epoch 627 (average epoch stats below)
[2022-01-03 15:24:38,189][train][INFO] - {"epoch": 627, "train_loss": "3.939", "train_ntokens": "1784.55", "train_nsentences": "4.95", "train_prob_perplexity": "64.004", "train_code_perplexity": "63.433", "train_temp": "1.764", "train_loss_0": "3.779", "train_loss_1": "0.13", "train_loss_2": "0.03", "train_accuracy": "0.29753", "train_wps": "3934.8", "train_ups": "2.2", "train_wpb": "1784.5", "train_bsz": "5", "train_num_updates": "25080", "train_lr": "0.000391875", "train_gnorm": "0.565", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11696"}
[2022-01-03 15:24:38,261][fairseq.trainer][INFO] - begin training epoch 628
[2022-01-03 15:24:38,262][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:24:52,165][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:24:52,577][valid][INFO] - {"epoch": 628, "valid_loss": "4.2", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "59.704", "valid_code_perplexity": "58.838", "valid_temp": "1.764", "valid_loss_0": "4.041", "valid_loss_1": "0.131", "valid_loss_2": "0.028", "valid_accuracy": "0.27116", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "25120", "valid_best_loss": "3.499"}
[2022-01-03 15:24:52,582][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 628 @ 25120 updates
[2022-01-03 15:24:52,584][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:24:56,347][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:24:56,369][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 628 @ 25120 updates, score 4.2) (writing took 3.786627611145377 seconds)
[2022-01-03 15:24:56,369][fairseq_cli.train][INFO] - end of epoch 628 (average epoch stats below)
[2022-01-03 15:24:56,382][train][INFO] - {"epoch": 628, "train_loss": "3.938", "train_ntokens": "1792.9", "train_nsentences": "4.95", "train_prob_perplexity": "64.345", "train_code_perplexity": "63.763", "train_temp": "1.764", "train_loss_0": "3.779", "train_loss_1": "0.13", "train_loss_2": "0.029", "train_accuracy": "0.30044", "train_wps": "3944.7", "train_ups": "2.2", "train_wpb": "1792.9", "train_bsz": "5", "train_num_updates": "25120", "train_lr": "0.0003925", "train_gnorm": "0.594", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "11714"}
[2022-01-03 15:24:56,425][fairseq.trainer][INFO] - begin training epoch 629
[2022-01-03 15:24:56,426][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:25:10,346][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:25:10,762][valid][INFO] - {"epoch": 629, "valid_loss": "3.953", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "61.092", "valid_code_perplexity": "60.626", "valid_temp": "1.764", "valid_loss_0": "3.791", "valid_loss_1": "0.13", "valid_loss_2": "0.032", "valid_accuracy": "0.29755", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "25160", "valid_best_loss": "3.499"}
[2022-01-03 15:25:10,765][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 629 @ 25160 updates
[2022-01-03 15:25:10,766][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:25:14,729][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:25:14,757][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 629 @ 25160 updates, score 3.953) (writing took 3.9916876554489136 seconds)
[2022-01-03 15:25:14,757][fairseq_cli.train][INFO] - end of epoch 629 (average epoch stats below)
[2022-01-03 15:25:14,770][train][INFO] - {"epoch": 629, "train_loss": "3.953", "train_ntokens": "1804.25", "train_nsentences": "4.95", "train_prob_perplexity": "64.348", "train_code_perplexity": "63.657", "train_temp": "1.764", "train_loss_0": "3.794", "train_loss_1": "0.13", "train_loss_2": "0.03", "train_accuracy": "0.29284", "train_wps": "3927.5", "train_ups": "2.18", "train_wpb": "1804.2", "train_bsz": "5", "train_num_updates": "25160", "train_lr": "0.000393125", "train_gnorm": "0.565", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11732"}
[2022-01-03 15:25:14,843][fairseq.trainer][INFO] - begin training epoch 630
[2022-01-03 15:25:14,844][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:25:28,796][train_inner][INFO] - {"epoch": 630, "update": 630.0, "loss": "3.932", "ntokens": "1790.84", "nsentences": "4.95", "prob_perplexity": "64.319", "code_perplexity": "63.706", "temp": "1.764", "loss_0": "3.772", "loss_1": "0.13", "loss_2": "0.03", "accuracy": "0.29845", "wps": "3923.9", "ups": "2.19", "wpb": "1790.8", "bsz": "5", "num_updates": "25200", "lr": "0.00039375", "gnorm": "0.576", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "11746"}
[2022-01-03 15:25:28,797][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:25:29,196][valid][INFO] - {"epoch": 630, "valid_loss": "3.803", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "60.781", "valid_code_perplexity": "59.603", "valid_temp": "1.763", "valid_loss_0": "3.642", "valid_loss_1": "0.131", "valid_loss_2": "0.03", "valid_accuracy": "0.30585", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "25200", "valid_best_loss": "3.499"}
[2022-01-03 15:25:29,199][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 630 @ 25200 updates
[2022-01-03 15:25:29,200][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:25:32,906][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:25:32,926][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 630 @ 25200 updates, score 3.803) (writing took 3.72742114122957 seconds)
[2022-01-03 15:25:32,927][fairseq_cli.train][INFO] - end of epoch 630 (average epoch stats below)
[2022-01-03 15:25:32,939][train][INFO] - {"epoch": 630, "train_loss": "3.923", "train_ntokens": "1793", "train_nsentences": "4.95", "train_prob_perplexity": "64.948", "train_code_perplexity": "64.3", "train_temp": "1.763", "train_loss_0": "3.763", "train_loss_1": "0.13", "train_loss_2": "0.031", "train_accuracy": "0.29919", "train_wps": "3950.2", "train_ups": "2.2", "train_wpb": "1793", "train_bsz": "5", "train_num_updates": "25200", "train_lr": "0.00039375", "train_gnorm": "0.578", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11750"}
[2022-01-03 15:25:32,999][fairseq.trainer][INFO] - begin training epoch 631
[2022-01-03 15:25:32,999][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:25:46,800][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:25:47,182][valid][INFO] - {"epoch": 631, "valid_loss": "4.192", "valid_ntokens": "808", "valid_nsentences": "2", "valid_prob_perplexity": "64.982", "valid_code_perplexity": "64.405", "valid_temp": "1.763", "valid_loss_0": "4.03", "valid_loss_1": "0.13", "valid_loss_2": "0.033", "valid_accuracy": "0.25866", "valid_wps": "0", "valid_wpb": "808", "valid_bsz": "2", "valid_num_updates": "25240", "valid_best_loss": "3.499"}
[2022-01-03 15:25:47,185][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 631 @ 25240 updates
[2022-01-03 15:25:47,186][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:25:51,117][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:25:51,144][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 631 @ 25240 updates, score 4.192) (writing took 3.9581680735573173 seconds)
[2022-01-03 15:25:51,144][fairseq_cli.train][INFO] - end of epoch 631 (average epoch stats below)
[2022-01-03 15:25:51,157][train][INFO] - {"epoch": 631, "train_loss": "3.959", "train_ntokens": "1804.65", "train_nsentences": "4.95", "train_prob_perplexity": "65.862", "train_code_perplexity": "65.14", "train_temp": "1.763", "train_loss_0": "3.798", "train_loss_1": "0.129", "train_loss_2": "0.031", "train_accuracy": "0.29044", "train_wps": "3965.1", "train_ups": "2.2", "train_wpb": "1804.7", "train_bsz": "5", "train_num_updates": "25240", "train_lr": "0.000394375", "train_gnorm": "0.599", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11769"}
[2022-01-03 15:25:51,207][fairseq.trainer][INFO] - begin training epoch 632
[2022-01-03 15:25:51,208][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:26:05,081][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:26:05,477][valid][INFO] - {"epoch": 632, "valid_loss": "4.049", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "60.818", "valid_code_perplexity": "60.074", "valid_temp": "1.763", "valid_loss_0": "3.886", "valid_loss_1": "0.131", "valid_loss_2": "0.032", "valid_accuracy": "0.27865", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "25280", "valid_best_loss": "3.499"}
[2022-01-03 15:26:05,480][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 632 @ 25280 updates
[2022-01-03 15:26:05,481][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:26:09,316][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:26:09,343][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 632 @ 25280 updates, score 4.049) (writing took 3.862294047139585 seconds)
[2022-01-03 15:26:09,343][fairseq_cli.train][INFO] - end of epoch 632 (average epoch stats below)
[2022-01-03 15:26:09,356][train][INFO] - {"epoch": 632, "train_loss": "3.991", "train_ntokens": "1803.22", "train_nsentences": "4.95", "train_prob_perplexity": "65.602", "train_code_perplexity": "64.806", "train_temp": "1.763", "train_loss_0": "3.83", "train_loss_1": "0.129", "train_loss_2": "0.031", "train_accuracy": "0.28828", "train_wps": "3966.1", "train_ups": "2.2", "train_wpb": "1803.2", "train_bsz": "5", "train_num_updates": "25280", "train_lr": "0.000395", "train_gnorm": "0.569", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11787"}
[2022-01-03 15:26:09,413][fairseq.trainer][INFO] - begin training epoch 633
[2022-01-03 15:26:09,414][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:26:23,339][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:26:23,737][valid][INFO] - {"epoch": 633, "valid_loss": "3.579", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "57.019", "valid_code_perplexity": "56.501", "valid_temp": "1.762", "valid_loss_0": "3.417", "valid_loss_1": "0.131", "valid_loss_2": "0.03", "valid_accuracy": "0.35602", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "25320", "valid_best_loss": "3.499"}
[2022-01-03 15:26:23,740][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 633 @ 25320 updates
[2022-01-03 15:26:23,741][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:26:27,489][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:26:27,512][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 633 @ 25320 updates, score 3.579) (writing took 3.771753045730293 seconds)
[2022-01-03 15:26:27,512][fairseq_cli.train][INFO] - end of epoch 633 (average epoch stats below)
[2022-01-03 15:26:27,524][train][INFO] - {"epoch": 633, "train_loss": "3.967", "train_ntokens": "1799.42", "train_nsentences": "4.95", "train_prob_perplexity": "65.469", "train_code_perplexity": "64.65", "train_temp": "1.762", "train_loss_0": "3.807", "train_loss_1": "0.13", "train_loss_2": "0.031", "train_accuracy": "0.29245", "train_wps": "3964.4", "train_ups": "2.2", "train_wpb": "1799.4", "train_bsz": "5", "train_num_updates": "25320", "train_lr": "0.000395625", "train_gnorm": "0.584", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11805"}
[2022-01-03 15:26:27,570][fairseq.trainer][INFO] - begin training epoch 634
[2022-01-03 15:26:27,570][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:26:41,525][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:26:42,023][valid][INFO] - {"epoch": 634, "valid_loss": "3.885", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "61.555", "valid_code_perplexity": "60.806", "valid_temp": "1.762", "valid_loss_0": "3.726", "valid_loss_1": "0.13", "valid_loss_2": "0.029", "valid_accuracy": "0.28992", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "25360", "valid_best_loss": "3.499"}
[2022-01-03 15:26:42,025][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 634 @ 25360 updates
[2022-01-03 15:26:42,025][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:26:45,757][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:26:45,785][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 634 @ 25360 updates, score 3.885) (writing took 3.759789007715881 seconds)
[2022-01-03 15:26:45,785][fairseq_cli.train][INFO] - end of epoch 634 (average epoch stats below)
[2022-01-03 15:26:45,798][train][INFO] - {"epoch": 634, "train_loss": "3.981", "train_ntokens": "1793.22", "train_nsentences": "4.95", "train_prob_perplexity": "66.081", "train_code_perplexity": "65.206", "train_temp": "1.762", "train_loss_0": "3.822", "train_loss_1": "0.129", "train_loss_2": "0.03", "train_accuracy": "0.28875", "train_wps": "3928", "train_ups": "2.19", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "25360", "train_lr": "0.00039625", "train_gnorm": "0.564", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "11823"}
[2022-01-03 15:26:45,870][fairseq.trainer][INFO] - begin training epoch 635
[2022-01-03 15:26:45,871][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:26:59,756][train_inner][INFO] - {"epoch": 635, "update": 635.0, "loss": "3.968", "ntokens": "1796.71", "nsentences": "4.95", "prob_perplexity": "65.775", "code_perplexity": "64.946", "temp": "1.762", "loss_0": "3.807", "loss_1": "0.129", "loss_2": "0.031", "accuracy": "0.29064", "wps": "3951.1", "ups": "2.2", "wpb": "1796.7", "bsz": "5", "num_updates": "25400", "lr": "0.000396875", "gnorm": "0.582", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "11837"}
[2022-01-03 15:26:59,757][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:27:00,161][valid][INFO] - {"epoch": 635, "valid_loss": "3.798", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "52.317", "valid_code_perplexity": "51.645", "valid_temp": "1.761", "valid_loss_0": "3.63", "valid_loss_1": "0.132", "valid_loss_2": "0.035", "valid_accuracy": "0.32626", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "25400", "valid_best_loss": "3.499"}
[2022-01-03 15:27:00,164][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 635 @ 25400 updates
[2022-01-03 15:27:00,165][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:27:04,100][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:27:04,102][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 635 @ 25400 updates, score 3.798) (writing took 3.937495047226548 seconds)
[2022-01-03 15:27:04,102][fairseq_cli.train][INFO] - end of epoch 635 (average epoch stats below)
[2022-01-03 15:27:04,115][train][INFO] - {"epoch": 635, "train_loss": "3.94", "train_ntokens": "1783.03", "train_nsentences": "4.95", "train_prob_perplexity": "65.861", "train_code_perplexity": "64.925", "train_temp": "1.762", "train_loss_0": "3.779", "train_loss_1": "0.129", "train_loss_2": "0.031", "train_accuracy": "0.29329", "train_wps": "3896.4", "train_ups": "2.19", "train_wpb": "1783", "train_bsz": "5", "train_num_updates": "25400", "train_lr": "0.000396875", "train_gnorm": "0.594", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11842"}
[2022-01-03 15:27:04,175][fairseq.trainer][INFO] - begin training epoch 636
[2022-01-03 15:27:04,176][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:27:17,998][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:27:18,406][valid][INFO] - {"epoch": 636, "valid_loss": "3.708", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "56.119", "valid_code_perplexity": "55.493", "valid_temp": "1.761", "valid_loss_0": "3.543", "valid_loss_1": "0.132", "valid_loss_2": "0.033", "valid_accuracy": "0.35081", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "25440", "valid_best_loss": "3.499"}
[2022-01-03 15:27:18,410][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 636 @ 25440 updates
[2022-01-03 15:27:18,411][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:27:22,385][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:27:22,416][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 636 @ 25440 updates, score 3.708) (writing took 4.0060009472072124 seconds)
[2022-01-03 15:27:22,416][fairseq_cli.train][INFO] - end of epoch 636 (average epoch stats below)
[2022-01-03 15:27:22,429][train][INFO] - {"epoch": 636, "train_loss": "3.958", "train_ntokens": "1785.08", "train_nsentences": "4.95", "train_prob_perplexity": "67.089", "train_code_perplexity": "66.033", "train_temp": "1.761", "train_loss_0": "3.797", "train_loss_1": "0.129", "train_loss_2": "0.032", "train_accuracy": "0.291", "train_wps": "3901.6", "train_ups": "2.19", "train_wpb": "1785.1", "train_bsz": "5", "train_num_updates": "25440", "train_lr": "0.0003975", "train_gnorm": "0.581", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11860"}
[2022-01-03 15:27:22,493][fairseq.trainer][INFO] - begin training epoch 637
[2022-01-03 15:27:22,493][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:27:36,369][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:27:36,762][valid][INFO] - {"epoch": 637, "valid_loss": "3.775", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "63.318", "valid_code_perplexity": "61.809", "valid_temp": "1.761", "valid_loss_0": "3.615", "valid_loss_1": "0.13", "valid_loss_2": "0.031", "valid_accuracy": "0.29644", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "25480", "valid_best_loss": "3.499"}
[2022-01-03 15:27:36,766][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 637 @ 25480 updates
[2022-01-03 15:27:36,766][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:27:40,615][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:27:40,641][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 637 @ 25480 updates, score 3.775) (writing took 3.875933007337153 seconds)
[2022-01-03 15:27:40,642][fairseq_cli.train][INFO] - end of epoch 637 (average epoch stats below)
[2022-01-03 15:27:40,655][train][INFO] - {"epoch": 637, "train_loss": "3.983", "train_ntokens": "1807.22", "train_nsentences": "4.95", "train_prob_perplexity": "66.816", "train_code_perplexity": "65.745", "train_temp": "1.761", "train_loss_0": "3.822", "train_loss_1": "0.129", "train_loss_2": "0.032", "train_accuracy": "0.28945", "train_wps": "3969.1", "train_ups": "2.2", "train_wpb": "1807.2", "train_bsz": "5", "train_num_updates": "25480", "train_lr": "0.000398125", "train_gnorm": "0.579", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "11878"}
[2022-01-03 15:27:40,720][fairseq.trainer][INFO] - begin training epoch 638
[2022-01-03 15:27:40,721][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:27:54,620][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:27:55,028][valid][INFO] - {"epoch": 638, "valid_loss": "3.809", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "59.715", "valid_code_perplexity": "58.154", "valid_temp": "1.76", "valid_loss_0": "3.646", "valid_loss_1": "0.131", "valid_loss_2": "0.032", "valid_accuracy": "0.30464", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "25520", "valid_best_loss": "3.499"}
[2022-01-03 15:27:55,032][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 638 @ 25520 updates
[2022-01-03 15:27:55,033][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:27:58,920][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:27:58,940][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 638 @ 25520 updates, score 3.809) (writing took 3.908571674488485 seconds)
[2022-01-03 15:27:58,941][fairseq_cli.train][INFO] - end of epoch 638 (average epoch stats below)
[2022-01-03 15:27:58,953][train][INFO] - {"epoch": 638, "train_loss": "3.962", "train_ntokens": "1793.2", "train_nsentences": "4.95", "train_prob_perplexity": "67.409", "train_code_perplexity": "66.274", "train_temp": "1.761", "train_loss_0": "3.803", "train_loss_1": "0.129", "train_loss_2": "0.03", "train_accuracy": "0.29061", "train_wps": "3922.6", "train_ups": "2.19", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "25520", "train_lr": "0.00039875", "train_gnorm": "0.568", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11896"}
[2022-01-03 15:27:59,004][fairseq.trainer][INFO] - begin training epoch 639
[2022-01-03 15:27:59,005][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:28:12,909][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:28:13,392][valid][INFO] - {"epoch": 639, "valid_loss": "4.06", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "58.882", "valid_code_perplexity": "58.062", "valid_temp": "1.76", "valid_loss_0": "3.902", "valid_loss_1": "0.131", "valid_loss_2": "0.028", "valid_accuracy": "0.29675", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "25560", "valid_best_loss": "3.499"}
[2022-01-03 15:28:13,394][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 639 @ 25560 updates
[2022-01-03 15:28:13,394][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:28:17,135][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:28:17,154][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 639 @ 25560 updates, score 4.06) (writing took 3.7598121454939246 seconds)
[2022-01-03 15:28:17,154][fairseq_cli.train][INFO] - end of epoch 639 (average epoch stats below)
[2022-01-03 15:28:17,166][train][INFO] - {"epoch": 639, "train_loss": "4.004", "train_ntokens": "1789.22", "train_nsentences": "4.95", "train_prob_perplexity": "67.698", "train_code_perplexity": "66.441", "train_temp": "1.76", "train_loss_0": "3.845", "train_loss_1": "0.129", "train_loss_2": "0.03", "train_accuracy": "0.28558", "train_wps": "3932.2", "train_ups": "2.2", "train_wpb": "1789.2", "train_bsz": "5", "train_num_updates": "25560", "train_lr": "0.000399375", "train_gnorm": "0.582", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11915"}
[2022-01-03 15:28:17,243][fairseq.trainer][INFO] - begin training epoch 640
[2022-01-03 15:28:17,244][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:28:31,147][train_inner][INFO] - {"epoch": 640, "update": 640.0, "loss": "3.974", "ntokens": "1793.48", "nsentences": "4.95", "prob_perplexity": "67.514", "code_perplexity": "66.361", "temp": "1.761", "loss_0": "3.815", "loss_1": "0.129", "loss_2": "0.03", "accuracy": "0.28892", "wps": "3925.4", "ups": "2.19", "wpb": "1793.5", "bsz": "5", "num_updates": "25600", "lr": "0.0004", "gnorm": "0.578", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "11929"}
[2022-01-03 15:28:31,148][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:28:31,649][valid][INFO] - {"epoch": 640, "valid_loss": "3.731", "valid_ntokens": "676", "valid_nsentences": "2", "valid_prob_perplexity": "62.458", "valid_code_perplexity": "60.781", "valid_temp": "1.76", "valid_loss_0": "3.573", "valid_loss_1": "0.13", "valid_loss_2": "0.027", "valid_accuracy": "0.31805", "valid_wps": "0", "valid_wpb": "676", "valid_bsz": "2", "valid_num_updates": "25600", "valid_best_loss": "3.499"}
[2022-01-03 15:28:31,650][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 640 @ 25600 updates
[2022-01-03 15:28:31,651][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:28:35,345][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:28:35,370][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 640 @ 25600 updates, score 3.731) (writing took 3.719867816194892 seconds)
[2022-01-03 15:28:35,371][fairseq_cli.train][INFO] - end of epoch 640 (average epoch stats below)
[2022-01-03 15:28:35,384][train][INFO] - {"epoch": 640, "train_loss": "3.965", "train_ntokens": "1792.67", "train_nsentences": "4.95", "train_prob_perplexity": "68.555", "train_code_perplexity": "67.311", "train_temp": "1.76", "train_loss_0": "3.807", "train_loss_1": "0.129", "train_loss_2": "0.029", "train_accuracy": "0.28795", "train_wps": "3939.1", "train_ups": "2.2", "train_wpb": "1792.7", "train_bsz": "5", "train_num_updates": "25600", "train_lr": "0.0004", "train_gnorm": "0.581", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "11933"}
[2022-01-03 15:28:35,444][fairseq.trainer][INFO] - begin training epoch 641
[2022-01-03 15:28:35,445][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:28:49,302][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:28:49,720][valid][INFO] - {"epoch": 641, "valid_loss": "3.803", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "64.214", "valid_code_perplexity": "63.115", "valid_temp": "1.759", "valid_loss_0": "3.642", "valid_loss_1": "0.13", "valid_loss_2": "0.031", "valid_accuracy": "0.31831", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "25640", "valid_best_loss": "3.499"}
[2022-01-03 15:28:49,723][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 641 @ 25640 updates
[2022-01-03 15:28:49,723][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:28:53,634][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:28:53,662][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 641 @ 25640 updates, score 3.803) (writing took 3.9392404351383448 seconds)
[2022-01-03 15:28:53,662][fairseq_cli.train][INFO] - end of epoch 641 (average epoch stats below)
[2022-01-03 15:28:53,675][train][INFO] - {"epoch": 641, "train_loss": "3.967", "train_ntokens": "1806.4", "train_nsentences": "4.95", "train_prob_perplexity": "68.395", "train_code_perplexity": "67.258", "train_temp": "1.76", "train_loss_0": "3.808", "train_loss_1": "0.129", "train_loss_2": "0.03", "train_accuracy": "0.28856", "train_wps": "3953", "train_ups": "2.19", "train_wpb": "1806.4", "train_bsz": "5", "train_num_updates": "25640", "train_lr": "0.000400625", "train_gnorm": "0.593", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "11951"}
[2022-01-03 15:28:53,755][fairseq.trainer][INFO] - begin training epoch 642
[2022-01-03 15:28:53,756][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:29:07,718][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:29:08,128][valid][INFO] - {"epoch": 642, "valid_loss": "3.951", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "62.92", "valid_code_perplexity": "61.355", "valid_temp": "1.759", "valid_loss_0": "3.792", "valid_loss_1": "0.13", "valid_loss_2": "0.028", "valid_accuracy": "0.31152", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "25680", "valid_best_loss": "3.499"}
[2022-01-03 15:29:08,131][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 642 @ 25680 updates
[2022-01-03 15:29:08,132][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:29:11,788][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:29:11,807][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 642 @ 25680 updates, score 3.951) (writing took 3.6759416246786714 seconds)
[2022-01-03 15:29:11,807][fairseq_cli.train][INFO] - end of epoch 642 (average epoch stats below)
[2022-01-03 15:29:11,820][train][INFO] - {"epoch": 642, "train_loss": "3.976", "train_ntokens": "1790.83", "train_nsentences": "4.95", "train_prob_perplexity": "69.477", "train_code_perplexity": "68.144", "train_temp": "1.759", "train_loss_0": "3.818", "train_loss_1": "0.129", "train_loss_2": "0.029", "train_accuracy": "0.28901", "train_wps": "3950.7", "train_ups": "2.21", "train_wpb": "1790.8", "train_bsz": "5", "train_num_updates": "25680", "train_lr": "0.00040125", "train_gnorm": "0.564", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "11969"}
[2022-01-03 15:29:11,860][fairseq.trainer][INFO] - begin training epoch 643
[2022-01-03 15:29:11,860][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:29:25,784][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:29:26,268][valid][INFO] - {"epoch": 643, "valid_loss": "3.957", "valid_ntokens": "822", "valid_nsentences": "2", "valid_prob_perplexity": "57.445", "valid_code_perplexity": "56.468", "valid_temp": "1.759", "valid_loss_0": "3.795", "valid_loss_1": "0.131", "valid_loss_2": "0.031", "valid_accuracy": "0.31509", "valid_wps": "0", "valid_wpb": "822", "valid_bsz": "2", "valid_num_updates": "25720", "valid_best_loss": "3.499"}
[2022-01-03 15:29:26,269][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 643 @ 25720 updates
[2022-01-03 15:29:26,270][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:29:30,140][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:29:30,169][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 643 @ 25720 updates, score 3.957) (writing took 3.900057532824576 seconds)
[2022-01-03 15:29:30,170][fairseq_cli.train][INFO] - end of epoch 643 (average epoch stats below)
[2022-01-03 15:29:30,182][train][INFO] - {"epoch": 643, "train_loss": "3.959", "train_ntokens": "1784.45", "train_nsentences": "4.95", "train_prob_perplexity": "69.127", "train_code_perplexity": "67.723", "train_temp": "1.759", "train_loss_0": "3.801", "train_loss_1": "0.129", "train_loss_2": "0.029", "train_accuracy": "0.29265", "train_wps": "3889.8", "train_ups": "2.18", "train_wpb": "1784.5", "train_bsz": "5", "train_num_updates": "25720", "train_lr": "0.000401875", "train_gnorm": "0.578", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "11988"}
[2022-01-03 15:29:30,240][fairseq.trainer][INFO] - begin training epoch 644
[2022-01-03 15:29:30,241][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:29:44,148][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:29:44,667][valid][INFO] - {"epoch": 644, "valid_loss": "3.906", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "59.213", "valid_code_perplexity": "57.486", "valid_temp": "1.758", "valid_loss_0": "3.742", "valid_loss_1": "0.131", "valid_loss_2": "0.032", "valid_accuracy": "0.29947", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "25760", "valid_best_loss": "3.499"}
[2022-01-03 15:29:44,669][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 644 @ 25760 updates
[2022-01-03 15:29:44,670][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:29:48,350][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:29:48,379][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 644 @ 25760 updates, score 3.906) (writing took 3.7095126463100314 seconds)
[2022-01-03 15:29:48,379][fairseq_cli.train][INFO] - end of epoch 644 (average epoch stats below)
[2022-01-03 15:29:48,392][train][INFO] - {"epoch": 644, "train_loss": "3.985", "train_ntokens": "1785.6", "train_nsentences": "4.95", "train_prob_perplexity": "69.044", "train_code_perplexity": "67.605", "train_temp": "1.758", "train_loss_0": "3.827", "train_loss_1": "0.129", "train_loss_2": "0.029", "train_accuracy": "0.28899", "train_wps": "3925", "train_ups": "2.2", "train_wpb": "1785.6", "train_bsz": "5", "train_num_updates": "25760", "train_lr": "0.0004025", "train_gnorm": "0.581", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "12006"}
[2022-01-03 15:29:48,435][fairseq.trainer][INFO] - begin training epoch 645
[2022-01-03 15:29:48,435][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:30:02,290][train_inner][INFO] - {"epoch": 645, "update": 645.0, "loss": "3.974", "ntokens": "1792.38", "nsentences": "4.95", "prob_perplexity": "69.129", "code_perplexity": "67.796", "temp": "1.759", "loss_0": "3.817", "loss_1": "0.129", "loss_2": "0.029", "accuracy": "0.28881", "wps": "3933.7", "ups": "2.19", "wpb": "1792.4", "bsz": "5", "num_updates": "25800", "lr": "0.000403125", "gnorm": "0.58", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "12020"}
[2022-01-03 15:30:02,291][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:30:02,704][valid][INFO] - {"epoch": 645, "valid_loss": "3.937", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "65.954", "valid_code_perplexity": "63.8", "valid_temp": "1.758", "valid_loss_0": "3.779", "valid_loss_1": "0.129", "valid_loss_2": "0.029", "valid_accuracy": "0.3", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "25800", "valid_best_loss": "3.499"}
[2022-01-03 15:30:02,706][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 645 @ 25800 updates
[2022-01-03 15:30:02,707][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:30:06,623][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:30:06,649][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 645 @ 25800 updates, score 3.937) (writing took 3.942897961474955 seconds)
[2022-01-03 15:30:06,650][fairseq_cli.train][INFO] - end of epoch 645 (average epoch stats below)
[2022-01-03 15:30:06,663][train][INFO] - {"epoch": 645, "train_loss": "3.986", "train_ntokens": "1794.62", "train_nsentences": "4.95", "train_prob_perplexity": "69.6", "train_code_perplexity": "68.252", "train_temp": "1.758", "train_loss_0": "3.829", "train_loss_1": "0.129", "train_loss_2": "0.028", "train_accuracy": "0.28486", "train_wps": "3931.7", "train_ups": "2.19", "train_wpb": "1794.6", "train_bsz": "5", "train_num_updates": "25800", "train_lr": "0.000403125", "train_gnorm": "0.584", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12024"}
[2022-01-03 15:30:06,716][fairseq.trainer][INFO] - begin training epoch 646
[2022-01-03 15:30:06,717][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:30:20,655][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:30:21,115][valid][INFO] - {"epoch": 646, "valid_loss": "3.593", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "65.318", "valid_code_perplexity": "63.412", "valid_temp": "1.758", "valid_loss_0": "3.437", "valid_loss_1": "0.13", "valid_loss_2": "0.027", "valid_accuracy": "0.32051", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "25840", "valid_best_loss": "3.499"}
[2022-01-03 15:30:21,117][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 646 @ 25840 updates
[2022-01-03 15:30:21,118][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:30:24,796][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:30:24,825][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 646 @ 25840 updates, score 3.593) (writing took 3.707539388909936 seconds)
[2022-01-03 15:30:24,825][fairseq_cli.train][INFO] - end of epoch 646 (average epoch stats below)
[2022-01-03 15:30:24,838][train][INFO] - {"epoch": 646, "train_loss": "3.985", "train_ntokens": "1784", "train_nsentences": "4.95", "train_prob_perplexity": "70.49", "train_code_perplexity": "69.021", "train_temp": "1.758", "train_loss_0": "3.83", "train_loss_1": "0.128", "train_loss_2": "0.027", "train_accuracy": "0.2843", "train_wps": "3929", "train_ups": "2.2", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "25840", "train_lr": "0.00040375", "train_gnorm": "0.59", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "12042"}
[2022-01-03 15:30:24,917][fairseq.trainer][INFO] - begin training epoch 647
[2022-01-03 15:30:24,918][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:30:38,817][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:30:39,230][valid][INFO] - {"epoch": 647, "valid_loss": "3.775", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "64.204", "valid_code_perplexity": "62.271", "valid_temp": "1.757", "valid_loss_0": "3.62", "valid_loss_1": "0.13", "valid_loss_2": "0.025", "valid_accuracy": "0.29443", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "25880", "valid_best_loss": "3.499"}
[2022-01-03 15:30:39,234][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 647 @ 25880 updates
[2022-01-03 15:30:39,235][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:30:43,059][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:30:43,085][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 647 @ 25880 updates, score 3.775) (writing took 3.850735191255808 seconds)
[2022-01-03 15:30:43,085][fairseq_cli.train][INFO] - end of epoch 647 (average epoch stats below)
[2022-01-03 15:30:43,098][train][INFO] - {"epoch": 647, "train_loss": "4.01", "train_ntokens": "1790.85", "train_nsentences": "4.95", "train_prob_perplexity": "70.387", "train_code_perplexity": "68.912", "train_temp": "1.757", "train_loss_0": "3.854", "train_loss_1": "0.128", "train_loss_2": "0.027", "train_accuracy": "0.2804", "train_wps": "3925.8", "train_ups": "2.19", "train_wpb": "1790.8", "train_bsz": "5", "train_num_updates": "25880", "train_lr": "0.000404375", "train_gnorm": "0.595", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12060"}
[2022-01-03 15:30:43,167][fairseq.trainer][INFO] - begin training epoch 648
[2022-01-03 15:30:43,168][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:30:56,958][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:30:57,394][valid][INFO] - {"epoch": 648, "valid_loss": "3.704", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "64.962", "valid_code_perplexity": "63.13", "valid_temp": "1.757", "valid_loss_0": "3.546", "valid_loss_1": "0.13", "valid_loss_2": "0.028", "valid_accuracy": "0.31635", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "25920", "valid_best_loss": "3.499"}
[2022-01-03 15:30:57,396][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 648 @ 25920 updates
[2022-01-03 15:30:57,397][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:31:01,306][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:31:01,331][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 648 @ 25920 updates, score 3.704) (writing took 3.935401549562812 seconds)
[2022-01-03 15:31:01,332][fairseq_cli.train][INFO] - end of epoch 648 (average epoch stats below)
[2022-01-03 15:31:01,346][train][INFO] - {"epoch": 648, "train_loss": "3.998", "train_ntokens": "1787.65", "train_nsentences": "4.95", "train_prob_perplexity": "70.722", "train_code_perplexity": "69.211", "train_temp": "1.757", "train_loss_0": "3.842", "train_loss_1": "0.128", "train_loss_2": "0.027", "train_accuracy": "0.28473", "train_wps": "3921.6", "train_ups": "2.19", "train_wpb": "1787.7", "train_bsz": "5", "train_num_updates": "25920", "train_lr": "0.000405", "train_gnorm": "0.567", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "12079"}
[2022-01-03 15:31:01,411][fairseq.trainer][INFO] - begin training epoch 649
[2022-01-03 15:31:01,412][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:31:15,315][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:31:15,797][valid][INFO] - {"epoch": 649, "valid_loss": "4.141", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "68.535", "valid_code_perplexity": "67.09", "valid_temp": "1.757", "valid_loss_0": "3.986", "valid_loss_1": "0.129", "valid_loss_2": "0.027", "valid_accuracy": "0.26501", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "25960", "valid_best_loss": "3.499"}
[2022-01-03 15:31:15,799][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 649 @ 25960 updates
[2022-01-03 15:31:15,800][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:31:19,516][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:31:19,546][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 649 @ 25960 updates, score 4.141) (writing took 3.7466345904394984 seconds)
[2022-01-03 15:31:19,546][fairseq_cli.train][INFO] - end of epoch 649 (average epoch stats below)
[2022-01-03 15:31:19,559][train][INFO] - {"epoch": 649, "train_loss": "3.99", "train_ntokens": "1795.28", "train_nsentences": "4.95", "train_prob_perplexity": "71.493", "train_code_perplexity": "70.019", "train_temp": "1.757", "train_loss_0": "3.835", "train_loss_1": "0.128", "train_loss_2": "0.027", "train_accuracy": "0.28505", "train_wps": "3945.6", "train_ups": "2.2", "train_wpb": "1795.3", "train_bsz": "5", "train_num_updates": "25960", "train_lr": "0.000405625", "train_gnorm": "0.563", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12097"}
[2022-01-03 15:31:19,637][fairseq.trainer][INFO] - begin training epoch 650
[2022-01-03 15:31:19,638][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:31:33,418][train_inner][INFO] - {"epoch": 650, "update": 650.0, "loss": "3.991", "ntokens": "1789.32", "nsentences": "4.95", "prob_perplexity": "71", "code_perplexity": "69.494", "temp": "1.757", "loss_0": "3.835", "loss_1": "0.128", "loss_2": "0.027", "accuracy": "0.28424", "wps": "3927.6", "ups": "2.2", "wpb": "1789.3", "bsz": "5", "num_updates": "26000", "lr": "0.00040625", "gnorm": "0.579", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "12111"}
[2022-01-03 15:31:33,419][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:31:33,830][valid][INFO] - {"epoch": 650, "valid_loss": "3.9", "valid_ntokens": "696", "valid_nsentences": "2", "valid_prob_perplexity": "68.081", "valid_code_perplexity": "67.084", "valid_temp": "1.756", "valid_loss_0": "3.745", "valid_loss_1": "0.129", "valid_loss_2": "0.026", "valid_accuracy": "0.29454", "valid_wps": "0", "valid_wpb": "696", "valid_bsz": "2", "valid_num_updates": "26000", "valid_best_loss": "3.499"}
[2022-01-03 15:31:33,834][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 650 @ 26000 updates
[2022-01-03 15:31:33,834][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:31:37,793][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:31:37,822][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 650 @ 26000 updates, score 3.9) (writing took 3.9880986949428916 seconds)
[2022-01-03 15:31:37,822][fairseq_cli.train][INFO] - end of epoch 650 (average epoch stats below)
[2022-01-03 15:31:37,836][train][INFO] - {"epoch": 650, "train_loss": "3.97", "train_ntokens": "1788.83", "train_nsentences": "4.95", "train_prob_perplexity": "71.909", "train_code_perplexity": "70.306", "train_temp": "1.756", "train_loss_0": "3.815", "train_loss_1": "0.128", "train_loss_2": "0.028", "train_accuracy": "0.28671", "train_wps": "3917.8", "train_ups": "2.19", "train_wpb": "1788.8", "train_bsz": "5", "train_num_updates": "26000", "train_lr": "0.00040625", "train_gnorm": "0.582", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "12115"}
[2022-01-03 15:31:37,902][fairseq.trainer][INFO] - begin training epoch 651
[2022-01-03 15:31:37,903][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:31:51,835][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:31:52,241][valid][INFO] - {"epoch": 651, "valid_loss": "3.722", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "66.737", "valid_code_perplexity": "65.152", "valid_temp": "1.756", "valid_loss_0": "3.564", "valid_loss_1": "0.129", "valid_loss_2": "0.029", "valid_accuracy": "0.32609", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "26040", "valid_best_loss": "3.499"}
[2022-01-03 15:31:52,244][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 651 @ 26040 updates
[2022-01-03 15:31:52,245][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:31:55,993][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:31:56,021][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 651 @ 26040 updates, score 3.722) (writing took 3.776629419066012 seconds)
[2022-01-03 15:31:56,022][fairseq_cli.train][INFO] - end of epoch 651 (average epoch stats below)
[2022-01-03 15:31:56,034][train][INFO] - {"epoch": 651, "train_loss": "3.949", "train_ntokens": "1788.78", "train_nsentences": "4.95", "train_prob_perplexity": "72.354", "train_code_perplexity": "70.578", "train_temp": "1.756", "train_loss_0": "3.794", "train_loss_1": "0.128", "train_loss_2": "0.027", "train_accuracy": "0.29038", "train_wps": "3934.6", "train_ups": "2.2", "train_wpb": "1788.8", "train_bsz": "5", "train_num_updates": "26040", "train_lr": "0.000406875", "train_gnorm": "0.562", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "12133"}
[2022-01-03 15:31:56,093][fairseq.trainer][INFO] - begin training epoch 652
[2022-01-03 15:31:56,094][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:32:09,973][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:32:10,381][valid][INFO] - {"epoch": 652, "valid_loss": "3.907", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "66.948", "valid_code_perplexity": "65.183", "valid_temp": "1.755", "valid_loss_0": "3.752", "valid_loss_1": "0.129", "valid_loss_2": "0.026", "valid_accuracy": "0.27885", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "26080", "valid_best_loss": "3.499"}
[2022-01-03 15:32:10,385][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 652 @ 26080 updates
[2022-01-03 15:32:10,387][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:32:14,257][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:32:14,284][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 652 @ 26080 updates, score 3.907) (writing took 3.899226823821664 seconds)
[2022-01-03 15:32:14,285][fairseq_cli.train][INFO] - end of epoch 652 (average epoch stats below)
[2022-01-03 15:32:14,297][train][INFO] - {"epoch": 652, "train_loss": "3.978", "train_ntokens": "1785.6", "train_nsentences": "4.95", "train_prob_perplexity": "73.503", "train_code_perplexity": "71.832", "train_temp": "1.756", "train_loss_0": "3.824", "train_loss_1": "0.128", "train_loss_2": "0.026", "train_accuracy": "0.28335", "train_wps": "3913.5", "train_ups": "2.19", "train_wpb": "1785.6", "train_bsz": "5", "train_num_updates": "26080", "train_lr": "0.0004075", "train_gnorm": "0.557", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12152"}
[2022-01-03 15:32:14,369][fairseq.trainer][INFO] - begin training epoch 653
[2022-01-03 15:32:14,369][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:32:28,248][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:32:28,640][valid][INFO] - {"epoch": 653, "valid_loss": "3.752", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "67.898", "valid_code_perplexity": "64.728", "valid_temp": "1.755", "valid_loss_0": "3.596", "valid_loss_1": "0.129", "valid_loss_2": "0.027", "valid_accuracy": "0.2942", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "26120", "valid_best_loss": "3.499"}
[2022-01-03 15:32:28,643][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 653 @ 26120 updates
[2022-01-03 15:32:28,644][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:32:32,481][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:32:32,508][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 653 @ 26120 updates, score 3.752) (writing took 3.8649567468091846 seconds)
[2022-01-03 15:32:32,509][fairseq_cli.train][INFO] - end of epoch 653 (average epoch stats below)
[2022-01-03 15:32:32,521][train][INFO] - {"epoch": 653, "train_loss": "3.98", "train_ntokens": "1779.88", "train_nsentences": "4.95", "train_prob_perplexity": "73.584", "train_code_perplexity": "71.904", "train_temp": "1.755", "train_loss_0": "3.828", "train_loss_1": "0.128", "train_loss_2": "0.025", "train_accuracy": "0.28371", "train_wps": "3909.4", "train_ups": "2.2", "train_wpb": "1779.9", "train_bsz": "5", "train_num_updates": "26120", "train_lr": "0.000408125", "train_gnorm": "0.573", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12170"}
[2022-01-03 15:32:32,593][fairseq.trainer][INFO] - begin training epoch 654
[2022-01-03 15:32:32,593][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:32:46,479][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:32:46,881][valid][INFO] - {"epoch": 654, "valid_loss": "4.04", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "57.692", "valid_code_perplexity": "56.181", "valid_temp": "1.755", "valid_loss_0": "3.882", "valid_loss_1": "0.131", "valid_loss_2": "0.027", "valid_accuracy": "0.29288", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "26160", "valid_best_loss": "3.499"}
[2022-01-03 15:32:46,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 654 @ 26160 updates
[2022-01-03 15:32:46,885][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:32:50,749][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:32:50,778][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 654 @ 26160 updates, score 4.04) (writing took 3.8936420595273376 seconds)
[2022-01-03 15:32:50,778][fairseq_cli.train][INFO] - end of epoch 654 (average epoch stats below)
[2022-01-03 15:32:50,791][train][INFO] - {"epoch": 654, "train_loss": "3.992", "train_ntokens": "1792.6", "train_nsentences": "4.95", "train_prob_perplexity": "73.839", "train_code_perplexity": "72.043", "train_temp": "1.755", "train_loss_0": "3.839", "train_loss_1": "0.128", "train_loss_2": "0.026", "train_accuracy": "0.28452", "train_wps": "3927.4", "train_ups": "2.19", "train_wpb": "1792.6", "train_bsz": "5", "train_num_updates": "26160", "train_lr": "0.00040875", "train_gnorm": "0.562", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "10.2", "train_wall": "12188"}
[2022-01-03 15:32:50,869][fairseq.trainer][INFO] - begin training epoch 655
[2022-01-03 15:32:50,870][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:33:04,727][train_inner][INFO] - {"epoch": 655, "update": 655.0, "loss": "3.977", "ntokens": "1787.57", "nsentences": "4.95", "prob_perplexity": "73.368", "code_perplexity": "71.65", "temp": "1.755", "loss_0": "3.824", "loss_1": "0.128", "loss_2": "0.026", "accuracy": "0.28485", "wps": "3916", "ups": "2.19", "wpb": "1787.6", "bsz": "5", "num_updates": "26200", "lr": "0.000409375", "gnorm": "0.565", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "12202"}
[2022-01-03 15:33:04,728][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:33:05,134][valid][INFO] - {"epoch": 655, "valid_loss": "4.208", "valid_ntokens": "706", "valid_nsentences": "2", "valid_prob_perplexity": "71.353", "valid_code_perplexity": "70.074", "valid_temp": "1.754", "valid_loss_0": "4.056", "valid_loss_1": "0.128", "valid_loss_2": "0.024", "valid_accuracy": "0.26346", "valid_wps": "0", "valid_wpb": "706", "valid_bsz": "2", "valid_num_updates": "26200", "valid_best_loss": "3.499"}
[2022-01-03 15:33:05,138][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 655 @ 26200 updates
[2022-01-03 15:33:05,139][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:33:08,973][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:33:09,001][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 655 @ 26200 updates, score 4.208) (writing took 3.8627583561465144 seconds)
[2022-01-03 15:33:09,001][fairseq_cli.train][INFO] - end of epoch 655 (average epoch stats below)
[2022-01-03 15:33:09,014][train][INFO] - {"epoch": 655, "train_loss": "3.986", "train_ntokens": "1791", "train_nsentences": "4.95", "train_prob_perplexity": "73.56", "train_code_perplexity": "71.893", "train_temp": "1.755", "train_loss_0": "3.834", "train_loss_1": "0.128", "train_loss_2": "0.025", "train_accuracy": "0.28229", "train_wps": "3934.1", "train_ups": "2.2", "train_wpb": "1791", "train_bsz": "5", "train_num_updates": "26200", "train_lr": "0.000409375", "train_gnorm": "0.569", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12206"}
[2022-01-03 15:33:09,064][fairseq.trainer][INFO] - begin training epoch 656
[2022-01-03 15:33:09,065][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:33:22,890][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:33:23,293][valid][INFO] - {"epoch": 656, "valid_loss": "3.913", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "65.5", "valid_code_perplexity": "63.101", "valid_temp": "1.754", "valid_loss_0": "3.758", "valid_loss_1": "0.13", "valid_loss_2": "0.025", "valid_accuracy": "0.29245", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "26240", "valid_best_loss": "3.499"}
[2022-01-03 15:33:23,296][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 656 @ 26240 updates
[2022-01-03 15:33:23,297][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:33:27,359][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:33:27,387][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 656 @ 26240 updates, score 3.913) (writing took 4.090100634843111 seconds)
[2022-01-03 15:33:27,387][fairseq_cli.train][INFO] - end of epoch 656 (average epoch stats below)
[2022-01-03 15:33:27,399][train][INFO] - {"epoch": 656, "train_loss": "3.945", "train_ntokens": "1786.35", "train_nsentences": "4.95", "train_prob_perplexity": "74.534", "train_code_perplexity": "72.88", "train_temp": "1.754", "train_loss_0": "3.792", "train_loss_1": "0.127", "train_loss_2": "0.025", "train_accuracy": "0.28875", "train_wps": "3889.2", "train_ups": "2.18", "train_wpb": "1786.3", "train_bsz": "5", "train_num_updates": "26240", "train_lr": "0.00041", "train_gnorm": "0.567", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12225"}
[2022-01-03 15:33:27,474][fairseq.trainer][INFO] - begin training epoch 657
[2022-01-03 15:33:27,475][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:33:41,290][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:33:41,708][valid][INFO] - {"epoch": 657, "valid_loss": "3.662", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "69.134", "valid_code_perplexity": "66.396", "valid_temp": "1.754", "valid_loss_0": "3.509", "valid_loss_1": "0.129", "valid_loss_2": "0.024", "valid_accuracy": "0.3356", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "26280", "valid_best_loss": "3.499"}
[2022-01-03 15:33:41,712][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 657 @ 26280 updates
[2022-01-03 15:33:41,714][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:33:45,651][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:33:45,670][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 657 @ 26280 updates, score 3.662) (writing took 3.9571467423811555 seconds)
[2022-01-03 15:33:45,670][fairseq_cli.train][INFO] - end of epoch 657 (average epoch stats below)
[2022-01-03 15:33:45,682][train][INFO] - {"epoch": 657, "train_loss": "4.013", "train_ntokens": "1786.62", "train_nsentences": "4.95", "train_prob_perplexity": "74.674", "train_code_perplexity": "72.884", "train_temp": "1.754", "train_loss_0": "3.861", "train_loss_1": "0.127", "train_loss_2": "0.024", "train_accuracy": "0.28015", "train_wps": "3911.5", "train_ups": "2.19", "train_wpb": "1786.6", "train_bsz": "5", "train_num_updates": "26280", "train_lr": "0.000410625", "train_gnorm": "0.566", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12243"}
[2022-01-03 15:33:45,730][fairseq.trainer][INFO] - begin training epoch 658
[2022-01-03 15:33:45,731][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:33:59,606][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:34:00,005][valid][INFO] - {"epoch": 658, "valid_loss": "4.001", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "68.797", "valid_code_perplexity": "66.517", "valid_temp": "1.753", "valid_loss_0": "3.849", "valid_loss_1": "0.129", "valid_loss_2": "0.023", "valid_accuracy": "0.29795", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "26320", "valid_best_loss": "3.499"}
[2022-01-03 15:34:00,009][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 658 @ 26320 updates
[2022-01-03 15:34:00,010][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:34:03,970][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:34:03,999][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 658 @ 26320 updates, score 4.001) (writing took 3.989649728871882 seconds)
[2022-01-03 15:34:03,999][fairseq_cli.train][INFO] - end of epoch 658 (average epoch stats below)
[2022-01-03 15:34:04,011][train][INFO] - {"epoch": 658, "train_loss": "3.99", "train_ntokens": "1801.55", "train_nsentences": "4.95", "train_prob_perplexity": "75.409", "train_code_perplexity": "73.587", "train_temp": "1.754", "train_loss_0": "3.838", "train_loss_1": "0.127", "train_loss_2": "0.024", "train_accuracy": "0.28403", "train_wps": "3934.1", "train_ups": "2.18", "train_wpb": "1801.5", "train_bsz": "5", "train_num_updates": "26320", "train_lr": "0.00041125", "train_gnorm": "0.571", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.4", "train_wall": "12261"}
[2022-01-03 15:34:04,069][fairseq.trainer][INFO] - begin training epoch 659
[2022-01-03 15:34:04,070][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:34:17,957][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:34:18,360][valid][INFO] - {"epoch": 659, "valid_loss": "3.961", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "73.96", "valid_code_perplexity": "72.236", "valid_temp": "1.753", "valid_loss_0": "3.811", "valid_loss_1": "0.128", "valid_loss_2": "0.023", "valid_accuracy": "0.29752", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "26360", "valid_best_loss": "3.499"}
[2022-01-03 15:34:18,363][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 659 @ 26360 updates
[2022-01-03 15:34:18,364][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:34:22,322][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:34:22,352][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 659 @ 26360 updates, score 3.961) (writing took 3.988432086072862 seconds)
[2022-01-03 15:34:22,352][fairseq_cli.train][INFO] - end of epoch 659 (average epoch stats below)
[2022-01-03 15:34:22,365][train][INFO] - {"epoch": 659, "train_loss": "3.983", "train_ntokens": "1798.72", "train_nsentences": "4.95", "train_prob_perplexity": "75.661", "train_code_perplexity": "73.908", "train_temp": "1.753", "train_loss_0": "3.832", "train_loss_1": "0.127", "train_loss_2": "0.023", "train_accuracy": "0.28276", "train_wps": "3922.9", "train_ups": "2.18", "train_wpb": "1798.7", "train_bsz": "5", "train_num_updates": "26360", "train_lr": "0.000411875", "train_gnorm": "0.576", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "12280"}
[2022-01-03 15:34:22,426][fairseq.trainer][INFO] - begin training epoch 660
[2022-01-03 15:34:22,426][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:34:36,197][train_inner][INFO] - {"epoch": 660, "update": 660.0, "loss": "3.972", "ntokens": "1795.87", "nsentences": "4.95", "prob_perplexity": "75.222", "code_perplexity": "73.463", "temp": "1.754", "loss_0": "3.821", "loss_1": "0.127", "loss_2": "0.024", "accuracy": "0.2847", "wps": "3927.2", "ups": "2.19", "wpb": "1795.9", "bsz": "5", "num_updates": "26400", "lr": "0.0004125", "gnorm": "0.569", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "12294"}
[2022-01-03 15:34:36,198][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:34:36,608][valid][INFO] - {"epoch": 660, "valid_loss": "4.027", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "73.615", "valid_code_perplexity": "71.445", "valid_temp": "1.753", "valid_loss_0": "3.875", "valid_loss_1": "0.128", "valid_loss_2": "0.025", "valid_accuracy": "0.29028", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "26400", "valid_best_loss": "3.499"}
[2022-01-03 15:34:36,611][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 660 @ 26400 updates
[2022-01-03 15:34:36,611][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:34:40,577][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:34:40,601][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 660 @ 26400 updates, score 4.027) (writing took 3.9902997883036733 seconds)
[2022-01-03 15:34:40,602][fairseq_cli.train][INFO] - end of epoch 660 (average epoch stats below)
[2022-01-03 15:34:40,614][train][INFO] - {"epoch": 660, "train_loss": "3.932", "train_ntokens": "1806.1", "train_nsentences": "4.95", "train_prob_perplexity": "75.831", "train_code_perplexity": "74.059", "train_temp": "1.753", "train_loss_0": "3.781", "train_loss_1": "0.127", "train_loss_2": "0.023", "train_accuracy": "0.28782", "train_wps": "3961.5", "train_ups": "2.19", "train_wpb": "1806.1", "train_bsz": "5", "train_num_updates": "26400", "train_lr": "0.0004125", "train_gnorm": "0.563", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12298"}
[2022-01-03 15:34:40,665][fairseq.trainer][INFO] - begin training epoch 661
[2022-01-03 15:34:40,666][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:34:54,500][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:34:54,958][valid][INFO] - {"epoch": 661, "valid_loss": "3.959", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "62.767", "valid_code_perplexity": "60.34", "valid_temp": "1.752", "valid_loss_0": "3.805", "valid_loss_1": "0.13", "valid_loss_2": "0.023", "valid_accuracy": "0.31558", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "26440", "valid_best_loss": "3.499"}
[2022-01-03 15:34:54,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 661 @ 26440 updates
[2022-01-03 15:34:54,960][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:34:58,740][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:34:58,769][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 661 @ 26440 updates, score 3.959) (writing took 3.8087920574471354 seconds)
[2022-01-03 15:34:58,769][fairseq_cli.train][INFO] - end of epoch 661 (average epoch stats below)
[2022-01-03 15:34:58,782][train][INFO] - {"epoch": 661, "train_loss": "3.974", "train_ntokens": "1799.78", "train_nsentences": "4.95", "train_prob_perplexity": "76.067", "train_code_perplexity": "74.344", "train_temp": "1.753", "train_loss_0": "3.824", "train_loss_1": "0.127", "train_loss_2": "0.023", "train_accuracy": "0.28305", "train_wps": "3965.4", "train_ups": "2.2", "train_wpb": "1799.8", "train_bsz": "5", "train_num_updates": "26440", "train_lr": "0.000413125", "train_gnorm": "0.569", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12316"}
[2022-01-03 15:34:58,859][fairseq.trainer][INFO] - begin training epoch 662
[2022-01-03 15:34:58,860][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:35:12,710][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:35:13,118][valid][INFO] - {"epoch": 662, "valid_loss": "3.637", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "74.863", "valid_code_perplexity": "72.295", "valid_temp": "1.752", "valid_loss_0": "3.485", "valid_loss_1": "0.127", "valid_loss_2": "0.024", "valid_accuracy": "0.34861", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "26480", "valid_best_loss": "3.499"}
[2022-01-03 15:35:13,121][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 662 @ 26480 updates
[2022-01-03 15:35:13,121][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:35:17,082][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:35:17,115][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 662 @ 26480 updates, score 3.637) (writing took 3.9942808458581567 seconds)
[2022-01-03 15:35:17,116][fairseq_cli.train][INFO] - end of epoch 662 (average epoch stats below)
[2022-01-03 15:35:17,129][train][INFO] - {"epoch": 662, "train_loss": "3.957", "train_ntokens": "1794.25", "train_nsentences": "4.95", "train_prob_perplexity": "76.245", "train_code_perplexity": "74.608", "train_temp": "1.752", "train_loss_0": "3.806", "train_loss_1": "0.127", "train_loss_2": "0.024", "train_accuracy": "0.28845", "train_wps": "3914.6", "train_ups": "2.18", "train_wpb": "1794.2", "train_bsz": "5", "train_num_updates": "26480", "train_lr": "0.00041375", "train_gnorm": "0.58", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "12335"}
[2022-01-03 15:35:17,213][fairseq.trainer][INFO] - begin training epoch 663
[2022-01-03 15:35:17,214][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:35:31,084][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:35:31,582][valid][INFO] - {"epoch": 663, "valid_loss": "3.727", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "73.564", "valid_code_perplexity": "71.979", "valid_temp": "1.752", "valid_loss_0": "3.579", "valid_loss_1": "0.128", "valid_loss_2": "0.02", "valid_accuracy": "0.31135", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "26520", "valid_best_loss": "3.499"}
[2022-01-03 15:35:31,584][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 663 @ 26520 updates
[2022-01-03 15:35:31,585][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:35:35,230][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:35:35,251][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 663 @ 26520 updates, score 3.727) (writing took 3.6668636687099934 seconds)
[2022-01-03 15:35:35,251][fairseq_cli.train][INFO] - end of epoch 663 (average epoch stats below)
[2022-01-03 15:35:35,264][train][INFO] - {"epoch": 663, "train_loss": "3.975", "train_ntokens": "1799.83", "train_nsentences": "4.95", "train_prob_perplexity": "77.23", "train_code_perplexity": "75.503", "train_temp": "1.752", "train_loss_0": "3.825", "train_loss_1": "0.127", "train_loss_2": "0.023", "train_accuracy": "0.28585", "train_wps": "3972.7", "train_ups": "2.21", "train_wpb": "1799.8", "train_bsz": "5", "train_num_updates": "26520", "train_lr": "0.000414375", "train_gnorm": "0.561", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12353"}
[2022-01-03 15:35:35,307][fairseq.trainer][INFO] - begin training epoch 664
[2022-01-03 15:35:35,307][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:35:49,327][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:35:49,735][valid][INFO] - {"epoch": 664, "valid_loss": "3.585", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "70.624", "valid_code_perplexity": "68.037", "valid_temp": "1.751", "valid_loss_0": "3.434", "valid_loss_1": "0.128", "valid_loss_2": "0.022", "valid_accuracy": "0.32967", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "26560", "valid_best_loss": "3.499"}
[2022-01-03 15:35:49,737][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 664 @ 26560 updates
[2022-01-03 15:35:49,738][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:35:53,523][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:35:53,536][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 664 @ 26560 updates, score 3.585) (writing took 3.7986105903983116 seconds)
[2022-01-03 15:35:53,536][fairseq_cli.train][INFO] - end of epoch 664 (average epoch stats below)
[2022-01-03 15:35:53,550][train][INFO] - {"epoch": 664, "train_loss": "3.979", "train_ntokens": "1798.85", "train_nsentences": "4.95", "train_prob_perplexity": "77.585", "train_code_perplexity": "75.879", "train_temp": "1.751", "train_loss_0": "3.83", "train_loss_1": "0.127", "train_loss_2": "0.022", "train_accuracy": "0.28489", "train_wps": "3937.9", "train_ups": "2.19", "train_wpb": "1798.8", "train_bsz": "5", "train_num_updates": "26560", "train_lr": "0.000415", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "12371"}
[2022-01-03 15:35:53,623][fairseq.trainer][INFO] - begin training epoch 665
[2022-01-03 15:35:53,624][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:36:07,485][train_inner][INFO] - {"epoch": 665, "update": 665.0, "loss": "3.974", "ntokens": "1798.23", "nsentences": "4.95", "prob_perplexity": "76.818", "code_perplexity": "75.112", "temp": "1.752", "loss_0": "3.824", "loss_1": "0.127", "loss_2": "0.023", "accuracy": "0.28487", "wps": "3940.2", "ups": "2.19", "wpb": "1798.2", "bsz": "5", "num_updates": "26600", "lr": "0.000415625", "gnorm": "0.559", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "12385"}
[2022-01-03 15:36:07,486][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:36:07,888][valid][INFO] - {"epoch": 665, "valid_loss": "4.01", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "74.187", "valid_code_perplexity": "72.126", "valid_temp": "1.751", "valid_loss_0": "3.861", "valid_loss_1": "0.128", "valid_loss_2": "0.022", "valid_accuracy": "0.27226", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "26600", "valid_best_loss": "3.499"}
[2022-01-03 15:36:07,891][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 665 @ 26600 updates
[2022-01-03 15:36:07,892][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:36:11,849][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:36:11,877][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 665 @ 26600 updates, score 4.01) (writing took 3.9858679957687855 seconds)
[2022-01-03 15:36:11,877][fairseq_cli.train][INFO] - end of epoch 665 (average epoch stats below)
[2022-01-03 15:36:11,890][train][INFO] - {"epoch": 665, "train_loss": "3.986", "train_ntokens": "1798.47", "train_nsentences": "4.95", "train_prob_perplexity": "76.963", "train_code_perplexity": "75.229", "train_temp": "1.751", "train_loss_0": "3.837", "train_loss_1": "0.127", "train_loss_2": "0.022", "train_accuracy": "0.28211", "train_wps": "3925.2", "train_ups": "2.18", "train_wpb": "1798.5", "train_bsz": "5", "train_num_updates": "26600", "train_lr": "0.000415625", "train_gnorm": "0.547", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12389"}
[2022-01-03 15:36:11,969][fairseq.trainer][INFO] - begin training epoch 666
[2022-01-03 15:36:11,970][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:36:25,783][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:36:26,183][valid][INFO] - {"epoch": 666, "valid_loss": "3.806", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "74.362", "valid_code_perplexity": "72.265", "valid_temp": "1.751", "valid_loss_0": "3.658", "valid_loss_1": "0.128", "valid_loss_2": "0.02", "valid_accuracy": "0.28324", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "26640", "valid_best_loss": "3.499"}
[2022-01-03 15:36:26,186][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 666 @ 26640 updates
[2022-01-03 15:36:26,187][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:36:30,145][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:36:30,173][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 666 @ 26640 updates, score 3.806) (writing took 3.98650630004704 seconds)
[2022-01-03 15:36:30,173][fairseq_cli.train][INFO] - end of epoch 666 (average epoch stats below)
[2022-01-03 15:36:30,186][train][INFO] - {"epoch": 666, "train_loss": "3.946", "train_ntokens": "1792.1", "train_nsentences": "4.95", "train_prob_perplexity": "78.672", "train_code_perplexity": "76.997", "train_temp": "1.751", "train_loss_0": "3.797", "train_loss_1": "0.127", "train_loss_2": "0.022", "train_accuracy": "0.28609", "train_wps": "3920.7", "train_ups": "2.19", "train_wpb": "1792.1", "train_bsz": "5", "train_num_updates": "26640", "train_lr": "0.00041625", "train_gnorm": "0.574", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12408"}
[2022-01-03 15:36:30,258][fairseq.trainer][INFO] - begin training epoch 667
[2022-01-03 15:36:30,259][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:36:44,140][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:36:44,555][valid][INFO] - {"epoch": 667, "valid_loss": "3.883", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "72.579", "valid_code_perplexity": "69.647", "valid_temp": "1.75", "valid_loss_0": "3.732", "valid_loss_1": "0.128", "valid_loss_2": "0.023", "valid_accuracy": "0.30084", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "26680", "valid_best_loss": "3.499"}
[2022-01-03 15:36:44,559][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 667 @ 26680 updates
[2022-01-03 15:36:44,560][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:36:48,377][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:36:48,406][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 667 @ 26680 updates, score 3.883) (writing took 3.847199860960245 seconds)
[2022-01-03 15:36:48,406][fairseq_cli.train][INFO] - end of epoch 667 (average epoch stats below)
[2022-01-03 15:36:48,419][train][INFO] - {"epoch": 667, "train_loss": "3.931", "train_ntokens": "1790.42", "train_nsentences": "4.95", "train_prob_perplexity": "76.891", "train_code_perplexity": "75.093", "train_temp": "1.75", "train_loss_0": "3.782", "train_loss_1": "0.127", "train_loss_2": "0.022", "train_accuracy": "0.29048", "train_wps": "3930.6", "train_ups": "2.2", "train_wpb": "1790.4", "train_bsz": "5", "train_num_updates": "26680", "train_lr": "0.000416875", "train_gnorm": "0.557", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12426"}
[2022-01-03 15:36:48,497][fairseq.trainer][INFO] - begin training epoch 668
[2022-01-03 15:36:48,498][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:37:02,365][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:37:02,766][valid][INFO] - {"epoch": 668, "valid_loss": "3.732", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "69.8", "valid_code_perplexity": "67.642", "valid_temp": "1.75", "valid_loss_0": "3.582", "valid_loss_1": "0.129", "valid_loss_2": "0.021", "valid_accuracy": "0.3033", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "26720", "valid_best_loss": "3.499"}
[2022-01-03 15:37:02,769][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 668 @ 26720 updates
[2022-01-03 15:37:02,770][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:37:06,596][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:37:06,621][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 668 @ 26720 updates, score 3.732) (writing took 3.8511631079018116 seconds)
[2022-01-03 15:37:06,621][fairseq_cli.train][INFO] - end of epoch 668 (average epoch stats below)
[2022-01-03 15:37:06,635][train][INFO] - {"epoch": 668, "train_loss": "3.968", "train_ntokens": "1798.22", "train_nsentences": "4.95", "train_prob_perplexity": "78.658", "train_code_perplexity": "76.944", "train_temp": "1.75", "train_loss_0": "3.819", "train_loss_1": "0.127", "train_loss_2": "0.023", "train_accuracy": "0.28296", "train_wps": "3951.8", "train_ups": "2.2", "train_wpb": "1798.2", "train_bsz": "5", "train_num_updates": "26720", "train_lr": "0.0004175", "train_gnorm": "0.558", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "12444"}
[2022-01-03 15:37:06,705][fairseq.trainer][INFO] - begin training epoch 669
[2022-01-03 15:37:06,706][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:37:20,686][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:37:21,116][valid][INFO] - {"epoch": 669, "valid_loss": "3.973", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "76.537", "valid_code_perplexity": "74.87", "valid_temp": "1.75", "valid_loss_0": "3.823", "valid_loss_1": "0.127", "valid_loss_2": "0.022", "valid_accuracy": "0.30252", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "26760", "valid_best_loss": "3.499"}
[2022-01-03 15:37:21,119][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 669 @ 26760 updates
[2022-01-03 15:37:21,119][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:37:24,860][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:37:24,887][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 669 @ 26760 updates, score 3.973) (writing took 3.7687485748901963 seconds)
[2022-01-03 15:37:24,888][fairseq_cli.train][INFO] - end of epoch 669 (average epoch stats below)
[2022-01-03 15:37:24,901][train][INFO] - {"epoch": 669, "train_loss": "3.939", "train_ntokens": "1794.4", "train_nsentences": "4.95", "train_prob_perplexity": "78.591", "train_code_perplexity": "76.933", "train_temp": "1.75", "train_loss_0": "3.79", "train_loss_1": "0.127", "train_loss_2": "0.022", "train_accuracy": "0.29104", "train_wps": "3932.3", "train_ups": "2.19", "train_wpb": "1794.4", "train_bsz": "5", "train_num_updates": "26760", "train_lr": "0.000418125", "train_gnorm": "0.552", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "12462"}
[2022-01-03 15:37:24,981][fairseq.trainer][INFO] - begin training epoch 670
[2022-01-03 15:37:24,982][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:37:38,866][train_inner][INFO] - {"epoch": 670, "update": 670.0, "loss": "3.946", "ntokens": "1794.36", "nsentences": "4.95", "prob_perplexity": "78.415", "code_perplexity": "76.719", "temp": "1.75", "loss_0": "3.797", "loss_1": "0.127", "loss_2": "0.022", "accuracy": "0.28774", "wps": "3927.7", "ups": "2.19", "wpb": "1794.4", "bsz": "5", "num_updates": "26800", "lr": "0.00041875", "gnorm": "0.557", "clip": "0", "train_wall": "67", "gb_free": "5.4", "wall": "12476"}
[2022-01-03 15:37:38,867][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:37:39,264][valid][INFO] - {"epoch": 670, "valid_loss": "3.782", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "74.655", "valid_code_perplexity": "72.538", "valid_temp": "1.749", "valid_loss_0": "3.632", "valid_loss_1": "0.127", "valid_loss_2": "0.023", "valid_accuracy": "0.32323", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "26800", "valid_best_loss": "3.499"}
[2022-01-03 15:37:39,268][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 670 @ 26800 updates
[2022-01-03 15:37:39,269][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:37:43,213][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:37:43,240][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 670 @ 26800 updates, score 3.782) (writing took 3.9717162335291505 seconds)
[2022-01-03 15:37:43,240][fairseq_cli.train][INFO] - end of epoch 670 (average epoch stats below)
[2022-01-03 15:37:43,252][train][INFO] - {"epoch": 670, "train_loss": "3.944", "train_ntokens": "1796.65", "train_nsentences": "4.95", "train_prob_perplexity": "79.261", "train_code_perplexity": "77.629", "train_temp": "1.749", "train_loss_0": "3.797", "train_loss_1": "0.126", "train_loss_2": "0.021", "train_accuracy": "0.28815", "train_wps": "3918.8", "train_ups": "2.18", "train_wpb": "1796.7", "train_bsz": "5", "train_num_updates": "26800", "train_lr": "0.00041875", "train_gnorm": "0.541", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "12481"}
[2022-01-03 15:37:43,311][fairseq.trainer][INFO] - begin training epoch 671
[2022-01-03 15:37:43,312][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:37:57,312][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:37:57,731][valid][INFO] - {"epoch": 671, "valid_loss": "3.694", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "73.793", "valid_code_perplexity": "71.301", "valid_temp": "1.749", "valid_loss_0": "3.546", "valid_loss_1": "0.128", "valid_loss_2": "0.021", "valid_accuracy": "0.33006", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "26840", "valid_best_loss": "3.499"}
[2022-01-03 15:37:57,736][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 671 @ 26840 updates
[2022-01-03 15:37:57,737][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:38:01,410][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:38:01,436][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 671 @ 26840 updates, score 3.694) (writing took 3.700897096656263 seconds)
[2022-01-03 15:38:01,437][fairseq_cli.train][INFO] - end of epoch 671 (average epoch stats below)
[2022-01-03 15:38:01,449][train][INFO] - {"epoch": 671, "train_loss": "3.945", "train_ntokens": "1796.6", "train_nsentences": "4.95", "train_prob_perplexity": "79.733", "train_code_perplexity": "78.028", "train_temp": "1.749", "train_loss_0": "3.798", "train_loss_1": "0.126", "train_loss_2": "0.021", "train_accuracy": "0.2875", "train_wps": "3952", "train_ups": "2.2", "train_wpb": "1796.6", "train_bsz": "5", "train_num_updates": "26840", "train_lr": "0.000419375", "train_gnorm": "0.56", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "12499"}
[2022-01-03 15:38:01,492][fairseq.trainer][INFO] - begin training epoch 672
[2022-01-03 15:38:01,493][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:38:15,377][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:38:15,782][valid][INFO] - {"epoch": 672, "valid_loss": "4.093", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "77.39", "valid_code_perplexity": "74.848", "valid_temp": "1.748", "valid_loss_0": "3.946", "valid_loss_1": "0.127", "valid_loss_2": "0.02", "valid_accuracy": "0.27882", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "26880", "valid_best_loss": "3.499"}
[2022-01-03 15:38:15,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 672 @ 26880 updates
[2022-01-03 15:38:15,787][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:38:19,712][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:38:19,732][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 672 @ 26880 updates, score 4.093) (writing took 3.9460608549416065 seconds)
[2022-01-03 15:38:19,732][fairseq_cli.train][INFO] - end of epoch 672 (average epoch stats below)
[2022-01-03 15:38:19,744][train][INFO] - {"epoch": 672, "train_loss": "3.93", "train_ntokens": "1792.42", "train_nsentences": "4.95", "train_prob_perplexity": "79.934", "train_code_perplexity": "78.14", "train_temp": "1.749", "train_loss_0": "3.783", "train_loss_1": "0.126", "train_loss_2": "0.022", "train_accuracy": "0.2894", "train_wps": "3921.5", "train_ups": "2.19", "train_wpb": "1792.4", "train_bsz": "5", "train_num_updates": "26880", "train_lr": "0.00042", "train_gnorm": "0.547", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12517"}
[2022-01-03 15:38:19,789][fairseq.trainer][INFO] - begin training epoch 673
[2022-01-03 15:38:19,789][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:38:33,657][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:38:34,137][valid][INFO] - {"epoch": 673, "valid_loss": "3.849", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "76.287", "valid_code_perplexity": "73.266", "valid_temp": "1.748", "valid_loss_0": "3.703", "valid_loss_1": "0.127", "valid_loss_2": "0.019", "valid_accuracy": "0.29839", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "26920", "valid_best_loss": "3.499"}
[2022-01-03 15:38:34,139][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 673 @ 26920 updates
[2022-01-03 15:38:34,139][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:38:38,127][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:38:38,156][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 673 @ 26920 updates, score 3.849) (writing took 4.017545961774886 seconds)
[2022-01-03 15:38:38,157][fairseq_cli.train][INFO] - end of epoch 673 (average epoch stats below)
[2022-01-03 15:38:38,170][train][INFO] - {"epoch": 673, "train_loss": "3.931", "train_ntokens": "1793.45", "train_nsentences": "4.95", "train_prob_perplexity": "80.958", "train_code_perplexity": "79.254", "train_temp": "1.748", "train_loss_0": "3.784", "train_loss_1": "0.126", "train_loss_2": "0.021", "train_accuracy": "0.28912", "train_wps": "3896.2", "train_ups": "2.17", "train_wpb": "1793.5", "train_bsz": "5", "train_num_updates": "26920", "train_lr": "0.000420625", "train_gnorm": "0.562", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12536"}
[2022-01-03 15:38:38,246][fairseq.trainer][INFO] - begin training epoch 674
[2022-01-03 15:38:38,247][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:38:52,093][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:38:52,570][valid][INFO] - {"epoch": 674, "valid_loss": "3.747", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "74.629", "valid_code_perplexity": "71.812", "valid_temp": "1.748", "valid_loss_0": "3.599", "valid_loss_1": "0.127", "valid_loss_2": "0.021", "valid_accuracy": "0.32071", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "26960", "valid_best_loss": "3.499"}
[2022-01-03 15:38:52,572][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 674 @ 26960 updates
[2022-01-03 15:38:52,572][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:38:56,224][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:38:56,253][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 674 @ 26960 updates, score 3.747) (writing took 3.681464336812496 seconds)
[2022-01-03 15:38:56,254][fairseq_cli.train][INFO] - end of epoch 674 (average epoch stats below)
[2022-01-03 15:38:56,266][train][INFO] - {"epoch": 674, "train_loss": "3.894", "train_ntokens": "1792.42", "train_nsentences": "4.95", "train_prob_perplexity": "81.034", "train_code_perplexity": "79.443", "train_temp": "1.748", "train_loss_0": "3.747", "train_loss_1": "0.126", "train_loss_2": "0.021", "train_accuracy": "0.2952", "train_wps": "3964.6", "train_ups": "2.21", "train_wpb": "1792.4", "train_bsz": "5", "train_num_updates": "26960", "train_lr": "0.00042125", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "12554"}
[2022-01-03 15:38:56,345][fairseq.trainer][INFO] - begin training epoch 675
[2022-01-03 15:38:56,345][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:39:10,275][train_inner][INFO] - {"epoch": 675, "update": 675.0, "loss": "3.93", "ntokens": "1793.58", "nsentences": "4.95", "prob_perplexity": "80.755", "code_perplexity": "79.073", "temp": "1.748", "loss_0": "3.783", "loss_1": "0.126", "loss_2": "0.021", "accuracy": "0.28985", "wps": "3924.8", "ups": "2.19", "wpb": "1793.6", "bsz": "5", "num_updates": "27000", "lr": "0.000421875", "gnorm": "0.558", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "12568"}
[2022-01-03 15:39:10,276][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:39:10,689][valid][INFO] - {"epoch": 675, "valid_loss": "3.975", "valid_ntokens": "834", "valid_nsentences": "2", "valid_prob_perplexity": "77.631", "valid_code_perplexity": "75.431", "valid_temp": "1.747", "valid_loss_0": "3.828", "valid_loss_1": "0.127", "valid_loss_2": "0.021", "valid_accuracy": "0.29616", "valid_wps": "0", "valid_wpb": "834", "valid_bsz": "2", "valid_num_updates": "27000", "valid_best_loss": "3.499"}
[2022-01-03 15:39:10,693][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 675 @ 27000 updates
[2022-01-03 15:39:10,694][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:39:14,438][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:39:14,458][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 675 @ 27000 updates, score 3.975) (writing took 3.765199288725853 seconds)
[2022-01-03 15:39:14,459][fairseq_cli.train][INFO] - end of epoch 675 (average epoch stats below)
[2022-01-03 15:39:14,471][train][INFO] - {"epoch": 675, "train_loss": "3.952", "train_ntokens": "1792.97", "train_nsentences": "4.95", "train_prob_perplexity": "82.115", "train_code_perplexity": "80.501", "train_temp": "1.748", "train_loss_0": "3.805", "train_loss_1": "0.126", "train_loss_2": "0.021", "train_accuracy": "0.28805", "train_wps": "3942.3", "train_ups": "2.2", "train_wpb": "1793", "train_bsz": "5", "train_num_updates": "27000", "train_lr": "0.000421875", "train_gnorm": "0.57", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12572"}
[2022-01-03 15:39:14,517][fairseq.trainer][INFO] - begin training epoch 676
[2022-01-03 15:39:14,518][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:39:28,441][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:39:28,842][valid][INFO] - {"epoch": 676, "valid_loss": "3.826", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "70.659", "valid_code_perplexity": "69.209", "valid_temp": "1.747", "valid_loss_0": "3.677", "valid_loss_1": "0.128", "valid_loss_2": "0.021", "valid_accuracy": "0.29973", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "27040", "valid_best_loss": "3.499"}
[2022-01-03 15:39:28,845][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 676 @ 27040 updates
[2022-01-03 15:39:28,846][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:39:32,813][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:39:32,842][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 676 @ 27040 updates, score 3.826) (writing took 3.9975574566051364 seconds)
[2022-01-03 15:39:32,843][fairseq_cli.train][INFO] - end of epoch 676 (average epoch stats below)
[2022-01-03 15:39:32,855][train][INFO] - {"epoch": 676, "train_loss": "3.913", "train_ntokens": "1786.42", "train_nsentences": "4.95", "train_prob_perplexity": "81.42", "train_code_perplexity": "79.698", "train_temp": "1.747", "train_loss_0": "3.766", "train_loss_1": "0.126", "train_loss_2": "0.021", "train_accuracy": "0.29121", "train_wps": "3889.4", "train_ups": "2.18", "train_wpb": "1786.4", "train_bsz": "5", "train_num_updates": "27040", "train_lr": "0.0004225", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12590"}
[2022-01-03 15:39:32,935][fairseq.trainer][INFO] - begin training epoch 677
[2022-01-03 15:39:32,935][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:39:46,869][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:39:47,282][valid][INFO] - {"epoch": 677, "valid_loss": "3.757", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "79.984", "valid_code_perplexity": "78.339", "valid_temp": "1.747", "valid_loss_0": "3.61", "valid_loss_1": "0.126", "valid_loss_2": "0.021", "valid_accuracy": "0.29733", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "27080", "valid_best_loss": "3.499"}
[2022-01-03 15:39:47,287][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 677 @ 27080 updates
[2022-01-03 15:39:47,289][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:39:51,026][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:39:51,055][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 677 @ 27080 updates, score 3.757) (writing took 3.7676066989079118 seconds)
[2022-01-03 15:39:51,056][fairseq_cli.train][INFO] - end of epoch 677 (average epoch stats below)
[2022-01-03 15:39:51,069][train][INFO] - {"epoch": 677, "train_loss": "3.917", "train_ntokens": "1786.5", "train_nsentences": "4.95", "train_prob_perplexity": "81.824", "train_code_perplexity": "80.074", "train_temp": "1.747", "train_loss_0": "3.771", "train_loss_1": "0.126", "train_loss_2": "0.02", "train_accuracy": "0.28864", "train_wps": "3926.3", "train_ups": "2.2", "train_wpb": "1786.5", "train_bsz": "5", "train_num_updates": "27080", "train_lr": "0.000423125", "train_gnorm": "0.567", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "7.1", "train_wall": "12608"}
[2022-01-03 15:39:51,145][fairseq.trainer][INFO] - begin training epoch 678
[2022-01-03 15:39:51,146][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:40:05,086][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:40:05,486][valid][INFO] - {"epoch": 678, "valid_loss": "3.626", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "80.244", "valid_code_perplexity": "78.577", "valid_temp": "1.746", "valid_loss_0": "3.478", "valid_loss_1": "0.126", "valid_loss_2": "0.022", "valid_accuracy": "0.37206", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "27120", "valid_best_loss": "3.499"}
[2022-01-03 15:40:05,489][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 678 @ 27120 updates
[2022-01-03 15:40:05,489][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:40:09,271][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:40:09,297][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 678 @ 27120 updates, score 3.626) (writing took 3.808532126247883 seconds)
[2022-01-03 15:40:09,298][fairseq_cli.train][INFO] - end of epoch 678 (average epoch stats below)
[2022-01-03 15:40:09,310][train][INFO] - {"epoch": 678, "train_loss": "3.955", "train_ntokens": "1800.5", "train_nsentences": "4.95", "train_prob_perplexity": "82.646", "train_code_perplexity": "80.906", "train_temp": "1.747", "train_loss_0": "3.809", "train_loss_1": "0.126", "train_loss_2": "0.02", "train_accuracy": "0.28538", "train_wps": "3950.8", "train_ups": "2.19", "train_wpb": "1800.5", "train_bsz": "5", "train_num_updates": "27120", "train_lr": "0.00042375", "train_gnorm": "0.539", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "12627"}
[2022-01-03 15:40:09,382][fairseq.trainer][INFO] - begin training epoch 679
[2022-01-03 15:40:09,383][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:40:23,264][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:40:23,670][valid][INFO] - {"epoch": 679, "valid_loss": "3.739", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "80.588", "valid_code_perplexity": "78.885", "valid_temp": "1.746", "valid_loss_0": "3.593", "valid_loss_1": "0.126", "valid_loss_2": "0.019", "valid_accuracy": "0.34459", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "27160", "valid_best_loss": "3.499"}
[2022-01-03 15:40:23,673][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 679 @ 27160 updates
[2022-01-03 15:40:23,674][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:40:27,616][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:40:27,636][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 679 @ 27160 updates, score 3.739) (writing took 3.96237538382411 seconds)
[2022-01-03 15:40:27,636][fairseq_cli.train][INFO] - end of epoch 679 (average epoch stats below)
[2022-01-03 15:40:27,649][train][INFO] - {"epoch": 679, "train_loss": "3.937", "train_ntokens": "1798.17", "train_nsentences": "4.95", "train_prob_perplexity": "81.878", "train_code_perplexity": "80.096", "train_temp": "1.746", "train_loss_0": "3.791", "train_loss_1": "0.126", "train_loss_2": "0.02", "train_accuracy": "0.2885", "train_wps": "3924.9", "train_ups": "2.18", "train_wpb": "1798.2", "train_bsz": "5", "train_num_updates": "27160", "train_lr": "0.000424375", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "12645"}
[2022-01-03 15:40:27,707][fairseq.trainer][INFO] - begin training epoch 680
[2022-01-03 15:40:27,708][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:40:41,704][train_inner][INFO] - {"epoch": 680, "update": 680.0, "loss": "3.926", "ntokens": "1791.03", "nsentences": "4.95", "prob_perplexity": "82.062", "code_perplexity": "80.324", "temp": "1.747", "loss_0": "3.779", "loss_1": "0.126", "loss_2": "0.02", "accuracy": "0.28918", "wps": "3918.4", "ups": "2.19", "wpb": "1791", "bsz": "5", "num_updates": "27200", "lr": "0.000425", "gnorm": "0.551", "clip": "0", "train_wall": "68", "gb_free": "6.1", "wall": "12659"}
[2022-01-03 15:40:41,705][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:40:42,115][valid][INFO] - {"epoch": 680, "valid_loss": "3.72", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "73.941", "valid_code_perplexity": "71.329", "valid_temp": "1.746", "valid_loss_0": "3.567", "valid_loss_1": "0.128", "valid_loss_2": "0.025", "valid_accuracy": "0.33668", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "27200", "valid_best_loss": "3.499"}
[2022-01-03 15:40:42,119][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 680 @ 27200 updates
[2022-01-03 15:40:42,119][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:40:45,825][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:40:45,850][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 680 @ 27200 updates, score 3.72) (writing took 3.7312496779486537 seconds)
[2022-01-03 15:40:45,850][fairseq_cli.train][INFO] - end of epoch 680 (average epoch stats below)
[2022-01-03 15:40:45,863][train][INFO] - {"epoch": 680, "train_loss": "3.907", "train_ntokens": "1783.55", "train_nsentences": "4.95", "train_prob_perplexity": "82.544", "train_code_perplexity": "80.844", "train_temp": "1.746", "train_loss_0": "3.761", "train_loss_1": "0.126", "train_loss_2": "0.02", "train_accuracy": "0.29223", "train_wps": "3919.6", "train_ups": "2.2", "train_wpb": "1783.5", "train_bsz": "5", "train_num_updates": "27200", "train_lr": "0.000425", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "12663"}
[2022-01-03 15:40:45,913][fairseq.trainer][INFO] - begin training epoch 681
[2022-01-03 15:40:45,914][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:40:59,802][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:41:00,206][valid][INFO] - {"epoch": 681, "valid_loss": "3.707", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "79.919", "valid_code_perplexity": "77.615", "valid_temp": "1.745", "valid_loss_0": "3.56", "valid_loss_1": "0.126", "valid_loss_2": "0.021", "valid_accuracy": "0.3172", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "27240", "valid_best_loss": "3.499"}
[2022-01-03 15:41:00,209][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 681 @ 27240 updates
[2022-01-03 15:41:00,210][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:41:04,145][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:41:04,170][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 681 @ 27240 updates, score 3.707) (writing took 3.9608620135113597 seconds)
[2022-01-03 15:41:04,170][fairseq_cli.train][INFO] - end of epoch 681 (average epoch stats below)
[2022-01-03 15:41:04,183][train][INFO] - {"epoch": 681, "train_loss": "3.902", "train_ntokens": "1797.7", "train_nsentences": "4.95", "train_prob_perplexity": "83.189", "train_code_perplexity": "81.555", "train_temp": "1.746", "train_loss_0": "3.756", "train_loss_1": "0.126", "train_loss_2": "0.02", "train_accuracy": "0.29198", "train_wps": "3927.8", "train_ups": "2.18", "train_wpb": "1797.7", "train_bsz": "5", "train_num_updates": "27240", "train_lr": "0.000425625", "train_gnorm": "0.574", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "12682"}
[2022-01-03 15:41:04,235][fairseq.trainer][INFO] - begin training epoch 682
[2022-01-03 15:41:04,236][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:41:18,172][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:41:18,573][valid][INFO] - {"epoch": 682, "valid_loss": "3.95", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "79.626", "valid_code_perplexity": "76.971", "valid_temp": "1.745", "valid_loss_0": "3.804", "valid_loss_1": "0.126", "valid_loss_2": "0.02", "valid_accuracy": "0.27646", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "27280", "valid_best_loss": "3.499"}
[2022-01-03 15:41:18,576][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 682 @ 27280 updates
[2022-01-03 15:41:18,577][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:41:22,370][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:41:22,398][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 682 @ 27280 updates, score 3.95) (writing took 3.8219282422214746 seconds)
[2022-01-03 15:41:22,398][fairseq_cli.train][INFO] - end of epoch 682 (average epoch stats below)
[2022-01-03 15:41:22,411][train][INFO] - {"epoch": 682, "train_loss": "3.885", "train_ntokens": "1782.4", "train_nsentences": "4.95", "train_prob_perplexity": "83.234", "train_code_perplexity": "81.702", "train_temp": "1.745", "train_loss_0": "3.74", "train_loss_1": "0.126", "train_loss_2": "0.02", "train_accuracy": "0.29529", "train_wps": "3914.2", "train_ups": "2.2", "train_wpb": "1782.4", "train_bsz": "5", "train_num_updates": "27280", "train_lr": "0.00042625", "train_gnorm": "0.55", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12700"}
[2022-01-03 15:41:22,489][fairseq.trainer][INFO] - begin training epoch 683
[2022-01-03 15:41:22,490][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:41:36,400][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:41:36,810][valid][INFO] - {"epoch": 683, "valid_loss": "3.854", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "83.526", "valid_code_perplexity": "81.697", "valid_temp": "1.745", "valid_loss_0": "3.71", "valid_loss_1": "0.125", "valid_loss_2": "0.018", "valid_accuracy": "0.2883", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "27320", "valid_best_loss": "3.499"}
[2022-01-03 15:41:36,813][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 683 @ 27320 updates
[2022-01-03 15:41:36,814][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:41:40,648][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:41:40,681][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 683 @ 27320 updates, score 3.854) (writing took 3.8677816037088633 seconds)
[2022-01-03 15:41:40,681][fairseq_cli.train][INFO] - end of epoch 683 (average epoch stats below)
[2022-01-03 15:41:40,694][train][INFO] - {"epoch": 683, "train_loss": "3.948", "train_ntokens": "1803.05", "train_nsentences": "4.95", "train_prob_perplexity": "84.626", "train_code_perplexity": "82.94", "train_temp": "1.745", "train_loss_0": "3.803", "train_loss_1": "0.125", "train_loss_2": "0.02", "train_accuracy": "0.28807", "train_wps": "3947.5", "train_ups": "2.19", "train_wpb": "1803", "train_bsz": "5", "train_num_updates": "27320", "train_lr": "0.000426875", "train_gnorm": "0.545", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12718"}
[2022-01-03 15:41:40,767][fairseq.trainer][INFO] - begin training epoch 684
[2022-01-03 15:41:40,768][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:41:54,660][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:41:55,065][valid][INFO] - {"epoch": 684, "valid_loss": "3.83", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "80.858", "valid_code_perplexity": "78.675", "valid_temp": "1.744", "valid_loss_0": "3.684", "valid_loss_1": "0.126", "valid_loss_2": "0.02", "valid_accuracy": "0.31034", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "27360", "valid_best_loss": "3.499"}
[2022-01-03 15:41:55,068][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 684 @ 27360 updates
[2022-01-03 15:41:55,069][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:41:58,882][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:41:58,909][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 684 @ 27360 updates, score 3.83) (writing took 3.8408311074599624 seconds)
[2022-01-03 15:41:58,909][fairseq_cli.train][INFO] - end of epoch 684 (average epoch stats below)
[2022-01-03 15:41:58,922][train][INFO] - {"epoch": 684, "train_loss": "3.9", "train_ntokens": "1783.8", "train_nsentences": "4.95", "train_prob_perplexity": "84.145", "train_code_perplexity": "82.487", "train_temp": "1.744", "train_loss_0": "3.755", "train_loss_1": "0.125", "train_loss_2": "0.019", "train_accuracy": "0.29207", "train_wps": "3917.2", "train_ups": "2.2", "train_wpb": "1783.8", "train_bsz": "5", "train_num_updates": "27360", "train_lr": "0.0004275", "train_gnorm": "0.558", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12736"}
[2022-01-03 15:41:58,960][fairseq.trainer][INFO] - begin training epoch 685
[2022-01-03 15:41:58,961][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:42:12,956][train_inner][INFO] - {"epoch": 685, "update": 685.0, "loss": "3.908", "ntokens": "1789.28", "nsentences": "4.95", "prob_perplexity": "84.038", "code_perplexity": "82.418", "temp": "1.745", "loss_0": "3.763", "loss_1": "0.125", "loss_2": "0.02", "accuracy": "0.29179", "wps": "3922.2", "ups": "2.19", "wpb": "1789.3", "bsz": "5", "num_updates": "27400", "lr": "0.000428125", "gnorm": "0.553", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "12750"}
[2022-01-03 15:42:12,957][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:42:13,361][valid][INFO] - {"epoch": 685, "valid_loss": "3.922", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "82.389", "valid_code_perplexity": "81.01", "valid_temp": "1.744", "valid_loss_0": "3.779", "valid_loss_1": "0.126", "valid_loss_2": "0.017", "valid_accuracy": "0.31586", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "27400", "valid_best_loss": "3.499"}
[2022-01-03 15:42:13,365][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 685 @ 27400 updates
[2022-01-03 15:42:13,366][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:42:17,123][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:42:17,152][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 685 @ 27400 updates, score 3.922) (writing took 3.787362809292972 seconds)
[2022-01-03 15:42:17,152][fairseq_cli.train][INFO] - end of epoch 685 (average epoch stats below)
[2022-01-03 15:42:17,166][train][INFO] - {"epoch": 685, "train_loss": "3.904", "train_ntokens": "1779.45", "train_nsentences": "4.95", "train_prob_perplexity": "84.995", "train_code_perplexity": "83.407", "train_temp": "1.744", "train_loss_0": "3.759", "train_loss_1": "0.125", "train_loss_2": "0.02", "train_accuracy": "0.29159", "train_wps": "3904.2", "train_ups": "2.19", "train_wpb": "1779.5", "train_bsz": "5", "train_num_updates": "27400", "train_lr": "0.000428125", "train_gnorm": "0.536", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "12755"}
[2022-01-03 15:42:17,246][fairseq.trainer][INFO] - begin training epoch 686
[2022-01-03 15:42:17,247][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:42:31,137][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:42:31,563][valid][INFO] - {"epoch": 686, "valid_loss": "3.952", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "81.99", "valid_code_perplexity": "79.336", "valid_temp": "1.744", "valid_loss_0": "3.808", "valid_loss_1": "0.126", "valid_loss_2": "0.019", "valid_accuracy": "0.28792", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "27440", "valid_best_loss": "3.499"}
[2022-01-03 15:42:31,568][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 686 @ 27440 updates
[2022-01-03 15:42:31,569][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:42:35,395][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:42:35,421][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 686 @ 27440 updates, score 3.952) (writing took 3.853640468791127 seconds)
[2022-01-03 15:42:35,422][fairseq_cli.train][INFO] - end of epoch 686 (average epoch stats below)
[2022-01-03 15:42:35,436][train][INFO] - {"epoch": 686, "train_loss": "3.876", "train_ntokens": "1787.6", "train_nsentences": "4.95", "train_prob_perplexity": "84.397", "train_code_perplexity": "82.766", "train_temp": "1.744", "train_loss_0": "3.731", "train_loss_1": "0.125", "train_loss_2": "0.019", "train_accuracy": "0.29533", "train_wps": "3916.7", "train_ups": "2.19", "train_wpb": "1787.6", "train_bsz": "5", "train_num_updates": "27440", "train_lr": "0.00042875", "train_gnorm": "0.558", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12773"}
[2022-01-03 15:42:35,499][fairseq.trainer][INFO] - begin training epoch 687
[2022-01-03 15:42:35,500][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:42:49,384][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:42:49,787][valid][INFO] - {"epoch": 687, "valid_loss": "3.904", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "81.011", "valid_code_perplexity": "78.807", "valid_temp": "1.743", "valid_loss_0": "3.76", "valid_loss_1": "0.126", "valid_loss_2": "0.018", "valid_accuracy": "0.28351", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "27480", "valid_best_loss": "3.499"}
[2022-01-03 15:42:49,789][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 687 @ 27480 updates
[2022-01-03 15:42:49,790][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:42:53,632][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:42:53,662][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 687 @ 27480 updates, score 3.904) (writing took 3.872115157544613 seconds)
[2022-01-03 15:42:53,662][fairseq_cli.train][INFO] - end of epoch 687 (average epoch stats below)
[2022-01-03 15:42:53,675][train][INFO] - {"epoch": 687, "train_loss": "3.891", "train_ntokens": "1785.65", "train_nsentences": "4.95", "train_prob_perplexity": "85.05", "train_code_perplexity": "83.465", "train_temp": "1.743", "train_loss_0": "3.746", "train_loss_1": "0.125", "train_loss_2": "0.02", "train_accuracy": "0.29197", "train_wps": "3918.9", "train_ups": "2.19", "train_wpb": "1785.7", "train_bsz": "5", "train_num_updates": "27480", "train_lr": "0.000429375", "train_gnorm": "0.54", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12791"}
[2022-01-03 15:42:53,734][fairseq.trainer][INFO] - begin training epoch 688
[2022-01-03 15:42:53,735][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:43:07,532][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:43:07,930][valid][INFO] - {"epoch": 688, "valid_loss": "3.873", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "81.084", "valid_code_perplexity": "78.3", "valid_temp": "1.743", "valid_loss_0": "3.728", "valid_loss_1": "0.126", "valid_loss_2": "0.019", "valid_accuracy": "0.3084", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "27520", "valid_best_loss": "3.499"}
[2022-01-03 15:43:07,933][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 688 @ 27520 updates
[2022-01-03 15:43:07,933][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:43:11,818][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:43:11,836][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 688 @ 27520 updates, score 3.873) (writing took 3.9035197058692575 seconds)
[2022-01-03 15:43:11,837][fairseq_cli.train][INFO] - end of epoch 688 (average epoch stats below)
[2022-01-03 15:43:11,849][train][INFO] - {"epoch": 688, "train_loss": "3.879", "train_ntokens": "1765.33", "train_nsentences": "4.95", "train_prob_perplexity": "85.065", "train_code_perplexity": "83.379", "train_temp": "1.743", "train_loss_0": "3.734", "train_loss_1": "0.125", "train_loss_2": "0.019", "train_accuracy": "0.29478", "train_wps": "3888", "train_ups": "2.2", "train_wpb": "1765.3", "train_bsz": "5", "train_num_updates": "27520", "train_lr": "0.00043", "train_gnorm": "0.571", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "12809"}
[2022-01-03 15:43:11,887][fairseq.trainer][INFO] - begin training epoch 689
[2022-01-03 15:43:11,888][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:43:25,825][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:43:26,238][valid][INFO] - {"epoch": 689, "valid_loss": "3.959", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "80.975", "valid_code_perplexity": "78.247", "valid_temp": "1.743", "valid_loss_0": "3.814", "valid_loss_1": "0.126", "valid_loss_2": "0.019", "valid_accuracy": "0.30299", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "27560", "valid_best_loss": "3.499"}
[2022-01-03 15:43:26,241][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 689 @ 27560 updates
[2022-01-03 15:43:26,242][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:43:30,035][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:43:30,060][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 689 @ 27560 updates, score 3.959) (writing took 3.8191420156508684 seconds)
[2022-01-03 15:43:30,061][fairseq_cli.train][INFO] - end of epoch 689 (average epoch stats below)
[2022-01-03 15:43:30,074][train][INFO] - {"epoch": 689, "train_loss": "3.885", "train_ntokens": "1812.35", "train_nsentences": "4.95", "train_prob_perplexity": "85.866", "train_code_perplexity": "84.161", "train_temp": "1.743", "train_loss_0": "3.741", "train_loss_1": "0.125", "train_loss_2": "0.019", "train_accuracy": "0.2958", "train_wps": "3980.7", "train_ups": "2.2", "train_wpb": "1812.3", "train_bsz": "5", "train_num_updates": "27560", "train_lr": "0.000430625", "train_gnorm": "0.533", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "12827"}
[2022-01-03 15:43:30,147][fairseq.trainer][INFO] - begin training epoch 690
[2022-01-03 15:43:30,148][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:43:43,944][train_inner][INFO] - {"epoch": 690, "update": 690.0, "loss": "3.885", "ntokens": "1789.74", "nsentences": "4.95", "prob_perplexity": "85.276", "code_perplexity": "83.64", "temp": "1.743", "loss_0": "3.741", "loss_1": "0.125", "loss_2": "0.019", "accuracy": "0.29407", "wps": "3934.6", "ups": "2.2", "wpb": "1789.7", "bsz": "5", "num_updates": "27600", "lr": "0.00043125", "gnorm": "0.548", "clip": "0", "train_wall": "67", "gb_free": "5.4", "wall": "12841"}
[2022-01-03 15:43:43,945][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:43:44,351][valid][INFO] - {"epoch": 690, "valid_loss": "4.071", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "85.209", "valid_code_perplexity": "82.821", "valid_temp": "1.742", "valid_loss_0": "3.926", "valid_loss_1": "0.125", "valid_loss_2": "0.019", "valid_accuracy": "0.28515", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "27600", "valid_best_loss": "3.499"}
[2022-01-03 15:43:44,354][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 690 @ 27600 updates
[2022-01-03 15:43:44,355][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:43:48,297][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:43:48,326][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 690 @ 27600 updates, score 4.071) (writing took 3.9714141311123967 seconds)
[2022-01-03 15:43:48,326][fairseq_cli.train][INFO] - end of epoch 690 (average epoch stats below)
[2022-01-03 15:43:48,339][train][INFO] - {"epoch": 690, "train_loss": "3.898", "train_ntokens": "1797.8", "train_nsentences": "4.95", "train_prob_perplexity": "86.004", "train_code_perplexity": "84.428", "train_temp": "1.742", "train_loss_0": "3.754", "train_loss_1": "0.125", "train_loss_2": "0.019", "train_accuracy": "0.29247", "train_wps": "3939.9", "train_ups": "2.19", "train_wpb": "1797.8", "train_bsz": "5", "train_num_updates": "27600", "train_lr": "0.00043125", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "12846"}
[2022-01-03 15:43:48,419][fairseq.trainer][INFO] - begin training epoch 691
[2022-01-03 15:43:48,420][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:44:02,140][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:44:02,530][valid][INFO] - {"epoch": 691, "valid_loss": "4.047", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "84.438", "valid_code_perplexity": "82.6", "valid_temp": "1.742", "valid_loss_0": "3.904", "valid_loss_1": "0.125", "valid_loss_2": "0.018", "valid_accuracy": "0.27632", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "27640", "valid_best_loss": "3.499"}
[2022-01-03 15:44:02,532][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 691 @ 27640 updates
[2022-01-03 15:44:02,533][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:44:06,436][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:44:06,448][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 691 @ 27640 updates, score 4.047) (writing took 3.916392126120627 seconds)
[2022-01-03 15:44:06,449][fairseq_cli.train][INFO] - end of epoch 691 (average epoch stats below)
[2022-01-03 15:44:06,462][train][INFO] - {"epoch": 691, "train_loss": "3.89", "train_ntokens": "1785.78", "train_nsentences": "4.95", "train_prob_perplexity": "86.364", "train_code_perplexity": "84.811", "train_temp": "1.742", "train_loss_0": "3.746", "train_loss_1": "0.125", "train_loss_2": "0.019", "train_accuracy": "0.29435", "train_wps": "3944.2", "train_ups": "2.21", "train_wpb": "1785.8", "train_bsz": "5", "train_num_updates": "27640", "train_lr": "0.000431875", "train_gnorm": "0.553", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12864"}
[2022-01-03 15:44:06,548][fairseq.trainer][INFO] - begin training epoch 692
[2022-01-03 15:44:06,549][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:44:20,446][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:44:20,850][valid][INFO] - {"epoch": 692, "valid_loss": "3.479", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "81.66", "valid_code_perplexity": "79.004", "valid_temp": "1.742", "valid_loss_0": "3.333", "valid_loss_1": "0.126", "valid_loss_2": "0.02", "valid_accuracy": "0.36327", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "27680", "valid_best_loss": "3.479"}
[2022-01-03 15:44:20,854][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 692 @ 27680 updates
[2022-01-03 15:44:20,855][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 15:44:24,678][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 15:44:32,946][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 692 @ 27680 updates, score 3.479) (writing took 12.092595224268734 seconds)
[2022-01-03 15:44:32,947][fairseq_cli.train][INFO] - end of epoch 692 (average epoch stats below)
[2022-01-03 15:44:32,961][train][INFO] - {"epoch": 692, "train_loss": "3.902", "train_ntokens": "1803.08", "train_nsentences": "4.95", "train_prob_perplexity": "87.206", "train_code_perplexity": "85.651", "train_temp": "1.742", "train_loss_0": "3.758", "train_loss_1": "0.125", "train_loss_2": "0.019", "train_accuracy": "0.29375", "train_wps": "2723.2", "train_ups": "1.51", "train_wpb": "1803.1", "train_bsz": "5", "train_num_updates": "27680", "train_lr": "0.0004325", "train_gnorm": "0.545", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12890"}
[2022-01-03 15:44:33,044][fairseq.trainer][INFO] - begin training epoch 693
[2022-01-03 15:44:33,044][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:44:46,794][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:44:47,200][valid][INFO] - {"epoch": 693, "valid_loss": "3.895", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "84.553", "valid_code_perplexity": "82.01", "valid_temp": "1.741", "valid_loss_0": "3.752", "valid_loss_1": "0.125", "valid_loss_2": "0.018", "valid_accuracy": "0.30315", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "27720", "valid_best_loss": "3.479"}
[2022-01-03 15:44:47,203][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 693 @ 27720 updates
[2022-01-03 15:44:47,204][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:44:51,112][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:44:51,132][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 693 @ 27720 updates, score 3.895) (writing took 3.92840903904289 seconds)
[2022-01-03 15:44:51,132][fairseq_cli.train][INFO] - end of epoch 693 (average epoch stats below)
[2022-01-03 15:44:51,144][train][INFO] - {"epoch": 693, "train_loss": "3.906", "train_ntokens": "1805.7", "train_nsentences": "4.95", "train_prob_perplexity": "86.363", "train_code_perplexity": "84.811", "train_temp": "1.741", "train_loss_0": "3.762", "train_loss_1": "0.125", "train_loss_2": "0.019", "train_accuracy": "0.29037", "train_wps": "3974.9", "train_ups": "2.2", "train_wpb": "1805.7", "train_bsz": "5", "train_num_updates": "27720", "train_lr": "0.000433125", "train_gnorm": "0.53", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12909"}
[2022-01-03 15:44:51,210][fairseq.trainer][INFO] - begin training epoch 694
[2022-01-03 15:44:51,211][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:45:05,005][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:45:05,411][valid][INFO] - {"epoch": 694, "valid_loss": "3.721", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "77.721", "valid_code_perplexity": "75.104", "valid_temp": "1.741", "valid_loss_0": "3.575", "valid_loss_1": "0.127", "valid_loss_2": "0.019", "valid_accuracy": "0.30256", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "27760", "valid_best_loss": "3.479"}
[2022-01-03 15:45:05,414][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 694 @ 27760 updates
[2022-01-03 15:45:05,414][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:45:09,315][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:45:09,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 694 @ 27760 updates, score 3.721) (writing took 3.930770787410438 seconds)
[2022-01-03 15:45:09,345][fairseq_cli.train][INFO] - end of epoch 694 (average epoch stats below)
[2022-01-03 15:45:09,358][train][INFO] - {"epoch": 694, "train_loss": "3.886", "train_ntokens": "1773.17", "train_nsentences": "4.95", "train_prob_perplexity": "87.529", "train_code_perplexity": "85.876", "train_temp": "1.741", "train_loss_0": "3.743", "train_loss_1": "0.125", "train_loss_2": "0.018", "train_accuracy": "0.29542", "train_wps": "3897", "train_ups": "2.2", "train_wpb": "1773.2", "train_bsz": "5", "train_num_updates": "27760", "train_lr": "0.00043375", "train_gnorm": "0.561", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12927"}
[2022-01-03 15:45:09,414][fairseq.trainer][INFO] - begin training epoch 695
[2022-01-03 15:45:09,415][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:45:23,315][train_inner][INFO] - {"epoch": 695, "update": 695.0, "loss": "3.899", "ntokens": "1789.21", "nsentences": "4.95", "prob_perplexity": "87.087", "code_perplexity": "85.526", "temp": "1.741", "loss_0": "3.756", "loss_1": "0.125", "loss_2": "0.019", "accuracy": "0.29251", "wps": "3601.5", "ups": "2.01", "wpb": "1789.2", "bsz": "5", "num_updates": "27800", "lr": "0.000434375", "gnorm": "0.546", "clip": "0", "train_wall": "67", "gb_free": "9.8", "wall": "12941"}
[2022-01-03 15:45:23,316][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:45:23,723][valid][INFO] - {"epoch": 695, "valid_loss": "3.815", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "86.898", "valid_code_perplexity": "84.09", "valid_temp": "1.74", "valid_loss_0": "3.67", "valid_loss_1": "0.125", "valid_loss_2": "0.021", "valid_accuracy": "0.31522", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "27800", "valid_best_loss": "3.479"}
[2022-01-03 15:45:23,725][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 695 @ 27800 updates
[2022-01-03 15:45:23,726][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:45:27,544][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:45:27,568][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 695 @ 27800 updates, score 3.815) (writing took 3.8430317332968116 seconds)
[2022-01-03 15:45:27,569][fairseq_cli.train][INFO] - end of epoch 695 (average epoch stats below)
[2022-01-03 15:45:27,582][train][INFO] - {"epoch": 695, "train_loss": "3.913", "train_ntokens": "1778.35", "train_nsentences": "4.95", "train_prob_perplexity": "87.973", "train_code_perplexity": "86.48", "train_temp": "1.741", "train_loss_0": "3.769", "train_loss_1": "0.124", "train_loss_2": "0.019", "train_accuracy": "0.28868", "train_wps": "3906.1", "train_ups": "2.2", "train_wpb": "1778.3", "train_bsz": "5", "train_num_updates": "27800", "train_lr": "0.000434375", "train_gnorm": "0.542", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.8", "train_wall": "12945"}
[2022-01-03 15:45:27,649][fairseq.trainer][INFO] - begin training epoch 696
[2022-01-03 15:45:27,650][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:45:41,542][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:45:41,958][valid][INFO] - {"epoch": 696, "valid_loss": "3.678", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "85.741", "valid_code_perplexity": "83.475", "valid_temp": "1.74", "valid_loss_0": "3.536", "valid_loss_1": "0.125", "valid_loss_2": "0.017", "valid_accuracy": "0.32289", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "27840", "valid_best_loss": "3.479"}
[2022-01-03 15:45:41,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 696 @ 27840 updates
[2022-01-03 15:45:41,961][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:45:45,769][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:45:45,793][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 696 @ 27840 updates, score 3.678) (writing took 3.8321962421759963 seconds)
[2022-01-03 15:45:45,793][fairseq_cli.train][INFO] - end of epoch 696 (average epoch stats below)
[2022-01-03 15:45:45,806][train][INFO] - {"epoch": 696, "train_loss": "3.915", "train_ntokens": "1796.78", "train_nsentences": "4.95", "train_prob_perplexity": "88.536", "train_code_perplexity": "87.02", "train_temp": "1.74", "train_loss_0": "3.772", "train_loss_1": "0.124", "train_loss_2": "0.019", "train_accuracy": "0.28888", "train_wps": "3946.5", "train_ups": "2.2", "train_wpb": "1796.8", "train_bsz": "5", "train_num_updates": "27840", "train_lr": "0.000435", "train_gnorm": "0.541", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "12963"}
[2022-01-03 15:45:45,865][fairseq.trainer][INFO] - begin training epoch 697
[2022-01-03 15:45:45,866][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:45:59,670][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:46:00,074][valid][INFO] - {"epoch": 697, "valid_loss": "3.939", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "83.616", "valid_code_perplexity": "81.172", "valid_temp": "1.74", "valid_loss_0": "3.794", "valid_loss_1": "0.125", "valid_loss_2": "0.02", "valid_accuracy": "0.27078", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "27880", "valid_best_loss": "3.479"}
[2022-01-03 15:46:00,077][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 697 @ 27880 updates
[2022-01-03 15:46:00,077][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:46:03,968][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:46:03,996][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 697 @ 27880 updates, score 3.939) (writing took 3.9197813598439097 seconds)
[2022-01-03 15:46:03,997][fairseq_cli.train][INFO] - end of epoch 697 (average epoch stats below)
[2022-01-03 15:46:04,009][train][INFO] - {"epoch": 697, "train_loss": "3.905", "train_ntokens": "1784.95", "train_nsentences": "4.95", "train_prob_perplexity": "88.506", "train_code_perplexity": "86.932", "train_temp": "1.74", "train_loss_0": "3.762", "train_loss_1": "0.124", "train_loss_2": "0.019", "train_accuracy": "0.2921", "train_wps": "3924.9", "train_ups": "2.2", "train_wpb": "1785", "train_bsz": "5", "train_num_updates": "27880", "train_lr": "0.000435625", "train_gnorm": "0.545", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "12981"}
[2022-01-03 15:46:04,088][fairseq.trainer][INFO] - begin training epoch 698
[2022-01-03 15:46:04,089][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:46:17,960][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:46:18,354][valid][INFO] - {"epoch": 698, "valid_loss": "3.649", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "82.412", "valid_code_perplexity": "79.933", "valid_temp": "1.739", "valid_loss_0": "3.504", "valid_loss_1": "0.126", "valid_loss_2": "0.019", "valid_accuracy": "0.29832", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "27920", "valid_best_loss": "3.479"}
[2022-01-03 15:46:18,357][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 698 @ 27920 updates
[2022-01-03 15:46:18,358][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:46:22,196][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:46:22,225][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 698 @ 27920 updates, score 3.649) (writing took 3.86798114515841 seconds)
[2022-01-03 15:46:22,225][fairseq_cli.train][INFO] - end of epoch 698 (average epoch stats below)
[2022-01-03 15:46:22,238][train][INFO] - {"epoch": 698, "train_loss": "3.895", "train_ntokens": "1795.83", "train_nsentences": "4.95", "train_prob_perplexity": "89.115", "train_code_perplexity": "87.697", "train_temp": "1.74", "train_loss_0": "3.751", "train_loss_1": "0.124", "train_loss_2": "0.02", "train_accuracy": "0.29574", "train_wps": "3943.4", "train_ups": "2.2", "train_wpb": "1795.8", "train_bsz": "5", "train_num_updates": "27920", "train_lr": "0.00043625", "train_gnorm": "0.572", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "13000"}
[2022-01-03 15:46:22,322][fairseq.trainer][INFO] - begin training epoch 699
[2022-01-03 15:46:22,323][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:46:36,023][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:46:36,420][valid][INFO] - {"epoch": 699, "valid_loss": "3.792", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "80.699", "valid_code_perplexity": "77.839", "valid_temp": "1.739", "valid_loss_0": "3.648", "valid_loss_1": "0.126", "valid_loss_2": "0.018", "valid_accuracy": "0.32021", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "27960", "valid_best_loss": "3.479"}
[2022-01-03 15:46:36,422][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 699 @ 27960 updates
[2022-01-03 15:46:36,423][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:46:40,336][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:46:40,363][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 699 @ 27960 updates, score 3.792) (writing took 3.940774836577475 seconds)
[2022-01-03 15:46:40,363][fairseq_cli.train][INFO] - end of epoch 699 (average epoch stats below)
[2022-01-03 15:46:40,376][train][INFO] - {"epoch": 699, "train_loss": "3.869", "train_ntokens": "1798.85", "train_nsentences": "4.95", "train_prob_perplexity": "89.047", "train_code_perplexity": "87.588", "train_temp": "1.739", "train_loss_0": "3.726", "train_loss_1": "0.124", "train_loss_2": "0.019", "train_accuracy": "0.29611", "train_wps": "3969.9", "train_ups": "2.21", "train_wpb": "1798.8", "train_bsz": "5", "train_num_updates": "27960", "train_lr": "0.000436875", "train_gnorm": "0.545", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13018"}
[2022-01-03 15:46:40,436][fairseq.trainer][INFO] - begin training epoch 700
[2022-01-03 15:46:40,437][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:46:54,352][train_inner][INFO] - {"epoch": 700, "update": 700.0, "loss": "3.888", "ntokens": "1795.79", "nsentences": "4.95", "prob_perplexity": "89.08", "code_perplexity": "87.595", "temp": "1.74", "loss_0": "3.745", "loss_1": "0.124", "loss_2": "0.019", "accuracy": "0.29383", "wps": "3945.8", "ups": "2.2", "wpb": "1795.8", "bsz": "5", "num_updates": "28000", "lr": "0.0004375", "gnorm": "0.548", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "13032"}
[2022-01-03 15:46:54,353][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:46:54,752][valid][INFO] - {"epoch": 700, "valid_loss": "3.571", "valid_ntokens": "796", "valid_nsentences": "2", "valid_prob_perplexity": "82.445", "valid_code_perplexity": "79.186", "valid_temp": "1.739", "valid_loss_0": "3.428", "valid_loss_1": "0.126", "valid_loss_2": "0.018", "valid_accuracy": "0.3706", "valid_wps": "0", "valid_wpb": "796", "valid_bsz": "2", "valid_num_updates": "28000", "valid_best_loss": "3.479"}
[2022-01-03 15:46:54,755][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 700 @ 28000 updates
[2022-01-03 15:46:54,756][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:46:58,567][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:46:58,594][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 700 @ 28000 updates, score 3.571) (writing took 3.839621338993311 seconds)
[2022-01-03 15:46:58,595][fairseq_cli.train][INFO] - end of epoch 700 (average epoch stats below)
[2022-01-03 15:46:58,608][train][INFO] - {"epoch": 700, "train_loss": "3.857", "train_ntokens": "1802.55", "train_nsentences": "4.95", "train_prob_perplexity": "90.194", "train_code_perplexity": "88.736", "train_temp": "1.739", "train_loss_0": "3.714", "train_loss_1": "0.124", "train_loss_2": "0.019", "train_accuracy": "0.29632", "train_wps": "3957.5", "train_ups": "2.2", "train_wpb": "1802.5", "train_bsz": "5", "train_num_updates": "28000", "train_lr": "0.0004375", "train_gnorm": "0.536", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13036"}
[2022-01-03 15:46:58,662][fairseq.trainer][INFO] - begin training epoch 701
[2022-01-03 15:46:58,663][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:47:12,462][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:47:12,869][valid][INFO] - {"epoch": 701, "valid_loss": "3.892", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "86.824", "valid_code_perplexity": "84.813", "valid_temp": "1.738", "valid_loss_0": "3.748", "valid_loss_1": "0.125", "valid_loss_2": "0.019", "valid_accuracy": "0.27949", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "28040", "valid_best_loss": "3.479"}
[2022-01-03 15:47:12,873][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 701 @ 28040 updates
[2022-01-03 15:47:12,873][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:47:16,790][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:47:16,819][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 701 @ 28040 updates, score 3.892) (writing took 3.9460975620895624 seconds)
[2022-01-03 15:47:16,819][fairseq_cli.train][INFO] - end of epoch 701 (average epoch stats below)
[2022-01-03 15:47:16,832][train][INFO] - {"epoch": 701, "train_loss": "3.892", "train_ntokens": "1802.35", "train_nsentences": "4.95", "train_prob_perplexity": "90.027", "train_code_perplexity": "88.467", "train_temp": "1.739", "train_loss_0": "3.75", "train_loss_1": "0.124", "train_loss_2": "0.018", "train_accuracy": "0.29331", "train_wps": "3958.8", "train_ups": "2.2", "train_wpb": "1802.3", "train_bsz": "5", "train_num_updates": "28040", "train_lr": "0.000438125", "train_gnorm": "0.553", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "13054"}
[2022-01-03 15:47:16,878][fairseq.trainer][INFO] - begin training epoch 702
[2022-01-03 15:47:16,879][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:47:30,724][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:47:31,207][valid][INFO] - {"epoch": 702, "valid_loss": "3.569", "valid_ntokens": "706", "valid_nsentences": "2", "valid_prob_perplexity": "83.709", "valid_code_perplexity": "81.053", "valid_temp": "1.738", "valid_loss_0": "3.426", "valid_loss_1": "0.125", "valid_loss_2": "0.018", "valid_accuracy": "0.32153", "valid_wps": "0", "valid_wpb": "706", "valid_bsz": "2", "valid_num_updates": "28080", "valid_best_loss": "3.479"}
[2022-01-03 15:47:31,209][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 702 @ 28080 updates
[2022-01-03 15:47:31,210][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:47:35,127][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:47:35,155][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 702 @ 28080 updates, score 3.569) (writing took 3.945988465100527 seconds)
[2022-01-03 15:47:35,156][fairseq_cli.train][INFO] - end of epoch 702 (average epoch stats below)
[2022-01-03 15:47:35,168][train][INFO] - {"epoch": 702, "train_loss": "3.888", "train_ntokens": "1795.88", "train_nsentences": "4.95", "train_prob_perplexity": "90.939", "train_code_perplexity": "89.425", "train_temp": "1.738", "train_loss_0": "3.747", "train_loss_1": "0.124", "train_loss_2": "0.018", "train_accuracy": "0.29504", "train_wps": "3920.3", "train_ups": "2.18", "train_wpb": "1795.9", "train_bsz": "5", "train_num_updates": "28080", "train_lr": "0.00043875", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13073"}
[2022-01-03 15:47:35,248][fairseq.trainer][INFO] - begin training epoch 703
[2022-01-03 15:47:35,248][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:47:49,044][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:47:49,492][valid][INFO] - {"epoch": 703, "valid_loss": "3.697", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "88.551", "valid_code_perplexity": "86.166", "valid_temp": "1.738", "valid_loss_0": "3.555", "valid_loss_1": "0.124", "valid_loss_2": "0.018", "valid_accuracy": "0.30739", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "28120", "valid_best_loss": "3.479"}
[2022-01-03 15:47:49,495][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 703 @ 28120 updates
[2022-01-03 15:47:49,495][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:47:53,454][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:47:53,481][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 703 @ 28120 updates, score 3.697) (writing took 3.986113282851875 seconds)
[2022-01-03 15:47:53,481][fairseq_cli.train][INFO] - end of epoch 703 (average epoch stats below)
[2022-01-03 15:47:53,494][train][INFO] - {"epoch": 703, "train_loss": "3.924", "train_ntokens": "1795.6", "train_nsentences": "4.95", "train_prob_perplexity": "90.71", "train_code_perplexity": "89.311", "train_temp": "1.738", "train_loss_0": "3.782", "train_loss_1": "0.124", "train_loss_2": "0.018", "train_accuracy": "0.29081", "train_wps": "3922.1", "train_ups": "2.18", "train_wpb": "1795.6", "train_bsz": "5", "train_num_updates": "28120", "train_lr": "0.000439375", "train_gnorm": "0.552", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "13091"}
[2022-01-03 15:47:53,567][fairseq.trainer][INFO] - begin training epoch 704
[2022-01-03 15:47:53,568][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:48:07,599][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:48:08,022][valid][INFO] - {"epoch": 704, "valid_loss": "3.888", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "86.315", "valid_code_perplexity": "82.934", "valid_temp": "1.737", "valid_loss_0": "3.745", "valid_loss_1": "0.125", "valid_loss_2": "0.018", "valid_accuracy": "0.29388", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "28160", "valid_best_loss": "3.479"}
[2022-01-03 15:48:08,025][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 704 @ 28160 updates
[2022-01-03 15:48:08,026][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:48:11,785][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:48:11,811][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 704 @ 28160 updates, score 3.888) (writing took 3.7858188413083553 seconds)
[2022-01-03 15:48:11,811][fairseq_cli.train][INFO] - end of epoch 704 (average epoch stats below)
[2022-01-03 15:48:11,824][train][INFO] - {"epoch": 704, "train_loss": "3.873", "train_ntokens": "1789.8", "train_nsentences": "4.95", "train_prob_perplexity": "91.353", "train_code_perplexity": "89.918", "train_temp": "1.738", "train_loss_0": "3.73", "train_loss_1": "0.124", "train_loss_2": "0.019", "train_accuracy": "0.29622", "train_wps": "3908.6", "train_ups": "2.18", "train_wpb": "1789.8", "train_bsz": "5", "train_num_updates": "28160", "train_lr": "0.00044", "train_gnorm": "0.543", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13109"}
[2022-01-03 15:48:11,903][fairseq.trainer][INFO] - begin training epoch 705
[2022-01-03 15:48:11,904][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:48:25,893][train_inner][INFO] - {"epoch": 705, "update": 705.0, "loss": "3.894", "ntokens": "1793.64", "nsentences": "4.95", "prob_perplexity": "90.826", "code_perplexity": "89.359", "temp": "1.738", "loss_0": "3.752", "loss_1": "0.124", "loss_2": "0.018", "accuracy": "0.29322", "wps": "3919.3", "ups": "2.19", "wpb": "1793.6", "bsz": "5", "num_updates": "28200", "lr": "0.000440625", "gnorm": "0.543", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "13123"}
[2022-01-03 15:48:25,894][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:48:26,299][valid][INFO] - {"epoch": 705, "valid_loss": "4.037", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "91.098", "valid_code_perplexity": "89.762", "valid_temp": "1.737", "valid_loss_0": "3.895", "valid_loss_1": "0.124", "valid_loss_2": "0.018", "valid_accuracy": "0.29552", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "28200", "valid_best_loss": "3.479"}
[2022-01-03 15:48:26,302][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 705 @ 28200 updates
[2022-01-03 15:48:26,302][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:48:29,998][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:48:30,027][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 705 @ 28200 updates, score 4.037) (writing took 3.725831273943186 seconds)
[2022-01-03 15:48:30,028][fairseq_cli.train][INFO] - end of epoch 705 (average epoch stats below)
[2022-01-03 15:48:30,041][train][INFO] - {"epoch": 705, "train_loss": "3.893", "train_ntokens": "1784.58", "train_nsentences": "4.95", "train_prob_perplexity": "91.101", "train_code_perplexity": "89.676", "train_temp": "1.737", "train_loss_0": "3.752", "train_loss_1": "0.124", "train_loss_2": "0.017", "train_accuracy": "0.29071", "train_wps": "3921.3", "train_ups": "2.2", "train_wpb": "1784.6", "train_bsz": "5", "train_num_updates": "28200", "train_lr": "0.000440625", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13127"}
[2022-01-03 15:48:30,122][fairseq.trainer][INFO] - begin training epoch 706
[2022-01-03 15:48:30,123][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:48:44,174][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:48:44,585][valid][INFO] - {"epoch": 706, "valid_loss": "4.184", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "91.767", "valid_code_perplexity": "89.593", "valid_temp": "1.737", "valid_loss_0": "4.042", "valid_loss_1": "0.124", "valid_loss_2": "0.018", "valid_accuracy": "0.27467", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "28240", "valid_best_loss": "3.479"}
[2022-01-03 15:48:44,588][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 706 @ 28240 updates
[2022-01-03 15:48:44,588][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:48:48,270][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:48:48,297][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 706 @ 28240 updates, score 4.184) (writing took 3.7093874141573906 seconds)
[2022-01-03 15:48:48,298][fairseq_cli.train][INFO] - end of epoch 706 (average epoch stats below)
[2022-01-03 15:48:48,310][train][INFO] - {"epoch": 706, "train_loss": "3.884", "train_ntokens": "1804.3", "train_nsentences": "4.95", "train_prob_perplexity": "91.449", "train_code_perplexity": "89.971", "train_temp": "1.737", "train_loss_0": "3.743", "train_loss_1": "0.124", "train_loss_2": "0.018", "train_accuracy": "0.29592", "train_wps": "3953.3", "train_ups": "2.19", "train_wpb": "1804.3", "train_bsz": "5", "train_num_updates": "28240", "train_lr": "0.00044125", "train_gnorm": "0.541", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "13146"}
[2022-01-03 15:48:48,353][fairseq.trainer][INFO] - begin training epoch 707
[2022-01-03 15:48:48,353][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:49:02,301][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:49:02,707][valid][INFO] - {"epoch": 707, "valid_loss": "3.878", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "90.91", "valid_code_perplexity": "89.018", "valid_temp": "1.736", "valid_loss_0": "3.737", "valid_loss_1": "0.124", "valid_loss_2": "0.017", "valid_accuracy": "0.32574", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "28280", "valid_best_loss": "3.479"}
[2022-01-03 15:49:02,710][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 707 @ 28280 updates
[2022-01-03 15:49:02,710][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:49:06,527][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:49:06,555][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 707 @ 28280 updates, score 3.878) (writing took 3.8454288253560662 seconds)
[2022-01-03 15:49:06,556][fairseq_cli.train][INFO] - end of epoch 707 (average epoch stats below)
[2022-01-03 15:49:06,568][train][INFO] - {"epoch": 707, "train_loss": "3.87", "train_ntokens": "1788.85", "train_nsentences": "4.95", "train_prob_perplexity": "91.604", "train_code_perplexity": "90.232", "train_temp": "1.736", "train_loss_0": "3.729", "train_loss_1": "0.124", "train_loss_2": "0.018", "train_accuracy": "0.29757", "train_wps": "3921.7", "train_ups": "2.19", "train_wpb": "1788.8", "train_bsz": "5", "train_num_updates": "28280", "train_lr": "0.000441875", "train_gnorm": "0.544", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13164"}
[2022-01-03 15:49:06,646][fairseq.trainer][INFO] - begin training epoch 708
[2022-01-03 15:49:06,647][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:49:20,530][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:49:20,933][valid][INFO] - {"epoch": 708, "valid_loss": "3.574", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "84.945", "valid_code_perplexity": "83.094", "valid_temp": "1.736", "valid_loss_0": "3.431", "valid_loss_1": "0.125", "valid_loss_2": "0.018", "valid_accuracy": "0.33799", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "28320", "valid_best_loss": "3.479"}
[2022-01-03 15:49:20,936][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 708 @ 28320 updates
[2022-01-03 15:49:20,937][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:49:24,838][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:49:24,857][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 708 @ 28320 updates, score 3.574) (writing took 3.920656956732273 seconds)
[2022-01-03 15:49:24,857][fairseq_cli.train][INFO] - end of epoch 708 (average epoch stats below)
[2022-01-03 15:49:24,870][train][INFO] - {"epoch": 708, "train_loss": "3.87", "train_ntokens": "1782.88", "train_nsentences": "4.95", "train_prob_perplexity": "92.045", "train_code_perplexity": "90.525", "train_temp": "1.736", "train_loss_0": "3.728", "train_loss_1": "0.124", "train_loss_2": "0.019", "train_accuracy": "0.29361", "train_wps": "3899.4", "train_ups": "2.19", "train_wpb": "1782.9", "train_bsz": "5", "train_num_updates": "28320", "train_lr": "0.0004425", "train_gnorm": "0.536", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "13182"}
[2022-01-03 15:49:24,920][fairseq.trainer][INFO] - begin training epoch 709
[2022-01-03 15:49:24,921][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:49:38,967][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:49:39,372][valid][INFO] - {"epoch": 709, "valid_loss": "3.751", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "87.975", "valid_code_perplexity": "85.714", "valid_temp": "1.736", "valid_loss_0": "3.606", "valid_loss_1": "0.124", "valid_loss_2": "0.02", "valid_accuracy": "0.31486", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "28360", "valid_best_loss": "3.479"}
[2022-01-03 15:49:39,375][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 709 @ 28360 updates
[2022-01-03 15:49:39,376][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:49:43,067][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:49:43,096][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 709 @ 28360 updates, score 3.751) (writing took 3.7208002265542746 seconds)
[2022-01-03 15:49:43,096][fairseq_cli.train][INFO] - end of epoch 709 (average epoch stats below)
[2022-01-03 15:49:43,109][train][INFO] - {"epoch": 709, "train_loss": "3.852", "train_ntokens": "1792.6", "train_nsentences": "4.95", "train_prob_perplexity": "92.179", "train_code_perplexity": "90.777", "train_temp": "1.736", "train_loss_0": "3.711", "train_loss_1": "0.123", "train_loss_2": "0.017", "train_accuracy": "0.29714", "train_wps": "3934.1", "train_ups": "2.19", "train_wpb": "1792.6", "train_bsz": "5", "train_num_updates": "28360", "train_lr": "0.000443125", "train_gnorm": "0.524", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "13201"}
[2022-01-03 15:49:43,184][fairseq.trainer][INFO] - begin training epoch 710
[2022-01-03 15:49:43,185][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:49:57,112][train_inner][INFO] - {"epoch": 710, "update": 710.0, "loss": "3.869", "ntokens": "1793.82", "nsentences": "4.95", "prob_perplexity": "92.066", "code_perplexity": "90.621", "temp": "1.736", "loss_0": "3.728", "loss_1": "0.124", "loss_2": "0.018", "accuracy": "0.29619", "wps": "3933.6", "ups": "2.19", "wpb": "1793.8", "bsz": "5", "num_updates": "28400", "lr": "0.00044375", "gnorm": "0.536", "clip": "0", "train_wall": "68", "gb_free": "6.1", "wall": "13215"}
[2022-01-03 15:49:57,113][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:49:57,668][valid][INFO] - {"epoch": 710, "valid_loss": "3.774", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "89.994", "valid_code_perplexity": "88.732", "valid_temp": "1.735", "valid_loss_0": "3.633", "valid_loss_1": "0.124", "valid_loss_2": "0.017", "valid_accuracy": "0.31944", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "28400", "valid_best_loss": "3.479"}
[2022-01-03 15:49:57,671][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 710 @ 28400 updates
[2022-01-03 15:49:57,672][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:50:01,313][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:50:01,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 710 @ 28400 updates, score 3.774) (writing took 3.673460847698152 seconds)
[2022-01-03 15:50:01,345][fairseq_cli.train][INFO] - end of epoch 710 (average epoch stats below)
[2022-01-03 15:50:01,358][train][INFO] - {"epoch": 710, "train_loss": "3.87", "train_ntokens": "1800.47", "train_nsentences": "4.95", "train_prob_perplexity": "93.053", "train_code_perplexity": "91.6", "train_temp": "1.735", "train_loss_0": "3.729", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.2967", "train_wps": "3949.2", "train_ups": "2.19", "train_wpb": "1800.5", "train_bsz": "5", "train_num_updates": "28400", "train_lr": "0.00044375", "train_gnorm": "0.532", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "13219"}
[2022-01-03 15:50:01,422][fairseq.trainer][INFO] - begin training epoch 711
[2022-01-03 15:50:01,422][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:50:15,396][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:50:15,803][valid][INFO] - {"epoch": 711, "valid_loss": "3.725", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "86.832", "valid_code_perplexity": "85.888", "valid_temp": "1.735", "valid_loss_0": "3.585", "valid_loss_1": "0.125", "valid_loss_2": "0.016", "valid_accuracy": "0.32353", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "28440", "valid_best_loss": "3.479"}
[2022-01-03 15:50:15,806][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 711 @ 28440 updates
[2022-01-03 15:50:15,807][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:50:19,596][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:50:19,617][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 711 @ 28440 updates, score 3.725) (writing took 3.8109369054436684 seconds)
[2022-01-03 15:50:19,617][fairseq_cli.train][INFO] - end of epoch 711 (average epoch stats below)
[2022-01-03 15:50:19,631][train][INFO] - {"epoch": 711, "train_loss": "3.855", "train_ntokens": "1792.28", "train_nsentences": "4.95", "train_prob_perplexity": "92.856", "train_code_perplexity": "91.388", "train_temp": "1.735", "train_loss_0": "3.714", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.2974", "train_wps": "3926.3", "train_ups": "2.19", "train_wpb": "1792.3", "train_bsz": "5", "train_num_updates": "28440", "train_lr": "0.000444375", "train_gnorm": "0.548", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13237"}
[2022-01-03 15:50:19,679][fairseq.trainer][INFO] - begin training epoch 712
[2022-01-03 15:50:19,679][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:50:33,473][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:50:33,938][valid][INFO] - {"epoch": 712, "valid_loss": "3.786", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "89.297", "valid_code_perplexity": "87.039", "valid_temp": "1.735", "valid_loss_0": "3.642", "valid_loss_1": "0.124", "valid_loss_2": "0.02", "valid_accuracy": "0.27366", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "28480", "valid_best_loss": "3.479"}
[2022-01-03 15:50:33,940][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 712 @ 28480 updates
[2022-01-03 15:50:33,941][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:50:37,899][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:50:37,926][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 712 @ 28480 updates, score 3.786) (writing took 3.9860081523656845 seconds)
[2022-01-03 15:50:37,927][fairseq_cli.train][INFO] - end of epoch 712 (average epoch stats below)
[2022-01-03 15:50:37,940][train][INFO] - {"epoch": 712, "train_loss": "3.872", "train_ntokens": "1789.7", "train_nsentences": "4.95", "train_prob_perplexity": "92.541", "train_code_perplexity": "91.103", "train_temp": "1.735", "train_loss_0": "3.73", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.29635", "train_wps": "3912.9", "train_ups": "2.19", "train_wpb": "1789.7", "train_bsz": "5", "train_num_updates": "28480", "train_lr": "0.000445", "train_gnorm": "0.555", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13255"}
[2022-01-03 15:50:37,994][fairseq.trainer][INFO] - begin training epoch 713
[2022-01-03 15:50:37,995][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:50:51,980][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:50:52,386][valid][INFO] - {"epoch": 713, "valid_loss": "3.875", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "88.083", "valid_code_perplexity": "85.863", "valid_temp": "1.734", "valid_loss_0": "3.735", "valid_loss_1": "0.124", "valid_loss_2": "0.016", "valid_accuracy": "0.30077", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "28520", "valid_best_loss": "3.479"}
[2022-01-03 15:50:52,390][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 713 @ 28520 updates
[2022-01-03 15:50:52,390][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:50:56,078][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:50:56,107][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 713 @ 28520 updates, score 3.875) (writing took 3.717385560274124 seconds)
[2022-01-03 15:50:56,108][fairseq_cli.train][INFO] - end of epoch 713 (average epoch stats below)
[2022-01-03 15:50:56,121][train][INFO] - {"epoch": 713, "train_loss": "3.875", "train_ntokens": "1792.38", "train_nsentences": "4.95", "train_prob_perplexity": "93.752", "train_code_perplexity": "92.286", "train_temp": "1.734", "train_loss_0": "3.733", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.29331", "train_wps": "3946.3", "train_ups": "2.2", "train_wpb": "1792.4", "train_bsz": "5", "train_num_updates": "28520", "train_lr": "0.000445625", "train_gnorm": "0.553", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13274"}
[2022-01-03 15:50:56,197][fairseq.trainer][INFO] - begin training epoch 714
[2022-01-03 15:50:56,197][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:51:10,148][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:51:10,555][valid][INFO] - {"epoch": 714, "valid_loss": "4.055", "valid_ntokens": "790", "valid_nsentences": "2", "valid_prob_perplexity": "89.864", "valid_code_perplexity": "86.56", "valid_temp": "1.734", "valid_loss_0": "3.913", "valid_loss_1": "0.124", "valid_loss_2": "0.019", "valid_accuracy": "0.2962", "valid_wps": "0", "valid_wpb": "790", "valid_bsz": "2", "valid_num_updates": "28560", "valid_best_loss": "3.479"}
[2022-01-03 15:51:10,558][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 714 @ 28560 updates
[2022-01-03 15:51:10,558][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:51:14,415][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:51:14,444][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 714 @ 28560 updates, score 4.055) (writing took 3.886468875221908 seconds)
[2022-01-03 15:51:14,445][fairseq_cli.train][INFO] - end of epoch 714 (average epoch stats below)
[2022-01-03 15:51:14,459][train][INFO] - {"epoch": 714, "train_loss": "3.841", "train_ntokens": "1788.72", "train_nsentences": "4.95", "train_prob_perplexity": "94.531", "train_code_perplexity": "93.253", "train_temp": "1.734", "train_loss_0": "3.701", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.29967", "train_wps": "3904.7", "train_ups": "2.18", "train_wpb": "1788.7", "train_bsz": "5", "train_num_updates": "28560", "train_lr": "0.00044625", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13292"}
[2022-01-03 15:51:14,527][fairseq.trainer][INFO] - begin training epoch 715
[2022-01-03 15:51:14,528][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:51:28,393][train_inner][INFO] - {"epoch": 715, "update": 715.0, "loss": "3.86", "ntokens": "1792.22", "nsentences": "4.95", "prob_perplexity": "93.557", "code_perplexity": "92.142", "temp": "1.734", "loss_0": "3.719", "loss_1": "0.123", "loss_2": "0.018", "accuracy": "0.29693", "wps": "3927.4", "ups": "2.19", "wpb": "1792.2", "bsz": "5", "num_updates": "28600", "lr": "0.000446875", "gnorm": "0.549", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "13306"}
[2022-01-03 15:51:28,394][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:51:28,801][valid][INFO] - {"epoch": 715, "valid_loss": "3.851", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "89.769", "valid_code_perplexity": "88.21", "valid_temp": "1.734", "valid_loss_0": "3.709", "valid_loss_1": "0.124", "valid_loss_2": "0.019", "valid_accuracy": "0.31744", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "28600", "valid_best_loss": "3.479"}
[2022-01-03 15:51:28,805][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 715 @ 28600 updates
[2022-01-03 15:51:28,807][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:51:32,720][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:51:32,745][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 715 @ 28600 updates, score 3.851) (writing took 3.939472710713744 seconds)
[2022-01-03 15:51:32,745][fairseq_cli.train][INFO] - end of epoch 715 (average epoch stats below)
[2022-01-03 15:51:32,758][train][INFO] - {"epoch": 715, "train_loss": "3.856", "train_ntokens": "1798.03", "train_nsentences": "4.95", "train_prob_perplexity": "94.103", "train_code_perplexity": "92.68", "train_temp": "1.734", "train_loss_0": "3.716", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.2979", "train_wps": "3933.1", "train_ups": "2.19", "train_wpb": "1798", "train_bsz": "5", "train_num_updates": "28600", "train_lr": "0.000446875", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "13310"}
[2022-01-03 15:51:32,829][fairseq.trainer][INFO] - begin training epoch 716
[2022-01-03 15:51:32,830][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:51:46,768][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:51:47,267][valid][INFO] - {"epoch": 716, "valid_loss": "4.04", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "90.547", "valid_code_perplexity": "87.29", "valid_temp": "1.733", "valid_loss_0": "3.899", "valid_loss_1": "0.124", "valid_loss_2": "0.017", "valid_accuracy": "0.29752", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "28640", "valid_best_loss": "3.479"}
[2022-01-03 15:51:47,268][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 716 @ 28640 updates
[2022-01-03 15:51:47,269][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:51:50,874][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:51:50,894][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 716 @ 28640 updates, score 4.04) (writing took 3.6253902362659574 seconds)
[2022-01-03 15:51:50,894][fairseq_cli.train][INFO] - end of epoch 716 (average epoch stats below)
[2022-01-03 15:51:50,907][train][INFO] - {"epoch": 716, "train_loss": "3.837", "train_ntokens": "1791.6", "train_nsentences": "4.95", "train_prob_perplexity": "94.121", "train_code_perplexity": "92.703", "train_temp": "1.733", "train_loss_0": "3.696", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.29817", "train_wps": "3951.5", "train_ups": "2.21", "train_wpb": "1791.6", "train_bsz": "5", "train_num_updates": "28640", "train_lr": "0.0004475", "train_gnorm": "0.527", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "13328"}
[2022-01-03 15:51:50,961][fairseq.trainer][INFO] - begin training epoch 717
[2022-01-03 15:51:50,962][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:52:04,862][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:52:05,275][valid][INFO] - {"epoch": 717, "valid_loss": "3.672", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "81.283", "valid_code_perplexity": "77.573", "valid_temp": "1.733", "valid_loss_0": "3.527", "valid_loss_1": "0.126", "valid_loss_2": "0.019", "valid_accuracy": "0.34958", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "28680", "valid_best_loss": "3.479"}
[2022-01-03 15:52:05,278][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 717 @ 28680 updates
[2022-01-03 15:52:05,278][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:52:09,322][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:52:09,349][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 717 @ 28680 updates, score 3.672) (writing took 4.070831454358995 seconds)
[2022-01-03 15:52:09,349][fairseq_cli.train][INFO] - end of epoch 717 (average epoch stats below)
[2022-01-03 15:52:09,362][train][INFO] - {"epoch": 717, "train_loss": "3.856", "train_ntokens": "1786.1", "train_nsentences": "4.95", "train_prob_perplexity": "95.175", "train_code_perplexity": "93.846", "train_temp": "1.733", "train_loss_0": "3.716", "train_loss_1": "0.123", "train_loss_2": "0.017", "train_accuracy": "0.29808", "train_wps": "3873.9", "train_ups": "2.17", "train_wpb": "1786.1", "train_bsz": "5", "train_num_updates": "28680", "train_lr": "0.000448125", "train_gnorm": "0.536", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "13347"}
[2022-01-03 15:52:09,435][fairseq.trainer][INFO] - begin training epoch 718
[2022-01-03 15:52:09,436][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:52:23,437][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:52:23,909][valid][INFO] - {"epoch": 718, "valid_loss": "3.553", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "89.037", "valid_code_perplexity": "86.184", "valid_temp": "1.732", "valid_loss_0": "3.412", "valid_loss_1": "0.124", "valid_loss_2": "0.017", "valid_accuracy": "0.33892", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "28720", "valid_best_loss": "3.479"}
[2022-01-03 15:52:23,911][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 718 @ 28720 updates
[2022-01-03 15:52:23,912][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:52:27,553][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:52:27,560][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 718 @ 28720 updates, score 3.553) (writing took 3.648994385264814 seconds)
[2022-01-03 15:52:27,561][fairseq_cli.train][INFO] - end of epoch 718 (average epoch stats below)
[2022-01-03 15:52:27,574][train][INFO] - {"epoch": 718, "train_loss": "3.882", "train_ntokens": "1801.1", "train_nsentences": "4.95", "train_prob_perplexity": "95.483", "train_code_perplexity": "94.177", "train_temp": "1.733", "train_loss_0": "3.742", "train_loss_1": "0.123", "train_loss_2": "0.017", "train_accuracy": "0.29265", "train_wps": "3958.7", "train_ups": "2.2", "train_wpb": "1801.1", "train_bsz": "5", "train_num_updates": "28720", "train_lr": "0.00044875", "train_gnorm": "0.524", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "13365"}
[2022-01-03 15:52:27,630][fairseq.trainer][INFO] - begin training epoch 719
[2022-01-03 15:52:27,631][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:52:41,543][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:52:41,951][valid][INFO] - {"epoch": 719, "valid_loss": "3.777", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "92.326", "valid_code_perplexity": "90.076", "valid_temp": "1.732", "valid_loss_0": "3.637", "valid_loss_1": "0.123", "valid_loss_2": "0.016", "valid_accuracy": "0.30946", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "28760", "valid_best_loss": "3.479"}
[2022-01-03 15:52:41,954][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 719 @ 28760 updates
[2022-01-03 15:52:41,955][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:52:45,855][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:52:45,883][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 719 @ 28760 updates, score 3.777) (writing took 3.9282304290682077 seconds)
[2022-01-03 15:52:45,883][fairseq_cli.train][INFO] - end of epoch 719 (average epoch stats below)
[2022-01-03 15:52:45,895][train][INFO] - {"epoch": 719, "train_loss": "3.846", "train_ntokens": "1778.8", "train_nsentences": "4.95", "train_prob_perplexity": "95.256", "train_code_perplexity": "93.849", "train_temp": "1.732", "train_loss_0": "3.707", "train_loss_1": "0.123", "train_loss_2": "0.017", "train_accuracy": "0.29766", "train_wps": "3886.1", "train_ups": "2.18", "train_wpb": "1778.8", "train_bsz": "5", "train_num_updates": "28760", "train_lr": "0.000449375", "train_gnorm": "0.542", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13383"}
[2022-01-03 15:52:45,971][fairseq.trainer][INFO] - begin training epoch 720
[2022-01-03 15:52:45,971][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:52:59,835][train_inner][INFO] - {"epoch": 720, "update": 720.0, "loss": "3.853", "ntokens": "1789.27", "nsentences": "4.95", "prob_perplexity": "95.091", "code_perplexity": "93.746", "temp": "1.733", "loss_0": "3.713", "loss_1": "0.123", "loss_2": "0.017", "accuracy": "0.29738", "wps": "3914", "ups": "2.19", "wpb": "1789.3", "bsz": "5", "num_updates": "28800", "lr": "0.00045", "gnorm": "0.538", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "13397"}
[2022-01-03 15:52:59,836][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:53:00,246][valid][INFO] - {"epoch": 720, "valid_loss": "3.755", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "91.76", "valid_code_perplexity": "89.279", "valid_temp": "1.732", "valid_loss_0": "3.613", "valid_loss_1": "0.124", "valid_loss_2": "0.018", "valid_accuracy": "0.31216", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "28800", "valid_best_loss": "3.479"}
[2022-01-03 15:53:00,249][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 720 @ 28800 updates
[2022-01-03 15:53:00,250][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:53:04,077][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:53:04,104][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 720 @ 28800 updates, score 3.755) (writing took 3.8547084238380194 seconds)
[2022-01-03 15:53:04,104][fairseq_cli.train][INFO] - end of epoch 720 (average epoch stats below)
[2022-01-03 15:53:04,117][train][INFO] - {"epoch": 720, "train_loss": "3.843", "train_ntokens": "1788.75", "train_nsentences": "4.95", "train_prob_perplexity": "95.418", "train_code_perplexity": "94.156", "train_temp": "1.732", "train_loss_0": "3.704", "train_loss_1": "0.123", "train_loss_2": "0.017", "train_accuracy": "0.30036", "train_wps": "3929.4", "train_ups": "2.2", "train_wpb": "1788.8", "train_bsz": "5", "train_num_updates": "28800", "train_lr": "0.00045", "train_gnorm": "0.559", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13402"}
[2022-01-03 15:53:04,175][fairseq.trainer][INFO] - begin training epoch 721
[2022-01-03 15:53:04,176][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:53:18,155][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:53:18,560][valid][INFO] - {"epoch": 721, "valid_loss": "3.872", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "90.57", "valid_code_perplexity": "87.559", "valid_temp": "1.731", "valid_loss_0": "3.731", "valid_loss_1": "0.124", "valid_loss_2": "0.018", "valid_accuracy": "0.30541", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "28840", "valid_best_loss": "3.479"}
[2022-01-03 15:53:18,563][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 721 @ 28840 updates
[2022-01-03 15:53:18,564][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:53:22,316][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:53:22,342][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 721 @ 28840 updates, score 3.872) (writing took 3.778724745847285 seconds)
[2022-01-03 15:53:22,343][fairseq_cli.train][INFO] - end of epoch 721 (average epoch stats below)
[2022-01-03 15:53:22,355][train][INFO] - {"epoch": 721, "train_loss": "3.91", "train_ntokens": "1812.2", "train_nsentences": "4.95", "train_prob_perplexity": "94.908", "train_code_perplexity": "93.549", "train_temp": "1.732", "train_loss_0": "3.77", "train_loss_1": "0.123", "train_loss_2": "0.017", "train_accuracy": "0.29199", "train_wps": "3977.2", "train_ups": "2.19", "train_wpb": "1812.2", "train_bsz": "5", "train_num_updates": "28840", "train_lr": "0.000450625", "train_gnorm": "0.561", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13420"}
[2022-01-03 15:53:22,406][fairseq.trainer][INFO] - begin training epoch 722
[2022-01-03 15:53:22,407][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:53:36,294][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:53:36,777][valid][INFO] - {"epoch": 722, "valid_loss": "3.393", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "94.988", "valid_code_perplexity": "92.986", "valid_temp": "1.731", "valid_loss_0": "3.255", "valid_loss_1": "0.123", "valid_loss_2": "0.016", "valid_accuracy": "0.35794", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "28880", "valid_best_loss": "3.393"}
[2022-01-03 15:53:36,779][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 722 @ 28880 updates
[2022-01-03 15:53:36,779][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 15:53:40,601][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 15:53:49,243][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 722 @ 28880 updates, score 3.393) (writing took 12.46465447358787 seconds)
[2022-01-03 15:53:49,244][fairseq_cli.train][INFO] - end of epoch 722 (average epoch stats below)
[2022-01-03 15:53:49,257][train][INFO] - {"epoch": 722, "train_loss": "3.844", "train_ntokens": "1799.22", "train_nsentences": "4.95", "train_prob_perplexity": "95.206", "train_code_perplexity": "93.797", "train_temp": "1.731", "train_loss_0": "3.703", "train_loss_1": "0.123", "train_loss_2": "0.017", "train_accuracy": "0.29861", "train_wps": "2676.6", "train_ups": "1.49", "train_wpb": "1799.2", "train_bsz": "5", "train_num_updates": "28880", "train_lr": "0.00045125", "train_gnorm": "0.532", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.7", "train_wall": "13447"}
[2022-01-03 15:53:49,342][fairseq.trainer][INFO] - begin training epoch 723
[2022-01-03 15:53:49,343][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:54:03,044][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:54:03,442][valid][INFO] - {"epoch": 723, "valid_loss": "3.957", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "93.749", "valid_code_perplexity": "92.261", "valid_temp": "1.731", "valid_loss_0": "3.817", "valid_loss_1": "0.123", "valid_loss_2": "0.017", "valid_accuracy": "0.29775", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "28920", "valid_best_loss": "3.393"}
[2022-01-03 15:54:03,445][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 723 @ 28920 updates
[2022-01-03 15:54:03,446][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:54:07,313][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:54:07,319][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 723 @ 28920 updates, score 3.957) (writing took 3.873384221456945 seconds)
[2022-01-03 15:54:07,319][fairseq_cli.train][INFO] - end of epoch 723 (average epoch stats below)
[2022-01-03 15:54:07,332][train][INFO] - {"epoch": 723, "train_loss": "3.872", "train_ntokens": "1792.8", "train_nsentences": "4.95", "train_prob_perplexity": "96.356", "train_code_perplexity": "94.989", "train_temp": "1.731", "train_loss_0": "3.732", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.29617", "train_wps": "3970.3", "train_ups": "2.21", "train_wpb": "1792.8", "train_bsz": "5", "train_num_updates": "28920", "train_lr": "0.000451875", "train_gnorm": "0.548", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "13465"}
[2022-01-03 15:54:07,375][fairseq.trainer][INFO] - begin training epoch 724
[2022-01-03 15:54:07,376][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:54:21,113][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:54:21,517][valid][INFO] - {"epoch": 724, "valid_loss": "3.783", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "92.497", "valid_code_perplexity": "89.332", "valid_temp": "1.73", "valid_loss_0": "3.642", "valid_loss_1": "0.123", "valid_loss_2": "0.017", "valid_accuracy": "0.28836", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "28960", "valid_best_loss": "3.393"}
[2022-01-03 15:54:21,521][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 724 @ 28960 updates
[2022-01-03 15:54:21,522][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:54:25,385][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:54:25,407][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 724 @ 28960 updates, score 3.783) (writing took 3.886063407175243 seconds)
[2022-01-03 15:54:25,408][fairseq_cli.train][INFO] - end of epoch 724 (average epoch stats below)
[2022-01-03 15:54:25,420][train][INFO] - {"epoch": 724, "train_loss": "3.842", "train_ntokens": "1782.62", "train_nsentences": "4.95", "train_prob_perplexity": "95.903", "train_code_perplexity": "94.504", "train_temp": "1.731", "train_loss_0": "3.702", "train_loss_1": "0.123", "train_loss_2": "0.018", "train_accuracy": "0.29935", "train_wps": "3944.7", "train_ups": "2.21", "train_wpb": "1782.6", "train_bsz": "5", "train_num_updates": "28960", "train_lr": "0.0004525", "train_gnorm": "0.541", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "13483"}
[2022-01-03 15:54:25,465][fairseq.trainer][INFO] - begin training epoch 725
[2022-01-03 15:54:25,466][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:54:39,416][train_inner][INFO] - {"epoch": 725, "update": 725.0, "loss": "3.866", "ntokens": "1794.19", "nsentences": "4.95", "prob_perplexity": "95.793", "code_perplexity": "94.396", "temp": "1.731", "loss_0": "3.726", "loss_1": "0.123", "loss_2": "0.017", "accuracy": "0.29656", "wps": "3603.9", "ups": "2.01", "wpb": "1794.2", "bsz": "5", "num_updates": "29000", "lr": "0.000453125", "gnorm": "0.544", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "13497"}
[2022-01-03 15:54:39,417][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:54:39,822][valid][INFO] - {"epoch": 725, "valid_loss": "3.972", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "95.385", "valid_code_perplexity": "93.751", "valid_temp": "1.73", "valid_loss_0": "3.833", "valid_loss_1": "0.123", "valid_loss_2": "0.016", "valid_accuracy": "0.28068", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "29000", "valid_best_loss": "3.393"}
[2022-01-03 15:54:39,824][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 725 @ 29000 updates
[2022-01-03 15:54:39,825][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:54:43,607][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:54:43,626][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 725 @ 29000 updates, score 3.972) (writing took 3.801511718891561 seconds)
[2022-01-03 15:54:43,626][fairseq_cli.train][INFO] - end of epoch 725 (average epoch stats below)
[2022-01-03 15:54:43,639][train][INFO] - {"epoch": 725, "train_loss": "3.863", "train_ntokens": "1784.12", "train_nsentences": "4.95", "train_prob_perplexity": "96.592", "train_code_perplexity": "95.139", "train_temp": "1.73", "train_loss_0": "3.724", "train_loss_1": "0.122", "train_loss_2": "0.017", "train_accuracy": "0.29674", "train_wps": "3919.9", "train_ups": "2.2", "train_wpb": "1784.1", "train_bsz": "5", "train_num_updates": "29000", "train_lr": "0.000453125", "train_gnorm": "0.536", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13501"}
[2022-01-03 15:54:43,684][fairseq.trainer][INFO] - begin training epoch 726
[2022-01-03 15:54:43,685][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:54:57,436][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:54:57,841][valid][INFO] - {"epoch": 726, "valid_loss": "3.983", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "91.643", "valid_code_perplexity": "89.308", "valid_temp": "1.73", "valid_loss_0": "3.842", "valid_loss_1": "0.124", "valid_loss_2": "0.017", "valid_accuracy": "0.29388", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "29040", "valid_best_loss": "3.393"}
[2022-01-03 15:54:57,845][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 726 @ 29040 updates
[2022-01-03 15:54:57,846][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:55:01,773][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:55:01,802][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 726 @ 29040 updates, score 3.983) (writing took 3.957679788582027 seconds)
[2022-01-03 15:55:01,803][fairseq_cli.train][INFO] - end of epoch 726 (average epoch stats below)
[2022-01-03 15:55:01,815][train][INFO] - {"epoch": 726, "train_loss": "3.86", "train_ntokens": "1789.45", "train_nsentences": "4.95", "train_prob_perplexity": "96.774", "train_code_perplexity": "95.418", "train_temp": "1.73", "train_loss_0": "3.721", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.29604", "train_wps": "3940.7", "train_ups": "2.2", "train_wpb": "1789.5", "train_bsz": "5", "train_num_updates": "29040", "train_lr": "0.00045375", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13519"}
[2022-01-03 15:55:01,894][fairseq.trainer][INFO] - begin training epoch 727
[2022-01-03 15:55:01,895][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:55:15,710][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:55:16,120][valid][INFO] - {"epoch": 727, "valid_loss": "3.72", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "89.516", "valid_code_perplexity": "87.657", "valid_temp": "1.729", "valid_loss_0": "3.579", "valid_loss_1": "0.124", "valid_loss_2": "0.017", "valid_accuracy": "0.31684", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "29080", "valid_best_loss": "3.393"}
[2022-01-03 15:55:16,123][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 727 @ 29080 updates
[2022-01-03 15:55:16,124][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:55:20,076][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:55:20,103][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 727 @ 29080 updates, score 3.72) (writing took 3.9795370558276772 seconds)
[2022-01-03 15:55:20,103][fairseq_cli.train][INFO] - end of epoch 727 (average epoch stats below)
[2022-01-03 15:55:20,116][train][INFO] - {"epoch": 727, "train_loss": "3.847", "train_ntokens": "1795.65", "train_nsentences": "4.95", "train_prob_perplexity": "96.88", "train_code_perplexity": "95.506", "train_temp": "1.73", "train_loss_0": "3.708", "train_loss_1": "0.122", "train_loss_2": "0.017", "train_accuracy": "0.29904", "train_wps": "3927.5", "train_ups": "2.19", "train_wpb": "1795.7", "train_bsz": "5", "train_num_updates": "29080", "train_lr": "0.000454375", "train_gnorm": "0.544", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13538"}
[2022-01-03 15:55:20,198][fairseq.trainer][INFO] - begin training epoch 728
[2022-01-03 15:55:20,199][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:55:34,237][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:55:34,648][valid][INFO] - {"epoch": 728, "valid_loss": "3.575", "valid_ntokens": "672", "valid_nsentences": "2", "valid_prob_perplexity": "81.137", "valid_code_perplexity": "78.993", "valid_temp": "1.729", "valid_loss_0": "3.429", "valid_loss_1": "0.126", "valid_loss_2": "0.02", "valid_accuracy": "0.38988", "valid_wps": "0", "valid_wpb": "672", "valid_bsz": "2", "valid_num_updates": "29120", "valid_best_loss": "3.393"}
[2022-01-03 15:55:34,651][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 728 @ 29120 updates
[2022-01-03 15:55:34,652][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:55:38,304][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:55:38,331][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 728 @ 29120 updates, score 3.575) (writing took 3.679570361971855 seconds)
[2022-01-03 15:55:38,331][fairseq_cli.train][INFO] - end of epoch 728 (average epoch stats below)
[2022-01-03 15:55:38,344][train][INFO] - {"epoch": 728, "train_loss": "3.838", "train_ntokens": "1779.53", "train_nsentences": "4.95", "train_prob_perplexity": "97.346", "train_code_perplexity": "95.957", "train_temp": "1.729", "train_loss_0": "3.699", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30129", "train_wps": "3907.8", "train_ups": "2.2", "train_wpb": "1779.5", "train_bsz": "5", "train_num_updates": "29120", "train_lr": "0.000455", "train_gnorm": "0.536", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.8", "train_wall": "13556"}
[2022-01-03 15:55:38,418][fairseq.trainer][INFO] - begin training epoch 729
[2022-01-03 15:55:38,419][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:55:52,332][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:55:52,760][valid][INFO] - {"epoch": 729, "valid_loss": "3.876", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "87.153", "valid_code_perplexity": "83.996", "valid_temp": "1.729", "valid_loss_0": "3.734", "valid_loss_1": "0.125", "valid_loss_2": "0.018", "valid_accuracy": "0.30137", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "29160", "valid_best_loss": "3.393"}
[2022-01-03 15:55:52,764][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 729 @ 29160 updates
[2022-01-03 15:55:52,765][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:55:56,516][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:55:56,540][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 729 @ 29160 updates, score 3.876) (writing took 3.7755674328655005 seconds)
[2022-01-03 15:55:56,540][fairseq_cli.train][INFO] - end of epoch 729 (average epoch stats below)
[2022-01-03 15:55:56,553][train][INFO] - {"epoch": 729, "train_loss": "3.799", "train_ntokens": "1796.35", "train_nsentences": "4.95", "train_prob_perplexity": "97.23", "train_code_perplexity": "95.815", "train_temp": "1.729", "train_loss_0": "3.66", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.3041", "train_wps": "3948.8", "train_ups": "2.2", "train_wpb": "1796.3", "train_bsz": "5", "train_num_updates": "29160", "train_lr": "0.000455625", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13574"}
[2022-01-03 15:55:56,605][fairseq.trainer][INFO] - begin training epoch 730
[2022-01-03 15:55:56,606][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:56:10,615][train_inner][INFO] - {"epoch": 730, "update": 730.0, "loss": "3.834", "ntokens": "1789.77", "nsentences": "4.95", "prob_perplexity": "97.269", "code_perplexity": "95.888", "temp": "1.729", "loss_0": "3.695", "loss_1": "0.122", "loss_2": "0.016", "accuracy": "0.30101", "wps": "3925.5", "ups": "2.19", "wpb": "1789.8", "bsz": "5", "num_updates": "29200", "lr": "0.00045625", "gnorm": "0.539", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "13588"}
[2022-01-03 15:56:10,616][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:56:11,036][valid][INFO] - {"epoch": 730, "valid_loss": "4.108", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "97.073", "valid_code_perplexity": "95.094", "valid_temp": "1.728", "valid_loss_0": "3.97", "valid_loss_1": "0.122", "valid_loss_2": "0.016", "valid_accuracy": "0.26883", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "29200", "valid_best_loss": "3.393"}
[2022-01-03 15:56:11,041][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 730 @ 29200 updates
[2022-01-03 15:56:11,041][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:56:14,751][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:56:14,780][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 730 @ 29200 updates, score 4.108) (writing took 3.7392872907221317 seconds)
[2022-01-03 15:56:14,781][fairseq_cli.train][INFO] - end of epoch 730 (average epoch stats below)
[2022-01-03 15:56:14,794][train][INFO] - {"epoch": 730, "train_loss": "3.826", "train_ntokens": "1787.88", "train_nsentences": "4.95", "train_prob_perplexity": "98.116", "train_code_perplexity": "96.747", "train_temp": "1.728", "train_loss_0": "3.688", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30455", "train_wps": "3923.4", "train_ups": "2.19", "train_wpb": "1787.9", "train_bsz": "5", "train_num_updates": "29200", "train_lr": "0.00045625", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13592"}
[2022-01-03 15:56:14,870][fairseq.trainer][INFO] - begin training epoch 731
[2022-01-03 15:56:14,870][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:56:28,874][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:56:29,281][valid][INFO] - {"epoch": 731, "valid_loss": "3.327", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "94.505", "valid_code_perplexity": "92.243", "valid_temp": "1.728", "valid_loss_0": "3.189", "valid_loss_1": "0.123", "valid_loss_2": "0.016", "valid_accuracy": "0.37602", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "29240", "valid_best_loss": "3.327"}
[2022-01-03 15:56:29,285][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 731 @ 29240 updates
[2022-01-03 15:56:29,286][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 15:56:33,074][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 15:56:42,479][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 731 @ 29240 updates, score 3.327) (writing took 13.194598527625203 seconds)
[2022-01-03 15:56:42,480][fairseq_cli.train][INFO] - end of epoch 731 (average epoch stats below)
[2022-01-03 15:56:42,494][train][INFO] - {"epoch": 731, "train_loss": "3.82", "train_ntokens": "1774.28", "train_nsentences": "4.95", "train_prob_perplexity": "98.1", "train_code_perplexity": "96.646", "train_temp": "1.728", "train_loss_0": "3.682", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30277", "train_wps": "2563.5", "train_ups": "1.44", "train_wpb": "1774.3", "train_bsz": "5", "train_num_updates": "29240", "train_lr": "0.000456875", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13620"}
[2022-01-03 15:56:42,578][fairseq.trainer][INFO] - begin training epoch 732
[2022-01-03 15:56:42,579][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:56:56,382][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:56:56,785][valid][INFO] - {"epoch": 732, "valid_loss": "3.684", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "87.506", "valid_code_perplexity": "84.037", "valid_temp": "1.728", "valid_loss_0": "3.544", "valid_loss_1": "0.125", "valid_loss_2": "0.016", "valid_accuracy": "0.33161", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "29280", "valid_best_loss": "3.327"}
[2022-01-03 15:56:56,789][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 732 @ 29280 updates
[2022-01-03 15:56:56,790][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:57:00,710][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:57:00,731][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 732 @ 29280 updates, score 3.684) (writing took 3.942302508279681 seconds)
[2022-01-03 15:57:00,732][fairseq_cli.train][INFO] - end of epoch 732 (average epoch stats below)
[2022-01-03 15:57:00,744][train][INFO] - {"epoch": 732, "train_loss": "3.832", "train_ntokens": "1799.38", "train_nsentences": "4.95", "train_prob_perplexity": "98.158", "train_code_perplexity": "96.855", "train_temp": "1.728", "train_loss_0": "3.694", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30151", "train_wps": "3946.5", "train_ups": "2.19", "train_wpb": "1799.4", "train_bsz": "5", "train_num_updates": "29280", "train_lr": "0.0004575", "train_gnorm": "0.541", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13638"}
[2022-01-03 15:57:00,817][fairseq.trainer][INFO] - begin training epoch 733
[2022-01-03 15:57:00,818][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:57:14,697][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:57:15,123][valid][INFO] - {"epoch": 733, "valid_loss": "3.7", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "93.791", "valid_code_perplexity": "91.036", "valid_temp": "1.727", "valid_loss_0": "3.56", "valid_loss_1": "0.123", "valid_loss_2": "0.017", "valid_accuracy": "0.32825", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "29320", "valid_best_loss": "3.327"}
[2022-01-03 15:57:15,126][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 733 @ 29320 updates
[2022-01-03 15:57:15,127][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:57:19,067][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:57:19,095][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 733 @ 29320 updates, score 3.7) (writing took 3.9689101492986083 seconds)
[2022-01-03 15:57:19,096][fairseq_cli.train][INFO] - end of epoch 733 (average epoch stats below)
[2022-01-03 15:57:19,109][train][INFO] - {"epoch": 733, "train_loss": "3.83", "train_ntokens": "1809.1", "train_nsentences": "4.95", "train_prob_perplexity": "98.609", "train_code_perplexity": "97.267", "train_temp": "1.727", "train_loss_0": "3.692", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30066", "train_wps": "3943.2", "train_ups": "2.18", "train_wpb": "1809.1", "train_bsz": "5", "train_num_updates": "29320", "train_lr": "0.000458125", "train_gnorm": "0.53", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13657"}
[2022-01-03 15:57:19,174][fairseq.trainer][INFO] - begin training epoch 734
[2022-01-03 15:57:19,175][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:57:32,989][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:57:33,391][valid][INFO] - {"epoch": 734, "valid_loss": "3.805", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "95.003", "valid_code_perplexity": "92.805", "valid_temp": "1.727", "valid_loss_0": "3.664", "valid_loss_1": "0.123", "valid_loss_2": "0.019", "valid_accuracy": "0.30159", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "29360", "valid_best_loss": "3.327"}
[2022-01-03 15:57:33,394][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 734 @ 29360 updates
[2022-01-03 15:57:33,394][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:57:37,284][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:57:37,305][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 734 @ 29360 updates, score 3.805) (writing took 3.911563348956406 seconds)
[2022-01-03 15:57:37,306][fairseq_cli.train][INFO] - end of epoch 734 (average epoch stats below)
[2022-01-03 15:57:37,319][train][INFO] - {"epoch": 734, "train_loss": "3.808", "train_ntokens": "1785.6", "train_nsentences": "4.95", "train_prob_perplexity": "98.144", "train_code_perplexity": "96.793", "train_temp": "1.727", "train_loss_0": "3.669", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30642", "train_wps": "3925.1", "train_ups": "2.2", "train_wpb": "1785.6", "train_bsz": "5", "train_num_updates": "29360", "train_lr": "0.00045875", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13675"}
[2022-01-03 15:57:37,373][fairseq.trainer][INFO] - begin training epoch 735
[2022-01-03 15:57:37,374][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:57:51,403][train_inner][INFO] - {"epoch": 735, "update": 735.0, "loss": "3.815", "ntokens": "1790.01", "nsentences": "4.95", "prob_perplexity": "98.237", "code_perplexity": "96.866", "temp": "1.727", "loss_0": "3.677", "loss_1": "0.122", "loss_2": "0.016", "accuracy": "0.30387", "wps": "3552.5", "ups": "1.98", "wpb": "1790", "bsz": "5", "num_updates": "29400", "lr": "0.000459375", "gnorm": "0.54", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "13689"}
[2022-01-03 15:57:51,404][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:57:51,802][valid][INFO] - {"epoch": 735, "valid_loss": "4.099", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "95.902", "valid_code_perplexity": "94.206", "valid_temp": "1.727", "valid_loss_0": "3.96", "valid_loss_1": "0.123", "valid_loss_2": "0.016", "valid_accuracy": "0.26227", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "29400", "valid_best_loss": "3.327"}
[2022-01-03 15:57:51,805][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 735 @ 29400 updates
[2022-01-03 15:57:51,806][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:57:55,475][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:57:55,494][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 735 @ 29400 updates, score 4.099) (writing took 3.688762867823243 seconds)
[2022-01-03 15:57:55,494][fairseq_cli.train][INFO] - end of epoch 735 (average epoch stats below)
[2022-01-03 15:57:55,508][train][INFO] - {"epoch": 735, "train_loss": "3.787", "train_ntokens": "1781.67", "train_nsentences": "4.95", "train_prob_perplexity": "98.177", "train_code_perplexity": "96.767", "train_temp": "1.727", "train_loss_0": "3.648", "train_loss_1": "0.122", "train_loss_2": "0.017", "train_accuracy": "0.30802", "train_wps": "3921", "train_ups": "2.2", "train_wpb": "1781.7", "train_bsz": "5", "train_num_updates": "29400", "train_lr": "0.000459375", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13693"}
[2022-01-03 15:57:55,546][fairseq.trainer][INFO] - begin training epoch 736
[2022-01-03 15:57:55,547][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:58:09,329][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:58:09,750][valid][INFO] - {"epoch": 736, "valid_loss": "3.649", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "93.818", "valid_code_perplexity": "91.34", "valid_temp": "1.726", "valid_loss_0": "3.509", "valid_loss_1": "0.123", "valid_loss_2": "0.017", "valid_accuracy": "0.30548", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "29440", "valid_best_loss": "3.327"}
[2022-01-03 15:58:09,754][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 736 @ 29440 updates
[2022-01-03 15:58:09,755][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:58:13,676][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:58:13,705][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 736 @ 29440 updates, score 3.649) (writing took 3.9509216398000717 seconds)
[2022-01-03 15:58:13,705][fairseq_cli.train][INFO] - end of epoch 736 (average epoch stats below)
[2022-01-03 15:58:13,718][train][INFO] - {"epoch": 736, "train_loss": "3.831", "train_ntokens": "1794.95", "train_nsentences": "4.95", "train_prob_perplexity": "98.92", "train_code_perplexity": "97.456", "train_temp": "1.726", "train_loss_0": "3.693", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30249", "train_wps": "3945.5", "train_ups": "2.2", "train_wpb": "1795", "train_bsz": "5", "train_num_updates": "29440", "train_lr": "0.00046", "train_gnorm": "0.531", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "13711"}
[2022-01-03 15:58:13,790][fairseq.trainer][INFO] - begin training epoch 737
[2022-01-03 15:58:13,790][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:58:27,594][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:58:28,085][valid][INFO] - {"epoch": 737, "valid_loss": "4.123", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "95.29", "valid_code_perplexity": "92.089", "valid_temp": "1.726", "valid_loss_0": "3.985", "valid_loss_1": "0.123", "valid_loss_2": "0.015", "valid_accuracy": "0.27112", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "29480", "valid_best_loss": "3.327"}
[2022-01-03 15:58:28,086][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 737 @ 29480 updates
[2022-01-03 15:58:28,087][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:58:31,884][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:58:31,913][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 737 @ 29480 updates, score 4.123) (writing took 3.826467489823699 seconds)
[2022-01-03 15:58:31,913][fairseq_cli.train][INFO] - end of epoch 737 (average epoch stats below)
[2022-01-03 15:58:31,926][train][INFO] - {"epoch": 737, "train_loss": "3.806", "train_ntokens": "1785.35", "train_nsentences": "4.95", "train_prob_perplexity": "98.978", "train_code_perplexity": "97.487", "train_temp": "1.726", "train_loss_0": "3.667", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30565", "train_wps": "3924.8", "train_ups": "2.2", "train_wpb": "1785.3", "train_bsz": "5", "train_num_updates": "29480", "train_lr": "0.000460625", "train_gnorm": "0.557", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "13729"}
[2022-01-03 15:58:32,002][fairseq.trainer][INFO] - begin training epoch 738
[2022-01-03 15:58:32,003][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:58:45,902][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:58:46,296][valid][INFO] - {"epoch": 738, "valid_loss": "3.704", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "87.176", "valid_code_perplexity": "83.997", "valid_temp": "1.726", "valid_loss_0": "3.56", "valid_loss_1": "0.125", "valid_loss_2": "0.02", "valid_accuracy": "0.33079", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "29520", "valid_best_loss": "3.327"}
[2022-01-03 15:58:46,299][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 738 @ 29520 updates
[2022-01-03 15:58:46,300][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:58:50,121][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:58:50,149][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 738 @ 29520 updates, score 3.704) (writing took 3.850518310442567 seconds)
[2022-01-03 15:58:50,150][fairseq_cli.train][INFO] - end of epoch 738 (average epoch stats below)
[2022-01-03 15:58:50,163][train][INFO] - {"epoch": 738, "train_loss": "3.836", "train_ntokens": "1795.8", "train_nsentences": "4.95", "train_prob_perplexity": "98.804", "train_code_perplexity": "97.385", "train_temp": "1.726", "train_loss_0": "3.698", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30072", "train_wps": "3941.6", "train_ups": "2.19", "train_wpb": "1795.8", "train_bsz": "5", "train_num_updates": "29520", "train_lr": "0.00046125", "train_gnorm": "0.543", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13748"}
[2022-01-03 15:58:50,220][fairseq.trainer][INFO] - begin training epoch 739
[2022-01-03 15:58:50,220][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:59:04,038][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:59:04,453][valid][INFO] - {"epoch": 739, "valid_loss": "3.696", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "96.904", "valid_code_perplexity": "94.328", "valid_temp": "1.725", "valid_loss_0": "3.559", "valid_loss_1": "0.122", "valid_loss_2": "0.015", "valid_accuracy": "0.32884", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "29560", "valid_best_loss": "3.327"}
[2022-01-03 15:59:04,456][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 739 @ 29560 updates
[2022-01-03 15:59:04,457][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:59:08,426][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:59:08,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 739 @ 29560 updates, score 3.696) (writing took 3.9961056783795357 seconds)
[2022-01-03 15:59:08,453][fairseq_cli.train][INFO] - end of epoch 739 (average epoch stats below)
[2022-01-03 15:59:08,466][train][INFO] - {"epoch": 739, "train_loss": "3.809", "train_ntokens": "1772.35", "train_nsentences": "4.95", "train_prob_perplexity": "99.775", "train_code_perplexity": "98.212", "train_temp": "1.725", "train_loss_0": "3.67", "train_loss_1": "0.122", "train_loss_2": "0.017", "train_accuracy": "0.30688", "train_wps": "3876.1", "train_ups": "2.19", "train_wpb": "1772.3", "train_bsz": "5", "train_num_updates": "29560", "train_lr": "0.000461875", "train_gnorm": "0.544", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13766"}
[2022-01-03 15:59:08,523][fairseq.trainer][INFO] - begin training epoch 740
[2022-01-03 15:59:08,523][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:59:22,494][train_inner][INFO] - {"epoch": 740, "update": 740.0, "loss": "3.815", "ntokens": "1787.36", "nsentences": "4.95", "prob_perplexity": "99.164", "code_perplexity": "97.683", "temp": "1.726", "loss_0": "3.676", "loss_1": "0.122", "loss_2": "0.016", "accuracy": "0.30481", "wps": "3924.9", "ups": "2.2", "wpb": "1787.4", "bsz": "5", "num_updates": "29600", "lr": "0.0004625", "gnorm": "0.542", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "13780"}
[2022-01-03 15:59:22,495][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:59:22,904][valid][INFO] - {"epoch": 740, "valid_loss": "3.525", "valid_ntokens": "816", "valid_nsentences": "2", "valid_prob_perplexity": "95.719", "valid_code_perplexity": "93.816", "valid_temp": "1.725", "valid_loss_0": "3.387", "valid_loss_1": "0.123", "valid_loss_2": "0.015", "valid_accuracy": "0.35539", "valid_wps": "0", "valid_wpb": "816", "valid_bsz": "2", "valid_num_updates": "29600", "valid_best_loss": "3.327"}
[2022-01-03 15:59:22,906][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 740 @ 29600 updates
[2022-01-03 15:59:22,907][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:59:26,623][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:59:26,650][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 740 @ 29600 updates, score 3.525) (writing took 3.7438557678833604 seconds)
[2022-01-03 15:59:26,651][fairseq_cli.train][INFO] - end of epoch 740 (average epoch stats below)
[2022-01-03 15:59:26,663][train][INFO] - {"epoch": 740, "train_loss": "3.79", "train_ntokens": "1788.35", "train_nsentences": "4.95", "train_prob_perplexity": "99.341", "train_code_perplexity": "97.874", "train_temp": "1.725", "train_loss_0": "3.652", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30837", "train_wps": "3933.7", "train_ups": "2.2", "train_wpb": "1788.3", "train_bsz": "5", "train_num_updates": "29600", "train_lr": "0.0004625", "train_gnorm": "0.534", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13784"}
[2022-01-03 15:59:26,718][fairseq.trainer][INFO] - begin training epoch 741
[2022-01-03 15:59:26,719][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:59:40,586][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:59:41,086][valid][INFO] - {"epoch": 741, "valid_loss": "3.624", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "93.685", "valid_code_perplexity": "91.326", "valid_temp": "1.725", "valid_loss_0": "3.485", "valid_loss_1": "0.123", "valid_loss_2": "0.016", "valid_accuracy": "0.34366", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "29640", "valid_best_loss": "3.327"}
[2022-01-03 15:59:41,087][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 741 @ 29640 updates
[2022-01-03 15:59:41,088][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:59:44,897][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 15:59:44,928][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 741 @ 29640 updates, score 3.624) (writing took 3.8407404320314527 seconds)
[2022-01-03 15:59:44,929][fairseq_cli.train][INFO] - end of epoch 741 (average epoch stats below)
[2022-01-03 15:59:44,943][train][INFO] - {"epoch": 741, "train_loss": "3.799", "train_ntokens": "1780.7", "train_nsentences": "4.95", "train_prob_perplexity": "100.398", "train_code_perplexity": "98.843", "train_temp": "1.725", "train_loss_0": "3.661", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30759", "train_wps": "3899.5", "train_ups": "2.19", "train_wpb": "1780.7", "train_bsz": "5", "train_num_updates": "29640", "train_lr": "0.000463125", "train_gnorm": "0.537", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "13802"}
[2022-01-03 15:59:45,004][fairseq.trainer][INFO] - begin training epoch 742
[2022-01-03 15:59:45,005][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 15:59:58,893][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 15:59:59,304][valid][INFO] - {"epoch": 742, "valid_loss": "3.724", "valid_ntokens": "696", "valid_nsentences": "2", "valid_prob_perplexity": "87.578", "valid_code_perplexity": "84.285", "valid_temp": "1.724", "valid_loss_0": "3.581", "valid_loss_1": "0.125", "valid_loss_2": "0.019", "valid_accuracy": "0.32615", "valid_wps": "0", "valid_wpb": "696", "valid_bsz": "2", "valid_num_updates": "29680", "valid_best_loss": "3.327"}
[2022-01-03 15:59:59,307][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 742 @ 29680 updates
[2022-01-03 15:59:59,308][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:00:03,165][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:00:03,193][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 742 @ 29680 updates, score 3.724) (writing took 3.885832691565156 seconds)
[2022-01-03 16:00:03,193][fairseq_cli.train][INFO] - end of epoch 742 (average epoch stats below)
[2022-01-03 16:00:03,206][train][INFO] - {"epoch": 742, "train_loss": "3.846", "train_ntokens": "1794.15", "train_nsentences": "4.95", "train_prob_perplexity": "100.678", "train_code_perplexity": "99.151", "train_temp": "1.724", "train_loss_0": "3.708", "train_loss_1": "0.122", "train_loss_2": "0.016", "train_accuracy": "0.30176", "train_wps": "3932.4", "train_ups": "2.19", "train_wpb": "1794.2", "train_bsz": "5", "train_num_updates": "29680", "train_lr": "0.00046375", "train_gnorm": "0.541", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "13821"}
[2022-01-03 16:00:03,246][fairseq.trainer][INFO] - begin training epoch 743
[2022-01-03 16:00:03,247][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:00:17,028][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:00:17,439][valid][INFO] - {"epoch": 743, "valid_loss": "3.544", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "99.403", "valid_code_perplexity": "96.224", "valid_temp": "1.724", "valid_loss_0": "3.405", "valid_loss_1": "0.122", "valid_loss_2": "0.017", "valid_accuracy": "0.32152", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "29720", "valid_best_loss": "3.327"}
[2022-01-03 16:00:17,442][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 743 @ 29720 updates
[2022-01-03 16:00:17,443][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:00:21,360][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:00:21,388][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 743 @ 29720 updates, score 3.544) (writing took 3.946098451502621 seconds)
[2022-01-03 16:00:21,389][fairseq_cli.train][INFO] - end of epoch 743 (average epoch stats below)
[2022-01-03 16:00:21,402][train][INFO] - {"epoch": 743, "train_loss": "3.813", "train_ntokens": "1800.28", "train_nsentences": "4.95", "train_prob_perplexity": "101.552", "train_code_perplexity": "99.985", "train_temp": "1.724", "train_loss_0": "3.675", "train_loss_1": "0.121", "train_loss_2": "0.017", "train_accuracy": "0.304", "train_wps": "3960.4", "train_ups": "2.2", "train_wpb": "1800.3", "train_bsz": "5", "train_num_updates": "29720", "train_lr": "0.000464375", "train_gnorm": "0.537", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13839"}
[2022-01-03 16:00:21,481][fairseq.trainer][INFO] - begin training epoch 744
[2022-01-03 16:00:21,482][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:00:35,347][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:00:35,834][valid][INFO] - {"epoch": 744, "valid_loss": "3.738", "valid_ntokens": "790", "valid_nsentences": "2", "valid_prob_perplexity": "99.018", "valid_code_perplexity": "95.613", "valid_temp": "1.723", "valid_loss_0": "3.601", "valid_loss_1": "0.122", "valid_loss_2": "0.016", "valid_accuracy": "0.33038", "valid_wps": "0", "valid_wpb": "790", "valid_bsz": "2", "valid_num_updates": "29760", "valid_best_loss": "3.327"}
[2022-01-03 16:00:35,837][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 744 @ 29760 updates
[2022-01-03 16:00:35,837][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:00:39,639][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:00:39,659][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 744 @ 29760 updates, score 3.738) (writing took 3.821990966796875 seconds)
[2022-01-03 16:00:39,659][fairseq_cli.train][INFO] - end of epoch 744 (average epoch stats below)
[2022-01-03 16:00:39,671][train][INFO] - {"epoch": 744, "train_loss": "3.803", "train_ntokens": "1786.9", "train_nsentences": "4.95", "train_prob_perplexity": "102", "train_code_perplexity": "100.247", "train_temp": "1.724", "train_loss_0": "3.666", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.3068", "train_wps": "3915", "train_ups": "2.19", "train_wpb": "1786.9", "train_bsz": "5", "train_num_updates": "29760", "train_lr": "0.000465", "train_gnorm": "0.539", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "13857"}
[2022-01-03 16:00:39,726][fairseq.trainer][INFO] - begin training epoch 745
[2022-01-03 16:00:39,726][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:00:53,606][train_inner][INFO] - {"epoch": 745, "update": 745.0, "loss": "3.812", "ntokens": "1792.69", "nsentences": "4.95", "prob_perplexity": "101.414", "code_perplexity": "99.775", "temp": "1.724", "loss_0": "3.675", "loss_1": "0.121", "loss_2": "0.016", "accuracy": "0.30541", "wps": "3935.7", "ups": "2.2", "wpb": "1792.7", "bsz": "5", "num_updates": "29800", "lr": "0.000465625", "gnorm": "0.539", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "13871"}
[2022-01-03 16:00:53,607][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:00:54,018][valid][INFO] - {"epoch": 745, "valid_loss": "3.676", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "99.308", "valid_code_perplexity": "96.741", "valid_temp": "1.723", "valid_loss_0": "3.539", "valid_loss_1": "0.122", "valid_loss_2": "0.014", "valid_accuracy": "0.32353", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "29800", "valid_best_loss": "3.327"}
[2022-01-03 16:00:54,022][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 745 @ 29800 updates
[2022-01-03 16:00:54,023][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:00:57,984][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:00:58,011][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 745 @ 29800 updates, score 3.676) (writing took 3.989054032601416 seconds)
[2022-01-03 16:00:58,011][fairseq_cli.train][INFO] - end of epoch 745 (average epoch stats below)
[2022-01-03 16:00:58,024][train][INFO] - {"epoch": 745, "train_loss": "3.799", "train_ntokens": "1801.42", "train_nsentences": "4.95", "train_prob_perplexity": "102.443", "train_code_perplexity": "100.649", "train_temp": "1.723", "train_loss_0": "3.662", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.30692", "train_wps": "3928.9", "train_ups": "2.18", "train_wpb": "1801.4", "train_bsz": "5", "train_num_updates": "29800", "train_lr": "0.000465625", "train_gnorm": "0.541", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "13875"}
[2022-01-03 16:00:58,094][fairseq.trainer][INFO] - begin training epoch 746
[2022-01-03 16:00:58,095][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:01:12,088][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:01:12,489][valid][INFO] - {"epoch": 746, "valid_loss": "3.553", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "103.765", "valid_code_perplexity": "101.116", "valid_temp": "1.723", "valid_loss_0": "3.416", "valid_loss_1": "0.121", "valid_loss_2": "0.016", "valid_accuracy": "0.37534", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "29840", "valid_best_loss": "3.327"}
[2022-01-03 16:01:12,492][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 746 @ 29840 updates
[2022-01-03 16:01:12,493][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:01:16,215][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:01:16,234][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 746 @ 29840 updates, score 3.553) (writing took 3.742278558202088 seconds)
[2022-01-03 16:01:16,235][fairseq_cli.train][INFO] - end of epoch 746 (average epoch stats below)
[2022-01-03 16:01:16,247][train][INFO] - {"epoch": 746, "train_loss": "3.792", "train_ntokens": "1775.35", "train_nsentences": "4.95", "train_prob_perplexity": "103.294", "train_code_perplexity": "101.529", "train_temp": "1.723", "train_loss_0": "3.655", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.30697", "train_wps": "3899.5", "train_ups": "2.2", "train_wpb": "1775.3", "train_bsz": "5", "train_num_updates": "29840", "train_lr": "0.00046625", "train_gnorm": "0.543", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13894"}
[2022-01-03 16:01:16,303][fairseq.trainer][INFO] - begin training epoch 747
[2022-01-03 16:01:16,304][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:01:30,145][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:01:30,545][valid][INFO] - {"epoch": 747, "valid_loss": "3.496", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "99.603", "valid_code_perplexity": "96.62", "valid_temp": "1.722", "valid_loss_0": "3.36", "valid_loss_1": "0.122", "valid_loss_2": "0.014", "valid_accuracy": "0.36376", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "29880", "valid_best_loss": "3.327"}
[2022-01-03 16:01:30,548][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 747 @ 29880 updates
[2022-01-03 16:01:30,549][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:01:34,433][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:01:34,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 747 @ 29880 updates, score 3.496) (writing took 3.9115274595096707 seconds)
[2022-01-03 16:01:34,460][fairseq_cli.train][INFO] - end of epoch 747 (average epoch stats below)
[2022-01-03 16:01:34,473][train][INFO] - {"epoch": 747, "train_loss": "3.802", "train_ntokens": "1797.55", "train_nsentences": "4.95", "train_prob_perplexity": "103.668", "train_code_perplexity": "102.02", "train_temp": "1.723", "train_loss_0": "3.665", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.30418", "train_wps": "3947.8", "train_ups": "2.2", "train_wpb": "1797.5", "train_bsz": "5", "train_num_updates": "29880", "train_lr": "0.000466875", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13912"}
[2022-01-03 16:01:34,548][fairseq.trainer][INFO] - begin training epoch 748
[2022-01-03 16:01:34,549][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:01:48,503][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:01:48,908][valid][INFO] - {"epoch": 748, "valid_loss": "3.594", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "100.303", "valid_code_perplexity": "98.071", "valid_temp": "1.722", "valid_loss_0": "3.456", "valid_loss_1": "0.122", "valid_loss_2": "0.016", "valid_accuracy": "0.33333", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "29920", "valid_best_loss": "3.327"}
[2022-01-03 16:01:48,911][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 748 @ 29920 updates
[2022-01-03 16:01:48,911][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:01:52,766][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:01:52,795][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 748 @ 29920 updates, score 3.594) (writing took 3.8845667894929647 seconds)
[2022-01-03 16:01:52,796][fairseq_cli.train][INFO] - end of epoch 748 (average epoch stats below)
[2022-01-03 16:01:52,808][train][INFO] - {"epoch": 748, "train_loss": "3.802", "train_ntokens": "1799.92", "train_nsentences": "4.95", "train_prob_perplexity": "103.743", "train_code_perplexity": "102.188", "train_temp": "1.722", "train_loss_0": "3.665", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.30793", "train_wps": "3929.5", "train_ups": "2.18", "train_wpb": "1799.9", "train_bsz": "5", "train_num_updates": "29920", "train_lr": "0.0004675", "train_gnorm": "0.535", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "13930"}
[2022-01-03 16:01:52,867][fairseq.trainer][INFO] - begin training epoch 749
[2022-01-03 16:01:52,868][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:02:06,554][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:02:06,974][valid][INFO] - {"epoch": 749, "valid_loss": "3.906", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "101.38", "valid_code_perplexity": "98.233", "valid_temp": "1.722", "valid_loss_0": "3.767", "valid_loss_1": "0.121", "valid_loss_2": "0.017", "valid_accuracy": "0.30052", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "29960", "valid_best_loss": "3.327"}
[2022-01-03 16:02:06,978][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 749 @ 29960 updates
[2022-01-03 16:02:06,979][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:02:10,916][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:02:10,924][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 749 @ 29960 updates, score 3.906) (writing took 3.946343089453876 seconds)
[2022-01-03 16:02:10,925][fairseq_cli.train][INFO] - end of epoch 749 (average epoch stats below)
[2022-01-03 16:02:10,938][train][INFO] - {"epoch": 749, "train_loss": "3.816", "train_ntokens": "1773.03", "train_nsentences": "4.95", "train_prob_perplexity": "104.093", "train_code_perplexity": "102.451", "train_temp": "1.722", "train_loss_0": "3.679", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.30559", "train_wps": "3914.7", "train_ups": "2.21", "train_wpb": "1773", "train_bsz": "5", "train_num_updates": "29960", "train_lr": "0.000468125", "train_gnorm": "0.542", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13948"}
[2022-01-03 16:02:11,018][fairseq.trainer][INFO] - begin training epoch 750
[2022-01-03 16:02:11,019][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:02:24,906][train_inner][INFO] - {"epoch": 750, "update": 750.0, "loss": "3.8", "ntokens": "1784.92", "nsentences": "4.95", "prob_perplexity": "103.903", "code_perplexity": "102.261", "temp": "1.722", "loss_0": "3.664", "loss_1": "0.121", "loss_2": "0.016", "accuracy": "0.30711", "wps": "3910.5", "ups": "2.19", "wpb": "1784.9", "bsz": "5", "num_updates": "30000", "lr": "0.00046875", "gnorm": "0.543", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "13962"}
[2022-01-03 16:02:24,907][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:02:25,328][valid][INFO] - {"epoch": 750, "valid_loss": "3.5", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "102.235", "valid_code_perplexity": "99.127", "valid_temp": "1.721", "valid_loss_0": "3.362", "valid_loss_1": "0.121", "valid_loss_2": "0.017", "valid_accuracy": "0.37042", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "30000", "valid_best_loss": "3.327"}
[2022-01-03 16:02:25,330][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 750 @ 30000 updates
[2022-01-03 16:02:25,331][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:02:29,088][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:02:29,113][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 750 @ 30000 updates, score 3.5) (writing took 3.7826376166194677 seconds)
[2022-01-03 16:02:29,113][fairseq_cli.train][INFO] - end of epoch 750 (average epoch stats below)
[2022-01-03 16:02:29,126][train][INFO] - {"epoch": 750, "train_loss": "3.791", "train_ntokens": "1778.78", "train_nsentences": "4.95", "train_prob_perplexity": "104.717", "train_code_perplexity": "103.117", "train_temp": "1.722", "train_loss_0": "3.654", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.31087", "train_wps": "3914.7", "train_ups": "2.2", "train_wpb": "1778.8", "train_bsz": "5", "train_num_updates": "30000", "train_lr": "0.00046875", "train_gnorm": "0.56", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "13967"}
[2022-01-03 16:02:29,173][fairseq.trainer][INFO] - begin training epoch 751
[2022-01-03 16:02:29,174][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:02:43,001][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:02:43,429][valid][INFO] - {"epoch": 751, "valid_loss": "3.529", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "99.657", "valid_code_perplexity": "96.105", "valid_temp": "1.721", "valid_loss_0": "3.39", "valid_loss_1": "0.122", "valid_loss_2": "0.017", "valid_accuracy": "0.34646", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "30040", "valid_best_loss": "3.327"}
[2022-01-03 16:02:43,432][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 751 @ 30040 updates
[2022-01-03 16:02:43,433][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:02:47,345][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:02:47,375][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 751 @ 30040 updates, score 3.529) (writing took 3.942566697485745 seconds)
[2022-01-03 16:02:47,375][fairseq_cli.train][INFO] - end of epoch 751 (average epoch stats below)
[2022-01-03 16:02:47,388][train][INFO] - {"epoch": 751, "train_loss": "3.755", "train_ntokens": "1798.6", "train_nsentences": "4.95", "train_prob_perplexity": "104.376", "train_code_perplexity": "102.688", "train_temp": "1.721", "train_loss_0": "3.619", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.30941", "train_wps": "3942.3", "train_ups": "2.19", "train_wpb": "1798.6", "train_bsz": "5", "train_num_updates": "30040", "train_lr": "0.000469375", "train_gnorm": "0.547", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "13985"}
[2022-01-03 16:02:47,462][fairseq.trainer][INFO] - begin training epoch 752
[2022-01-03 16:02:47,463][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:03:01,471][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:03:01,877][valid][INFO] - {"epoch": 752, "valid_loss": "3.952", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "100.768", "valid_code_perplexity": "99.127", "valid_temp": "1.721", "valid_loss_0": "3.816", "valid_loss_1": "0.122", "valid_loss_2": "0.015", "valid_accuracy": "0.26823", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "30080", "valid_best_loss": "3.327"}
[2022-01-03 16:03:01,880][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 752 @ 30080 updates
[2022-01-03 16:03:01,881][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:03:05,556][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:03:05,587][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 752 @ 30080 updates, score 3.952) (writing took 3.7063805954530835 seconds)
[2022-01-03 16:03:05,587][fairseq_cli.train][INFO] - end of epoch 752 (average epoch stats below)
[2022-01-03 16:03:05,600][train][INFO] - {"epoch": 752, "train_loss": "3.795", "train_ntokens": "1791.58", "train_nsentences": "4.95", "train_prob_perplexity": "104.934", "train_code_perplexity": "103.268", "train_temp": "1.721", "train_loss_0": "3.658", "train_loss_1": "0.121", "train_loss_2": "0.016", "train_accuracy": "0.30567", "train_wps": "3937.8", "train_ups": "2.2", "train_wpb": "1791.6", "train_bsz": "5", "train_num_updates": "30080", "train_lr": "0.00047", "train_gnorm": "0.548", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14003"}
[2022-01-03 16:03:05,669][fairseq.trainer][INFO] - begin training epoch 753
[2022-01-03 16:03:05,669][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:03:19,514][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:03:19,916][valid][INFO] - {"epoch": 753, "valid_loss": "3.494", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "102.863", "valid_code_perplexity": "100.343", "valid_temp": "1.72", "valid_loss_0": "3.357", "valid_loss_1": "0.121", "valid_loss_2": "0.016", "valid_accuracy": "0.38127", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "30120", "valid_best_loss": "3.327"}
[2022-01-03 16:03:19,919][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 753 @ 30120 updates
[2022-01-03 16:03:19,919][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:03:23,885][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:03:23,913][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 753 @ 30120 updates, score 3.494) (writing took 3.9940267857164145 seconds)
[2022-01-03 16:03:23,913][fairseq_cli.train][INFO] - end of epoch 753 (average epoch stats below)
[2022-01-03 16:03:23,926][train][INFO] - {"epoch": 753, "train_loss": "3.829", "train_ntokens": "1802.7", "train_nsentences": "4.95", "train_prob_perplexity": "104.705", "train_code_perplexity": "103.104", "train_temp": "1.721", "train_loss_0": "3.693", "train_loss_1": "0.121", "train_loss_2": "0.015", "train_accuracy": "0.3004", "train_wps": "3937.4", "train_ups": "2.18", "train_wpb": "1802.7", "train_bsz": "5", "train_num_updates": "30120", "train_lr": "0.000470625", "train_gnorm": "0.554", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "14021"}
[2022-01-03 16:03:24,010][fairseq.trainer][INFO] - begin training epoch 754
[2022-01-03 16:03:24,011][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:03:37,934][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:03:38,337][valid][INFO] - {"epoch": 754, "valid_loss": "3.658", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "104.617", "valid_code_perplexity": "102.26", "valid_temp": "1.72", "valid_loss_0": "3.52", "valid_loss_1": "0.121", "valid_loss_2": "0.017", "valid_accuracy": "0.31186", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "30160", "valid_best_loss": "3.327"}
[2022-01-03 16:03:38,340][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 754 @ 30160 updates
[2022-01-03 16:03:38,341][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:03:42,092][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:03:42,119][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 754 @ 30160 updates, score 3.658) (writing took 3.7788820965215564 seconds)
[2022-01-03 16:03:42,120][fairseq_cli.train][INFO] - end of epoch 754 (average epoch stats below)
[2022-01-03 16:03:42,132][train][INFO] - {"epoch": 754, "train_loss": "3.775", "train_ntokens": "1812.15", "train_nsentences": "4.95", "train_prob_perplexity": "105.691", "train_code_perplexity": "104.165", "train_temp": "1.72", "train_loss_0": "3.639", "train_loss_1": "0.12", "train_loss_2": "0.016", "train_accuracy": "0.30825", "train_wps": "3984.2", "train_ups": "2.2", "train_wpb": "1812.2", "train_bsz": "5", "train_num_updates": "30160", "train_lr": "0.00047125", "train_gnorm": "0.519", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14040"}
[2022-01-03 16:03:42,210][fairseq.trainer][INFO] - begin training epoch 755
[2022-01-03 16:03:42,211][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:03:56,047][train_inner][INFO] - {"epoch": 755, "update": 755.0, "loss": "3.8", "ntokens": "1800.29", "nsentences": "4.95", "prob_perplexity": "105.079", "code_perplexity": "103.427", "temp": "1.721", "loss_0": "3.663", "loss_1": "0.121", "loss_2": "0.016", "accuracy": "0.30479", "wps": "3951.1", "ups": "2.19", "wpb": "1800.3", "bsz": "5", "num_updates": "30200", "lr": "0.000471875", "gnorm": "0.539", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "14053"}
[2022-01-03 16:03:56,048][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:03:56,542][valid][INFO] - {"epoch": 755, "valid_loss": "3.538", "valid_ntokens": "796", "valid_nsentences": "2", "valid_prob_perplexity": "100.986", "valid_code_perplexity": "98.003", "valid_temp": "1.72", "valid_loss_0": "3.401", "valid_loss_1": "0.122", "valid_loss_2": "0.015", "valid_accuracy": "0.34171", "valid_wps": "0", "valid_wpb": "796", "valid_bsz": "2", "valid_num_updates": "30200", "valid_best_loss": "3.327"}
[2022-01-03 16:03:56,543][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 755 @ 30200 updates
[2022-01-03 16:03:56,544][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:04:00,349][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:04:00,378][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 755 @ 30200 updates, score 3.538) (writing took 3.8343012100085616 seconds)
[2022-01-03 16:04:00,378][fairseq_cli.train][INFO] - end of epoch 755 (average epoch stats below)
[2022-01-03 16:04:00,391][train][INFO] - {"epoch": 755, "train_loss": "3.844", "train_ntokens": "1796.4", "train_nsentences": "4.95", "train_prob_perplexity": "105.688", "train_code_perplexity": "103.91", "train_temp": "1.72", "train_loss_0": "3.708", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.30018", "train_wps": "3938.2", "train_ups": "2.19", "train_wpb": "1796.4", "train_bsz": "5", "train_num_updates": "30200", "train_lr": "0.000471875", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14058"}
[2022-01-03 16:04:00,468][fairseq.trainer][INFO] - begin training epoch 756
[2022-01-03 16:04:00,469][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:04:14,311][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:04:14,714][valid][INFO] - {"epoch": 756, "valid_loss": "3.297", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "101.761", "valid_code_perplexity": "98.772", "valid_temp": "1.719", "valid_loss_0": "3.162", "valid_loss_1": "0.121", "valid_loss_2": "0.014", "valid_accuracy": "0.38904", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "30240", "valid_best_loss": "3.297"}
[2022-01-03 16:04:14,717][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 756 @ 30240 updates
[2022-01-03 16:04:14,718][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 16:04:18,686][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 16:04:26,550][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 756 @ 30240 updates, score 3.297) (writing took 11.833048813045025 seconds)
[2022-01-03 16:04:26,550][fairseq_cli.train][INFO] - end of epoch 756 (average epoch stats below)
[2022-01-03 16:04:26,564][train][INFO] - {"epoch": 756, "train_loss": "3.781", "train_ntokens": "1800.33", "train_nsentences": "4.95", "train_prob_perplexity": "105.765", "train_code_perplexity": "104.148", "train_temp": "1.72", "train_loss_0": "3.645", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.30779", "train_wps": "2752.9", "train_ups": "1.53", "train_wpb": "1800.3", "train_bsz": "5", "train_num_updates": "30240", "train_lr": "0.0004725", "train_gnorm": "0.527", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14084"}
[2022-01-03 16:04:26,643][fairseq.trainer][INFO] - begin training epoch 757
[2022-01-03 16:04:26,644][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:04:40,334][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:04:40,735][valid][INFO] - {"epoch": 757, "valid_loss": "3.807", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "103.651", "valid_code_perplexity": "100.342", "valid_temp": "1.719", "valid_loss_0": "3.67", "valid_loss_1": "0.121", "valid_loss_2": "0.016", "valid_accuracy": "0.32092", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "30280", "valid_best_loss": "3.297"}
[2022-01-03 16:04:40,738][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 757 @ 30280 updates
[2022-01-03 16:04:40,739][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:04:44,647][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:04:44,670][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 757 @ 30280 updates, score 3.807) (writing took 3.9313197499141097 seconds)
[2022-01-03 16:04:44,670][fairseq_cli.train][INFO] - end of epoch 757 (average epoch stats below)
[2022-01-03 16:04:44,683][train][INFO] - {"epoch": 757, "train_loss": "3.781", "train_ntokens": "1788.78", "train_nsentences": "4.95", "train_prob_perplexity": "105.72", "train_code_perplexity": "104.107", "train_temp": "1.719", "train_loss_0": "3.645", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.30965", "train_wps": "3951.7", "train_ups": "2.21", "train_wpb": "1788.8", "train_bsz": "5", "train_num_updates": "30280", "train_lr": "0.000473125", "train_gnorm": "0.529", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14102"}
[2022-01-03 16:04:44,760][fairseq.trainer][INFO] - begin training epoch 758
[2022-01-03 16:04:44,761][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:04:58,710][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:04:59,105][valid][INFO] - {"epoch": 758, "valid_loss": "3.487", "valid_ntokens": "700", "valid_nsentences": "2", "valid_prob_perplexity": "102.996", "valid_code_perplexity": "100.009", "valid_temp": "1.719", "valid_loss_0": "3.351", "valid_loss_1": "0.121", "valid_loss_2": "0.015", "valid_accuracy": "0.34", "valid_wps": "0", "valid_wpb": "700", "valid_bsz": "2", "valid_num_updates": "30320", "valid_best_loss": "3.297"}
[2022-01-03 16:04:59,109][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 758 @ 30320 updates
[2022-01-03 16:04:59,110][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:05:02,902][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:05:02,931][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 758 @ 30320 updates, score 3.487) (writing took 3.822429114021361 seconds)
[2022-01-03 16:05:02,932][fairseq_cli.train][INFO] - end of epoch 758 (average epoch stats below)
[2022-01-03 16:05:02,944][train][INFO] - {"epoch": 758, "train_loss": "3.774", "train_ntokens": "1775.62", "train_nsentences": "4.95", "train_prob_perplexity": "105.851", "train_code_perplexity": "104.188", "train_temp": "1.719", "train_loss_0": "3.638", "train_loss_1": "0.12", "train_loss_2": "0.016", "train_accuracy": "0.31082", "train_wps": "3892.1", "train_ups": "2.19", "train_wpb": "1775.6", "train_bsz": "5", "train_num_updates": "30320", "train_lr": "0.00047375", "train_gnorm": "0.537", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.7", "train_wall": "14120"}
[2022-01-03 16:05:03,024][fairseq.trainer][INFO] - begin training epoch 759
[2022-01-03 16:05:03,025][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:05:16,965][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:05:17,375][valid][INFO] - {"epoch": 759, "valid_loss": "3.734", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "103.721", "valid_code_perplexity": "101.437", "valid_temp": "1.718", "valid_loss_0": "3.599", "valid_loss_1": "0.121", "valid_loss_2": "0.014", "valid_accuracy": "0.29464", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "30360", "valid_best_loss": "3.297"}
[2022-01-03 16:05:17,379][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 759 @ 30360 updates
[2022-01-03 16:05:17,380][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:05:21,314][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:05:21,341][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 759 @ 30360 updates, score 3.734) (writing took 3.9621719056740403 seconds)
[2022-01-03 16:05:21,342][fairseq_cli.train][INFO] - end of epoch 759 (average epoch stats below)
[2022-01-03 16:05:21,354][train][INFO] - {"epoch": 759, "train_loss": "3.8", "train_ntokens": "1793.38", "train_nsentences": "4.95", "train_prob_perplexity": "105.76", "train_code_perplexity": "104.01", "train_temp": "1.718", "train_loss_0": "3.664", "train_loss_1": "0.12", "train_loss_2": "0.016", "train_accuracy": "0.30595", "train_wps": "3899", "train_ups": "2.17", "train_wpb": "1793.4", "train_bsz": "5", "train_num_updates": "30360", "train_lr": "0.000474375", "train_gnorm": "0.522", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "14139"}
[2022-01-03 16:05:21,428][fairseq.trainer][INFO] - begin training epoch 760
[2022-01-03 16:05:21,428][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:05:35,307][train_inner][INFO] - {"epoch": 760, "update": 760.0, "loss": "3.788", "ntokens": "1790.14", "nsentences": "4.95", "prob_perplexity": "105.859", "code_perplexity": "104.17", "temp": "1.719", "loss_0": "3.652", "loss_1": "0.12", "loss_2": "0.015", "accuracy": "0.30794", "wps": "3607.5", "ups": "2.02", "wpb": "1790.1", "bsz": "5", "num_updates": "30400", "lr": "0.000475", "gnorm": "0.529", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "14153"}
[2022-01-03 16:05:35,308][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:05:35,715][valid][INFO] - {"epoch": 760, "valid_loss": "3.463", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "98.875", "valid_code_perplexity": "95.972", "valid_temp": "1.718", "valid_loss_0": "3.326", "valid_loss_1": "0.122", "valid_loss_2": "0.015", "valid_accuracy": "0.35751", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "30400", "valid_best_loss": "3.297"}
[2022-01-03 16:05:35,719][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 760 @ 30400 updates
[2022-01-03 16:05:35,720][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:05:39,581][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:05:39,610][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 760 @ 30400 updates, score 3.463) (writing took 3.8904911912977695 seconds)
[2022-01-03 16:05:39,610][fairseq_cli.train][INFO] - end of epoch 760 (average epoch stats below)
[2022-01-03 16:05:39,623][train][INFO] - {"epoch": 760, "train_loss": "3.806", "train_ntokens": "1792.62", "train_nsentences": "4.95", "train_prob_perplexity": "106.198", "train_code_perplexity": "104.398", "train_temp": "1.718", "train_loss_0": "3.67", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.3055", "train_wps": "3927.8", "train_ups": "2.19", "train_wpb": "1792.6", "train_bsz": "5", "train_num_updates": "30400", "train_lr": "0.000475", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14157"}
[2022-01-03 16:05:39,706][fairseq.trainer][INFO] - begin training epoch 761
[2022-01-03 16:05:39,707][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:05:53,672][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:05:54,157][valid][INFO] - {"epoch": 761, "valid_loss": "3.699", "valid_ntokens": "802", "valid_nsentences": "2", "valid_prob_perplexity": "100.006", "valid_code_perplexity": "97.308", "valid_temp": "1.718", "valid_loss_0": "3.563", "valid_loss_1": "0.122", "valid_loss_2": "0.015", "valid_accuracy": "0.31671", "valid_wps": "0", "valid_wpb": "802", "valid_bsz": "2", "valid_num_updates": "30440", "valid_best_loss": "3.297"}
[2022-01-03 16:05:54,159][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 761 @ 30440 updates
[2022-01-03 16:05:54,160][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:05:57,828][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:05:57,854][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 761 @ 30440 updates, score 3.699) (writing took 3.6946341656148434 seconds)
[2022-01-03 16:05:57,854][fairseq_cli.train][INFO] - end of epoch 761 (average epoch stats below)
[2022-01-03 16:05:57,866][train][INFO] - {"epoch": 761, "train_loss": "3.766", "train_ntokens": "1796.88", "train_nsentences": "4.95", "train_prob_perplexity": "107.008", "train_code_perplexity": "105.294", "train_temp": "1.718", "train_loss_0": "3.631", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.31059", "train_wps": "3942.4", "train_ups": "2.19", "train_wpb": "1796.9", "train_bsz": "5", "train_num_updates": "30440", "train_lr": "0.000475625", "train_gnorm": "0.535", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14175"}
[2022-01-03 16:05:57,934][fairseq.trainer][INFO] - begin training epoch 762
[2022-01-03 16:05:57,935][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:06:11,841][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:06:12,269][valid][INFO] - {"epoch": 762, "valid_loss": "3.541", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "104.054", "valid_code_perplexity": "100.681", "valid_temp": "1.717", "valid_loss_0": "3.406", "valid_loss_1": "0.121", "valid_loss_2": "0.014", "valid_accuracy": "0.32997", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "30480", "valid_best_loss": "3.297"}
[2022-01-03 16:06:12,273][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 762 @ 30480 updates
[2022-01-03 16:06:12,275][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:06:16,070][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:06:16,098][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 762 @ 30480 updates, score 3.541) (writing took 3.8246172331273556 seconds)
[2022-01-03 16:06:16,098][fairseq_cli.train][INFO] - end of epoch 762 (average epoch stats below)
[2022-01-03 16:06:16,111][train][INFO] - {"epoch": 762, "train_loss": "3.758", "train_ntokens": "1782.38", "train_nsentences": "4.95", "train_prob_perplexity": "106.884", "train_code_perplexity": "105.124", "train_temp": "1.717", "train_loss_0": "3.623", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.31253", "train_wps": "3910.5", "train_ups": "2.19", "train_wpb": "1782.4", "train_bsz": "5", "train_num_updates": "30480", "train_lr": "0.00047625", "train_gnorm": "0.559", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "14194"}
[2022-01-03 16:06:16,180][fairseq.trainer][INFO] - begin training epoch 763
[2022-01-03 16:06:16,181][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:06:30,055][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:06:30,459][valid][INFO] - {"epoch": 763, "valid_loss": "3.501", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "103.204", "valid_code_perplexity": "98.89", "valid_temp": "1.717", "valid_loss_0": "3.365", "valid_loss_1": "0.121", "valid_loss_2": "0.016", "valid_accuracy": "0.38408", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "30520", "valid_best_loss": "3.297"}
[2022-01-03 16:06:30,461][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 763 @ 30520 updates
[2022-01-03 16:06:30,462][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:06:34,400][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:06:34,430][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 763 @ 30520 updates, score 3.501) (writing took 3.9682956635951996 seconds)
[2022-01-03 16:06:34,430][fairseq_cli.train][INFO] - end of epoch 763 (average epoch stats below)
[2022-01-03 16:06:34,442][train][INFO] - {"epoch": 763, "train_loss": "3.754", "train_ntokens": "1788.2", "train_nsentences": "4.95", "train_prob_perplexity": "108.165", "train_code_perplexity": "106.522", "train_temp": "1.717", "train_loss_0": "3.617", "train_loss_1": "0.12", "train_loss_2": "0.016", "train_accuracy": "0.31371", "train_wps": "3904.5", "train_ups": "2.18", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "30520", "train_lr": "0.000476875", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14212"}
[2022-01-03 16:06:34,521][fairseq.trainer][INFO] - begin training epoch 764
[2022-01-03 16:06:34,522][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:06:48,431][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:06:48,857][valid][INFO] - {"epoch": 764, "valid_loss": "3.675", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "106.253", "valid_code_perplexity": "103.034", "valid_temp": "1.717", "valid_loss_0": "3.54", "valid_loss_1": "0.12", "valid_loss_2": "0.015", "valid_accuracy": "0.34123", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "30560", "valid_best_loss": "3.297"}
[2022-01-03 16:06:48,862][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 764 @ 30560 updates
[2022-01-03 16:06:48,863][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:06:52,594][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:06:52,622][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 764 @ 30560 updates, score 3.675) (writing took 3.7601813478395343 seconds)
[2022-01-03 16:06:52,622][fairseq_cli.train][INFO] - end of epoch 764 (average epoch stats below)
[2022-01-03 16:06:52,636][train][INFO] - {"epoch": 764, "train_loss": "3.776", "train_ntokens": "1790.75", "train_nsentences": "4.95", "train_prob_perplexity": "107.588", "train_code_perplexity": "105.824", "train_temp": "1.717", "train_loss_0": "3.64", "train_loss_1": "0.12", "train_loss_2": "0.016", "train_accuracy": "0.30942", "train_wps": "3940", "train_ups": "2.2", "train_wpb": "1790.8", "train_bsz": "5", "train_num_updates": "30560", "train_lr": "0.0004775", "train_gnorm": "0.543", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14230"}
[2022-01-03 16:06:52,710][fairseq.trainer][INFO] - begin training epoch 765
[2022-01-03 16:06:52,711][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:07:06,668][train_inner][INFO] - {"epoch": 765, "update": 765.0, "loss": "3.769", "ntokens": "1789.18", "nsentences": "4.95", "prob_perplexity": "107.51", "code_perplexity": "105.795", "temp": "1.717", "loss_0": "3.633", "loss_1": "0.12", "loss_2": "0.016", "accuracy": "0.31085", "wps": "3917.3", "ups": "2.19", "wpb": "1789.2", "bsz": "5", "num_updates": "30600", "lr": "0.000478125", "gnorm": "0.538", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "14244"}
[2022-01-03 16:07:06,669][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:07:07,093][valid][INFO] - {"epoch": 765, "valid_loss": "3.781", "valid_ntokens": "790", "valid_nsentences": "2", "valid_prob_perplexity": "106.227", "valid_code_perplexity": "103.461", "valid_temp": "1.716", "valid_loss_0": "3.645", "valid_loss_1": "0.12", "valid_loss_2": "0.016", "valid_accuracy": "0.31266", "valid_wps": "0", "valid_wpb": "790", "valid_bsz": "2", "valid_num_updates": "30600", "valid_best_loss": "3.297"}
[2022-01-03 16:07:07,096][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 765 @ 30600 updates
[2022-01-03 16:07:07,097][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:07:10,845][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:07:10,868][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 765 @ 30600 updates, score 3.781) (writing took 3.7719011837616563 seconds)
[2022-01-03 16:07:10,868][fairseq_cli.train][INFO] - end of epoch 765 (average epoch stats below)
[2022-01-03 16:07:10,881][train][INFO] - {"epoch": 765, "train_loss": "3.789", "train_ntokens": "1787.7", "train_nsentences": "4.95", "train_prob_perplexity": "107.907", "train_code_perplexity": "106.209", "train_temp": "1.716", "train_loss_0": "3.653", "train_loss_1": "0.12", "train_loss_2": "0.016", "train_accuracy": "0.30799", "train_wps": "3922.1", "train_ups": "2.19", "train_wpb": "1787.7", "train_bsz": "5", "train_num_updates": "30600", "train_lr": "0.000478125", "train_gnorm": "0.527", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "14248"}
[2022-01-03 16:07:10,936][fairseq.trainer][INFO] - begin training epoch 766
[2022-01-03 16:07:10,936][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:07:24,951][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:07:25,359][valid][INFO] - {"epoch": 766, "valid_loss": "3.461", "valid_ntokens": "660", "valid_nsentences": "2", "valid_prob_perplexity": "104.672", "valid_code_perplexity": "101.767", "valid_temp": "1.716", "valid_loss_0": "3.326", "valid_loss_1": "0.121", "valid_loss_2": "0.015", "valid_accuracy": "0.35909", "valid_wps": "0", "valid_wpb": "660", "valid_bsz": "2", "valid_num_updates": "30640", "valid_best_loss": "3.297"}
[2022-01-03 16:07:25,362][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 766 @ 30640 updates
[2022-01-03 16:07:25,363][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:07:29,068][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:07:29,095][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 766 @ 30640 updates, score 3.461) (writing took 3.732317772693932 seconds)
[2022-01-03 16:07:29,095][fairseq_cli.train][INFO] - end of epoch 766 (average epoch stats below)
[2022-01-03 16:07:29,108][train][INFO] - {"epoch": 766, "train_loss": "3.744", "train_ntokens": "1796.67", "train_nsentences": "4.95", "train_prob_perplexity": "109.226", "train_code_perplexity": "107.496", "train_temp": "1.716", "train_loss_0": "3.609", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.31427", "train_wps": "3945.6", "train_ups": "2.2", "train_wpb": "1796.7", "train_bsz": "5", "train_num_updates": "30640", "train_lr": "0.00047875", "train_gnorm": "0.517", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14267"}
[2022-01-03 16:07:29,182][fairseq.trainer][INFO] - begin training epoch 767
[2022-01-03 16:07:29,183][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:07:43,001][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:07:43,492][valid][INFO] - {"epoch": 767, "valid_loss": "3.819", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "107.666", "valid_code_perplexity": "105.288", "valid_temp": "1.716", "valid_loss_0": "3.681", "valid_loss_1": "0.12", "valid_loss_2": "0.017", "valid_accuracy": "0.31616", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "30680", "valid_best_loss": "3.297"}
[2022-01-03 16:07:43,494][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 767 @ 30680 updates
[2022-01-03 16:07:43,494][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:07:47,319][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:07:47,346][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 767 @ 30680 updates, score 3.819) (writing took 3.852593369781971 seconds)
[2022-01-03 16:07:47,347][fairseq_cli.train][INFO] - end of epoch 767 (average epoch stats below)
[2022-01-03 16:07:47,359][train][INFO] - {"epoch": 767, "train_loss": "3.76", "train_ntokens": "1801.75", "train_nsentences": "4.95", "train_prob_perplexity": "108.637", "train_code_perplexity": "106.928", "train_temp": "1.716", "train_loss_0": "3.626", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.31207", "train_wps": "3951.6", "train_ups": "2.19", "train_wpb": "1801.8", "train_bsz": "5", "train_num_updates": "30680", "train_lr": "0.000479375", "train_gnorm": "0.531", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14285"}
[2022-01-03 16:07:47,438][fairseq.trainer][INFO] - begin training epoch 768
[2022-01-03 16:07:47,439][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:08:01,395][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:08:01,805][valid][INFO] - {"epoch": 768, "valid_loss": "3.655", "valid_ntokens": "684", "valid_nsentences": "2", "valid_prob_perplexity": "105.042", "valid_code_perplexity": "101.113", "valid_temp": "1.715", "valid_loss_0": "3.516", "valid_loss_1": "0.121", "valid_loss_2": "0.018", "valid_accuracy": "0.34503", "valid_wps": "0", "valid_wpb": "684", "valid_bsz": "2", "valid_num_updates": "30720", "valid_best_loss": "3.297"}
[2022-01-03 16:08:01,808][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 768 @ 30720 updates
[2022-01-03 16:08:01,809][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:08:05,568][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:08:05,596][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 768 @ 30720 updates, score 3.655) (writing took 3.7875848170369864 seconds)
[2022-01-03 16:08:05,596][fairseq_cli.train][INFO] - end of epoch 768 (average epoch stats below)
[2022-01-03 16:08:05,609][train][INFO] - {"epoch": 768, "train_loss": "3.752", "train_ntokens": "1780.55", "train_nsentences": "4.95", "train_prob_perplexity": "107.933", "train_code_perplexity": "106.026", "train_temp": "1.715", "train_loss_0": "3.617", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.31371", "train_wps": "3905.3", "train_ups": "2.19", "train_wpb": "1780.5", "train_bsz": "5", "train_num_updates": "30720", "train_lr": "0.00048", "train_gnorm": "0.525", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14303"}
[2022-01-03 16:08:05,647][fairseq.trainer][INFO] - begin training epoch 769
[2022-01-03 16:08:05,648][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:08:19,636][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:08:20,039][valid][INFO] - {"epoch": 769, "valid_loss": "3.938", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "105.786", "valid_code_perplexity": "102.633", "valid_temp": "1.715", "valid_loss_0": "3.803", "valid_loss_1": "0.12", "valid_loss_2": "0.014", "valid_accuracy": "0.30556", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "30760", "valid_best_loss": "3.297"}
[2022-01-03 16:08:20,041][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 769 @ 30760 updates
[2022-01-03 16:08:20,042][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:08:23,971][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:08:24,001][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 769 @ 30760 updates, score 3.938) (writing took 3.9596763476729393 seconds)
[2022-01-03 16:08:24,001][fairseq_cli.train][INFO] - end of epoch 769 (average epoch stats below)
[2022-01-03 16:08:24,014][train][INFO] - {"epoch": 769, "train_loss": "3.745", "train_ntokens": "1772.58", "train_nsentences": "4.95", "train_prob_perplexity": "108.67", "train_code_perplexity": "107.02", "train_temp": "1.715", "train_loss_0": "3.61", "train_loss_1": "0.12", "train_loss_2": "0.016", "train_accuracy": "0.31282", "train_wps": "3855.1", "train_ups": "2.17", "train_wpb": "1772.6", "train_bsz": "5", "train_num_updates": "30760", "train_lr": "0.000480625", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "14321"}
[2022-01-03 16:08:24,096][fairseq.trainer][INFO] - begin training epoch 770
[2022-01-03 16:08:24,096][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:08:37,914][train_inner][INFO] - {"epoch": 770, "update": 770.0, "loss": "3.76", "ntokens": "1789.37", "nsentences": "4.95", "prob_perplexity": "108.785", "code_perplexity": "107.044", "temp": "1.715", "loss_0": "3.625", "loss_1": "0.12", "loss_2": "0.015", "accuracy": "0.31221", "wps": "3922.6", "ups": "2.19", "wpb": "1789.4", "bsz": "5", "num_updates": "30800", "lr": "0.00048125", "gnorm": "0.526", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "14335"}
[2022-01-03 16:08:37,915][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:08:38,321][valid][INFO] - {"epoch": 770, "valid_loss": "3.573", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "107.349", "valid_code_perplexity": "105.588", "valid_temp": "1.715", "valid_loss_0": "3.438", "valid_loss_1": "0.12", "valid_loss_2": "0.015", "valid_accuracy": "0.33564", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "30800", "valid_best_loss": "3.297"}
[2022-01-03 16:08:38,324][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 770 @ 30800 updates
[2022-01-03 16:08:38,325][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:08:42,044][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:08:42,063][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 770 @ 30800 updates, score 3.573) (writing took 3.738914703950286 seconds)
[2022-01-03 16:08:42,064][fairseq_cli.train][INFO] - end of epoch 770 (average epoch stats below)
[2022-01-03 16:08:42,077][train][INFO] - {"epoch": 770, "train_loss": "3.8", "train_ntokens": "1795.28", "train_nsentences": "4.95", "train_prob_perplexity": "109.461", "train_code_perplexity": "107.75", "train_temp": "1.715", "train_loss_0": "3.665", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.30818", "train_wps": "3978.6", "train_ups": "2.22", "train_wpb": "1795.3", "train_bsz": "5", "train_num_updates": "30800", "train_lr": "0.00048125", "train_gnorm": "0.527", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14339"}
[2022-01-03 16:08:42,130][fairseq.trainer][INFO] - begin training epoch 771
[2022-01-03 16:08:42,131][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:08:55,956][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:08:56,392][valid][INFO] - {"epoch": 771, "valid_loss": "3.545", "valid_ntokens": "652", "valid_nsentences": "2", "valid_prob_perplexity": "103.886", "valid_code_perplexity": "100.352", "valid_temp": "1.714", "valid_loss_0": "3.411", "valid_loss_1": "0.121", "valid_loss_2": "0.013", "valid_accuracy": "0.34816", "valid_wps": "0", "valid_wpb": "652", "valid_bsz": "2", "valid_num_updates": "30840", "valid_best_loss": "3.297"}
[2022-01-03 16:08:56,395][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 771 @ 30840 updates
[2022-01-03 16:08:56,395][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:09:00,310][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:09:00,333][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 771 @ 30840 updates, score 3.545) (writing took 3.9385738018900156 seconds)
[2022-01-03 16:09:00,334][fairseq_cli.train][INFO] - end of epoch 771 (average epoch stats below)
[2022-01-03 16:09:00,346][train][INFO] - {"epoch": 771, "train_loss": "3.706", "train_ntokens": "1791.3", "train_nsentences": "4.95", "train_prob_perplexity": "109.254", "train_code_perplexity": "107.468", "train_temp": "1.714", "train_loss_0": "3.571", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.31995", "train_wps": "3924.6", "train_ups": "2.19", "train_wpb": "1791.3", "train_bsz": "5", "train_num_updates": "30840", "train_lr": "0.000481875", "train_gnorm": "0.522", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14358"}
[2022-01-03 16:09:00,394][fairseq.trainer][INFO] - begin training epoch 772
[2022-01-03 16:09:00,395][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:09:14,293][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:09:14,704][valid][INFO] - {"epoch": 772, "valid_loss": "3.365", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "107.889", "valid_code_perplexity": "104.968", "valid_temp": "1.714", "valid_loss_0": "3.23", "valid_loss_1": "0.12", "valid_loss_2": "0.016", "valid_accuracy": "0.39211", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "30880", "valid_best_loss": "3.297"}
[2022-01-03 16:09:14,707][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 772 @ 30880 updates
[2022-01-03 16:09:14,708][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:09:18,616][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:09:18,644][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 772 @ 30880 updates, score 3.365) (writing took 3.936930892057717 seconds)
[2022-01-03 16:09:18,645][fairseq_cli.train][INFO] - end of epoch 772 (average epoch stats below)
[2022-01-03 16:09:18,657][train][INFO] - {"epoch": 772, "train_loss": "3.77", "train_ntokens": "1792.25", "train_nsentences": "4.95", "train_prob_perplexity": "109.656", "train_code_perplexity": "107.897", "train_temp": "1.714", "train_loss_0": "3.635", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.31255", "train_wps": "3917.9", "train_ups": "2.19", "train_wpb": "1792.2", "train_bsz": "5", "train_num_updates": "30880", "train_lr": "0.0004825", "train_gnorm": "0.526", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14376"}
[2022-01-03 16:09:18,734][fairseq.trainer][INFO] - begin training epoch 773
[2022-01-03 16:09:18,735][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:09:32,716][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:09:33,124][valid][INFO] - {"epoch": 773, "valid_loss": "3.826", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "105.195", "valid_code_perplexity": "102.127", "valid_temp": "1.714", "valid_loss_0": "3.692", "valid_loss_1": "0.121", "valid_loss_2": "0.013", "valid_accuracy": "0.30463", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "30920", "valid_best_loss": "3.297"}
[2022-01-03 16:09:33,128][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 773 @ 30920 updates
[2022-01-03 16:09:33,129][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:09:36,810][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:09:36,837][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 773 @ 30920 updates, score 3.826) (writing took 3.709251554682851 seconds)
[2022-01-03 16:09:36,838][fairseq_cli.train][INFO] - end of epoch 773 (average epoch stats below)
[2022-01-03 16:09:36,852][train][INFO] - {"epoch": 773, "train_loss": "3.791", "train_ntokens": "1797.85", "train_nsentences": "4.95", "train_prob_perplexity": "109.758", "train_code_perplexity": "107.989", "train_temp": "1.714", "train_loss_0": "3.656", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.30973", "train_wps": "3955.6", "train_ups": "2.2", "train_wpb": "1797.8", "train_bsz": "5", "train_num_updates": "30920", "train_lr": "0.000483125", "train_gnorm": "0.529", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14394"}
[2022-01-03 16:09:36,927][fairseq.trainer][INFO] - begin training epoch 774
[2022-01-03 16:09:36,928][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:09:50,802][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:09:51,212][valid][INFO] - {"epoch": 774, "valid_loss": "3.71", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "103.472", "valid_code_perplexity": "99.369", "valid_temp": "1.713", "valid_loss_0": "3.575", "valid_loss_1": "0.121", "valid_loss_2": "0.014", "valid_accuracy": "0.33787", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "30960", "valid_best_loss": "3.297"}
[2022-01-03 16:09:51,215][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 774 @ 30960 updates
[2022-01-03 16:09:51,216][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:09:55,148][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:09:55,154][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 774 @ 30960 updates, score 3.71) (writing took 3.938392681069672 seconds)
[2022-01-03 16:09:55,154][fairseq_cli.train][INFO] - end of epoch 774 (average epoch stats below)
[2022-01-03 16:09:55,167][train][INFO] - {"epoch": 774, "train_loss": "3.764", "train_ntokens": "1787.88", "train_nsentences": "4.95", "train_prob_perplexity": "109.263", "train_code_perplexity": "107.371", "train_temp": "1.713", "train_loss_0": "3.63", "train_loss_1": "0.12", "train_loss_2": "0.015", "train_accuracy": "0.31361", "train_wps": "3907.4", "train_ups": "2.19", "train_wpb": "1787.9", "train_bsz": "5", "train_num_updates": "30960", "train_lr": "0.00048375", "train_gnorm": "0.524", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14413"}
[2022-01-03 16:09:55,225][fairseq.trainer][INFO] - begin training epoch 775
[2022-01-03 16:09:55,225][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:10:09,059][train_inner][INFO] - {"epoch": 775, "update": 775.0, "loss": "3.758", "ntokens": "1788.27", "nsentences": "4.95", "prob_perplexity": "109.592", "code_perplexity": "107.784", "temp": "1.714", "loss_0": "3.624", "loss_1": "0.12", "loss_2": "0.015", "accuracy": "0.3135", "wps": "3924.6", "ups": "2.19", "wpb": "1788.3", "bsz": "5", "num_updates": "31000", "lr": "0.000484375", "gnorm": "0.524", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "14426"}
[2022-01-03 16:10:09,060][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:10:09,567][valid][INFO] - {"epoch": 775, "valid_loss": "3.576", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "106.461", "valid_code_perplexity": "102.447", "valid_temp": "1.713", "valid_loss_0": "3.441", "valid_loss_1": "0.12", "valid_loss_2": "0.015", "valid_accuracy": "0.33681", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "31000", "valid_best_loss": "3.297"}
[2022-01-03 16:10:09,569][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 775 @ 31000 updates
[2022-01-03 16:10:09,570][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:10:13,461][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:10:13,468][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 775 @ 31000 updates, score 3.576) (writing took 3.898402706719935 seconds)
[2022-01-03 16:10:13,468][fairseq_cli.train][INFO] - end of epoch 775 (average epoch stats below)
[2022-01-03 16:10:13,482][train][INFO] - {"epoch": 775, "train_loss": "3.761", "train_ntokens": "1772.08", "train_nsentences": "4.95", "train_prob_perplexity": "110.027", "train_code_perplexity": "108.193", "train_temp": "1.713", "train_loss_0": "3.626", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31167", "train_wps": "3873.2", "train_ups": "2.19", "train_wpb": "1772.1", "train_bsz": "5", "train_num_updates": "31000", "train_lr": "0.000484375", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14431"}
[2022-01-03 16:10:13,537][fairseq.trainer][INFO] - begin training epoch 776
[2022-01-03 16:10:13,537][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:10:27,548][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:10:27,950][valid][INFO] - {"epoch": 776, "valid_loss": "3.615", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "106.487", "valid_code_perplexity": "103.128", "valid_temp": "1.712", "valid_loss_0": "3.48", "valid_loss_1": "0.12", "valid_loss_2": "0.014", "valid_accuracy": "0.35714", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "31040", "valid_best_loss": "3.297"}
[2022-01-03 16:10:27,953][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 776 @ 31040 updates
[2022-01-03 16:10:27,954][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:10:31,736][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:10:31,765][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 776 @ 31040 updates, score 3.615) (writing took 3.8126002801582217 seconds)
[2022-01-03 16:10:31,766][fairseq_cli.train][INFO] - end of epoch 776 (average epoch stats below)
[2022-01-03 16:10:31,779][train][INFO] - {"epoch": 776, "train_loss": "3.76", "train_ntokens": "1780.9", "train_nsentences": "4.95", "train_prob_perplexity": "110.282", "train_code_perplexity": "108.559", "train_temp": "1.713", "train_loss_0": "3.626", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31084", "train_wps": "3896", "train_ups": "2.19", "train_wpb": "1780.9", "train_bsz": "5", "train_num_updates": "31040", "train_lr": "0.000485", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.8", "train_wall": "14449"}
[2022-01-03 16:10:31,860][fairseq.trainer][INFO] - begin training epoch 777
[2022-01-03 16:10:31,860][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:10:45,693][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:10:46,092][valid][INFO] - {"epoch": 777, "valid_loss": "3.482", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "102.39", "valid_code_perplexity": "99.733", "valid_temp": "1.712", "valid_loss_0": "3.347", "valid_loss_1": "0.121", "valid_loss_2": "0.014", "valid_accuracy": "0.34153", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "31080", "valid_best_loss": "3.297"}
[2022-01-03 16:10:46,096][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 777 @ 31080 updates
[2022-01-03 16:10:46,097][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:10:49,990][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:10:50,018][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 777 @ 31080 updates, score 3.482) (writing took 3.9223104333505034 seconds)
[2022-01-03 16:10:50,019][fairseq_cli.train][INFO] - end of epoch 777 (average epoch stats below)
[2022-01-03 16:10:50,031][train][INFO] - {"epoch": 777, "train_loss": "3.777", "train_ntokens": "1807.2", "train_nsentences": "4.95", "train_prob_perplexity": "110.55", "train_code_perplexity": "108.798", "train_temp": "1.712", "train_loss_0": "3.643", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.30954", "train_wps": "3963.2", "train_ups": "2.19", "train_wpb": "1807.2", "train_bsz": "5", "train_num_updates": "31080", "train_lr": "0.000485625", "train_gnorm": "0.531", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "14467"}
[2022-01-03 16:10:50,109][fairseq.trainer][INFO] - begin training epoch 778
[2022-01-03 16:10:50,110][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:11:04,093][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:11:04,494][valid][INFO] - {"epoch": 778, "valid_loss": "4.053", "valid_ntokens": "688", "valid_nsentences": "2", "valid_prob_perplexity": "107.91", "valid_code_perplexity": "104.863", "valid_temp": "1.712", "valid_loss_0": "3.918", "valid_loss_1": "0.12", "valid_loss_2": "0.015", "valid_accuracy": "0.29797", "valid_wps": "0", "valid_wpb": "688", "valid_bsz": "2", "valid_num_updates": "31120", "valid_best_loss": "3.297"}
[2022-01-03 16:11:04,497][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 778 @ 31120 updates
[2022-01-03 16:11:04,497][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:11:08,288][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:11:08,316][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 778 @ 31120 updates, score 4.053) (writing took 3.819597512483597 seconds)
[2022-01-03 16:11:08,317][fairseq_cli.train][INFO] - end of epoch 778 (average epoch stats below)
[2022-01-03 16:11:08,330][train][INFO] - {"epoch": 778, "train_loss": "3.75", "train_ntokens": "1802.03", "train_nsentences": "4.95", "train_prob_perplexity": "110.618", "train_code_perplexity": "108.776", "train_temp": "1.712", "train_loss_0": "3.616", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31497", "train_wps": "3941.9", "train_ups": "2.19", "train_wpb": "1802", "train_bsz": "5", "train_num_updates": "31120", "train_lr": "0.00048625", "train_gnorm": "0.536", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14486"}
[2022-01-03 16:11:08,409][fairseq.trainer][INFO] - begin training epoch 779
[2022-01-03 16:11:08,409][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:11:22,344][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:11:22,750][valid][INFO] - {"epoch": 779, "valid_loss": "3.83", "valid_ntokens": "830", "valid_nsentences": "2", "valid_prob_perplexity": "108.247", "valid_code_perplexity": "105.242", "valid_temp": "1.711", "valid_loss_0": "3.697", "valid_loss_1": "0.12", "valid_loss_2": "0.013", "valid_accuracy": "0.29759", "valid_wps": "0", "valid_wpb": "830", "valid_bsz": "2", "valid_num_updates": "31160", "valid_best_loss": "3.297"}
[2022-01-03 16:11:22,753][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 779 @ 31160 updates
[2022-01-03 16:11:22,754][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:11:26,538][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:11:26,557][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 779 @ 31160 updates, score 3.83) (writing took 3.803681157529354 seconds)
[2022-01-03 16:11:26,557][fairseq_cli.train][INFO] - end of epoch 779 (average epoch stats below)
[2022-01-03 16:11:26,570][train][INFO] - {"epoch": 779, "train_loss": "3.758", "train_ntokens": "1806.25", "train_nsentences": "4.95", "train_prob_perplexity": "111.921", "train_code_perplexity": "110.103", "train_temp": "1.712", "train_loss_0": "3.625", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31271", "train_wps": "3963.9", "train_ups": "2.19", "train_wpb": "1806.2", "train_bsz": "5", "train_num_updates": "31160", "train_lr": "0.000486875", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14504"}
[2022-01-03 16:11:26,620][fairseq.trainer][INFO] - begin training epoch 780
[2022-01-03 16:11:26,621][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:11:40,378][train_inner][INFO] - {"epoch": 780, "update": 780.0, "loss": "3.761", "ntokens": "1799.86", "nsentences": "4.95", "prob_perplexity": "111.012", "code_perplexity": "109.22", "temp": "1.712", "loss_0": "3.627", "loss_1": "0.119", "loss_2": "0.015", "accuracy": "0.31264", "wps": "3942.5", "ups": "2.19", "wpb": "1799.9", "bsz": "5", "num_updates": "31200", "lr": "0.0004875", "gnorm": "0.531", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "14518"}
[2022-01-03 16:11:40,379][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:11:40,786][valid][INFO] - {"epoch": 780, "valid_loss": "3.315", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "110.645", "valid_code_perplexity": "107.012", "valid_temp": "1.711", "valid_loss_0": "3.182", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.38723", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "31200", "valid_best_loss": "3.297"}
[2022-01-03 16:11:40,789][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 780 @ 31200 updates
[2022-01-03 16:11:40,790][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:11:44,713][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:11:44,741][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 780 @ 31200 updates, score 3.315) (writing took 3.951763281598687 seconds)
[2022-01-03 16:11:44,742][fairseq_cli.train][INFO] - end of epoch 780 (average epoch stats below)
[2022-01-03 16:11:44,754][train][INFO] - {"epoch": 780, "train_loss": "3.757", "train_ntokens": "1802.9", "train_nsentences": "4.95", "train_prob_perplexity": "111.689", "train_code_perplexity": "109.863", "train_temp": "1.711", "train_loss_0": "3.623", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31515", "train_wps": "3968.6", "train_ups": "2.2", "train_wpb": "1802.9", "train_bsz": "5", "train_num_updates": "31200", "train_lr": "0.0004875", "train_gnorm": "0.544", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14522"}
[2022-01-03 16:11:44,830][fairseq.trainer][INFO] - begin training epoch 781
[2022-01-03 16:11:44,830][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:11:58,653][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:11:59,078][valid][INFO] - {"epoch": 781, "valid_loss": "4", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "107.527", "valid_code_perplexity": "106.313", "valid_temp": "1.711", "valid_loss_0": "3.868", "valid_loss_1": "0.12", "valid_loss_2": "0.012", "valid_accuracy": "0.30471", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "31240", "valid_best_loss": "3.297"}
[2022-01-03 16:11:59,081][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 781 @ 31240 updates
[2022-01-03 16:11:59,082][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:12:02,929][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:12:02,959][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 781 @ 31240 updates, score 4.0) (writing took 3.8780036382377148 seconds)
[2022-01-03 16:12:02,960][fairseq_cli.train][INFO] - end of epoch 781 (average epoch stats below)
[2022-01-03 16:12:02,973][train][INFO] - {"epoch": 781, "train_loss": "3.775", "train_ntokens": "1777.42", "train_nsentences": "4.95", "train_prob_perplexity": "112.003", "train_code_perplexity": "110.168", "train_temp": "1.711", "train_loss_0": "3.642", "train_loss_1": "0.119", "train_loss_2": "0.014", "train_accuracy": "0.31087", "train_wps": "3905.2", "train_ups": "2.2", "train_wpb": "1777.4", "train_bsz": "5", "train_num_updates": "31240", "train_lr": "0.000488125", "train_gnorm": "0.542", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "14540"}
[2022-01-03 16:12:03,053][fairseq.trainer][INFO] - begin training epoch 782
[2022-01-03 16:12:03,053][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:12:16,738][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:12:17,220][valid][INFO] - {"epoch": 782, "valid_loss": "3.421", "valid_ntokens": "818", "valid_nsentences": "2", "valid_prob_perplexity": "107.795", "valid_code_perplexity": "104.406", "valid_temp": "1.71", "valid_loss_0": "3.287", "valid_loss_1": "0.12", "valid_loss_2": "0.014", "valid_accuracy": "0.35452", "valid_wps": "0", "valid_wpb": "818", "valid_bsz": "2", "valid_num_updates": "31280", "valid_best_loss": "3.297"}
[2022-01-03 16:12:17,222][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 782 @ 31280 updates
[2022-01-03 16:12:17,222][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:12:21,099][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:12:21,113][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 782 @ 31280 updates, score 3.421) (writing took 3.891764137893915 seconds)
[2022-01-03 16:12:21,114][fairseq_cli.train][INFO] - end of epoch 782 (average epoch stats below)
[2022-01-03 16:12:21,127][train][INFO] - {"epoch": 782, "train_loss": "3.745", "train_ntokens": "1791.7", "train_nsentences": "4.95", "train_prob_perplexity": "111.443", "train_code_perplexity": "109.779", "train_temp": "1.711", "train_loss_0": "3.61", "train_loss_1": "0.119", "train_loss_2": "0.016", "train_accuracy": "0.31322", "train_wps": "3950.7", "train_ups": "2.2", "train_wpb": "1791.7", "train_bsz": "5", "train_num_updates": "31280", "train_lr": "0.00048875", "train_gnorm": "0.53", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "14559"}
[2022-01-03 16:12:21,190][fairseq.trainer][INFO] - begin training epoch 783
[2022-01-03 16:12:21,191][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:12:35,152][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:12:35,636][valid][INFO] - {"epoch": 783, "valid_loss": "3.687", "valid_ntokens": "802", "valid_nsentences": "2", "valid_prob_perplexity": "108.778", "valid_code_perplexity": "106.705", "valid_temp": "1.71", "valid_loss_0": "3.554", "valid_loss_1": "0.12", "valid_loss_2": "0.014", "valid_accuracy": "0.33915", "valid_wps": "0", "valid_wpb": "802", "valid_bsz": "2", "valid_num_updates": "31320", "valid_best_loss": "3.297"}
[2022-01-03 16:12:35,638][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 783 @ 31320 updates
[2022-01-03 16:12:35,639][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:12:39,318][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:12:39,347][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 783 @ 31320 updates, score 3.687) (writing took 3.709032606333494 seconds)
[2022-01-03 16:12:39,348][fairseq_cli.train][INFO] - end of epoch 783 (average epoch stats below)
[2022-01-03 16:12:39,360][train][INFO] - {"epoch": 783, "train_loss": "3.738", "train_ntokens": "1779.88", "train_nsentences": "4.95", "train_prob_perplexity": "111.977", "train_code_perplexity": "110.241", "train_temp": "1.71", "train_loss_0": "3.604", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31218", "train_wps": "3907.4", "train_ups": "2.2", "train_wpb": "1779.9", "train_bsz": "5", "train_num_updates": "31320", "train_lr": "0.000489375", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14577"}
[2022-01-03 16:12:39,430][fairseq.trainer][INFO] - begin training epoch 784
[2022-01-03 16:12:39,431][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:12:53,315][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:12:53,740][valid][INFO] - {"epoch": 784, "valid_loss": "3.663", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "112.951", "valid_code_perplexity": "109.172", "valid_temp": "1.71", "valid_loss_0": "3.528", "valid_loss_1": "0.119", "valid_loss_2": "0.016", "valid_accuracy": "0.3453", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "31360", "valid_best_loss": "3.297"}
[2022-01-03 16:12:53,743][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 784 @ 31360 updates
[2022-01-03 16:12:53,744][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:12:57,560][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:12:57,590][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 784 @ 31360 updates, score 3.663) (writing took 3.846482364460826 seconds)
[2022-01-03 16:12:57,591][fairseq_cli.train][INFO] - end of epoch 784 (average epoch stats below)
[2022-01-03 16:12:57,604][train][INFO] - {"epoch": 784, "train_loss": "3.74", "train_ntokens": "1790.2", "train_nsentences": "4.95", "train_prob_perplexity": "111.713", "train_code_perplexity": "109.901", "train_temp": "1.71", "train_loss_0": "3.607", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31645", "train_wps": "3927.9", "train_ups": "2.19", "train_wpb": "1790.2", "train_bsz": "5", "train_num_updates": "31360", "train_lr": "0.00049", "train_gnorm": "0.542", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "14595"}
[2022-01-03 16:12:57,661][fairseq.trainer][INFO] - begin training epoch 785
[2022-01-03 16:12:57,662][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:13:11,662][train_inner][INFO] - {"epoch": 785, "update": 785.0, "loss": "3.756", "ntokens": "1782.93", "nsentences": "4.95", "prob_perplexity": "111.764", "code_perplexity": "109.982", "temp": "1.71", "loss_0": "3.622", "loss_1": "0.119", "loss_2": "0.015", "accuracy": "0.31284", "wps": "3906.9", "ups": "2.19", "wpb": "1782.9", "bsz": "5", "num_updates": "31400", "lr": "0.000490625", "gnorm": "0.535", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "14609"}
[2022-01-03 16:13:11,663][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:13:12,073][valid][INFO] - {"epoch": 785, "valid_loss": "3.455", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "107.611", "valid_code_perplexity": "104.048", "valid_temp": "1.709", "valid_loss_0": "3.319", "valid_loss_1": "0.12", "valid_loss_2": "0.016", "valid_accuracy": "0.34375", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "31400", "valid_best_loss": "3.297"}
[2022-01-03 16:13:12,076][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 785 @ 31400 updates
[2022-01-03 16:13:12,077][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:13:15,811][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:13:15,839][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 785 @ 31400 updates, score 3.455) (writing took 3.762936339713633 seconds)
[2022-01-03 16:13:15,840][fairseq_cli.train][INFO] - end of epoch 785 (average epoch stats below)
[2022-01-03 16:13:15,852][train][INFO] - {"epoch": 785, "train_loss": "3.781", "train_ntokens": "1775.47", "train_nsentences": "4.95", "train_prob_perplexity": "111.687", "train_code_perplexity": "109.822", "train_temp": "1.71", "train_loss_0": "3.647", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31144", "train_wps": "3894.6", "train_ups": "2.19", "train_wpb": "1775.5", "train_bsz": "5", "train_num_updates": "31400", "train_lr": "0.000490625", "train_gnorm": "0.532", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14613"}
[2022-01-03 16:13:15,935][fairseq.trainer][INFO] - begin training epoch 786
[2022-01-03 16:13:15,936][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:13:29,933][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:13:30,371][valid][INFO] - {"epoch": 786, "valid_loss": "3.498", "valid_ntokens": "826", "valid_nsentences": "2", "valid_prob_perplexity": "106.912", "valid_code_perplexity": "103.662", "valid_temp": "1.709", "valid_loss_0": "3.364", "valid_loss_1": "0.12", "valid_loss_2": "0.013", "valid_accuracy": "0.33777", "valid_wps": "0", "valid_wpb": "826", "valid_bsz": "2", "valid_num_updates": "31440", "valid_best_loss": "3.297"}
[2022-01-03 16:13:30,376][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 786 @ 31440 updates
[2022-01-03 16:13:30,377][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:13:34,076][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:13:34,102][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 786 @ 31440 updates, score 3.498) (writing took 3.725946879014373 seconds)
[2022-01-03 16:13:34,102][fairseq_cli.train][INFO] - end of epoch 786 (average epoch stats below)
[2022-01-03 16:13:34,115][train][INFO] - {"epoch": 786, "train_loss": "3.757", "train_ntokens": "1801.17", "train_nsentences": "4.95", "train_prob_perplexity": "112.682", "train_code_perplexity": "110.757", "train_temp": "1.709", "train_loss_0": "3.623", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31502", "train_wps": "3947.8", "train_ups": "2.19", "train_wpb": "1801.2", "train_bsz": "5", "train_num_updates": "31440", "train_lr": "0.00049125", "train_gnorm": "0.546", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.7", "train_wall": "14632"}
[2022-01-03 16:13:34,187][fairseq.trainer][INFO] - begin training epoch 787
[2022-01-03 16:13:34,188][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:13:48,139][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:13:48,547][valid][INFO] - {"epoch": 787, "valid_loss": "3.948", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "110.49", "valid_code_perplexity": "105.603", "valid_temp": "1.709", "valid_loss_0": "3.815", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.30239", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "31480", "valid_best_loss": "3.297"}
[2022-01-03 16:13:48,550][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 787 @ 31480 updates
[2022-01-03 16:13:48,551][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:13:52,442][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:13:52,472][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 787 @ 31480 updates, score 3.948) (writing took 3.921573651023209 seconds)
[2022-01-03 16:13:52,472][fairseq_cli.train][INFO] - end of epoch 787 (average epoch stats below)
[2022-01-03 16:13:52,485][train][INFO] - {"epoch": 787, "train_loss": "3.756", "train_ntokens": "1798.67", "train_nsentences": "4.95", "train_prob_perplexity": "113.189", "train_code_perplexity": "111.343", "train_temp": "1.709", "train_loss_0": "3.622", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31437", "train_wps": "3919.2", "train_ups": "2.18", "train_wpb": "1798.7", "train_bsz": "5", "train_num_updates": "31480", "train_lr": "0.000491875", "train_gnorm": "0.543", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "14650"}
[2022-01-03 16:13:52,571][fairseq.trainer][INFO] - begin training epoch 788
[2022-01-03 16:13:52,571][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:14:06,431][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:14:06,841][valid][INFO] - {"epoch": 788, "valid_loss": "3.802", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "110.115", "valid_code_perplexity": "107.359", "valid_temp": "1.708", "valid_loss_0": "3.67", "valid_loss_1": "0.119", "valid_loss_2": "0.013", "valid_accuracy": "0.31707", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "31520", "valid_best_loss": "3.297"}
[2022-01-03 16:14:06,844][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 788 @ 31520 updates
[2022-01-03 16:14:06,845][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:14:10,562][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:14:10,588][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 788 @ 31520 updates, score 3.802) (writing took 3.744245252572 seconds)
[2022-01-03 16:14:10,589][fairseq_cli.train][INFO] - end of epoch 788 (average epoch stats below)
[2022-01-03 16:14:10,602][train][INFO] - {"epoch": 788, "train_loss": "3.779", "train_ntokens": "1789.38", "train_nsentences": "4.95", "train_prob_perplexity": "113.303", "train_code_perplexity": "111.456", "train_temp": "1.709", "train_loss_0": "3.646", "train_loss_1": "0.119", "train_loss_2": "0.014", "train_accuracy": "0.30798", "train_wps": "3953.6", "train_ups": "2.21", "train_wpb": "1789.4", "train_bsz": "5", "train_num_updates": "31520", "train_lr": "0.0004925", "train_gnorm": "0.545", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14668"}
[2022-01-03 16:14:10,658][fairseq.trainer][INFO] - begin training epoch 789
[2022-01-03 16:14:10,659][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:14:24,564][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:14:24,979][valid][INFO] - {"epoch": 789, "valid_loss": "3.559", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "108.101", "valid_code_perplexity": "105.389", "valid_temp": "1.708", "valid_loss_0": "3.425", "valid_loss_1": "0.12", "valid_loss_2": "0.014", "valid_accuracy": "0.3382", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "31560", "valid_best_loss": "3.297"}
[2022-01-03 16:14:24,982][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 789 @ 31560 updates
[2022-01-03 16:14:24,983][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:14:28,885][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:14:28,905][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 789 @ 31560 updates, score 3.559) (writing took 3.922236753627658 seconds)
[2022-01-03 16:14:28,905][fairseq_cli.train][INFO] - end of epoch 789 (average epoch stats below)
[2022-01-03 16:14:28,917][train][INFO] - {"epoch": 789, "train_loss": "3.752", "train_ntokens": "1776.75", "train_nsentences": "4.95", "train_prob_perplexity": "113.179", "train_code_perplexity": "111.223", "train_temp": "1.708", "train_loss_0": "3.618", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31307", "train_wps": "3882.9", "train_ups": "2.19", "train_wpb": "1776.8", "train_bsz": "5", "train_num_updates": "31560", "train_lr": "0.000493125", "train_gnorm": "0.534", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14686"}
[2022-01-03 16:14:28,968][fairseq.trainer][INFO] - begin training epoch 790
[2022-01-03 16:14:28,969][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:14:42,924][train_inner][INFO] - {"epoch": 790, "update": 790.0, "loss": "3.763", "ntokens": "1792.46", "nsentences": "4.95", "prob_perplexity": "113.129", "code_perplexity": "111.249", "temp": "1.709", "loss_0": "3.629", "loss_1": "0.119", "loss_2": "0.015", "accuracy": "0.31201", "wps": "3928.7", "ups": "2.19", "wpb": "1792.5", "bsz": "5", "num_updates": "31600", "lr": "0.00049375", "gnorm": "0.538", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "14700"}
[2022-01-03 16:14:42,925][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:14:43,342][valid][INFO] - {"epoch": 790, "valid_loss": "3.483", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "107.481", "valid_code_perplexity": "103.537", "valid_temp": "1.708", "valid_loss_0": "3.35", "valid_loss_1": "0.12", "valid_loss_2": "0.013", "valid_accuracy": "0.36096", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "31600", "valid_best_loss": "3.297"}
[2022-01-03 16:14:43,346][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 790 @ 31600 updates
[2022-01-03 16:14:43,348][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:14:47,109][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:14:47,136][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 790 @ 31600 updates, score 3.483) (writing took 3.789841255173087 seconds)
[2022-01-03 16:14:47,137][fairseq_cli.train][INFO] - end of epoch 790 (average epoch stats below)
[2022-01-03 16:14:47,149][train][INFO] - {"epoch": 790, "train_loss": "3.772", "train_ntokens": "1796.35", "train_nsentences": "4.95", "train_prob_perplexity": "113.293", "train_code_perplexity": "111.466", "train_temp": "1.708", "train_loss_0": "3.638", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.3096", "train_wps": "3943.8", "train_ups": "2.2", "train_wpb": "1796.3", "train_bsz": "5", "train_num_updates": "31600", "train_lr": "0.00049375", "train_gnorm": "0.522", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14705"}
[2022-01-03 16:14:47,205][fairseq.trainer][INFO] - begin training epoch 791
[2022-01-03 16:14:47,205][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:15:01,093][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:15:01,502][valid][INFO] - {"epoch": 791, "valid_loss": "3.529", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "110.421", "valid_code_perplexity": "107.064", "valid_temp": "1.707", "valid_loss_0": "3.396", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.34986", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "31640", "valid_best_loss": "3.297"}
[2022-01-03 16:15:01,507][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 791 @ 31640 updates
[2022-01-03 16:15:01,508][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:15:05,443][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:15:05,470][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 791 @ 31640 updates, score 3.529) (writing took 3.963238764554262 seconds)
[2022-01-03 16:15:05,471][fairseq_cli.train][INFO] - end of epoch 791 (average epoch stats below)
[2022-01-03 16:15:05,483][train][INFO] - {"epoch": 791, "train_loss": "3.734", "train_ntokens": "1795.6", "train_nsentences": "4.95", "train_prob_perplexity": "113.64", "train_code_perplexity": "111.716", "train_temp": "1.708", "train_loss_0": "3.601", "train_loss_1": "0.119", "train_loss_2": "0.015", "train_accuracy": "0.31641", "train_wps": "3920.3", "train_ups": "2.18", "train_wpb": "1795.6", "train_bsz": "5", "train_num_updates": "31640", "train_lr": "0.000494375", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14723"}
[2022-01-03 16:15:05,556][fairseq.trainer][INFO] - begin training epoch 792
[2022-01-03 16:15:05,556][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:15:19,477][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:15:19,902][valid][INFO] - {"epoch": 792, "valid_loss": "3.381", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "111.345", "valid_code_perplexity": "108.009", "valid_temp": "1.707", "valid_loss_0": "3.247", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.36533", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "31680", "valid_best_loss": "3.297"}
[2022-01-03 16:15:19,905][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 792 @ 31680 updates
[2022-01-03 16:15:19,906][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:15:23,654][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:15:23,683][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 792 @ 31680 updates, score 3.381) (writing took 3.7773481644690037 seconds)
[2022-01-03 16:15:23,683][fairseq_cli.train][INFO] - end of epoch 792 (average epoch stats below)
[2022-01-03 16:15:23,696][train][INFO] - {"epoch": 792, "train_loss": "3.711", "train_ntokens": "1774.6", "train_nsentences": "4.95", "train_prob_perplexity": "113.975", "train_code_perplexity": "112.092", "train_temp": "1.707", "train_loss_0": "3.578", "train_loss_1": "0.119", "train_loss_2": "0.014", "train_accuracy": "0.31731", "train_wps": "3900.2", "train_ups": "2.2", "train_wpb": "1774.6", "train_bsz": "5", "train_num_updates": "31680", "train_lr": "0.000495", "train_gnorm": "0.541", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14741"}
[2022-01-03 16:15:23,776][fairseq.trainer][INFO] - begin training epoch 793
[2022-01-03 16:15:23,777][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:15:37,646][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:15:38,048][valid][INFO] - {"epoch": 793, "valid_loss": "3.647", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "113.285", "valid_code_perplexity": "111.242", "valid_temp": "1.707", "valid_loss_0": "3.515", "valid_loss_1": "0.119", "valid_loss_2": "0.013", "valid_accuracy": "0.31818", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "31720", "valid_best_loss": "3.297"}
[2022-01-03 16:15:38,052][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 793 @ 31720 updates
[2022-01-03 16:15:38,052][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:15:42,003][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:15:42,031][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 793 @ 31720 updates, score 3.647) (writing took 3.979545255191624 seconds)
[2022-01-03 16:15:42,032][fairseq_cli.train][INFO] - end of epoch 793 (average epoch stats below)
[2022-01-03 16:15:42,044][train][INFO] - {"epoch": 793, "train_loss": "3.719", "train_ntokens": "1781.47", "train_nsentences": "4.95", "train_prob_perplexity": "113.892", "train_code_perplexity": "112.01", "train_temp": "1.707", "train_loss_0": "3.586", "train_loss_1": "0.119", "train_loss_2": "0.014", "train_accuracy": "0.31892", "train_wps": "3886.4", "train_ups": "2.18", "train_wpb": "1781.5", "train_bsz": "5", "train_num_updates": "31720", "train_lr": "0.000495625", "train_gnorm": "0.523", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "14759"}
[2022-01-03 16:15:42,122][fairseq.trainer][INFO] - begin training epoch 794
[2022-01-03 16:15:42,123][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:15:55,860][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:15:56,260][valid][INFO] - {"epoch": 794, "valid_loss": "3.707", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "109.667", "valid_code_perplexity": "106.958", "valid_temp": "1.706", "valid_loss_0": "3.574", "valid_loss_1": "0.12", "valid_loss_2": "0.013", "valid_accuracy": "0.34375", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "31760", "valid_best_loss": "3.297"}
[2022-01-03 16:15:56,263][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 794 @ 31760 updates
[2022-01-03 16:15:56,263][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:16:00,196][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:16:00,224][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 794 @ 31760 updates, score 3.707) (writing took 3.9608745481818914 seconds)
[2022-01-03 16:16:00,224][fairseq_cli.train][INFO] - end of epoch 794 (average epoch stats below)
[2022-01-03 16:16:00,237][train][INFO] - {"epoch": 794, "train_loss": "3.773", "train_ntokens": "1798.15", "train_nsentences": "4.95", "train_prob_perplexity": "114.829", "train_code_perplexity": "112.945", "train_temp": "1.707", "train_loss_0": "3.64", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31218", "train_wps": "3956.4", "train_ups": "2.2", "train_wpb": "1798.2", "train_bsz": "5", "train_num_updates": "31760", "train_lr": "0.00049625", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14778"}
[2022-01-03 16:16:00,315][fairseq.trainer][INFO] - begin training epoch 795
[2022-01-03 16:16:00,315][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:16:14,316][train_inner][INFO] - {"epoch": 795, "update": 795.0, "loss": "3.74", "ntokens": "1787.56", "nsentences": "4.95", "prob_perplexity": "114.123", "code_perplexity": "112.241", "temp": "1.707", "loss_0": "3.607", "loss_1": "0.119", "loss_2": "0.014", "accuracy": "0.31539", "wps": "3912.4", "ups": "2.19", "wpb": "1787.6", "bsz": "5", "num_updates": "31800", "lr": "0.000496875", "gnorm": "0.528", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "14792"}
[2022-01-03 16:16:14,317][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:16:14,729][valid][INFO] - {"epoch": 795, "valid_loss": "3.89", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "112.3", "valid_code_perplexity": "108.652", "valid_temp": "1.706", "valid_loss_0": "3.757", "valid_loss_1": "0.119", "valid_loss_2": "0.015", "valid_accuracy": "0.30758", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "31800", "valid_best_loss": "3.297"}
[2022-01-03 16:16:14,732][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 795 @ 31800 updates
[2022-01-03 16:16:14,733][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:16:18,427][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:16:18,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 795 @ 31800 updates, score 3.89) (writing took 3.721187378279865 seconds)
[2022-01-03 16:16:18,454][fairseq_cli.train][INFO] - end of epoch 795 (average epoch stats below)
[2022-01-03 16:16:18,467][train][INFO] - {"epoch": 795, "train_loss": "3.764", "train_ntokens": "1787.95", "train_nsentences": "4.95", "train_prob_perplexity": "114.277", "train_code_perplexity": "112.442", "train_temp": "1.706", "train_loss_0": "3.631", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31216", "train_wps": "3926", "train_ups": "2.2", "train_wpb": "1788", "train_bsz": "5", "train_num_updates": "31800", "train_lr": "0.000496875", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "14796"}
[2022-01-03 16:16:18,546][fairseq.trainer][INFO] - begin training epoch 796
[2022-01-03 16:16:18,547][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:16:32,422][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:16:32,831][valid][INFO] - {"epoch": 796, "valid_loss": "3.406", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "108.902", "valid_code_perplexity": "105.597", "valid_temp": "1.706", "valid_loss_0": "3.273", "valid_loss_1": "0.12", "valid_loss_2": "0.014", "valid_accuracy": "0.35794", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "31840", "valid_best_loss": "3.297"}
[2022-01-03 16:16:32,834][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 796 @ 31840 updates
[2022-01-03 16:16:32,835][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:16:36,709][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:16:36,729][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 796 @ 31840 updates, score 3.406) (writing took 3.8955166339874268 seconds)
[2022-01-03 16:16:36,730][fairseq_cli.train][INFO] - end of epoch 796 (average epoch stats below)
[2022-01-03 16:16:36,743][train][INFO] - {"epoch": 796, "train_loss": "3.738", "train_ntokens": "1806.05", "train_nsentences": "4.95", "train_prob_perplexity": "115.151", "train_code_perplexity": "113.12", "train_temp": "1.706", "train_loss_0": "3.605", "train_loss_1": "0.118", "train_loss_2": "0.015", "train_accuracy": "0.31811", "train_wps": "3955.6", "train_ups": "2.19", "train_wpb": "1806", "train_bsz": "5", "train_num_updates": "31840", "train_lr": "0.0004975", "train_gnorm": "0.533", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "14814"}
[2022-01-03 16:16:36,782][fairseq.trainer][INFO] - begin training epoch 797
[2022-01-03 16:16:36,783][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:16:50,730][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:16:51,144][valid][INFO] - {"epoch": 797, "valid_loss": "3.47", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "105.558", "valid_code_perplexity": "102.426", "valid_temp": "1.705", "valid_loss_0": "3.335", "valid_loss_1": "0.12", "valid_loss_2": "0.014", "valid_accuracy": "0.36828", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "31880", "valid_best_loss": "3.297"}
[2022-01-03 16:16:51,147][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 797 @ 31880 updates
[2022-01-03 16:16:51,147][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:16:54,924][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:16:54,953][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 797 @ 31880 updates, score 3.47) (writing took 3.8060826119035482 seconds)
[2022-01-03 16:16:54,953][fairseq_cli.train][INFO] - end of epoch 797 (average epoch stats below)
[2022-01-03 16:16:54,966][train][INFO] - {"epoch": 797, "train_loss": "3.75", "train_ntokens": "1794.42", "train_nsentences": "4.95", "train_prob_perplexity": "115.786", "train_code_perplexity": "113.781", "train_temp": "1.705", "train_loss_0": "3.618", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31355", "train_wps": "3941.6", "train_ups": "2.2", "train_wpb": "1794.4", "train_bsz": "5", "train_num_updates": "31880", "train_lr": "0.000498125", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "14832"}
[2022-01-03 16:16:55,038][fairseq.trainer][INFO] - begin training epoch 798
[2022-01-03 16:16:55,038][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:17:09,043][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:17:09,429][valid][INFO] - {"epoch": 798, "valid_loss": "3.383", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "105.358", "valid_code_perplexity": "101.743", "valid_temp": "1.705", "valid_loss_0": "3.248", "valid_loss_1": "0.121", "valid_loss_2": "0.014", "valid_accuracy": "0.36081", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "31920", "valid_best_loss": "3.297"}
[2022-01-03 16:17:09,433][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 798 @ 31920 updates
[2022-01-03 16:17:09,434][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:17:13,180][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:17:13,209][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 798 @ 31920 updates, score 3.383) (writing took 3.7761640269309282 seconds)
[2022-01-03 16:17:13,210][fairseq_cli.train][INFO] - end of epoch 798 (average epoch stats below)
[2022-01-03 16:17:13,223][train][INFO] - {"epoch": 798, "train_loss": "3.749", "train_ntokens": "1796.65", "train_nsentences": "4.95", "train_prob_perplexity": "115.236", "train_code_perplexity": "113.214", "train_temp": "1.705", "train_loss_0": "3.616", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31424", "train_wps": "3939.2", "train_ups": "2.19", "train_wpb": "1796.7", "train_bsz": "5", "train_num_updates": "31920", "train_lr": "0.00049875", "train_gnorm": "0.535", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14851"}
[2022-01-03 16:17:13,283][fairseq.trainer][INFO] - begin training epoch 799
[2022-01-03 16:17:13,283][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:17:27,137][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:17:27,548][valid][INFO] - {"epoch": 799, "valid_loss": "3.49", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "111.421", "valid_code_perplexity": "107.492", "valid_temp": "1.705", "valid_loss_0": "3.358", "valid_loss_1": "0.119", "valid_loss_2": "0.013", "valid_accuracy": "0.34478", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "31960", "valid_best_loss": "3.297"}
[2022-01-03 16:17:27,552][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 799 @ 31960 updates
[2022-01-03 16:17:27,554][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:17:31,540][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:17:31,565][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 799 @ 31960 updates, score 3.49) (writing took 4.012632247060537 seconds)
[2022-01-03 16:17:31,566][fairseq_cli.train][INFO] - end of epoch 799 (average epoch stats below)
[2022-01-03 16:17:31,579][train][INFO] - {"epoch": 799, "train_loss": "3.751", "train_ntokens": "1802", "train_nsentences": "4.95", "train_prob_perplexity": "116.371", "train_code_perplexity": "114.449", "train_temp": "1.705", "train_loss_0": "3.618", "train_loss_1": "0.118", "train_loss_2": "0.015", "train_accuracy": "0.31486", "train_wps": "3929.6", "train_ups": "2.18", "train_wpb": "1802", "train_bsz": "5", "train_num_updates": "31960", "train_lr": "0.000499375", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "14869"}
[2022-01-03 16:17:31,631][fairseq.trainer][INFO] - begin training epoch 800
[2022-01-03 16:17:31,631][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:17:45,595][train_inner][INFO] - {"epoch": 800, "update": 800.0, "loss": "3.743", "ntokens": "1799.13", "nsentences": "4.95", "prob_perplexity": "115.659", "code_perplexity": "113.661", "temp": "1.705", "loss_0": "3.61", "loss_1": "0.118", "loss_2": "0.014", "accuracy": "0.31532", "wps": "3942.6", "ups": "2.19", "wpb": "1799.1", "bsz": "5", "num_updates": "32000", "lr": "0.0005", "gnorm": "0.524", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "14883"}
[2022-01-03 16:17:45,596][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:17:46,006][valid][INFO] - {"epoch": 800, "valid_loss": "3.475", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "102.675", "valid_code_perplexity": "99.524", "valid_temp": "1.704", "valid_loss_0": "3.341", "valid_loss_1": "0.121", "valid_loss_2": "0.013", "valid_accuracy": "0.36037", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "32000", "valid_best_loss": "3.297"}
[2022-01-03 16:17:46,009][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 800 @ 32000 updates
[2022-01-03 16:17:46,010][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:17:49,770][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:17:49,794][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 800 @ 32000 updates, score 3.475) (writing took 3.785201038233936 seconds)
[2022-01-03 16:17:49,795][fairseq_cli.train][INFO] - end of epoch 800 (average epoch stats below)
[2022-01-03 16:17:49,808][train][INFO] - {"epoch": 800, "train_loss": "3.725", "train_ntokens": "1796.53", "train_nsentences": "4.95", "train_prob_perplexity": "115.752", "train_code_perplexity": "113.741", "train_temp": "1.704", "train_loss_0": "3.594", "train_loss_1": "0.118", "train_loss_2": "0.013", "train_accuracy": "0.3158", "train_wps": "3945", "train_ups": "2.2", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "32000", "train_lr": "0.0005", "train_gnorm": "0.521", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14887"}
[2022-01-03 16:17:49,879][fairseq.trainer][INFO] - begin training epoch 801
[2022-01-03 16:17:49,880][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:18:03,857][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:18:04,260][valid][INFO] - {"epoch": 801, "valid_loss": "3.662", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "109.549", "valid_code_perplexity": "106.513", "valid_temp": "1.704", "valid_loss_0": "3.531", "valid_loss_1": "0.12", "valid_loss_2": "0.012", "valid_accuracy": "0.34945", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "32040", "valid_best_loss": "3.297"}
[2022-01-03 16:18:04,263][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 801 @ 32040 updates
[2022-01-03 16:18:04,264][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:18:08,045][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:18:08,073][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 801 @ 32040 updates, score 3.662) (writing took 3.809860561043024 seconds)
[2022-01-03 16:18:08,073][fairseq_cli.train][INFO] - end of epoch 801 (average epoch stats below)
[2022-01-03 16:18:08,086][train][INFO] - {"epoch": 801, "train_loss": "3.723", "train_ntokens": "1793.4", "train_nsentences": "4.95", "train_prob_perplexity": "116.557", "train_code_perplexity": "114.636", "train_temp": "1.704", "train_loss_0": "3.591", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31872", "train_wps": "3927.4", "train_ups": "2.19", "train_wpb": "1793.4", "train_bsz": "5", "train_num_updates": "32040", "train_lr": "0.000499946", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "14905"}
[2022-01-03 16:18:08,159][fairseq.trainer][INFO] - begin training epoch 802
[2022-01-03 16:18:08,160][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:18:22,173][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:18:22,594][valid][INFO] - {"epoch": 802, "valid_loss": "3.668", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "111.966", "valid_code_perplexity": "108.035", "valid_temp": "1.704", "valid_loss_0": "3.536", "valid_loss_1": "0.119", "valid_loss_2": "0.012", "valid_accuracy": "0.32262", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "32080", "valid_best_loss": "3.297"}
[2022-01-03 16:18:22,598][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 802 @ 32080 updates
[2022-01-03 16:18:22,599][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:18:26,318][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:18:26,347][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 802 @ 32080 updates, score 3.668) (writing took 3.7486432129517198 seconds)
[2022-01-03 16:18:26,347][fairseq_cli.train][INFO] - end of epoch 802 (average epoch stats below)
[2022-01-03 16:18:26,360][train][INFO] - {"epoch": 802, "train_loss": "3.75", "train_ntokens": "1783.9", "train_nsentences": "4.95", "train_prob_perplexity": "116.423", "train_code_perplexity": "114.342", "train_temp": "1.704", "train_loss_0": "3.618", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31442", "train_wps": "3907.7", "train_ups": "2.19", "train_wpb": "1783.9", "train_bsz": "5", "train_num_updates": "32080", "train_lr": "0.000499891", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14924"}
[2022-01-03 16:18:26,440][fairseq.trainer][INFO] - begin training epoch 803
[2022-01-03 16:18:26,441][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:18:40,305][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:18:40,731][valid][INFO] - {"epoch": 803, "valid_loss": "3.605", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "112.039", "valid_code_perplexity": "107.852", "valid_temp": "1.703", "valid_loss_0": "3.472", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.36376", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "32120", "valid_best_loss": "3.297"}
[2022-01-03 16:18:40,734][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 803 @ 32120 updates
[2022-01-03 16:18:40,735][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:18:44,539][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:18:44,567][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 803 @ 32120 updates, score 3.605) (writing took 3.8330922117456794 seconds)
[2022-01-03 16:18:44,568][fairseq_cli.train][INFO] - end of epoch 803 (average epoch stats below)
[2022-01-03 16:18:44,581][train][INFO] - {"epoch": 803, "train_loss": "3.716", "train_ntokens": "1793.4", "train_nsentences": "4.95", "train_prob_perplexity": "117.349", "train_code_perplexity": "115.47", "train_temp": "1.703", "train_loss_0": "3.584", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31904", "train_wps": "3939.8", "train_ups": "2.2", "train_wpb": "1793.4", "train_bsz": "5", "train_num_updates": "32120", "train_lr": "0.000499837", "train_gnorm": "0.525", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14942"}
[2022-01-03 16:18:44,659][fairseq.trainer][INFO] - begin training epoch 804
[2022-01-03 16:18:44,659][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:18:58,660][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:18:59,041][valid][INFO] - {"epoch": 804, "valid_loss": "4.074", "valid_ntokens": "692", "valid_nsentences": "2", "valid_prob_perplexity": "114.198", "valid_code_perplexity": "109.682", "valid_temp": "1.703", "valid_loss_0": "3.938", "valid_loss_1": "0.119", "valid_loss_2": "0.017", "valid_accuracy": "0.27457", "valid_wps": "0", "valid_wpb": "692", "valid_bsz": "2", "valid_num_updates": "32160", "valid_best_loss": "3.297"}
[2022-01-03 16:18:59,045][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 804 @ 32160 updates
[2022-01-03 16:18:59,046][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:19:02,862][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:19:02,890][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 804 @ 32160 updates, score 4.074) (writing took 3.845428006723523 seconds)
[2022-01-03 16:19:02,891][fairseq_cli.train][INFO] - end of epoch 804 (average epoch stats below)
[2022-01-03 16:19:02,904][train][INFO] - {"epoch": 804, "train_loss": "3.718", "train_ntokens": "1784.65", "train_nsentences": "4.95", "train_prob_perplexity": "116.745", "train_code_perplexity": "114.871", "train_temp": "1.703", "train_loss_0": "3.585", "train_loss_1": "0.118", "train_loss_2": "0.015", "train_accuracy": "0.3168", "train_wps": "3898.7", "train_ups": "2.18", "train_wpb": "1784.7", "train_bsz": "5", "train_num_updates": "32160", "train_lr": "0.000499783", "train_gnorm": "0.542", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "14960"}
[2022-01-03 16:19:02,977][fairseq.trainer][INFO] - begin training epoch 805
[2022-01-03 16:19:02,978][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:19:16,909][train_inner][INFO] - {"epoch": 805, "update": 805.0, "loss": "3.727", "ntokens": "1790.56", "nsentences": "4.95", "prob_perplexity": "117.054", "code_perplexity": "115.126", "temp": "1.703", "loss_0": "3.595", "loss_1": "0.118", "loss_2": "0.014", "accuracy": "0.31706", "wps": "3922.3", "ups": "2.19", "wpb": "1790.6", "bsz": "5", "num_updates": "32200", "lr": "0.000499728", "gnorm": "0.524", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "14974"}
[2022-01-03 16:19:16,910][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:19:17,307][valid][INFO] - {"epoch": 805, "valid_loss": "3.599", "valid_ntokens": "684", "valid_nsentences": "2", "valid_prob_perplexity": "110.174", "valid_code_perplexity": "106.814", "valid_temp": "1.703", "valid_loss_0": "3.465", "valid_loss_1": "0.119", "valid_loss_2": "0.015", "valid_accuracy": "0.34503", "valid_wps": "0", "valid_wpb": "684", "valid_bsz": "2", "valid_num_updates": "32200", "valid_best_loss": "3.297"}
[2022-01-03 16:19:17,310][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 805 @ 32200 updates
[2022-01-03 16:19:17,311][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:19:21,005][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:19:21,034][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 805 @ 32200 updates, score 3.599) (writing took 3.724426744505763 seconds)
[2022-01-03 16:19:21,035][fairseq_cli.train][INFO] - end of epoch 805 (average epoch stats below)
[2022-01-03 16:19:21,048][train][INFO] - {"epoch": 805, "train_loss": "3.73", "train_ntokens": "1797.42", "train_nsentences": "4.95", "train_prob_perplexity": "118.195", "train_code_perplexity": "116.309", "train_temp": "1.703", "train_loss_0": "3.598", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31629", "train_wps": "3965.6", "train_ups": "2.21", "train_wpb": "1797.4", "train_bsz": "5", "train_num_updates": "32200", "train_lr": "0.000499728", "train_gnorm": "0.516", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14978"}
[2022-01-03 16:19:21,127][fairseq.trainer][INFO] - begin training epoch 806
[2022-01-03 16:19:21,128][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:19:35,068][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:19:35,532][valid][INFO] - {"epoch": 806, "valid_loss": "3.569", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "118.227", "valid_code_perplexity": "116.227", "valid_temp": "1.702", "valid_loss_0": "3.437", "valid_loss_1": "0.118", "valid_loss_2": "0.014", "valid_accuracy": "0.32891", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "32240", "valid_best_loss": "3.297"}
[2022-01-03 16:19:35,535][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 806 @ 32240 updates
[2022-01-03 16:19:35,535][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:19:39,268][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:19:39,297][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 806 @ 32240 updates, score 3.569) (writing took 3.761840012855828 seconds)
[2022-01-03 16:19:39,297][fairseq_cli.train][INFO] - end of epoch 806 (average epoch stats below)
[2022-01-03 16:19:39,310][train][INFO] - {"epoch": 806, "train_loss": "3.725", "train_ntokens": "1798.9", "train_nsentences": "4.95", "train_prob_perplexity": "116.987", "train_code_perplexity": "115.105", "train_temp": "1.702", "train_loss_0": "3.593", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31993", "train_wps": "3943", "train_ups": "2.19", "train_wpb": "1798.9", "train_bsz": "5", "train_num_updates": "32240", "train_lr": "0.000499674", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "14997"}
[2022-01-03 16:19:39,389][fairseq.trainer][INFO] - begin training epoch 807
[2022-01-03 16:19:39,390][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:19:53,311][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:19:53,805][valid][INFO] - {"epoch": 807, "valid_loss": "3.495", "valid_ntokens": "800", "valid_nsentences": "2", "valid_prob_perplexity": "114.379", "valid_code_perplexity": "110.839", "valid_temp": "1.702", "valid_loss_0": "3.364", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.34875", "valid_wps": "0", "valid_wpb": "800", "valid_bsz": "2", "valid_num_updates": "32280", "valid_best_loss": "3.297"}
[2022-01-03 16:19:53,807][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 807 @ 32280 updates
[2022-01-03 16:19:53,807][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:19:57,526][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:19:57,551][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 807 @ 32280 updates, score 3.495) (writing took 3.7440633485093713 seconds)
[2022-01-03 16:19:57,551][fairseq_cli.train][INFO] - end of epoch 807 (average epoch stats below)
[2022-01-03 16:19:57,566][train][INFO] - {"epoch": 807, "train_loss": "3.727", "train_ntokens": "1783.62", "train_nsentences": "4.95", "train_prob_perplexity": "118.328", "train_code_perplexity": "116.533", "train_temp": "1.702", "train_loss_0": "3.595", "train_loss_1": "0.118", "train_loss_2": "0.014", "train_accuracy": "0.31865", "train_wps": "3911.2", "train_ups": "2.19", "train_wpb": "1783.6", "train_bsz": "5", "train_num_updates": "32280", "train_lr": "0.00049962", "train_gnorm": "0.514", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "15015"}
[2022-01-03 16:19:57,636][fairseq.trainer][INFO] - begin training epoch 808
[2022-01-03 16:19:57,637][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:20:11,421][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:20:11,844][valid][INFO] - {"epoch": 808, "valid_loss": "3.549", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "113.081", "valid_code_perplexity": "110.138", "valid_temp": "1.702", "valid_loss_0": "3.416", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.33978", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "32320", "valid_best_loss": "3.297"}
[2022-01-03 16:20:11,848][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 808 @ 32320 updates
[2022-01-03 16:20:11,849][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:20:15,875][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:20:15,902][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 808 @ 32320 updates, score 3.549) (writing took 4.053958311676979 seconds)
[2022-01-03 16:20:15,903][fairseq_cli.train][INFO] - end of epoch 808 (average epoch stats below)
[2022-01-03 16:20:15,916][train][INFO] - {"epoch": 808, "train_loss": "3.752", "train_ntokens": "1790.22", "train_nsentences": "4.95", "train_prob_perplexity": "117.233", "train_code_perplexity": "115.215", "train_temp": "1.702", "train_loss_0": "3.619", "train_loss_1": "0.118", "train_loss_2": "0.015", "train_accuracy": "0.31375", "train_wps": "3905.2", "train_ups": "2.18", "train_wpb": "1790.2", "train_bsz": "5", "train_num_updates": "32320", "train_lr": "0.000499565", "train_gnorm": "0.535", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "15033"}
[2022-01-03 16:20:15,985][fairseq.trainer][INFO] - begin training epoch 809
[2022-01-03 16:20:15,985][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:20:29,639][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:20:30,039][valid][INFO] - {"epoch": 809, "valid_loss": "3.845", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "102.997", "valid_code_perplexity": "98.635", "valid_temp": "1.701", "valid_loss_0": "3.709", "valid_loss_1": "0.121", "valid_loss_2": "0.016", "valid_accuracy": "0.32474", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "32360", "valid_best_loss": "3.297"}
[2022-01-03 16:20:30,042][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 809 @ 32360 updates
[2022-01-03 16:20:30,043][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:20:33,978][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:20:34,005][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 809 @ 32360 updates, score 3.845) (writing took 3.9627004927024245 seconds)
[2022-01-03 16:20:34,006][fairseq_cli.train][INFO] - end of epoch 809 (average epoch stats below)
[2022-01-03 16:20:34,019][train][INFO] - {"epoch": 809, "train_loss": "3.742", "train_ntokens": "1785.8", "train_nsentences": "4.95", "train_prob_perplexity": "118.833", "train_code_perplexity": "116.842", "train_temp": "1.701", "train_loss_0": "3.61", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.3161", "train_wps": "3948.7", "train_ups": "2.21", "train_wpb": "1785.8", "train_bsz": "5", "train_num_updates": "32360", "train_lr": "0.000499511", "train_gnorm": "0.519", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "15051"}
[2022-01-03 16:20:34,096][fairseq.trainer][INFO] - begin training epoch 810
[2022-01-03 16:20:34,097][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:20:47,964][train_inner][INFO] - {"epoch": 810, "update": 810.0, "loss": "3.74", "ntokens": "1790.35", "nsentences": "4.95", "prob_perplexity": "118.142", "code_perplexity": "116.218", "temp": "1.702", "loss_0": "3.609", "loss_1": "0.118", "loss_2": "0.014", "accuracy": "0.31601", "wps": "3933", "ups": "2.2", "wpb": "1790.3", "bsz": "5", "num_updates": "32400", "lr": "0.000499457", "gnorm": "0.523", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "15065"}
[2022-01-03 16:20:47,965][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:20:48,364][valid][INFO] - {"epoch": 810, "valid_loss": "3.735", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "113.965", "valid_code_perplexity": "110.29", "valid_temp": "1.701", "valid_loss_0": "3.604", "valid_loss_1": "0.119", "valid_loss_2": "0.012", "valid_accuracy": "0.32219", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "32400", "valid_best_loss": "3.297"}
[2022-01-03 16:20:48,367][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 810 @ 32400 updates
[2022-01-03 16:20:48,367][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:20:52,200][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:20:52,227][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 810 @ 32400 updates, score 3.735) (writing took 3.860213260166347 seconds)
[2022-01-03 16:20:52,228][fairseq_cli.train][INFO] - end of epoch 810 (average epoch stats below)
[2022-01-03 16:20:52,240][train][INFO] - {"epoch": 810, "train_loss": "3.756", "train_ntokens": "1793.2", "train_nsentences": "4.95", "train_prob_perplexity": "119.332", "train_code_perplexity": "117.393", "train_temp": "1.701", "train_loss_0": "3.626", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.31161", "train_wps": "3939.2", "train_ups": "2.2", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "32400", "train_lr": "0.000499457", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15070"}
[2022-01-03 16:20:52,281][fairseq.trainer][INFO] - begin training epoch 811
[2022-01-03 16:20:52,282][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:21:06,205][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:21:06,604][valid][INFO] - {"epoch": 811, "valid_loss": "3.808", "valid_ntokens": "796", "valid_nsentences": "2", "valid_prob_perplexity": "114.512", "valid_code_perplexity": "111.193", "valid_temp": "1.701", "valid_loss_0": "3.674", "valid_loss_1": "0.118", "valid_loss_2": "0.016", "valid_accuracy": "0.3505", "valid_wps": "0", "valid_wpb": "796", "valid_bsz": "2", "valid_num_updates": "32440", "valid_best_loss": "3.297"}
[2022-01-03 16:21:06,608][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 811 @ 32440 updates
[2022-01-03 16:21:06,609][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:21:10,507][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:21:10,534][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 811 @ 32440 updates, score 3.808) (writing took 3.9265923239290714 seconds)
[2022-01-03 16:21:10,535][fairseq_cli.train][INFO] - end of epoch 811 (average epoch stats below)
[2022-01-03 16:21:10,547][train][INFO] - {"epoch": 811, "train_loss": "3.699", "train_ntokens": "1797.33", "train_nsentences": "4.95", "train_prob_perplexity": "118.822", "train_code_perplexity": "116.934", "train_temp": "1.701", "train_loss_0": "3.569", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.32124", "train_wps": "3929.7", "train_ups": "2.19", "train_wpb": "1797.3", "train_bsz": "5", "train_num_updates": "32440", "train_lr": "0.000499402", "train_gnorm": "0.521", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15088"}
[2022-01-03 16:21:10,598][fairseq.trainer][INFO] - begin training epoch 812
[2022-01-03 16:21:10,598][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:21:24,576][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:21:24,996][valid][INFO] - {"epoch": 812, "valid_loss": "3.446", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "100.623", "valid_code_perplexity": "96.551", "valid_temp": "1.7", "valid_loss_0": "3.309", "valid_loss_1": "0.122", "valid_loss_2": "0.015", "valid_accuracy": "0.34658", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "32480", "valid_best_loss": "3.297"}
[2022-01-03 16:21:25,001][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 812 @ 32480 updates
[2022-01-03 16:21:25,002][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:21:28,684][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:21:28,711][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 812 @ 32480 updates, score 3.446) (writing took 3.7103516114875674 seconds)
[2022-01-03 16:21:28,711][fairseq_cli.train][INFO] - end of epoch 812 (average epoch stats below)
[2022-01-03 16:21:28,724][train][INFO] - {"epoch": 812, "train_loss": "3.738", "train_ntokens": "1788.17", "train_nsentences": "4.95", "train_prob_perplexity": "119.619", "train_code_perplexity": "117.774", "train_temp": "1.7", "train_loss_0": "3.606", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31553", "train_wps": "3937.9", "train_ups": "2.2", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "32480", "train_lr": "0.000499348", "train_gnorm": "0.53", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15106"}
[2022-01-03 16:21:28,779][fairseq.trainer][INFO] - begin training epoch 813
[2022-01-03 16:21:28,780][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:21:42,869][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:21:43,357][valid][INFO] - {"epoch": 813, "valid_loss": "3.782", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "113.017", "valid_code_perplexity": "109.873", "valid_temp": "1.7", "valid_loss_0": "3.649", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.32632", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "32520", "valid_best_loss": "3.297"}
[2022-01-03 16:21:43,358][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 813 @ 32520 updates
[2022-01-03 16:21:43,359][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:21:47,043][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:21:47,070][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 813 @ 32520 updates, score 3.782) (writing took 3.711760968901217 seconds)
[2022-01-03 16:21:47,071][fairseq_cli.train][INFO] - end of epoch 813 (average epoch stats below)
[2022-01-03 16:21:47,084][train][INFO] - {"epoch": 813, "train_loss": "3.706", "train_ntokens": "1793.25", "train_nsentences": "4.95", "train_prob_perplexity": "119.765", "train_code_perplexity": "117.855", "train_temp": "1.7", "train_loss_0": "3.574", "train_loss_1": "0.117", "train_loss_2": "0.015", "train_accuracy": "0.31853", "train_wps": "3909.7", "train_ups": "2.18", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "32520", "train_lr": "0.000499293", "train_gnorm": "0.525", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15124"}
[2022-01-03 16:21:47,153][fairseq.trainer][INFO] - begin training epoch 814
[2022-01-03 16:21:47,154][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:22:01,069][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:22:01,466][valid][INFO] - {"epoch": 814, "valid_loss": "3.596", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "112.836", "valid_code_perplexity": "109.445", "valid_temp": "1.7", "valid_loss_0": "3.462", "valid_loss_1": "0.119", "valid_loss_2": "0.015", "valid_accuracy": "0.35411", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "32560", "valid_best_loss": "3.297"}
[2022-01-03 16:22:01,469][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 814 @ 32560 updates
[2022-01-03 16:22:01,470][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:22:05,276][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:22:05,303][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 814 @ 32560 updates, score 3.596) (writing took 3.8341639200225472 seconds)
[2022-01-03 16:22:05,304][fairseq_cli.train][INFO] - end of epoch 814 (average epoch stats below)
[2022-01-03 16:22:05,316][train][INFO] - {"epoch": 814, "train_loss": "3.729", "train_ntokens": "1785.28", "train_nsentences": "4.95", "train_prob_perplexity": "119.905", "train_code_perplexity": "117.945", "train_temp": "1.7", "train_loss_0": "3.598", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31523", "train_wps": "3919.4", "train_ups": "2.2", "train_wpb": "1785.3", "train_bsz": "5", "train_num_updates": "32560", "train_lr": "0.000499239", "train_gnorm": "0.519", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "15143"}
[2022-01-03 16:22:05,377][fairseq.trainer][INFO] - begin training epoch 815
[2022-01-03 16:22:05,378][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:22:19,399][train_inner][INFO] - {"epoch": 815, "update": 815.0, "loss": "3.714", "ntokens": "1792.03", "nsentences": "4.95", "prob_perplexity": "119.419", "code_perplexity": "117.501", "temp": "1.7", "loss_0": "3.583", "loss_1": "0.117", "loss_2": "0.014", "accuracy": "0.31851", "wps": "3920.4", "ups": "2.19", "wpb": "1792", "bsz": "5", "num_updates": "32600", "lr": "0.000499185", "gnorm": "0.526", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "15157"}
[2022-01-03 16:22:19,400][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:22:19,811][valid][INFO] - {"epoch": 815, "valid_loss": "3.712", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "115.455", "valid_code_perplexity": "111.344", "valid_temp": "1.699", "valid_loss_0": "3.58", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.35067", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "32600", "valid_best_loss": "3.297"}
[2022-01-03 16:22:19,814][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 815 @ 32600 updates
[2022-01-03 16:22:19,815][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:22:23,515][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:22:23,543][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 815 @ 32600 updates, score 3.712) (writing took 3.728765893727541 seconds)
[2022-01-03 16:22:23,544][fairseq_cli.train][INFO] - end of epoch 815 (average epoch stats below)
[2022-01-03 16:22:23,557][train][INFO] - {"epoch": 815, "train_loss": "3.699", "train_ntokens": "1796.1", "train_nsentences": "4.95", "train_prob_perplexity": "118.983", "train_code_perplexity": "116.996", "train_temp": "1.699", "train_loss_0": "3.567", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.32196", "train_wps": "3941.6", "train_ups": "2.19", "train_wpb": "1796.1", "train_bsz": "5", "train_num_updates": "32600", "train_lr": "0.000499185", "train_gnorm": "0.537", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15161"}
[2022-01-03 16:22:23,614][fairseq.trainer][INFO] - begin training epoch 816
[2022-01-03 16:22:23,614][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:22:37,427][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:22:37,924][valid][INFO] - {"epoch": 816, "valid_loss": "3.221", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "114.549", "valid_code_perplexity": "110.254", "valid_temp": "1.699", "valid_loss_0": "3.092", "valid_loss_1": "0.118", "valid_loss_2": "0.011", "valid_accuracy": "0.39973", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "32640", "valid_best_loss": "3.221"}
[2022-01-03 16:22:37,926][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 816 @ 32640 updates
[2022-01-03 16:22:37,926][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 16:22:41,764][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 16:22:48,425][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 816 @ 32640 updates, score 3.221) (writing took 10.498904351145029 seconds)
[2022-01-03 16:22:48,425][fairseq_cli.train][INFO] - end of epoch 816 (average epoch stats below)
[2022-01-03 16:22:48,439][train][INFO] - {"epoch": 816, "train_loss": "3.72", "train_ntokens": "1793.53", "train_nsentences": "4.95", "train_prob_perplexity": "119.722", "train_code_perplexity": "117.838", "train_temp": "1.699", "train_loss_0": "3.589", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31952", "train_wps": "2884.8", "train_ups": "1.61", "train_wpb": "1793.5", "train_bsz": "5", "train_num_updates": "32640", "train_lr": "0.00049913", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "15186"}
[2022-01-03 16:22:48,521][fairseq.trainer][INFO] - begin training epoch 817
[2022-01-03 16:22:48,521][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:23:02,379][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:23:02,787][valid][INFO] - {"epoch": 817, "valid_loss": "3.724", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "116.609", "valid_code_perplexity": "114.261", "valid_temp": "1.699", "valid_loss_0": "3.591", "valid_loss_1": "0.118", "valid_loss_2": "0.015", "valid_accuracy": "0.31698", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "32680", "valid_best_loss": "3.221"}
[2022-01-03 16:23:02,790][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 817 @ 32680 updates
[2022-01-03 16:23:02,791][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:23:06,718][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:23:06,739][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 817 @ 32680 updates, score 3.724) (writing took 3.948227080516517 seconds)
[2022-01-03 16:23:06,739][fairseq_cli.train][INFO] - end of epoch 817 (average epoch stats below)
[2022-01-03 16:23:06,753][train][INFO] - {"epoch": 817, "train_loss": "3.733", "train_ntokens": "1780.72", "train_nsentences": "4.95", "train_prob_perplexity": "119.643", "train_code_perplexity": "117.755", "train_temp": "1.699", "train_loss_0": "3.602", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.3149", "train_wps": "3892.2", "train_ups": "2.19", "train_wpb": "1780.7", "train_bsz": "5", "train_num_updates": "32680", "train_lr": "0.000499076", "train_gnorm": "0.526", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15204"}
[2022-01-03 16:23:06,826][fairseq.trainer][INFO] - begin training epoch 818
[2022-01-03 16:23:06,826][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:23:20,580][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:23:20,974][valid][INFO] - {"epoch": 818, "valid_loss": "4.179", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "115.461", "valid_code_perplexity": "113.094", "valid_temp": "1.698", "valid_loss_0": "4.047", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.27202", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "32720", "valid_best_loss": "3.221"}
[2022-01-03 16:23:20,976][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 818 @ 32720 updates
[2022-01-03 16:23:20,977][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:23:24,863][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:23:24,887][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 818 @ 32720 updates, score 4.179) (writing took 3.911271484568715 seconds)
[2022-01-03 16:23:24,888][fairseq_cli.train][INFO] - end of epoch 818 (average epoch stats below)
[2022-01-03 16:23:24,901][train][INFO] - {"epoch": 818, "train_loss": "3.748", "train_ntokens": "1805.35", "train_nsentences": "4.95", "train_prob_perplexity": "120.249", "train_code_perplexity": "118.137", "train_temp": "1.698", "train_loss_0": "3.616", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31427", "train_wps": "3982.1", "train_ups": "2.21", "train_wpb": "1805.3", "train_bsz": "5", "train_num_updates": "32720", "train_lr": "0.000499022", "train_gnorm": "0.527", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15222"}
[2022-01-03 16:23:24,971][fairseq.trainer][INFO] - begin training epoch 819
[2022-01-03 16:23:24,972][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:23:38,833][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:23:39,239][valid][INFO] - {"epoch": 819, "valid_loss": "4.021", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "115.344", "valid_code_perplexity": "112.852", "valid_temp": "1.698", "valid_loss_0": "3.891", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.28629", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "32760", "valid_best_loss": "3.221"}
[2022-01-03 16:23:39,242][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 819 @ 32760 updates
[2022-01-03 16:23:39,243][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:23:43,214][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:23:43,241][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 819 @ 32760 updates, score 4.021) (writing took 3.999530860222876 seconds)
[2022-01-03 16:23:43,242][fairseq_cli.train][INFO] - end of epoch 819 (average epoch stats below)
[2022-01-03 16:23:43,255][train][INFO] - {"epoch": 819, "train_loss": "3.728", "train_ntokens": "1780.97", "train_nsentences": "4.95", "train_prob_perplexity": "120.248", "train_code_perplexity": "118.207", "train_temp": "1.698", "train_loss_0": "3.597", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31877", "train_wps": "3884.2", "train_ups": "2.18", "train_wpb": "1781", "train_bsz": "5", "train_num_updates": "32760", "train_lr": "0.000498967", "train_gnorm": "0.527", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "15241"}
[2022-01-03 16:23:43,335][fairseq.trainer][INFO] - begin training epoch 820
[2022-01-03 16:23:43,336][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:23:57,150][train_inner][INFO] - {"epoch": 820, "update": 820.0, "loss": "3.726", "ntokens": "1790.19", "nsentences": "4.95", "prob_perplexity": "119.877", "code_perplexity": "117.895", "temp": "1.698", "loss_0": "3.595", "loss_1": "0.117", "loss_2": "0.014", "accuracy": "0.31739", "wps": "3663.2", "ups": "2.05", "wpb": "1790.2", "bsz": "5", "num_updates": "32800", "lr": "0.000498913", "gnorm": "0.528", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "15255"}
[2022-01-03 16:23:57,151][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:23:57,564][valid][INFO] - {"epoch": 820, "valid_loss": "3.368", "valid_ntokens": "670", "valid_nsentences": "2", "valid_prob_perplexity": "116.39", "valid_code_perplexity": "110.897", "valid_temp": "1.697", "valid_loss_0": "3.237", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.34478", "valid_wps": "0", "valid_wpb": "670", "valid_bsz": "2", "valid_num_updates": "32800", "valid_best_loss": "3.221"}
[2022-01-03 16:23:57,568][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 820 @ 32800 updates
[2022-01-03 16:23:57,569][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:24:01,514][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:24:01,542][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 820 @ 32800 updates, score 3.368) (writing took 3.974150775000453 seconds)
[2022-01-03 16:24:01,542][fairseq_cli.train][INFO] - end of epoch 820 (average epoch stats below)
[2022-01-03 16:24:01,555][train][INFO] - {"epoch": 820, "train_loss": "3.699", "train_ntokens": "1790.4", "train_nsentences": "4.95", "train_prob_perplexity": "119.522", "train_code_perplexity": "117.541", "train_temp": "1.698", "train_loss_0": "3.568", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31948", "train_wps": "3916.2", "train_ups": "2.19", "train_wpb": "1790.4", "train_bsz": "5", "train_num_updates": "32800", "train_lr": "0.000498913", "train_gnorm": "0.54", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15259"}
[2022-01-03 16:24:01,633][fairseq.trainer][INFO] - begin training epoch 821
[2022-01-03 16:24:01,634][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:24:15,498][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:24:15,917][valid][INFO] - {"epoch": 821, "valid_loss": "3.559", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "113.005", "valid_code_perplexity": "108.976", "valid_temp": "1.697", "valid_loss_0": "3.425", "valid_loss_1": "0.119", "valid_loss_2": "0.015", "valid_accuracy": "0.34753", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "32840", "valid_best_loss": "3.221"}
[2022-01-03 16:24:15,921][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 821 @ 32840 updates
[2022-01-03 16:24:15,922][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:24:19,749][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:24:19,776][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 821 @ 32840 updates, score 3.559) (writing took 3.8550144396722317 seconds)
[2022-01-03 16:24:19,777][fairseq_cli.train][INFO] - end of epoch 821 (average epoch stats below)
[2022-01-03 16:24:19,789][train][INFO] - {"epoch": 821, "train_loss": "3.691", "train_ntokens": "1792.38", "train_nsentences": "4.95", "train_prob_perplexity": "120.327", "train_code_perplexity": "118.342", "train_temp": "1.697", "train_loss_0": "3.56", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.32246", "train_wps": "3934.6", "train_ups": "2.2", "train_wpb": "1792.4", "train_bsz": "5", "train_num_updates": "32840", "train_lr": "0.000498859", "train_gnorm": "0.508", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15277"}
[2022-01-03 16:24:19,859][fairseq.trainer][INFO] - begin training epoch 822
[2022-01-03 16:24:19,860][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:24:33,744][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:24:34,157][valid][INFO] - {"epoch": 822, "valid_loss": "3.462", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "105.353", "valid_code_perplexity": "101.651", "valid_temp": "1.697", "valid_loss_0": "3.328", "valid_loss_1": "0.121", "valid_loss_2": "0.014", "valid_accuracy": "0.36695", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "32880", "valid_best_loss": "3.221"}
[2022-01-03 16:24:34,160][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 822 @ 32880 updates
[2022-01-03 16:24:34,162][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:24:38,045][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:24:38,072][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 822 @ 32880 updates, score 3.462) (writing took 3.9114152854308486 seconds)
[2022-01-03 16:24:38,072][fairseq_cli.train][INFO] - end of epoch 822 (average epoch stats below)
[2022-01-03 16:24:38,085][train][INFO] - {"epoch": 822, "train_loss": "3.72", "train_ntokens": "1789.25", "train_nsentences": "4.95", "train_prob_perplexity": "120.661", "train_code_perplexity": "118.855", "train_temp": "1.697", "train_loss_0": "3.589", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31861", "train_wps": "3914.6", "train_ups": "2.19", "train_wpb": "1789.2", "train_bsz": "5", "train_num_updates": "32880", "train_lr": "0.000498804", "train_gnorm": "0.517", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15295"}
[2022-01-03 16:24:38,159][fairseq.trainer][INFO] - begin training epoch 823
[2022-01-03 16:24:38,160][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:24:51,959][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:24:52,366][valid][INFO] - {"epoch": 823, "valid_loss": "3.577", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "113.358", "valid_code_perplexity": "110.733", "valid_temp": "1.696", "valid_loss_0": "3.446", "valid_loss_1": "0.119", "valid_loss_2": "0.012", "valid_accuracy": "0.37135", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "32920", "valid_best_loss": "3.221"}
[2022-01-03 16:24:52,369][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 823 @ 32920 updates
[2022-01-03 16:24:52,370][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:24:56,297][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:24:56,327][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 823 @ 32920 updates, score 3.577) (writing took 3.9575718520209193 seconds)
[2022-01-03 16:24:56,327][fairseq_cli.train][INFO] - end of epoch 823 (average epoch stats below)
[2022-01-03 16:24:56,340][train][INFO] - {"epoch": 823, "train_loss": "3.699", "train_ntokens": "1792.22", "train_nsentences": "4.95", "train_prob_perplexity": "120.687", "train_code_perplexity": "118.733", "train_temp": "1.697", "train_loss_0": "3.569", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.32267", "train_wps": "3930", "train_ups": "2.19", "train_wpb": "1792.2", "train_bsz": "5", "train_num_updates": "32920", "train_lr": "0.00049875", "train_gnorm": "0.515", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "15314"}
[2022-01-03 16:24:56,397][fairseq.trainer][INFO] - begin training epoch 824
[2022-01-03 16:24:56,398][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:25:10,325][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:25:10,742][valid][INFO] - {"epoch": 824, "valid_loss": "3.573", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "116.788", "valid_code_perplexity": "114.246", "valid_temp": "1.696", "valid_loss_0": "3.441", "valid_loss_1": "0.118", "valid_loss_2": "0.014", "valid_accuracy": "0.36148", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "32960", "valid_best_loss": "3.221"}
[2022-01-03 16:25:10,746][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 824 @ 32960 updates
[2022-01-03 16:25:10,747][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:25:14,498][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:25:14,526][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 824 @ 32960 updates, score 3.573) (writing took 3.779948399402201 seconds)
[2022-01-03 16:25:14,526][fairseq_cli.train][INFO] - end of epoch 824 (average epoch stats below)
[2022-01-03 16:25:14,540][train][INFO] - {"epoch": 824, "train_loss": "3.697", "train_ntokens": "1805.42", "train_nsentences": "4.95", "train_prob_perplexity": "121.19", "train_code_perplexity": "119.256", "train_temp": "1.696", "train_loss_0": "3.567", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.32141", "train_wps": "3971.1", "train_ups": "2.2", "train_wpb": "1805.4", "train_bsz": "5", "train_num_updates": "32960", "train_lr": "0.000498696", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15332"}
[2022-01-03 16:25:14,613][fairseq.trainer][INFO] - begin training epoch 825
[2022-01-03 16:25:14,614][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:25:28,671][train_inner][INFO] - {"epoch": 825, "update": 825.0, "loss": "3.7", "ntokens": "1796.89", "nsentences": "4.95", "prob_perplexity": "120.809", "code_perplexity": "118.904", "temp": "1.697", "loss_0": "3.569", "loss_1": "0.117", "loss_2": "0.014", "accuracy": "0.32163", "wps": "3927.3", "ups": "2.19", "wpb": "1796.9", "bsz": "5", "num_updates": "33000", "lr": "0.000498641", "gnorm": "0.521", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "15346"}
[2022-01-03 16:25:28,672][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:25:29,082][valid][INFO] - {"epoch": 825, "valid_loss": "3.368", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "116.078", "valid_code_perplexity": "112.765", "valid_temp": "1.696", "valid_loss_0": "3.236", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.36197", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "33000", "valid_best_loss": "3.221"}
[2022-01-03 16:25:29,085][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 825 @ 33000 updates
[2022-01-03 16:25:29,086][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:25:32,761][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:25:32,790][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 825 @ 33000 updates, score 3.368) (writing took 3.704777190461755 seconds)
[2022-01-03 16:25:32,791][fairseq_cli.train][INFO] - end of epoch 825 (average epoch stats below)
[2022-01-03 16:25:32,803][train][INFO] - {"epoch": 825, "train_loss": "3.691", "train_ntokens": "1805.2", "train_nsentences": "4.95", "train_prob_perplexity": "121.18", "train_code_perplexity": "119.336", "train_temp": "1.696", "train_loss_0": "3.561", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.323", "train_wps": "3956.4", "train_ups": "2.19", "train_wpb": "1805.2", "train_bsz": "5", "train_num_updates": "33000", "train_lr": "0.000498641", "train_gnorm": "0.546", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15350"}
[2022-01-03 16:25:32,875][fairseq.trainer][INFO] - begin training epoch 826
[2022-01-03 16:25:32,876][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:25:46,785][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:25:47,200][valid][INFO] - {"epoch": 826, "valid_loss": "3.851", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "117.424", "valid_code_perplexity": "113.588", "valid_temp": "1.695", "valid_loss_0": "3.721", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.31969", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "33040", "valid_best_loss": "3.221"}
[2022-01-03 16:25:47,204][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 826 @ 33040 updates
[2022-01-03 16:25:47,205][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:25:50,990][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:25:51,011][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 826 @ 33040 updates, score 3.851) (writing took 3.8066830057650805 seconds)
[2022-01-03 16:25:51,011][fairseq_cli.train][INFO] - end of epoch 826 (average epoch stats below)
[2022-01-03 16:25:51,023][train][INFO] - {"epoch": 826, "train_loss": "3.711", "train_ntokens": "1790.4", "train_nsentences": "4.95", "train_prob_perplexity": "121.696", "train_code_perplexity": "119.689", "train_temp": "1.696", "train_loss_0": "3.58", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31983", "train_wps": "3933.2", "train_ups": "2.2", "train_wpb": "1790.4", "train_bsz": "5", "train_num_updates": "33040", "train_lr": "0.000498587", "train_gnorm": "0.525", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15368"}
[2022-01-03 16:25:51,077][fairseq.trainer][INFO] - begin training epoch 827
[2022-01-03 16:25:51,077][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:26:05,013][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:26:05,503][valid][INFO] - {"epoch": 827, "valid_loss": "4.059", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "115.41", "valid_code_perplexity": "112.226", "valid_temp": "1.695", "valid_loss_0": "3.928", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.29759", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "33080", "valid_best_loss": "3.221"}
[2022-01-03 16:26:05,504][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 827 @ 33080 updates
[2022-01-03 16:26:05,505][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:26:09,299][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:26:09,325][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 827 @ 33080 updates, score 4.059) (writing took 3.82085351832211 seconds)
[2022-01-03 16:26:09,326][fairseq_cli.train][INFO] - end of epoch 827 (average epoch stats below)
[2022-01-03 16:26:09,339][train][INFO] - {"epoch": 827, "train_loss": "3.725", "train_ntokens": "1790.35", "train_nsentences": "4.95", "train_prob_perplexity": "121.416", "train_code_perplexity": "119.503", "train_temp": "1.695", "train_loss_0": "3.594", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.31707", "train_wps": "3912.7", "train_ups": "2.19", "train_wpb": "1790.3", "train_bsz": "5", "train_num_updates": "33080", "train_lr": "0.000498533", "train_gnorm": "0.526", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15387"}
[2022-01-03 16:26:09,406][fairseq.trainer][INFO] - begin training epoch 828
[2022-01-03 16:26:09,407][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:26:23,337][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:26:23,735][valid][INFO] - {"epoch": 828, "valid_loss": "3.476", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "115.968", "valid_code_perplexity": "112.411", "valid_temp": "1.695", "valid_loss_0": "3.347", "valid_loss_1": "0.118", "valid_loss_2": "0.011", "valid_accuracy": "0.37679", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "33120", "valid_best_loss": "3.221"}
[2022-01-03 16:26:23,738][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 828 @ 33120 updates
[2022-01-03 16:26:23,738][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:26:27,540][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:26:27,568][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 828 @ 33120 updates, score 3.476) (writing took 3.8307789796963334 seconds)
[2022-01-03 16:26:27,569][fairseq_cli.train][INFO] - end of epoch 828 (average epoch stats below)
[2022-01-03 16:26:27,582][train][INFO] - {"epoch": 828, "train_loss": "3.717", "train_ntokens": "1784.33", "train_nsentences": "4.95", "train_prob_perplexity": "122.611", "train_code_perplexity": "120.654", "train_temp": "1.695", "train_loss_0": "3.587", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.31815", "train_wps": "3915.1", "train_ups": "2.19", "train_wpb": "1784.3", "train_bsz": "5", "train_num_updates": "33120", "train_lr": "0.000498478", "train_gnorm": "0.525", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15405"}
[2022-01-03 16:26:27,656][fairseq.trainer][INFO] - begin training epoch 829
[2022-01-03 16:26:27,657][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:26:41,561][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:26:41,983][valid][INFO] - {"epoch": 829, "valid_loss": "3.305", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "117.038", "valid_code_perplexity": "113.994", "valid_temp": "1.694", "valid_loss_0": "3.174", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.40212", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "33160", "valid_best_loss": "3.221"}
[2022-01-03 16:26:41,987][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 829 @ 33160 updates
[2022-01-03 16:26:41,988][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:26:45,784][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:26:45,811][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 829 @ 33160 updates, score 3.305) (writing took 3.8243653075769544 seconds)
[2022-01-03 16:26:45,812][fairseq_cli.train][INFO] - end of epoch 829 (average epoch stats below)
[2022-01-03 16:26:45,824][train][INFO] - {"epoch": 829, "train_loss": "3.702", "train_ntokens": "1783.97", "train_nsentences": "4.95", "train_prob_perplexity": "121.01", "train_code_perplexity": "119.028", "train_temp": "1.695", "train_loss_0": "3.572", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.3191", "train_wps": "3914.4", "train_ups": "2.19", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "33160", "train_lr": "0.000498424", "train_gnorm": "0.526", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "15423"}
[2022-01-03 16:26:45,905][fairseq.trainer][INFO] - begin training epoch 830
[2022-01-03 16:26:45,905][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:26:59,843][train_inner][INFO] - {"epoch": 830, "update": 830.0, "loss": "3.711", "ntokens": "1787.83", "nsentences": "4.95", "prob_perplexity": "121.8", "code_perplexity": "119.834", "temp": "1.695", "loss_0": "3.581", "loss_1": "0.117", "loss_2": "0.013", "accuracy": "0.31917", "wps": "3922.4", "ups": "2.19", "wpb": "1787.8", "bsz": "5", "num_updates": "33200", "lr": "0.00049837", "gnorm": "0.525", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "15437"}
[2022-01-03 16:26:59,844][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:27:00,318][valid][INFO] - {"epoch": 830, "valid_loss": "3.822", "valid_ntokens": "718", "valid_nsentences": "2", "valid_prob_perplexity": "118.583", "valid_code_perplexity": "115.072", "valid_temp": "1.694", "valid_loss_0": "3.691", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.31894", "valid_wps": "0", "valid_wpb": "718", "valid_bsz": "2", "valid_num_updates": "33200", "valid_best_loss": "3.221"}
[2022-01-03 16:27:00,320][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 830 @ 33200 updates
[2022-01-03 16:27:00,321][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:27:04,095][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:27:04,123][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 830 @ 33200 updates, score 3.822) (writing took 3.8032247591763735 seconds)
[2022-01-03 16:27:04,124][fairseq_cli.train][INFO] - end of epoch 830 (average epoch stats below)
[2022-01-03 16:27:04,137][train][INFO] - {"epoch": 830, "train_loss": "3.701", "train_ntokens": "1790.08", "train_nsentences": "4.95", "train_prob_perplexity": "122.27", "train_code_perplexity": "120.296", "train_temp": "1.694", "train_loss_0": "3.571", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.32168", "train_wps": "3912.9", "train_ups": "2.19", "train_wpb": "1790.1", "train_bsz": "5", "train_num_updates": "33200", "train_lr": "0.00049837", "train_gnorm": "0.522", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15442"}
[2022-01-03 16:27:04,211][fairseq.trainer][INFO] - begin training epoch 831
[2022-01-03 16:27:04,212][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:27:18,150][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:27:18,575][valid][INFO] - {"epoch": 831, "valid_loss": "3.522", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "116.387", "valid_code_perplexity": "114.295", "valid_temp": "1.694", "valid_loss_0": "3.393", "valid_loss_1": "0.118", "valid_loss_2": "0.011", "valid_accuracy": "0.34121", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "33240", "valid_best_loss": "3.221"}
[2022-01-03 16:27:18,579][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 831 @ 33240 updates
[2022-01-03 16:27:18,580][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:27:22,298][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:27:22,327][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 831 @ 33240 updates, score 3.522) (writing took 3.7483388213440776 seconds)
[2022-01-03 16:27:22,328][fairseq_cli.train][INFO] - end of epoch 831 (average epoch stats below)
[2022-01-03 16:27:22,340][train][INFO] - {"epoch": 831, "train_loss": "3.721", "train_ntokens": "1779.55", "train_nsentences": "4.95", "train_prob_perplexity": "122.435", "train_code_perplexity": "120.497", "train_temp": "1.694", "train_loss_0": "3.59", "train_loss_1": "0.117", "train_loss_2": "0.014", "train_accuracy": "0.31807", "train_wps": "3913", "train_ups": "2.2", "train_wpb": "1779.5", "train_bsz": "5", "train_num_updates": "33240", "train_lr": "0.000498315", "train_gnorm": "0.549", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "15460"}
[2022-01-03 16:27:22,410][fairseq.trainer][INFO] - begin training epoch 832
[2022-01-03 16:27:22,411][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:27:36,217][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:27:36,699][valid][INFO] - {"epoch": 832, "valid_loss": "3.29", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "121.005", "valid_code_perplexity": "117.566", "valid_temp": "1.693", "valid_loss_0": "3.161", "valid_loss_1": "0.117", "valid_loss_2": "0.012", "valid_accuracy": "0.40404", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "33280", "valid_best_loss": "3.221"}
[2022-01-03 16:27:36,701][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 832 @ 33280 updates
[2022-01-03 16:27:36,702][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:27:40,629][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:27:40,657][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 832 @ 33280 updates, score 3.29) (writing took 3.95616801828146 seconds)
[2022-01-03 16:27:40,658][fairseq_cli.train][INFO] - end of epoch 832 (average epoch stats below)
[2022-01-03 16:27:40,671][train][INFO] - {"epoch": 832, "train_loss": "3.726", "train_ntokens": "1813.8", "train_nsentences": "4.95", "train_prob_perplexity": "122.198", "train_code_perplexity": "120.31", "train_temp": "1.694", "train_loss_0": "3.596", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.31999", "train_wps": "3960.8", "train_ups": "2.18", "train_wpb": "1813.8", "train_bsz": "5", "train_num_updates": "33280", "train_lr": "0.000498261", "train_gnorm": "0.524", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "15478"}
[2022-01-03 16:27:40,748][fairseq.trainer][INFO] - begin training epoch 833
[2022-01-03 16:27:40,749][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:27:54,729][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:27:55,116][valid][INFO] - {"epoch": 833, "valid_loss": "3.28", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "115.129", "valid_code_perplexity": "109.541", "valid_temp": "1.693", "valid_loss_0": "3.148", "valid_loss_1": "0.118", "valid_loss_2": "0.014", "valid_accuracy": "0.37752", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "33320", "valid_best_loss": "3.221"}
[2022-01-03 16:27:55,119][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 833 @ 33320 updates
[2022-01-03 16:27:55,120][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:27:58,865][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:27:58,892][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 833 @ 33320 updates, score 3.28) (writing took 3.773354866541922 seconds)
[2022-01-03 16:27:58,893][fairseq_cli.train][INFO] - end of epoch 833 (average epoch stats below)
[2022-01-03 16:27:58,906][train][INFO] - {"epoch": 833, "train_loss": "3.706", "train_ntokens": "1795.22", "train_nsentences": "4.95", "train_prob_perplexity": "122.639", "train_code_perplexity": "120.663", "train_temp": "1.693", "train_loss_0": "3.576", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.32103", "train_wps": "3940.7", "train_ups": "2.2", "train_wpb": "1795.2", "train_bsz": "5", "train_num_updates": "33320", "train_lr": "0.000498207", "train_gnorm": "0.516", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15496"}
[2022-01-03 16:27:58,979][fairseq.trainer][INFO] - begin training epoch 834
[2022-01-03 16:27:58,980][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:28:12,946][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:28:13,365][valid][INFO] - {"epoch": 834, "valid_loss": "3.456", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "117.369", "valid_code_perplexity": "113.041", "valid_temp": "1.693", "valid_loss_0": "3.327", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.36695", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "33360", "valid_best_loss": "3.221"}
[2022-01-03 16:28:13,368][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 834 @ 33360 updates
[2022-01-03 16:28:13,369][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:28:17,197][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:28:17,226][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 834 @ 33360 updates, score 3.456) (writing took 3.8575008139014244 seconds)
[2022-01-03 16:28:17,226][fairseq_cli.train][INFO] - end of epoch 834 (average epoch stats below)
[2022-01-03 16:28:17,239][train][INFO] - {"epoch": 834, "train_loss": "3.708", "train_ntokens": "1787.62", "train_nsentences": "4.95", "train_prob_perplexity": "122.789", "train_code_perplexity": "120.926", "train_temp": "1.693", "train_loss_0": "3.578", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.3176", "train_wps": "3903", "train_ups": "2.18", "train_wpb": "1787.6", "train_bsz": "5", "train_num_updates": "33360", "train_lr": "0.000498152", "train_gnorm": "0.506", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "15515"}
[2022-01-03 16:28:17,301][fairseq.trainer][INFO] - begin training epoch 835
[2022-01-03 16:28:17,302][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:28:31,323][train_inner][INFO] - {"epoch": 835, "update": 835.0, "loss": "3.708", "ntokens": "1790.44", "nsentences": "4.95", "prob_perplexity": "122.466", "code_perplexity": "120.546", "temp": "1.693", "loss_0": "3.578", "loss_1": "0.117", "loss_2": "0.013", "accuracy": "0.31975", "wps": "3915", "ups": "2.19", "wpb": "1790.4", "bsz": "5", "num_updates": "33400", "lr": "0.000498098", "gnorm": "0.525", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "15529"}
[2022-01-03 16:28:31,324][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:28:31,744][valid][INFO] - {"epoch": 835, "valid_loss": "3.604", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "119.7", "valid_code_perplexity": "117.175", "valid_temp": "1.692", "valid_loss_0": "3.474", "valid_loss_1": "0.117", "valid_loss_2": "0.013", "valid_accuracy": "0.32597", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "33400", "valid_best_loss": "3.221"}
[2022-01-03 16:28:31,747][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 835 @ 33400 updates
[2022-01-03 16:28:31,748][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:28:35,434][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:28:35,461][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 835 @ 33400 updates, score 3.604) (writing took 3.7140432372689247 seconds)
[2022-01-03 16:28:35,462][fairseq_cli.train][INFO] - end of epoch 835 (average epoch stats below)
[2022-01-03 16:28:35,474][train][INFO] - {"epoch": 835, "train_loss": "3.68", "train_ntokens": "1776.03", "train_nsentences": "4.95", "train_prob_perplexity": "122.268", "train_code_perplexity": "120.334", "train_temp": "1.693", "train_loss_0": "3.55", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.32207", "train_wps": "3898.5", "train_ups": "2.2", "train_wpb": "1776", "train_bsz": "5", "train_num_updates": "33400", "train_lr": "0.000498098", "train_gnorm": "0.53", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15533"}
[2022-01-03 16:28:35,538][fairseq.trainer][INFO] - begin training epoch 836
[2022-01-03 16:28:35,538][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:28:49,467][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:28:49,874][valid][INFO] - {"epoch": 836, "valid_loss": "3.468", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "114.504", "valid_code_perplexity": "110.646", "valid_temp": "1.692", "valid_loss_0": "3.337", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.38046", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "33440", "valid_best_loss": "3.221"}
[2022-01-03 16:28:49,877][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 836 @ 33440 updates
[2022-01-03 16:28:49,879][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:28:53,743][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:28:53,769][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 836 @ 33440 updates, score 3.468) (writing took 3.8918214859440923 seconds)
[2022-01-03 16:28:53,770][fairseq_cli.train][INFO] - end of epoch 836 (average epoch stats below)
[2022-01-03 16:28:53,783][train][INFO] - {"epoch": 836, "train_loss": "3.674", "train_ntokens": "1783.53", "train_nsentences": "4.95", "train_prob_perplexity": "123.752", "train_code_perplexity": "121.91", "train_temp": "1.692", "train_loss_0": "3.545", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.32346", "train_wps": "3899.4", "train_ups": "2.19", "train_wpb": "1783.5", "train_bsz": "5", "train_num_updates": "33440", "train_lr": "0.000498043", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "15551"}
[2022-01-03 16:28:53,851][fairseq.trainer][INFO] - begin training epoch 837
[2022-01-03 16:28:53,852][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:29:07,698][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:29:08,112][valid][INFO] - {"epoch": 837, "valid_loss": "3.751", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "119.56", "valid_code_perplexity": "115.814", "valid_temp": "1.692", "valid_loss_0": "3.62", "valid_loss_1": "0.117", "valid_loss_2": "0.013", "valid_accuracy": "0.3078", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "33480", "valid_best_loss": "3.221"}
[2022-01-03 16:29:08,115][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 837 @ 33480 updates
[2022-01-03 16:29:08,115][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:29:11,938][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:29:11,967][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 837 @ 33480 updates, score 3.751) (writing took 3.8521746611222625 seconds)
[2022-01-03 16:29:11,967][fairseq_cli.train][INFO] - end of epoch 837 (average epoch stats below)
[2022-01-03 16:29:11,980][train][INFO] - {"epoch": 837, "train_loss": "3.744", "train_ntokens": "1791.08", "train_nsentences": "4.95", "train_prob_perplexity": "122.72", "train_code_perplexity": "120.6", "train_temp": "1.692", "train_loss_0": "3.614", "train_loss_1": "0.117", "train_loss_2": "0.013", "train_accuracy": "0.31343", "train_wps": "3939.8", "train_ups": "2.2", "train_wpb": "1791.1", "train_bsz": "5", "train_num_updates": "33480", "train_lr": "0.000497989", "train_gnorm": "0.53", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "15569"}
[2022-01-03 16:29:12,059][fairseq.trainer][INFO] - begin training epoch 838
[2022-01-03 16:29:12,059][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:29:26,072][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:29:26,482][valid][INFO] - {"epoch": 838, "valid_loss": "3.585", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "122.366", "valid_code_perplexity": "119.851", "valid_temp": "1.691", "valid_loss_0": "3.459", "valid_loss_1": "0.117", "valid_loss_2": "0.009", "valid_accuracy": "0.35634", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "33520", "valid_best_loss": "3.221"}
[2022-01-03 16:29:26,485][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 838 @ 33520 updates
[2022-01-03 16:29:26,485][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:29:30,161][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:29:30,189][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 838 @ 33520 updates, score 3.585) (writing took 3.7042595809325576 seconds)
[2022-01-03 16:29:30,189][fairseq_cli.train][INFO] - end of epoch 838 (average epoch stats below)
[2022-01-03 16:29:30,202][train][INFO] - {"epoch": 838, "train_loss": "3.756", "train_ntokens": "1788.2", "train_nsentences": "4.95", "train_prob_perplexity": "123.757", "train_code_perplexity": "121.722", "train_temp": "1.692", "train_loss_0": "3.627", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.31256", "train_wps": "3928.2", "train_ups": "2.2", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "33520", "train_lr": "0.000497935", "train_gnorm": "0.517", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15588"}
[2022-01-03 16:29:30,249][fairseq.trainer][INFO] - begin training epoch 839
[2022-01-03 16:29:30,250][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:29:44,164][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:29:44,601][valid][INFO] - {"epoch": 839, "valid_loss": "3.517", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "122.769", "valid_code_perplexity": "118.541", "valid_temp": "1.691", "valid_loss_0": "3.389", "valid_loss_1": "0.117", "valid_loss_2": "0.012", "valid_accuracy": "0.36412", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "33560", "valid_best_loss": "3.221"}
[2022-01-03 16:29:44,606][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 839 @ 33560 updates
[2022-01-03 16:29:44,607][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:29:48,432][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:29:48,459][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 839 @ 33560 updates, score 3.517) (writing took 3.8533122995868325 seconds)
[2022-01-03 16:29:48,460][fairseq_cli.train][INFO] - end of epoch 839 (average epoch stats below)
[2022-01-03 16:29:48,472][train][INFO] - {"epoch": 839, "train_loss": "3.711", "train_ntokens": "1804.67", "train_nsentences": "4.95", "train_prob_perplexity": "124.031", "train_code_perplexity": "122.123", "train_temp": "1.691", "train_loss_0": "3.582", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.31931", "train_wps": "3953.9", "train_ups": "2.19", "train_wpb": "1804.7", "train_bsz": "5", "train_num_updates": "33560", "train_lr": "0.00049788", "train_gnorm": "0.505", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15606"}
[2022-01-03 16:29:48,542][fairseq.trainer][INFO] - begin training epoch 840
[2022-01-03 16:29:48,543][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:30:02,576][train_inner][INFO] - {"epoch": 840, "update": 840.0, "loss": "3.717", "ntokens": "1792.29", "nsentences": "4.95", "prob_perplexity": "123.58", "code_perplexity": "121.618", "temp": "1.692", "loss_0": "3.588", "loss_1": "0.116", "loss_2": "0.013", "accuracy": "0.31794", "wps": "3928.7", "ups": "2.19", "wpb": "1792.3", "bsz": "5", "num_updates": "33600", "lr": "0.000497826", "gnorm": "0.519", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "15620"}
[2022-01-03 16:30:02,577][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:30:02,982][valid][INFO] - {"epoch": 840, "valid_loss": "3.487", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "110.368", "valid_code_perplexity": "105.478", "valid_temp": "1.691", "valid_loss_0": "3.354", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.36104", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "33600", "valid_best_loss": "3.221"}
[2022-01-03 16:30:02,985][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 840 @ 33600 updates
[2022-01-03 16:30:02,986][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:30:06,653][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:30:06,672][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 840 @ 33600 updates, score 3.487) (writing took 3.6873469930142164 seconds)
[2022-01-03 16:30:06,673][fairseq_cli.train][INFO] - end of epoch 840 (average epoch stats below)
[2022-01-03 16:30:06,686][train][INFO] - {"epoch": 840, "train_loss": "3.7", "train_ntokens": "1793.97", "train_nsentences": "4.95", "train_prob_perplexity": "123.64", "train_code_perplexity": "121.737", "train_temp": "1.691", "train_loss_0": "3.57", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.32094", "train_wps": "3942.7", "train_ups": "2.2", "train_wpb": "1794", "train_bsz": "5", "train_num_updates": "33600", "train_lr": "0.000497826", "train_gnorm": "0.524", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15624"}
[2022-01-03 16:30:06,747][fairseq.trainer][INFO] - begin training epoch 841
[2022-01-03 16:30:06,748][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:30:20,732][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:30:21,139][valid][INFO] - {"epoch": 841, "valid_loss": "3.493", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "117.256", "valid_code_perplexity": "113.016", "valid_temp": "1.69", "valid_loss_0": "3.362", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.33421", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "33640", "valid_best_loss": "3.221"}
[2022-01-03 16:30:21,141][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 841 @ 33640 updates
[2022-01-03 16:30:21,142][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:30:24,890][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:30:24,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 841 @ 33640 updates, score 3.493) (writing took 3.7749988846480846 seconds)
[2022-01-03 16:30:24,916][fairseq_cli.train][INFO] - end of epoch 841 (average epoch stats below)
[2022-01-03 16:30:24,930][train][INFO] - {"epoch": 841, "train_loss": "3.713", "train_ntokens": "1800.17", "train_nsentences": "4.95", "train_prob_perplexity": "123.596", "train_code_perplexity": "121.598", "train_temp": "1.691", "train_loss_0": "3.583", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.3209", "train_wps": "3949.8", "train_ups": "2.19", "train_wpb": "1800.2", "train_bsz": "5", "train_num_updates": "33640", "train_lr": "0.000497772", "train_gnorm": "0.515", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "15642"}
[2022-01-03 16:30:24,970][fairseq.trainer][INFO] - begin training epoch 842
[2022-01-03 16:30:24,971][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:30:38,911][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:30:39,314][valid][INFO] - {"epoch": 842, "valid_loss": "3.89", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "123.355", "valid_code_perplexity": "120.075", "valid_temp": "1.69", "valid_loss_0": "3.762", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.31217", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "33680", "valid_best_loss": "3.221"}
[2022-01-03 16:30:39,317][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 842 @ 33680 updates
[2022-01-03 16:30:39,318][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:30:43,246][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:30:43,273][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 842 @ 33680 updates, score 3.89) (writing took 3.956587789580226 seconds)
[2022-01-03 16:30:43,274][fairseq_cli.train][INFO] - end of epoch 842 (average epoch stats below)
[2022-01-03 16:30:43,286][train][INFO] - {"epoch": 842, "train_loss": "3.651", "train_ntokens": "1783.95", "train_nsentences": "4.95", "train_prob_perplexity": "124.061", "train_code_perplexity": "122.105", "train_temp": "1.69", "train_loss_0": "3.522", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32952", "train_wps": "3890", "train_ups": "2.18", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "33680", "train_lr": "0.000497717", "train_gnorm": "0.521", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15661"}
[2022-01-03 16:30:43,363][fairseq.trainer][INFO] - begin training epoch 843
[2022-01-03 16:30:43,364][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:30:57,301][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:30:57,728][valid][INFO] - {"epoch": 843, "valid_loss": "3.565", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "120.078", "valid_code_perplexity": "117.167", "valid_temp": "1.69", "valid_loss_0": "3.438", "valid_loss_1": "0.117", "valid_loss_2": "0.01", "valid_accuracy": "0.34184", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "33720", "valid_best_loss": "3.221"}
[2022-01-03 16:30:57,731][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 843 @ 33720 updates
[2022-01-03 16:30:57,732][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:31:01,414][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:31:01,441][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 843 @ 33720 updates, score 3.565) (writing took 3.7093260334804654 seconds)
[2022-01-03 16:31:01,441][fairseq_cli.train][INFO] - end of epoch 843 (average epoch stats below)
[2022-01-03 16:31:01,453][train][INFO] - {"epoch": 843, "train_loss": "3.672", "train_ntokens": "1788.88", "train_nsentences": "4.95", "train_prob_perplexity": "123.6", "train_code_perplexity": "121.585", "train_temp": "1.69", "train_loss_0": "3.543", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32501", "train_wps": "3941.4", "train_ups": "2.2", "train_wpb": "1788.9", "train_bsz": "5", "train_num_updates": "33720", "train_lr": "0.000497663", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15679"}
[2022-01-03 16:31:01,526][fairseq.trainer][INFO] - begin training epoch 844
[2022-01-03 16:31:01,527][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:31:15,410][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:31:15,833][valid][INFO] - {"epoch": 844, "valid_loss": "3.805", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "118.465", "valid_code_perplexity": "115.048", "valid_temp": "1.689", "valid_loss_0": "3.675", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.30902", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "33760", "valid_best_loss": "3.221"}
[2022-01-03 16:31:15,837][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 844 @ 33760 updates
[2022-01-03 16:31:15,838][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:31:19,725][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:31:19,754][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 844 @ 33760 updates, score 3.805) (writing took 3.9175221659243107 seconds)
[2022-01-03 16:31:19,755][fairseq_cli.train][INFO] - end of epoch 844 (average epoch stats below)
[2022-01-03 16:31:19,768][train][INFO] - {"epoch": 844, "train_loss": "3.677", "train_ntokens": "1802.22", "train_nsentences": "4.95", "train_prob_perplexity": "123.63", "train_code_perplexity": "121.532", "train_temp": "1.69", "train_loss_0": "3.548", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.3256", "train_wps": "3939", "train_ups": "2.19", "train_wpb": "1802.2", "train_bsz": "5", "train_num_updates": "33760", "train_lr": "0.000497609", "train_gnorm": "0.514", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "15697"}
[2022-01-03 16:31:19,824][fairseq.trainer][INFO] - begin training epoch 845
[2022-01-03 16:31:19,825][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:31:33,909][train_inner][INFO] - {"epoch": 845, "update": 845.0, "loss": "3.684", "ntokens": "1797.07", "nsentences": "4.95", "prob_perplexity": "123.714", "code_perplexity": "121.692", "temp": "1.69", "loss_0": "3.555", "loss_1": "0.116", "loss_2": "0.012", "accuracy": "0.32405", "wps": "3935.8", "ups": "2.19", "wpb": "1797.1", "bsz": "5", "num_updates": "33800", "lr": "0.000497554", "gnorm": "0.517", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "15711"}
[2022-01-03 16:31:33,910][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:31:34,355][valid][INFO] - {"epoch": 845, "valid_loss": "3.496", "valid_ntokens": "702", "valid_nsentences": "2", "valid_prob_perplexity": "119.509", "valid_code_perplexity": "114.531", "valid_temp": "1.689", "valid_loss_0": "3.365", "valid_loss_1": "0.117", "valid_loss_2": "0.014", "valid_accuracy": "0.37892", "valid_wps": "0", "valid_wpb": "702", "valid_bsz": "2", "valid_num_updates": "33800", "valid_best_loss": "3.221"}
[2022-01-03 16:31:34,358][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 845 @ 33800 updates
[2022-01-03 16:31:34,359][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:31:37,972][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:31:37,993][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 845 @ 33800 updates, score 3.496) (writing took 3.634483901783824 seconds)
[2022-01-03 16:31:37,993][fairseq_cli.train][INFO] - end of epoch 845 (average epoch stats below)
[2022-01-03 16:31:38,005][train][INFO] - {"epoch": 845, "train_loss": "3.709", "train_ntokens": "1810.1", "train_nsentences": "4.95", "train_prob_perplexity": "123.681", "train_code_perplexity": "121.639", "train_temp": "1.689", "train_loss_0": "3.58", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.31928", "train_wps": "3972.7", "train_ups": "2.19", "train_wpb": "1810.1", "train_bsz": "5", "train_num_updates": "33800", "train_lr": "0.000497554", "train_gnorm": "0.525", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15715"}
[2022-01-03 16:31:38,074][fairseq.trainer][INFO] - begin training epoch 846
[2022-01-03 16:31:38,075][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:31:52,122][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:31:52,534][valid][INFO] - {"epoch": 846, "valid_loss": "3.789", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "124.363", "valid_code_perplexity": "119.821", "valid_temp": "1.689", "valid_loss_0": "3.66", "valid_loss_1": "0.116", "valid_loss_2": "0.013", "valid_accuracy": "0.30295", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "33840", "valid_best_loss": "3.221"}
[2022-01-03 16:31:52,536][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 846 @ 33840 updates
[2022-01-03 16:31:52,537][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:31:56,195][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:31:56,220][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 846 @ 33840 updates, score 3.789) (writing took 3.683289185166359 seconds)
[2022-01-03 16:31:56,220][fairseq_cli.train][INFO] - end of epoch 846 (average epoch stats below)
[2022-01-03 16:31:56,233][train][INFO] - {"epoch": 846, "train_loss": "3.678", "train_ntokens": "1793.65", "train_nsentences": "4.95", "train_prob_perplexity": "124.29", "train_code_perplexity": "122.257", "train_temp": "1.689", "train_loss_0": "3.549", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.32465", "train_wps": "3938.9", "train_ups": "2.2", "train_wpb": "1793.7", "train_bsz": "5", "train_num_updates": "33840", "train_lr": "0.0004975", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15734"}
[2022-01-03 16:31:56,304][fairseq.trainer][INFO] - begin training epoch 847
[2022-01-03 16:31:56,304][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:32:10,174][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:32:10,579][valid][INFO] - {"epoch": 847, "valid_loss": "3.439", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "119.77", "valid_code_perplexity": "115.854", "valid_temp": "1.688", "valid_loss_0": "3.311", "valid_loss_1": "0.117", "valid_loss_2": "0.011", "valid_accuracy": "0.34734", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "33880", "valid_best_loss": "3.221"}
[2022-01-03 16:32:10,582][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 847 @ 33880 updates
[2022-01-03 16:32:10,582][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:32:14,520][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:32:14,548][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 847 @ 33880 updates, score 3.439) (writing took 3.9662822261452675 seconds)
[2022-01-03 16:32:14,548][fairseq_cli.train][INFO] - end of epoch 847 (average epoch stats below)
[2022-01-03 16:32:14,561][train][INFO] - {"epoch": 847, "train_loss": "3.72", "train_ntokens": "1779.97", "train_nsentences": "4.95", "train_prob_perplexity": "124.171", "train_code_perplexity": "122.094", "train_temp": "1.689", "train_loss_0": "3.59", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.31882", "train_wps": "3887.4", "train_ups": "2.18", "train_wpb": "1780", "train_bsz": "5", "train_num_updates": "33880", "train_lr": "0.000497446", "train_gnorm": "0.538", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15752"}
[2022-01-03 16:32:14,615][fairseq.trainer][INFO] - begin training epoch 848
[2022-01-03 16:32:14,616][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:32:28,527][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:32:28,929][valid][INFO] - {"epoch": 848, "valid_loss": "3.549", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "121.25", "valid_code_perplexity": "117.358", "valid_temp": "1.688", "valid_loss_0": "3.42", "valid_loss_1": "0.117", "valid_loss_2": "0.012", "valid_accuracy": "0.34574", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "33920", "valid_best_loss": "3.221"}
[2022-01-03 16:32:28,931][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 848 @ 33920 updates
[2022-01-03 16:32:28,932][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:32:32,727][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:32:32,754][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 848 @ 33920 updates, score 3.549) (writing took 3.8226916706189513 seconds)
[2022-01-03 16:32:32,755][fairseq_cli.train][INFO] - end of epoch 848 (average epoch stats below)
[2022-01-03 16:32:32,767][train][INFO] - {"epoch": 848, "train_loss": "3.669", "train_ntokens": "1798.42", "train_nsentences": "4.95", "train_prob_perplexity": "124.99", "train_code_perplexity": "123.045", "train_temp": "1.688", "train_loss_0": "3.541", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32616", "train_wps": "3953.9", "train_ups": "2.2", "train_wpb": "1798.4", "train_bsz": "5", "train_num_updates": "33920", "train_lr": "0.000497391", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15770"}
[2022-01-03 16:32:32,840][fairseq.trainer][INFO] - begin training epoch 849
[2022-01-03 16:32:32,841][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:32:46,733][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:32:47,191][valid][INFO] - {"epoch": 849, "valid_loss": "3.716", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "116.739", "valid_code_perplexity": "112.316", "valid_temp": "1.688", "valid_loss_0": "3.587", "valid_loss_1": "0.118", "valid_loss_2": "0.011", "valid_accuracy": "0.28982", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "33960", "valid_best_loss": "3.221"}
[2022-01-03 16:32:47,194][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 849 @ 33960 updates
[2022-01-03 16:32:47,195][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:32:50,974][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:32:51,002][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 849 @ 33960 updates, score 3.716) (writing took 3.8079080497846007 seconds)
[2022-01-03 16:32:51,002][fairseq_cli.train][INFO] - end of epoch 849 (average epoch stats below)
[2022-01-03 16:32:51,015][train][INFO] - {"epoch": 849, "train_loss": "3.713", "train_ntokens": "1791.62", "train_nsentences": "4.95", "train_prob_perplexity": "124.747", "train_code_perplexity": "122.556", "train_temp": "1.688", "train_loss_0": "3.584", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32056", "train_wps": "3930", "train_ups": "2.19", "train_wpb": "1791.6", "train_bsz": "5", "train_num_updates": "33960", "train_lr": "0.000497337", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15788"}
[2022-01-03 16:32:51,093][fairseq.trainer][INFO] - begin training epoch 850
[2022-01-03 16:32:51,093][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:33:04,870][train_inner][INFO] - {"epoch": 850, "update": 850.0, "loss": "3.701", "ntokens": "1792.43", "nsentences": "4.95", "prob_perplexity": "124.474", "code_perplexity": "122.391", "temp": "1.688", "loss_0": "3.572", "loss_1": "0.116", "loss_2": "0.013", "accuracy": "0.32155", "wps": "3941.6", "ups": "2.2", "wpb": "1792.4", "bsz": "5", "num_updates": "34000", "lr": "0.000497283", "gnorm": "0.52", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "15802"}
[2022-01-03 16:33:04,871][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:33:05,270][valid][INFO] - {"epoch": 850, "valid_loss": "3.294", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "122.494", "valid_code_perplexity": "117.428", "valid_temp": "1.687", "valid_loss_0": "3.165", "valid_loss_1": "0.117", "valid_loss_2": "0.012", "valid_accuracy": "0.39548", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "34000", "valid_best_loss": "3.221"}
[2022-01-03 16:33:05,273][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 850 @ 34000 updates
[2022-01-03 16:33:05,274][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:33:09,207][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:33:09,234][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 850 @ 34000 updates, score 3.294) (writing took 3.960788117721677 seconds)
[2022-01-03 16:33:09,234][fairseq_cli.train][INFO] - end of epoch 850 (average epoch stats below)
[2022-01-03 16:33:09,247][train][INFO] - {"epoch": 850, "train_loss": "3.723", "train_ntokens": "1798.5", "train_nsentences": "4.95", "train_prob_perplexity": "124.173", "train_code_perplexity": "122.005", "train_temp": "1.688", "train_loss_0": "3.594", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.31753", "train_wps": "3948.5", "train_ups": "2.2", "train_wpb": "1798.5", "train_bsz": "5", "train_num_updates": "34000", "train_lr": "0.000497283", "train_gnorm": "0.522", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "15807"}
[2022-01-03 16:33:09,302][fairseq.trainer][INFO] - begin training epoch 851
[2022-01-03 16:33:09,303][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:33:23,249][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:33:23,731][valid][INFO] - {"epoch": 851, "valid_loss": "4.161", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "122.496", "valid_code_perplexity": "118.579", "valid_temp": "1.687", "valid_loss_0": "4.032", "valid_loss_1": "0.117", "valid_loss_2": "0.013", "valid_accuracy": "0.2931", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "34040", "valid_best_loss": "3.221"}
[2022-01-03 16:33:23,733][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 851 @ 34040 updates
[2022-01-03 16:33:23,733][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:33:27,412][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:33:27,421][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 851 @ 34040 updates, score 4.161) (writing took 3.688501943834126 seconds)
[2022-01-03 16:33:27,422][fairseq_cli.train][INFO] - end of epoch 851 (average epoch stats below)
[2022-01-03 16:33:27,435][train][INFO] - {"epoch": 851, "train_loss": "3.676", "train_ntokens": "1777.67", "train_nsentences": "4.95", "train_prob_perplexity": "125.386", "train_code_perplexity": "123.347", "train_temp": "1.687", "train_loss_0": "3.548", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.32616", "train_wps": "3912.4", "train_ups": "2.2", "train_wpb": "1777.7", "train_bsz": "5", "train_num_updates": "34040", "train_lr": "0.000497228", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15825"}
[2022-01-03 16:33:27,489][fairseq.trainer][INFO] - begin training epoch 852
[2022-01-03 16:33:27,490][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:33:41,470][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:33:41,882][valid][INFO] - {"epoch": 852, "valid_loss": "3.628", "valid_ntokens": "800", "valid_nsentences": "2", "valid_prob_perplexity": "122.171", "valid_code_perplexity": "118.621", "valid_temp": "1.687", "valid_loss_0": "3.5", "valid_loss_1": "0.117", "valid_loss_2": "0.011", "valid_accuracy": "0.3375", "valid_wps": "0", "valid_wpb": "800", "valid_bsz": "2", "valid_num_updates": "34080", "valid_best_loss": "3.221"}
[2022-01-03 16:33:41,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 852 @ 34080 updates
[2022-01-03 16:33:41,885][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:33:45,681][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:33:45,710][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 852 @ 34080 updates, score 3.628) (writing took 3.825507524423301 seconds)
[2022-01-03 16:33:45,711][fairseq_cli.train][INFO] - end of epoch 852 (average epoch stats below)
[2022-01-03 16:33:45,723][train][INFO] - {"epoch": 852, "train_loss": "3.646", "train_ntokens": "1781.47", "train_nsentences": "4.95", "train_prob_perplexity": "125.32", "train_code_perplexity": "123.106", "train_temp": "1.687", "train_loss_0": "3.517", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32782", "train_wps": "3899.1", "train_ups": "2.19", "train_wpb": "1781.5", "train_bsz": "5", "train_num_updates": "34080", "train_lr": "0.000497174", "train_gnorm": "0.524", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15843"}
[2022-01-03 16:33:45,777][fairseq.trainer][INFO] - begin training epoch 853
[2022-01-03 16:33:45,778][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:33:59,723][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:34:00,227][valid][INFO] - {"epoch": 853, "valid_loss": "3.555", "valid_ntokens": "794", "valid_nsentences": "2", "valid_prob_perplexity": "124.893", "valid_code_perplexity": "121.552", "valid_temp": "1.686", "valid_loss_0": "3.428", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.35768", "valid_wps": "0", "valid_wpb": "794", "valid_bsz": "2", "valid_num_updates": "34120", "valid_best_loss": "3.221"}
[2022-01-03 16:34:00,229][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 853 @ 34120 updates
[2022-01-03 16:34:00,229][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:34:03,895][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:34:03,924][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 853 @ 34120 updates, score 3.555) (writing took 3.6954154865816236 seconds)
[2022-01-03 16:34:03,925][fairseq_cli.train][INFO] - end of epoch 853 (average epoch stats below)
[2022-01-03 16:34:03,938][train][INFO] - {"epoch": 853, "train_loss": "3.667", "train_ntokens": "1792.5", "train_nsentences": "4.95", "train_prob_perplexity": "124.574", "train_code_perplexity": "122.34", "train_temp": "1.686", "train_loss_0": "3.538", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.32476", "train_wps": "3939.1", "train_ups": "2.2", "train_wpb": "1792.5", "train_bsz": "5", "train_num_updates": "34120", "train_lr": "0.00049712", "train_gnorm": "0.527", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "15861"}
[2022-01-03 16:34:04,024][fairseq.trainer][INFO] - begin training epoch 854
[2022-01-03 16:34:04,025][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:34:17,929][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:34:18,340][valid][INFO] - {"epoch": 854, "valid_loss": "3.383", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "119.783", "valid_code_perplexity": "114.845", "valid_temp": "1.686", "valid_loss_0": "3.254", "valid_loss_1": "0.117", "valid_loss_2": "0.011", "valid_accuracy": "0.38251", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "34160", "valid_best_loss": "3.221"}
[2022-01-03 16:34:18,343][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 854 @ 34160 updates
[2022-01-03 16:34:18,344][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:34:22,142][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:34:22,168][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 854 @ 34160 updates, score 3.383) (writing took 3.825067969970405 seconds)
[2022-01-03 16:34:22,169][fairseq_cli.train][INFO] - end of epoch 854 (average epoch stats below)
[2022-01-03 16:34:22,182][train][INFO] - {"epoch": 854, "train_loss": "3.688", "train_ntokens": "1800.72", "train_nsentences": "4.95", "train_prob_perplexity": "126.602", "train_code_perplexity": "124.498", "train_temp": "1.686", "train_loss_0": "3.56", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.32051", "train_wps": "3951.1", "train_ups": "2.19", "train_wpb": "1800.7", "train_bsz": "5", "train_num_updates": "34160", "train_lr": "0.000497065", "train_gnorm": "0.526", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "15880"}
[2022-01-03 16:34:22,254][fairseq.trainer][INFO] - begin training epoch 855
[2022-01-03 16:34:22,255][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:34:36,184][train_inner][INFO] - {"epoch": 855, "update": 855.0, "loss": "3.673", "ntokens": "1789.18", "nsentences": "4.95", "prob_perplexity": "125.78", "code_perplexity": "123.671", "temp": "1.686", "loss_0": "3.544", "loss_1": "0.116", "loss_2": "0.013", "accuracy": "0.32425", "wps": "3919.3", "ups": "2.19", "wpb": "1789.2", "bsz": "5", "num_updates": "34200", "lr": "0.000497011", "gnorm": "0.518", "clip": "0", "train_wall": "68", "gb_free": "6.1", "wall": "15894"}
[2022-01-03 16:34:36,185][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:34:36,593][valid][INFO] - {"epoch": 855, "valid_loss": "3.622", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "110.199", "valid_code_perplexity": "107.153", "valid_temp": "1.686", "valid_loss_0": "3.49", "valid_loss_1": "0.119", "valid_loss_2": "0.013", "valid_accuracy": "0.35014", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "34200", "valid_best_loss": "3.221"}
[2022-01-03 16:34:36,598][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 855 @ 34200 updates
[2022-01-03 16:34:36,599][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:34:40,473][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:34:40,502][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 855 @ 34200 updates, score 3.622) (writing took 3.904298571869731 seconds)
[2022-01-03 16:34:40,502][fairseq_cli.train][INFO] - end of epoch 855 (average epoch stats below)
[2022-01-03 16:34:40,515][train][INFO] - {"epoch": 855, "train_loss": "3.685", "train_ntokens": "1793.55", "train_nsentences": "4.95", "train_prob_perplexity": "127.018", "train_code_perplexity": "125.064", "train_temp": "1.686", "train_loss_0": "3.557", "train_loss_1": "0.116", "train_loss_2": "0.013", "train_accuracy": "0.32206", "train_wps": "3915.9", "train_ups": "2.18", "train_wpb": "1793.5", "train_bsz": "5", "train_num_updates": "34200", "train_lr": "0.000497011", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "15898"}
[2022-01-03 16:34:40,597][fairseq.trainer][INFO] - begin training epoch 856
[2022-01-03 16:34:40,598][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:34:54,504][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:34:54,935][valid][INFO] - {"epoch": 856, "valid_loss": "3.53", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "124.086", "valid_code_perplexity": "120.746", "valid_temp": "1.685", "valid_loss_0": "3.402", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.36184", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "34240", "valid_best_loss": "3.221"}
[2022-01-03 16:34:54,940][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 856 @ 34240 updates
[2022-01-03 16:34:54,942][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:34:58,742][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:34:58,770][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 856 @ 34240 updates, score 3.53) (writing took 3.8297247579321265 seconds)
[2022-01-03 16:34:58,771][fairseq_cli.train][INFO] - end of epoch 856 (average epoch stats below)
[2022-01-03 16:34:58,783][train][INFO] - {"epoch": 856, "train_loss": "3.666", "train_ntokens": "1789.58", "train_nsentences": "4.95", "train_prob_perplexity": "126.301", "train_code_perplexity": "124.128", "train_temp": "1.685", "train_loss_0": "3.537", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.3255", "train_wps": "3921.2", "train_ups": "2.19", "train_wpb": "1789.6", "train_bsz": "5", "train_num_updates": "34240", "train_lr": "0.000496957", "train_gnorm": "0.533", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15916"}
[2022-01-03 16:34:58,861][fairseq.trainer][INFO] - begin training epoch 857
[2022-01-03 16:34:58,862][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:35:12,636][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:35:13,043][valid][INFO] - {"epoch": 857, "valid_loss": "3.586", "valid_ntokens": "804", "valid_nsentences": "2", "valid_prob_perplexity": "119.232", "valid_code_perplexity": "114.41", "valid_temp": "1.685", "valid_loss_0": "3.458", "valid_loss_1": "0.117", "valid_loss_2": "0.011", "valid_accuracy": "0.34701", "valid_wps": "0", "valid_wpb": "804", "valid_bsz": "2", "valid_num_updates": "34280", "valid_best_loss": "3.221"}
[2022-01-03 16:35:13,046][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 857 @ 34280 updates
[2022-01-03 16:35:13,047][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:35:16,992][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:35:17,020][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 857 @ 34280 updates, score 3.586) (writing took 3.973621374927461 seconds)
[2022-01-03 16:35:17,020][fairseq_cli.train][INFO] - end of epoch 857 (average epoch stats below)
[2022-01-03 16:35:17,033][train][INFO] - {"epoch": 857, "train_loss": "3.658", "train_ntokens": "1790.75", "train_nsentences": "4.95", "train_prob_perplexity": "126.101", "train_code_perplexity": "123.656", "train_temp": "1.685", "train_loss_0": "3.53", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32697", "train_wps": "3927.7", "train_ups": "2.19", "train_wpb": "1790.8", "train_bsz": "5", "train_num_updates": "34280", "train_lr": "0.000496902", "train_gnorm": "0.516", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15934"}
[2022-01-03 16:35:17,102][fairseq.trainer][INFO] - begin training epoch 858
[2022-01-03 16:35:17,103][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:35:31,031][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:35:31,442][valid][INFO] - {"epoch": 858, "valid_loss": "3.434", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "125.903", "valid_code_perplexity": "121.845", "valid_temp": "1.685", "valid_loss_0": "3.307", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.35946", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "34320", "valid_best_loss": "3.221"}
[2022-01-03 16:35:31,445][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 858 @ 34320 updates
[2022-01-03 16:35:31,445][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:35:35,259][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:35:35,288][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 858 @ 34320 updates, score 3.434) (writing took 3.8429125901311636 seconds)
[2022-01-03 16:35:35,288][fairseq_cli.train][INFO] - end of epoch 858 (average epoch stats below)
[2022-01-03 16:35:35,301][train][INFO] - {"epoch": 858, "train_loss": "3.664", "train_ntokens": "1790.9", "train_nsentences": "4.95", "train_prob_perplexity": "126.875", "train_code_perplexity": "124.691", "train_temp": "1.685", "train_loss_0": "3.537", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32671", "train_wps": "3924.1", "train_ups": "2.19", "train_wpb": "1790.9", "train_bsz": "5", "train_num_updates": "34320", "train_lr": "0.000496848", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "15953"}
[2022-01-03 16:35:35,381][fairseq.trainer][INFO] - begin training epoch 859
[2022-01-03 16:35:35,382][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:35:49,189][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:35:49,606][valid][INFO] - {"epoch": 859, "valid_loss": "3.366", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "118.257", "valid_code_perplexity": "114.189", "valid_temp": "1.684", "valid_loss_0": "3.237", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.36842", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "34360", "valid_best_loss": "3.221"}
[2022-01-03 16:35:49,611][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 859 @ 34360 updates
[2022-01-03 16:35:49,612][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:35:53,523][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:35:53,551][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 859 @ 34360 updates, score 3.366) (writing took 3.9403245076537132 seconds)
[2022-01-03 16:35:53,551][fairseq_cli.train][INFO] - end of epoch 859 (average epoch stats below)
[2022-01-03 16:35:53,564][train][INFO] - {"epoch": 859, "train_loss": "3.68", "train_ntokens": "1775.03", "train_nsentences": "4.95", "train_prob_perplexity": "126.563", "train_code_perplexity": "124.245", "train_temp": "1.684", "train_loss_0": "3.552", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32577", "train_wps": "3890.5", "train_ups": "2.19", "train_wpb": "1775", "train_bsz": "5", "train_num_updates": "34360", "train_lr": "0.000496793", "train_gnorm": "0.533", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "15971"}
[2022-01-03 16:35:53,639][fairseq.trainer][INFO] - begin training epoch 860
[2022-01-03 16:35:53,640][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:36:07,632][train_inner][INFO] - {"epoch": 860, "update": 860.0, "loss": "3.67", "ntokens": "1791.92", "nsentences": "4.95", "prob_perplexity": "126.669", "code_perplexity": "124.423", "temp": "1.685", "loss_0": "3.542", "loss_1": "0.116", "loss_2": "0.012", "accuracy": "0.32573", "wps": "3919.5", "ups": "2.19", "wpb": "1791.9", "bsz": "5", "num_updates": "34400", "lr": "0.000496739", "gnorm": "0.52", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "15985"}
[2022-01-03 16:36:07,633][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:36:08,036][valid][INFO] - {"epoch": 860, "valid_loss": "3.4", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "124.587", "valid_code_perplexity": "121.203", "valid_temp": "1.684", "valid_loss_0": "3.272", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.35676", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "34400", "valid_best_loss": "3.221"}
[2022-01-03 16:36:08,039][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 860 @ 34400 updates
[2022-01-03 16:36:08,040][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:36:11,748][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:36:11,777][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 860 @ 34400 updates, score 3.4) (writing took 3.737919809296727 seconds)
[2022-01-03 16:36:11,777][fairseq_cli.train][INFO] - end of epoch 860 (average epoch stats below)
[2022-01-03 16:36:11,790][train][INFO] - {"epoch": 860, "train_loss": "3.683", "train_ntokens": "1813.38", "train_nsentences": "4.95", "train_prob_perplexity": "127.502", "train_code_perplexity": "125.396", "train_temp": "1.684", "train_loss_0": "3.555", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32375", "train_wps": "3982.7", "train_ups": "2.2", "train_wpb": "1813.4", "train_bsz": "5", "train_num_updates": "34400", "train_lr": "0.000496739", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "15989"}
[2022-01-03 16:36:11,871][fairseq.trainer][INFO] - begin training epoch 861
[2022-01-03 16:36:11,872][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:36:25,678][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:36:26,092][valid][INFO] - {"epoch": 861, "valid_loss": "3.528", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "114.435", "valid_code_perplexity": "111.656", "valid_temp": "1.684", "valid_loss_0": "3.396", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.36639", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "34440", "valid_best_loss": "3.221"}
[2022-01-03 16:36:26,095][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 861 @ 34440 updates
[2022-01-03 16:36:26,095][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:36:30,006][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:36:30,033][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 861 @ 34440 updates, score 3.528) (writing took 3.9380488181486726 seconds)
[2022-01-03 16:36:30,033][fairseq_cli.train][INFO] - end of epoch 861 (average epoch stats below)
[2022-01-03 16:36:30,046][train][INFO] - {"epoch": 861, "train_loss": "3.679", "train_ntokens": "1778.08", "train_nsentences": "4.95", "train_prob_perplexity": "126.949", "train_code_perplexity": "124.669", "train_temp": "1.684", "train_loss_0": "3.551", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32504", "train_wps": "3898.7", "train_ups": "2.19", "train_wpb": "1778.1", "train_bsz": "5", "train_num_updates": "34440", "train_lr": "0.000496685", "train_gnorm": "0.517", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16007"}
[2022-01-03 16:36:30,100][fairseq.trainer][INFO] - begin training epoch 862
[2022-01-03 16:36:30,100][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:36:44,044][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:36:44,467][valid][INFO] - {"epoch": 862, "valid_loss": "3.515", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "127.524", "valid_code_perplexity": "123.927", "valid_temp": "1.683", "valid_loss_0": "3.386", "valid_loss_1": "0.116", "valid_loss_2": "0.013", "valid_accuracy": "0.36563", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "34480", "valid_best_loss": "3.221"}
[2022-01-03 16:36:44,469][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 862 @ 34480 updates
[2022-01-03 16:36:44,470][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:36:48,189][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:36:48,209][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 862 @ 34480 updates, score 3.515) (writing took 3.7400891315191984 seconds)
[2022-01-03 16:36:48,210][fairseq_cli.train][INFO] - end of epoch 862 (average epoch stats below)
[2022-01-03 16:36:48,222][train][INFO] - {"epoch": 862, "train_loss": "3.667", "train_ntokens": "1798.75", "train_nsentences": "4.95", "train_prob_perplexity": "128.058", "train_code_perplexity": "126.024", "train_temp": "1.683", "train_loss_0": "3.539", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32563", "train_wps": "3961.2", "train_ups": "2.2", "train_wpb": "1798.8", "train_bsz": "5", "train_num_updates": "34480", "train_lr": "0.00049663", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "16026"}
[2022-01-03 16:36:48,287][fairseq.trainer][INFO] - begin training epoch 863
[2022-01-03 16:36:48,287][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:37:02,223][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:37:02,637][valid][INFO] - {"epoch": 863, "valid_loss": "3.5", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "122.47", "valid_code_perplexity": "118.978", "valid_temp": "1.683", "valid_loss_0": "3.37", "valid_loss_1": "0.117", "valid_loss_2": "0.013", "valid_accuracy": "0.36538", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "34520", "valid_best_loss": "3.221"}
[2022-01-03 16:37:02,640][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 863 @ 34520 updates
[2022-01-03 16:37:02,641][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:37:06,485][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:37:06,510][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 863 @ 34520 updates, score 3.5) (writing took 3.8694854928180575 seconds)
[2022-01-03 16:37:06,510][fairseq_cli.train][INFO] - end of epoch 863 (average epoch stats below)
[2022-01-03 16:37:06,523][train][INFO] - {"epoch": 863, "train_loss": "3.656", "train_ntokens": "1790.88", "train_nsentences": "4.95", "train_prob_perplexity": "125.913", "train_code_perplexity": "123.623", "train_temp": "1.683", "train_loss_0": "3.528", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.326", "train_wps": "3917.1", "train_ups": "2.19", "train_wpb": "1790.9", "train_bsz": "5", "train_num_updates": "34520", "train_lr": "0.000496576", "train_gnorm": "0.513", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16044"}
[2022-01-03 16:37:06,566][fairseq.trainer][INFO] - begin training epoch 864
[2022-01-03 16:37:06,567][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:37:20,544][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:37:21,012][valid][INFO] - {"epoch": 864, "valid_loss": "3.471", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "122.204", "valid_code_perplexity": "118.128", "valid_temp": "1.683", "valid_loss_0": "3.342", "valid_loss_1": "0.117", "valid_loss_2": "0.013", "valid_accuracy": "0.35121", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "34560", "valid_best_loss": "3.221"}
[2022-01-03 16:37:21,015][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 864 @ 34560 updates
[2022-01-03 16:37:21,016][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:37:24,706][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:37:24,735][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 864 @ 34560 updates, score 3.471) (writing took 3.719832146540284 seconds)
[2022-01-03 16:37:24,736][fairseq_cli.train][INFO] - end of epoch 864 (average epoch stats below)
[2022-01-03 16:37:24,750][train][INFO] - {"epoch": 864, "train_loss": "3.679", "train_ntokens": "1796.72", "train_nsentences": "4.95", "train_prob_perplexity": "126.96", "train_code_perplexity": "124.813", "train_temp": "1.683", "train_loss_0": "3.551", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32316", "train_wps": "3946.1", "train_ups": "2.2", "train_wpb": "1796.7", "train_bsz": "5", "train_num_updates": "34560", "train_lr": "0.000496522", "train_gnorm": "0.519", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "16062"}
[2022-01-03 16:37:24,831][fairseq.trainer][INFO] - begin training epoch 865
[2022-01-03 16:37:24,832][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:37:38,814][train_inner][INFO] - {"epoch": 865, "update": 865.0, "loss": "3.665", "ntokens": "1788.38", "nsentences": "4.95", "prob_perplexity": "127.148", "code_perplexity": "124.992", "temp": "1.683", "loss_0": "3.537", "loss_1": "0.116", "loss_2": "0.012", "accuracy": "0.32629", "wps": "3923.2", "ups": "2.19", "wpb": "1788.4", "bsz": "5", "num_updates": "34600", "lr": "0.000496467", "gnorm": "0.516", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "16076"}
[2022-01-03 16:37:38,815][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:37:39,231][valid][INFO] - {"epoch": 865, "valid_loss": "3.684", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "122.276", "valid_code_perplexity": "117.32", "valid_temp": "1.682", "valid_loss_0": "3.555", "valid_loss_1": "0.117", "valid_loss_2": "0.012", "valid_accuracy": "0.32958", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "34600", "valid_best_loss": "3.221"}
[2022-01-03 16:37:39,234][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 865 @ 34600 updates
[2022-01-03 16:37:39,235][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:37:43,006][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:37:43,026][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 865 @ 34600 updates, score 3.684) (writing took 3.7918203258886933 seconds)
[2022-01-03 16:37:43,026][fairseq_cli.train][INFO] - end of epoch 865 (average epoch stats below)
[2022-01-03 16:37:43,039][train][INFO] - {"epoch": 865, "train_loss": "3.644", "train_ntokens": "1777.5", "train_nsentences": "4.95", "train_prob_perplexity": "127.859", "train_code_perplexity": "125.831", "train_temp": "1.682", "train_loss_0": "3.516", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.33166", "train_wps": "3890.3", "train_ups": "2.19", "train_wpb": "1777.5", "train_bsz": "5", "train_num_updates": "34600", "train_lr": "0.000496467", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16080"}
[2022-01-03 16:37:43,090][fairseq.trainer][INFO] - begin training epoch 866
[2022-01-03 16:37:43,091][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:37:57,093][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:37:57,503][valid][INFO] - {"epoch": 866, "valid_loss": "3.821", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "126.562", "valid_code_perplexity": "122.604", "valid_temp": "1.682", "valid_loss_0": "3.694", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.29515", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "34640", "valid_best_loss": "3.221"}
[2022-01-03 16:37:57,506][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 866 @ 34640 updates
[2022-01-03 16:37:57,507][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:38:01,317][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:38:01,349][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 866 @ 34640 updates, score 3.821) (writing took 3.8428890770301223 seconds)
[2022-01-03 16:38:01,350][fairseq_cli.train][INFO] - end of epoch 866 (average epoch stats below)
[2022-01-03 16:38:01,362][train][INFO] - {"epoch": 866, "train_loss": "3.694", "train_ntokens": "1800.33", "train_nsentences": "4.95", "train_prob_perplexity": "128.012", "train_code_perplexity": "125.876", "train_temp": "1.682", "train_loss_0": "3.566", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.3203", "train_wps": "3932.7", "train_ups": "2.18", "train_wpb": "1800.3", "train_bsz": "5", "train_num_updates": "34640", "train_lr": "0.000496413", "train_gnorm": "0.519", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16099"}
[2022-01-03 16:38:01,438][fairseq.trainer][INFO] - begin training epoch 867
[2022-01-03 16:38:01,439][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:38:15,486][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:38:15,894][valid][INFO] - {"epoch": 867, "valid_loss": "3.301", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "117.594", "valid_code_perplexity": "112.6", "valid_temp": "1.682", "valid_loss_0": "3.171", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.39863", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "34680", "valid_best_loss": "3.221"}
[2022-01-03 16:38:15,897][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 867 @ 34680 updates
[2022-01-03 16:38:15,898][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:38:19,556][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:38:19,585][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 867 @ 34680 updates, score 3.301) (writing took 3.688049671240151 seconds)
[2022-01-03 16:38:19,585][fairseq_cli.train][INFO] - end of epoch 867 (average epoch stats below)
[2022-01-03 16:38:19,599][train][INFO] - {"epoch": 867, "train_loss": "3.724", "train_ntokens": "1800.58", "train_nsentences": "4.95", "train_prob_perplexity": "127.637", "train_code_perplexity": "125.358", "train_temp": "1.682", "train_loss_0": "3.596", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.3193", "train_wps": "3952.3", "train_ups": "2.2", "train_wpb": "1800.6", "train_bsz": "5", "train_num_updates": "34680", "train_lr": "0.000496359", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16117"}
[2022-01-03 16:38:19,655][fairseq.trainer][INFO] - begin training epoch 868
[2022-01-03 16:38:19,656][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:38:33,660][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:38:34,072][valid][INFO] - {"epoch": 868, "valid_loss": "3.337", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "120.797", "valid_code_perplexity": "117.201", "valid_temp": "1.681", "valid_loss_0": "3.208", "valid_loss_1": "0.117", "valid_loss_2": "0.012", "valid_accuracy": "0.3812", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "34720", "valid_best_loss": "3.221"}
[2022-01-03 16:38:34,075][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 868 @ 34720 updates
[2022-01-03 16:38:34,075][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:38:37,806][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:38:37,834][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 868 @ 34720 updates, score 3.337) (writing took 3.759593724273145 seconds)
[2022-01-03 16:38:37,835][fairseq_cli.train][INFO] - end of epoch 868 (average epoch stats below)
[2022-01-03 16:38:37,848][train][INFO] - {"epoch": 868, "train_loss": "3.677", "train_ntokens": "1804.75", "train_nsentences": "4.95", "train_prob_perplexity": "127.057", "train_code_perplexity": "124.933", "train_temp": "1.681", "train_loss_0": "3.549", "train_loss_1": "0.116", "train_loss_2": "0.012", "train_accuracy": "0.32305", "train_wps": "3958.6", "train_ups": "2.19", "train_wpb": "1804.8", "train_bsz": "5", "train_num_updates": "34720", "train_lr": "0.000496304", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "16135"}
[2022-01-03 16:38:37,924][fairseq.trainer][INFO] - begin training epoch 869
[2022-01-03 16:38:37,925][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:38:51,891][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:38:52,386][valid][INFO] - {"epoch": 869, "valid_loss": "3.682", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "123.807", "valid_code_perplexity": "120.891", "valid_temp": "1.681", "valid_loss_0": "3.555", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.33646", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "34760", "valid_best_loss": "3.221"}
[2022-01-03 16:38:52,388][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 869 @ 34760 updates
[2022-01-03 16:38:52,389][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:38:56,070][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:38:56,098][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 869 @ 34760 updates, score 3.682) (writing took 3.709890869446099 seconds)
[2022-01-03 16:38:56,099][fairseq_cli.train][INFO] - end of epoch 869 (average epoch stats below)
[2022-01-03 16:38:56,111][train][INFO] - {"epoch": 869, "train_loss": "3.686", "train_ntokens": "1789.4", "train_nsentences": "4.95", "train_prob_perplexity": "127.77", "train_code_perplexity": "125.514", "train_temp": "1.681", "train_loss_0": "3.558", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32314", "train_wps": "3921.8", "train_ups": "2.19", "train_wpb": "1789.4", "train_bsz": "5", "train_num_updates": "34760", "train_lr": "0.00049625", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "16154"}
[2022-01-03 16:38:56,162][fairseq.trainer][INFO] - begin training epoch 870
[2022-01-03 16:38:56,163][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:39:10,000][train_inner][INFO] - {"epoch": 870, "update": 870.0, "loss": "3.693", "ntokens": "1798.68", "nsentences": "4.95", "prob_perplexity": "127.672", "code_perplexity": "125.468", "temp": "1.681", "loss_0": "3.566", "loss_1": "0.115", "loss_2": "0.012", "accuracy": "0.3216", "wps": "3945.6", "ups": "2.19", "wpb": "1798.7", "bsz": "5", "num_updates": "34800", "lr": "0.000496196", "gnorm": "0.515", "clip": "0", "train_wall": "68", "gb_free": "6", "wall": "16167"}
[2022-01-03 16:39:10,001][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:39:10,403][valid][INFO] - {"epoch": 870, "valid_loss": "3.372", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "116.309", "valid_code_perplexity": "112.071", "valid_temp": "1.681", "valid_loss_0": "3.241", "valid_loss_1": "0.118", "valid_loss_2": "0.013", "valid_accuracy": "0.4", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "34800", "valid_best_loss": "3.221"}
[2022-01-03 16:39:10,406][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 870 @ 34800 updates
[2022-01-03 16:39:10,407][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:39:14,387][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:39:14,402][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 870 @ 34800 updates, score 3.372) (writing took 3.9957592766731977 seconds)
[2022-01-03 16:39:14,402][fairseq_cli.train][INFO] - end of epoch 870 (average epoch stats below)
[2022-01-03 16:39:14,415][train][INFO] - {"epoch": 870, "train_loss": "3.685", "train_ntokens": "1798.35", "train_nsentences": "4.95", "train_prob_perplexity": "127.885", "train_code_perplexity": "125.66", "train_temp": "1.681", "train_loss_0": "3.558", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32221", "train_wps": "3932.6", "train_ups": "2.19", "train_wpb": "1798.3", "train_bsz": "5", "train_num_updates": "34800", "train_lr": "0.000496196", "train_gnorm": "0.515", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "16172"}
[2022-01-03 16:39:14,488][fairseq.trainer][INFO] - begin training epoch 871
[2022-01-03 16:39:14,489][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:39:28,429][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:39:28,926][valid][INFO] - {"epoch": 871, "valid_loss": "3.501", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "118.822", "valid_code_perplexity": "113.049", "valid_temp": "1.68", "valid_loss_0": "3.371", "valid_loss_1": "0.117", "valid_loss_2": "0.013", "valid_accuracy": "0.35574", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "34840", "valid_best_loss": "3.221"}
[2022-01-03 16:39:28,928][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 871 @ 34840 updates
[2022-01-03 16:39:28,929][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:39:32,659][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:39:32,688][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 871 @ 34840 updates, score 3.501) (writing took 3.759127650409937 seconds)
[2022-01-03 16:39:32,688][fairseq_cli.train][INFO] - end of epoch 871 (average epoch stats below)
[2022-01-03 16:39:32,701][train][INFO] - {"epoch": 871, "train_loss": "3.663", "train_ntokens": "1784.72", "train_nsentences": "4.95", "train_prob_perplexity": "128.34", "train_code_perplexity": "126.105", "train_temp": "1.68", "train_loss_0": "3.537", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.32576", "train_wps": "3906.9", "train_ups": "2.19", "train_wpb": "1784.7", "train_bsz": "5", "train_num_updates": "34840", "train_lr": "0.000496141", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "16190"}
[2022-01-03 16:39:32,776][fairseq.trainer][INFO] - begin training epoch 872
[2022-01-03 16:39:32,777][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:39:46,495][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:39:47,000][valid][INFO] - {"epoch": 872, "valid_loss": "3.807", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "125.003", "valid_code_perplexity": "121.725", "valid_temp": "1.68", "valid_loss_0": "3.681", "valid_loss_1": "0.116", "valid_loss_2": "0.01", "valid_accuracy": "0.34225", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "34880", "valid_best_loss": "3.221"}
[2022-01-03 16:39:47,001][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 872 @ 34880 updates
[2022-01-03 16:39:47,002][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:39:50,876][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:39:50,903][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 872 @ 34880 updates, score 3.807) (writing took 3.901432584039867 seconds)
[2022-01-03 16:39:50,903][fairseq_cli.train][INFO] - end of epoch 872 (average epoch stats below)
[2022-01-03 16:39:50,916][train][INFO] - {"epoch": 872, "train_loss": "3.669", "train_ntokens": "1799.47", "train_nsentences": "4.95", "train_prob_perplexity": "128.58", "train_code_perplexity": "126.365", "train_temp": "1.68", "train_loss_0": "3.542", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32426", "train_wps": "3954.5", "train_ups": "2.2", "train_wpb": "1799.5", "train_bsz": "5", "train_num_updates": "34880", "train_lr": "0.000496087", "train_gnorm": "0.523", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "10.5", "train_wall": "16208"}
[2022-01-03 16:39:50,987][fairseq.trainer][INFO] - begin training epoch 873
[2022-01-03 16:39:50,988][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:40:04,881][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:40:05,295][valid][INFO] - {"epoch": 873, "valid_loss": "3.499", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "125.23", "valid_code_perplexity": "122.31", "valid_temp": "1.68", "valid_loss_0": "3.371", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.34271", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "34920", "valid_best_loss": "3.221"}
[2022-01-03 16:40:05,298][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 873 @ 34920 updates
[2022-01-03 16:40:05,299][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:40:09,116][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:40:09,144][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 873 @ 34920 updates, score 3.499) (writing took 3.8453952185809612 seconds)
[2022-01-03 16:40:09,144][fairseq_cli.train][INFO] - end of epoch 873 (average epoch stats below)
[2022-01-03 16:40:09,157][train][INFO] - {"epoch": 873, "train_loss": "3.641", "train_ntokens": "1799.6", "train_nsentences": "4.95", "train_prob_perplexity": "128.401", "train_code_perplexity": "126.188", "train_temp": "1.68", "train_loss_0": "3.514", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32816", "train_wps": "3949.2", "train_ups": "2.19", "train_wpb": "1799.6", "train_bsz": "5", "train_num_updates": "34920", "train_lr": "0.000496033", "train_gnorm": "0.524", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "16227"}
[2022-01-03 16:40:09,217][fairseq.trainer][INFO] - begin training epoch 874
[2022-01-03 16:40:09,218][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:40:23,198][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:40:23,626][valid][INFO] - {"epoch": 874, "valid_loss": "3.74", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "123.519", "valid_code_perplexity": "119.741", "valid_temp": "1.679", "valid_loss_0": "3.611", "valid_loss_1": "0.116", "valid_loss_2": "0.013", "valid_accuracy": "0.31988", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "34960", "valid_best_loss": "3.221"}
[2022-01-03 16:40:23,631][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 874 @ 34960 updates
[2022-01-03 16:40:23,633][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:40:27,362][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:40:27,389][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 874 @ 34960 updates, score 3.74) (writing took 3.7583274701610208 seconds)
[2022-01-03 16:40:27,390][fairseq_cli.train][INFO] - end of epoch 874 (average epoch stats below)
[2022-01-03 16:40:27,402][train][INFO] - {"epoch": 874, "train_loss": "3.692", "train_ntokens": "1809.53", "train_nsentences": "4.95", "train_prob_perplexity": "129.837", "train_code_perplexity": "127.739", "train_temp": "1.679", "train_loss_0": "3.564", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32075", "train_wps": "3969.9", "train_ups": "2.19", "train_wpb": "1809.5", "train_bsz": "5", "train_num_updates": "34960", "train_lr": "0.000495978", "train_gnorm": "0.514", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "16245"}
[2022-01-03 16:40:27,472][fairseq.trainer][INFO] - begin training epoch 875
[2022-01-03 16:40:27,473][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:40:41,285][train_inner][INFO] - {"epoch": 875, "update": 875.0, "loss": "3.667", "ntokens": "1795.74", "nsentences": "4.95", "prob_perplexity": "128.854", "code_perplexity": "126.664", "temp": "1.68", "loss_0": "3.54", "loss_1": "0.115", "loss_2": "0.012", "accuracy": "0.32496", "wps": "3934.9", "ups": "2.19", "wpb": "1795.7", "bsz": "5", "num_updates": "35000", "lr": "0.000495924", "gnorm": "0.521", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "16259"}
[2022-01-03 16:40:41,286][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:40:41,698][valid][INFO] - {"epoch": 875, "valid_loss": "3.564", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "117.164", "valid_code_perplexity": "112.377", "valid_temp": "1.679", "valid_loss_0": "3.435", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.33468", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "35000", "valid_best_loss": "3.221"}
[2022-01-03 16:40:41,702][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 875 @ 35000 updates
[2022-01-03 16:40:41,704][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:40:45,658][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:40:45,679][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 875 @ 35000 updates, score 3.564) (writing took 3.9767224565148354 seconds)
[2022-01-03 16:40:45,679][fairseq_cli.train][INFO] - end of epoch 875 (average epoch stats below)
[2022-01-03 16:40:45,692][train][INFO] - {"epoch": 875, "train_loss": "3.67", "train_ntokens": "1785.38", "train_nsentences": "4.95", "train_prob_perplexity": "129.113", "train_code_perplexity": "126.921", "train_temp": "1.679", "train_loss_0": "3.544", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32588", "train_wps": "3907.4", "train_ups": "2.19", "train_wpb": "1785.4", "train_bsz": "5", "train_num_updates": "35000", "train_lr": "0.000495924", "train_gnorm": "0.523", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "16263"}
[2022-01-03 16:40:45,764][fairseq.trainer][INFO] - begin training epoch 876
[2022-01-03 16:40:45,765][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:40:59,606][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:41:00,034][valid][INFO] - {"epoch": 876, "valid_loss": "3.248", "valid_ntokens": "684", "valid_nsentences": "2", "valid_prob_perplexity": "119.014", "valid_code_perplexity": "113.012", "valid_temp": "1.679", "valid_loss_0": "3.119", "valid_loss_1": "0.117", "valid_loss_2": "0.011", "valid_accuracy": "0.40058", "valid_wps": "0", "valid_wpb": "684", "valid_bsz": "2", "valid_num_updates": "35040", "valid_best_loss": "3.221"}
[2022-01-03 16:41:00,039][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 876 @ 35040 updates
[2022-01-03 16:41:00,041][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:41:03,936][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:41:03,962][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 876 @ 35040 updates, score 3.248) (writing took 3.9230264062061906 seconds)
[2022-01-03 16:41:03,963][fairseq_cli.train][INFO] - end of epoch 876 (average epoch stats below)
[2022-01-03 16:41:03,976][train][INFO] - {"epoch": 876, "train_loss": "3.644", "train_ntokens": "1768.8", "train_nsentences": "4.95", "train_prob_perplexity": "129.161", "train_code_perplexity": "126.963", "train_temp": "1.679", "train_loss_0": "3.518", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.33007", "train_wps": "3872.5", "train_ups": "2.19", "train_wpb": "1768.8", "train_bsz": "5", "train_num_updates": "35040", "train_lr": "0.00049587", "train_gnorm": "0.526", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16281"}
[2022-01-03 16:41:04,052][fairseq.trainer][INFO] - begin training epoch 877
[2022-01-03 16:41:04,053][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:41:17,845][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:41:18,250][valid][INFO] - {"epoch": 877, "valid_loss": "3.771", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "125.3", "valid_code_perplexity": "120.122", "valid_temp": "1.678", "valid_loss_0": "3.643", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.33896", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "35080", "valid_best_loss": "3.221"}
[2022-01-03 16:41:18,252][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 877 @ 35080 updates
[2022-01-03 16:41:18,253][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:41:22,229][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:41:22,257][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 877 @ 35080 updates, score 3.771) (writing took 4.004246762022376 seconds)
[2022-01-03 16:41:22,257][fairseq_cli.train][INFO] - end of epoch 877 (average epoch stats below)
[2022-01-03 16:41:22,271][train][INFO] - {"epoch": 877, "train_loss": "3.667", "train_ntokens": "1778.83", "train_nsentences": "4.95", "train_prob_perplexity": "129.818", "train_code_perplexity": "127.62", "train_temp": "1.678", "train_loss_0": "3.54", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.3262", "train_wps": "3892.1", "train_ups": "2.19", "train_wpb": "1778.8", "train_bsz": "5", "train_num_updates": "35080", "train_lr": "0.000495815", "train_gnorm": "0.531", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16300"}
[2022-01-03 16:41:22,320][fairseq.trainer][INFO] - begin training epoch 878
[2022-01-03 16:41:22,321][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:41:36,334][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:41:36,814][valid][INFO] - {"epoch": 878, "valid_loss": "3.733", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "114.911", "valid_code_perplexity": "110.855", "valid_temp": "1.678", "valid_loss_0": "3.603", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.3338", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "35120", "valid_best_loss": "3.221"}
[2022-01-03 16:41:36,816][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 878 @ 35120 updates
[2022-01-03 16:41:36,817][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:41:40,447][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:41:40,477][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 878 @ 35120 updates, score 3.733) (writing took 3.6608976991847157 seconds)
[2022-01-03 16:41:40,478][fairseq_cli.train][INFO] - end of epoch 878 (average epoch stats below)
[2022-01-03 16:41:40,490][train][INFO] - {"epoch": 878, "train_loss": "3.651", "train_ntokens": "1777.97", "train_nsentences": "4.95", "train_prob_perplexity": "129.669", "train_code_perplexity": "127.543", "train_temp": "1.678", "train_loss_0": "3.524", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32811", "train_wps": "3906.2", "train_ups": "2.2", "train_wpb": "1778", "train_bsz": "5", "train_num_updates": "35120", "train_lr": "0.000495761", "train_gnorm": "0.508", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16318"}
[2022-01-03 16:41:40,567][fairseq.trainer][INFO] - begin training epoch 879
[2022-01-03 16:41:40,568][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:41:54,597][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:41:55,028][valid][INFO] - {"epoch": 879, "valid_loss": "3.448", "valid_ntokens": "678", "valid_nsentences": "2", "valid_prob_perplexity": "127.069", "valid_code_perplexity": "122.009", "valid_temp": "1.678", "valid_loss_0": "3.322", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.35988", "valid_wps": "0", "valid_wpb": "678", "valid_bsz": "2", "valid_num_updates": "35160", "valid_best_loss": "3.221"}
[2022-01-03 16:41:55,032][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 879 @ 35160 updates
[2022-01-03 16:41:55,033][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:41:58,739][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:41:58,768][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 879 @ 35160 updates, score 3.448) (writing took 3.736618828959763 seconds)
[2022-01-03 16:41:58,769][fairseq_cli.train][INFO] - end of epoch 879 (average epoch stats below)
[2022-01-03 16:41:58,782][train][INFO] - {"epoch": 879, "train_loss": "3.678", "train_ntokens": "1799.05", "train_nsentences": "4.95", "train_prob_perplexity": "128.713", "train_code_perplexity": "126.52", "train_temp": "1.678", "train_loss_0": "3.551", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32323", "train_wps": "3937", "train_ups": "2.19", "train_wpb": "1799", "train_bsz": "5", "train_num_updates": "35160", "train_lr": "0.000495707", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16336"}
[2022-01-03 16:41:58,861][fairseq.trainer][INFO] - begin training epoch 880
[2022-01-03 16:41:58,861][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:42:12,737][train_inner][INFO] - {"epoch": 880, "update": 880.0, "loss": "3.662", "ntokens": "1782.51", "nsentences": "4.95", "prob_perplexity": "129.325", "code_perplexity": "127.129", "temp": "1.678", "loss_0": "3.535", "loss_1": "0.115", "loss_2": "0.012", "accuracy": "0.32693", "wps": "3898.8", "ups": "2.19", "wpb": "1782.5", "bsz": "5", "num_updates": "35200", "lr": "0.000495652", "gnorm": "0.52", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "16350"}
[2022-01-03 16:42:12,738][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:42:13,147][valid][INFO] - {"epoch": 880, "valid_loss": "3.757", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "126.949", "valid_code_perplexity": "123.186", "valid_temp": "1.677", "valid_loss_0": "3.631", "valid_loss_1": "0.116", "valid_loss_2": "0.01", "valid_accuracy": "0.31202", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "35200", "valid_best_loss": "3.221"}
[2022-01-03 16:42:13,150][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 880 @ 35200 updates
[2022-01-03 16:42:13,151][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:42:16,941][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:42:16,969][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 880 @ 35200 updates, score 3.757) (writing took 3.819134929217398 seconds)
[2022-01-03 16:42:16,970][fairseq_cli.train][INFO] - end of epoch 880 (average epoch stats below)
[2022-01-03 16:42:16,982][train][INFO] - {"epoch": 880, "train_loss": "3.667", "train_ntokens": "1787.9", "train_nsentences": "4.95", "train_prob_perplexity": "129.266", "train_code_perplexity": "126.997", "train_temp": "1.677", "train_loss_0": "3.54", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32709", "train_wps": "3932", "train_ups": "2.2", "train_wpb": "1787.9", "train_bsz": "5", "train_num_updates": "35200", "train_lr": "0.000495652", "train_gnorm": "0.528", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16354"}
[2022-01-03 16:42:17,057][fairseq.trainer][INFO] - begin training epoch 881
[2022-01-03 16:42:17,058][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:42:30,889][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:42:31,311][valid][INFO] - {"epoch": 881, "valid_loss": "3.303", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "123.65", "valid_code_perplexity": "117.793", "valid_temp": "1.677", "valid_loss_0": "3.175", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.39665", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "35240", "valid_best_loss": "3.221"}
[2022-01-03 16:42:31,314][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 881 @ 35240 updates
[2022-01-03 16:42:31,315][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:42:35,262][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:42:35,292][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 881 @ 35240 updates, score 3.303) (writing took 3.9775134129449725 seconds)
[2022-01-03 16:42:35,292][fairseq_cli.train][INFO] - end of epoch 881 (average epoch stats below)
[2022-01-03 16:42:35,305][train][INFO] - {"epoch": 881, "train_loss": "3.634", "train_ntokens": "1783.95", "train_nsentences": "4.95", "train_prob_perplexity": "129.557", "train_code_perplexity": "127.344", "train_temp": "1.677", "train_loss_0": "3.507", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.33147", "train_wps": "3897.2", "train_ups": "2.18", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "35240", "train_lr": "0.000495598", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16373"}
[2022-01-03 16:42:35,386][fairseq.trainer][INFO] - begin training epoch 882
[2022-01-03 16:42:35,387][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:42:49,275][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:42:49,695][valid][INFO] - {"epoch": 882, "valid_loss": "3.388", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "127.427", "valid_code_perplexity": "124.297", "valid_temp": "1.677", "valid_loss_0": "3.261", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.3719", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "35280", "valid_best_loss": "3.221"}
[2022-01-03 16:42:49,700][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 882 @ 35280 updates
[2022-01-03 16:42:49,701][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:42:53,527][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:42:53,555][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 882 @ 35280 updates, score 3.388) (writing took 3.8550831163302064 seconds)
[2022-01-03 16:42:53,555][fairseq_cli.train][INFO] - end of epoch 882 (average epoch stats below)
[2022-01-03 16:42:53,567][train][INFO] - {"epoch": 882, "train_loss": "3.685", "train_ntokens": "1793.65", "train_nsentences": "4.95", "train_prob_perplexity": "130.378", "train_code_perplexity": "128.186", "train_temp": "1.677", "train_loss_0": "3.558", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.3231", "train_wps": "3931.3", "train_ups": "2.19", "train_wpb": "1793.7", "train_bsz": "5", "train_num_updates": "35280", "train_lr": "0.000495543", "train_gnorm": "0.511", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "16391"}
[2022-01-03 16:42:53,618][fairseq.trainer][INFO] - begin training epoch 883
[2022-01-03 16:42:53,619][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:43:07,620][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:43:08,032][valid][INFO] - {"epoch": 883, "valid_loss": "3.512", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "113.63", "valid_code_perplexity": "107.56", "valid_temp": "1.676", "valid_loss_0": "3.379", "valid_loss_1": "0.119", "valid_loss_2": "0.014", "valid_accuracy": "0.34718", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "35320", "valid_best_loss": "3.221"}
[2022-01-03 16:43:08,037][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 883 @ 35320 updates
[2022-01-03 16:43:08,038][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:43:11,747][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:43:11,775][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 883 @ 35320 updates, score 3.512) (writing took 3.738545885309577 seconds)
[2022-01-03 16:43:11,776][fairseq_cli.train][INFO] - end of epoch 883 (average epoch stats below)
[2022-01-03 16:43:11,788][train][INFO] - {"epoch": 883, "train_loss": "3.681", "train_ntokens": "1788.05", "train_nsentences": "4.95", "train_prob_perplexity": "129.693", "train_code_perplexity": "127.37", "train_temp": "1.676", "train_loss_0": "3.554", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32342", "train_wps": "3928", "train_ups": "2.2", "train_wpb": "1788", "train_bsz": "5", "train_num_updates": "35320", "train_lr": "0.000495489", "train_gnorm": "0.513", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16409"}
[2022-01-03 16:43:11,869][fairseq.trainer][INFO] - begin training epoch 884
[2022-01-03 16:43:11,870][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:43:25,786][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:43:26,209][valid][INFO] - {"epoch": 884, "valid_loss": "3.33", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "120.431", "valid_code_perplexity": "114.935", "valid_temp": "1.676", "valid_loss_0": "3.202", "valid_loss_1": "0.117", "valid_loss_2": "0.011", "valid_accuracy": "0.35908", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "35360", "valid_best_loss": "3.221"}
[2022-01-03 16:43:26,214][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 884 @ 35360 updates
[2022-01-03 16:43:26,216][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:43:30,003][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:43:30,030][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 884 @ 35360 updates, score 3.33) (writing took 3.8157825535163283 seconds)
[2022-01-03 16:43:30,030][fairseq_cli.train][INFO] - end of epoch 884 (average epoch stats below)
[2022-01-03 16:43:30,044][train][INFO] - {"epoch": 884, "train_loss": "3.673", "train_ntokens": "1797.4", "train_nsentences": "4.95", "train_prob_perplexity": "130.703", "train_code_perplexity": "128.562", "train_temp": "1.676", "train_loss_0": "3.546", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32534", "train_wps": "3941.3", "train_ups": "2.19", "train_wpb": "1797.4", "train_bsz": "5", "train_num_updates": "35360", "train_lr": "0.000495435", "train_gnorm": "0.508", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16427"}
[2022-01-03 16:43:30,102][fairseq.trainer][INFO] - begin training epoch 885
[2022-01-03 16:43:30,103][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:43:44,048][train_inner][INFO] - {"epoch": 885, "update": 885.0, "loss": "3.664", "ntokens": "1785.38", "nsentences": "4.95", "prob_perplexity": "130.136", "code_perplexity": "127.918", "temp": "1.676", "loss_0": "3.537", "loss_1": "0.115", "loss_2": "0.012", "accuracy": "0.3264", "wps": "3911.1", "ups": "2.19", "wpb": "1785.4", "bsz": "5", "num_updates": "35400", "lr": "0.00049538", "gnorm": "0.514", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "16441"}
[2022-01-03 16:43:44,049][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:43:44,464][valid][INFO] - {"epoch": 885, "valid_loss": "3.399", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "113.884", "valid_code_perplexity": "109.605", "valid_temp": "1.676", "valid_loss_0": "3.268", "valid_loss_1": "0.119", "valid_loss_2": "0.013", "valid_accuracy": "0.37123", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "35400", "valid_best_loss": "3.221"}
[2022-01-03 16:43:44,466][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 885 @ 35400 updates
[2022-01-03 16:43:44,467][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:43:48,271][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:43:48,295][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 885 @ 35400 updates, score 3.399) (writing took 3.8288573157042265 seconds)
[2022-01-03 16:43:48,296][fairseq_cli.train][INFO] - end of epoch 885 (average epoch stats below)
[2022-01-03 16:43:48,308][train][INFO] - {"epoch": 885, "train_loss": "3.644", "train_ntokens": "1763.85", "train_nsentences": "4.95", "train_prob_perplexity": "130.347", "train_code_perplexity": "128.129", "train_temp": "1.676", "train_loss_0": "3.518", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.32874", "train_wps": "3865.5", "train_ups": "2.19", "train_wpb": "1763.8", "train_bsz": "5", "train_num_updates": "35400", "train_lr": "0.00049538", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16446"}
[2022-01-03 16:43:48,355][fairseq.trainer][INFO] - begin training epoch 886
[2022-01-03 16:43:48,356][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:44:02,228][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:44:02,602][valid][INFO] - {"epoch": 886, "valid_loss": "3.235", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "125.913", "valid_code_perplexity": "121.46", "valid_temp": "1.675", "valid_loss_0": "3.109", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.39021", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "35440", "valid_best_loss": "3.221"}
[2022-01-03 16:44:02,606][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 886 @ 35440 updates
[2022-01-03 16:44:02,607][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:44:06,733][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:44:06,762][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 886 @ 35440 updates, score 3.235) (writing took 4.155970587395132 seconds)
[2022-01-03 16:44:06,762][fairseq_cli.train][INFO] - end of epoch 886 (average epoch stats below)
[2022-01-03 16:44:06,775][train][INFO] - {"epoch": 886, "train_loss": "3.693", "train_ntokens": "1787.53", "train_nsentences": "4.95", "train_prob_perplexity": "130.573", "train_code_perplexity": "128.315", "train_temp": "1.675", "train_loss_0": "3.566", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32495", "train_wps": "3874.6", "train_ups": "2.17", "train_wpb": "1787.5", "train_bsz": "5", "train_num_updates": "35440", "train_lr": "0.000495326", "train_gnorm": "0.515", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16464"}
[2022-01-03 16:44:06,853][fairseq.trainer][INFO] - begin training epoch 887
[2022-01-03 16:44:06,854][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:44:20,740][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:44:21,153][valid][INFO] - {"epoch": 887, "valid_loss": "3.717", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "119.797", "valid_code_perplexity": "115.231", "valid_temp": "1.675", "valid_loss_0": "3.587", "valid_loss_1": "0.117", "valid_loss_2": "0.013", "valid_accuracy": "0.34143", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "35480", "valid_best_loss": "3.221"}
[2022-01-03 16:44:21,156][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 887 @ 35480 updates
[2022-01-03 16:44:21,157][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:44:24,741][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:44:24,765][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 887 @ 35480 updates, score 3.717) (writing took 3.60819492675364 seconds)
[2022-01-03 16:44:24,765][fairseq_cli.train][INFO] - end of epoch 887 (average epoch stats below)
[2022-01-03 16:44:24,777][train][INFO] - {"epoch": 887, "train_loss": "3.651", "train_ntokens": "1783.08", "train_nsentences": "4.95", "train_prob_perplexity": "131.982", "train_code_perplexity": "129.729", "train_temp": "1.675", "train_loss_0": "3.525", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.32916", "train_wps": "3964.5", "train_ups": "2.22", "train_wpb": "1783.1", "train_bsz": "5", "train_num_updates": "35480", "train_lr": "0.000495272", "train_gnorm": "0.519", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "16482"}
[2022-01-03 16:44:24,824][fairseq.trainer][INFO] - begin training epoch 888
[2022-01-03 16:44:24,824][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:44:38,722][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:44:39,131][valid][INFO] - {"epoch": 888, "valid_loss": "3.816", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "125.208", "valid_code_perplexity": "120.142", "valid_temp": "1.675", "valid_loss_0": "3.688", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.31184", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "35520", "valid_best_loss": "3.221"}
[2022-01-03 16:44:39,134][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 888 @ 35520 updates
[2022-01-03 16:44:39,135][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:44:43,012][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:44:43,039][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 888 @ 35520 updates, score 3.816) (writing took 3.90455908048898 seconds)
[2022-01-03 16:44:43,039][fairseq_cli.train][INFO] - end of epoch 888 (average epoch stats below)
[2022-01-03 16:44:43,052][train][INFO] - {"epoch": 888, "train_loss": "3.643", "train_ntokens": "1800.47", "train_nsentences": "4.95", "train_prob_perplexity": "130.048", "train_code_perplexity": "127.62", "train_temp": "1.675", "train_loss_0": "3.517", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.33065", "train_wps": "3943.7", "train_ups": "2.19", "train_wpb": "1800.5", "train_bsz": "5", "train_num_updates": "35520", "train_lr": "0.000495217", "train_gnorm": "0.515", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "16500"}
[2022-01-03 16:44:43,127][fairseq.trainer][INFO] - begin training epoch 889
[2022-01-03 16:44:43,128][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:44:57,066][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:44:57,469][valid][INFO] - {"epoch": 889, "valid_loss": "3.665", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "126.073", "valid_code_perplexity": "120.633", "valid_temp": "1.674", "valid_loss_0": "3.539", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.31627", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "35560", "valid_best_loss": "3.221"}
[2022-01-03 16:44:57,473][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 889 @ 35560 updates
[2022-01-03 16:44:57,474][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:45:01,318][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:45:01,346][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 889 @ 35560 updates, score 3.665) (writing took 3.8729539001360536 seconds)
[2022-01-03 16:45:01,346][fairseq_cli.train][INFO] - end of epoch 889 (average epoch stats below)
[2022-01-03 16:45:01,359][train][INFO] - {"epoch": 889, "train_loss": "3.673", "train_ntokens": "1781.62", "train_nsentences": "4.95", "train_prob_perplexity": "130.79", "train_code_perplexity": "128.556", "train_temp": "1.674", "train_loss_0": "3.547", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.32344", "train_wps": "3895.5", "train_ups": "2.19", "train_wpb": "1781.6", "train_bsz": "5", "train_num_updates": "35560", "train_lr": "0.000495163", "train_gnorm": "0.513", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16519"}
[2022-01-03 16:45:01,432][fairseq.trainer][INFO] - begin training epoch 890
[2022-01-03 16:45:01,433][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:45:15,365][train_inner][INFO] - {"epoch": 890, "update": 890.0, "loss": "3.666", "ntokens": "1790.02", "nsentences": "4.95", "prob_perplexity": "130.836", "code_perplexity": "128.533", "temp": "1.675", "loss_0": "3.54", "loss_1": "0.115", "loss_2": "0.012", "accuracy": "0.32696", "wps": "3921", "ups": "2.19", "wpb": "1790", "bsz": "5", "num_updates": "35600", "lr": "0.000495109", "gnorm": "0.517", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "16533"}
[2022-01-03 16:45:15,366][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:45:15,774][valid][INFO] - {"epoch": 890, "valid_loss": "3.244", "valid_ntokens": "678", "valid_nsentences": "2", "valid_prob_perplexity": "124.524", "valid_code_perplexity": "120.443", "valid_temp": "1.674", "valid_loss_0": "3.116", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.4233", "valid_wps": "0", "valid_wpb": "678", "valid_bsz": "2", "valid_num_updates": "35600", "valid_best_loss": "3.221"}
[2022-01-03 16:45:15,778][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 890 @ 35600 updates
[2022-01-03 16:45:15,779][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:45:19,604][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:45:19,633][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 890 @ 35600 updates, score 3.244) (writing took 3.8553219316527247 seconds)
[2022-01-03 16:45:19,634][fairseq_cli.train][INFO] - end of epoch 890 (average epoch stats below)
[2022-01-03 16:45:19,647][train][INFO] - {"epoch": 890, "train_loss": "3.668", "train_ntokens": "1797.38", "train_nsentences": "4.95", "train_prob_perplexity": "130.787", "train_code_perplexity": "128.446", "train_temp": "1.674", "train_loss_0": "3.542", "train_loss_1": "0.115", "train_loss_2": "0.012", "train_accuracy": "0.32657", "train_wps": "3934.2", "train_ups": "2.19", "train_wpb": "1797.4", "train_bsz": "5", "train_num_updates": "35600", "train_lr": "0.000495109", "train_gnorm": "0.522", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16537"}
[2022-01-03 16:45:19,727][fairseq.trainer][INFO] - begin training epoch 891
[2022-01-03 16:45:19,728][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:45:33,687][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:45:34,113][valid][INFO] - {"epoch": 891, "valid_loss": "3.924", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "129.28", "valid_code_perplexity": "125.697", "valid_temp": "1.674", "valid_loss_0": "3.799", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.30809", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "35640", "valid_best_loss": "3.221"}
[2022-01-03 16:45:34,116][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 891 @ 35640 updates
[2022-01-03 16:45:34,117][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:45:38,039][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:45:38,068][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 891 @ 35640 updates, score 3.924) (writing took 3.9518005466088653 seconds)
[2022-01-03 16:45:38,069][fairseq_cli.train][INFO] - end of epoch 891 (average epoch stats below)
[2022-01-03 16:45:38,081][train][INFO] - {"epoch": 891, "train_loss": "3.677", "train_ntokens": "1803.05", "train_nsentences": "4.95", "train_prob_perplexity": "131.276", "train_code_perplexity": "129.09", "train_temp": "1.674", "train_loss_0": "3.551", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.32657", "train_wps": "3915.1", "train_ups": "2.17", "train_wpb": "1803", "train_bsz": "5", "train_num_updates": "35640", "train_lr": "0.000495054", "train_gnorm": "0.499", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16555"}
[2022-01-03 16:45:38,159][fairseq.trainer][INFO] - begin training epoch 892
[2022-01-03 16:45:38,160][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:45:52,092][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:45:52,506][valid][INFO] - {"epoch": 892, "valid_loss": "3.519", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "129.878", "valid_code_perplexity": "126.693", "valid_temp": "1.673", "valid_loss_0": "3.393", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.34893", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "35680", "valid_best_loss": "3.221"}
[2022-01-03 16:45:52,508][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 892 @ 35680 updates
[2022-01-03 16:45:52,509][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:45:56,310][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:45:56,339][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 892 @ 35680 updates, score 3.519) (writing took 3.830458663403988 seconds)
[2022-01-03 16:45:56,339][fairseq_cli.train][INFO] - end of epoch 892 (average epoch stats below)
[2022-01-03 16:45:56,352][train][INFO] - {"epoch": 892, "train_loss": "3.641", "train_ntokens": "1775.05", "train_nsentences": "4.95", "train_prob_perplexity": "131.957", "train_code_perplexity": "129.761", "train_temp": "1.673", "train_loss_0": "3.515", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.33134", "train_wps": "3888.9", "train_ups": "2.19", "train_wpb": "1775", "train_bsz": "5", "train_num_updates": "35680", "train_lr": "0.000495", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16574"}
[2022-01-03 16:45:56,432][fairseq.trainer][INFO] - begin training epoch 893
[2022-01-03 16:45:56,433][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:46:10,322][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:46:10,734][valid][INFO] - {"epoch": 893, "valid_loss": "3.317", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "126.231", "valid_code_perplexity": "122.882", "valid_temp": "1.673", "valid_loss_0": "3.191", "valid_loss_1": "0.116", "valid_loss_2": "0.01", "valid_accuracy": "0.38369", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "35720", "valid_best_loss": "3.221"}
[2022-01-03 16:46:10,737][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 893 @ 35720 updates
[2022-01-03 16:46:10,738][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:46:14,689][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:46:14,709][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 893 @ 35720 updates, score 3.317) (writing took 3.9717806484550238 seconds)
[2022-01-03 16:46:14,709][fairseq_cli.train][INFO] - end of epoch 893 (average epoch stats below)
[2022-01-03 16:46:14,722][train][INFO] - {"epoch": 893, "train_loss": "3.632", "train_ntokens": "1794", "train_nsentences": "4.95", "train_prob_perplexity": "132.33", "train_code_perplexity": "130.149", "train_temp": "1.673", "train_loss_0": "3.506", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33028", "train_wps": "3909.1", "train_ups": "2.18", "train_wpb": "1794", "train_bsz": "5", "train_num_updates": "35720", "train_lr": "0.000494946", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "16592"}
[2022-01-03 16:46:14,773][fairseq.trainer][INFO] - begin training epoch 894
[2022-01-03 16:46:14,774][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:46:28,711][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:46:29,128][valid][INFO] - {"epoch": 894, "valid_loss": "3.515", "valid_ntokens": "644", "valid_nsentences": "2", "valid_prob_perplexity": "131.146", "valid_code_perplexity": "127.599", "valid_temp": "1.673", "valid_loss_0": "3.39", "valid_loss_1": "0.115", "valid_loss_2": "0.011", "valid_accuracy": "0.36801", "valid_wps": "0", "valid_wpb": "644", "valid_bsz": "2", "valid_num_updates": "35760", "valid_best_loss": "3.221"}
[2022-01-03 16:46:29,131][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 894 @ 35760 updates
[2022-01-03 16:46:29,132][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:46:32,927][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:46:32,960][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 894 @ 35760 updates, score 3.515) (writing took 3.8285293681547046 seconds)
[2022-01-03 16:46:32,960][fairseq_cli.train][INFO] - end of epoch 894 (average epoch stats below)
[2022-01-03 16:46:32,973][train][INFO] - {"epoch": 894, "train_loss": "3.642", "train_ntokens": "1791.65", "train_nsentences": "4.95", "train_prob_perplexity": "131.598", "train_code_perplexity": "129.327", "train_temp": "1.673", "train_loss_0": "3.516", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.3318", "train_wps": "3929.4", "train_ups": "2.19", "train_wpb": "1791.7", "train_bsz": "5", "train_num_updates": "35760", "train_lr": "0.000494891", "train_gnorm": "0.506", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16610"}
[2022-01-03 16:46:33,052][fairseq.trainer][INFO] - begin training epoch 895
[2022-01-03 16:46:33,052][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:46:46,875][train_inner][INFO] - {"epoch": 895, "update": 895.0, "loss": "3.645", "ntokens": "1790.04", "nsentences": "4.95", "prob_perplexity": "131.798", "code_perplexity": "129.566", "temp": "1.673", "loss_0": "3.52", "loss_1": "0.115", "loss_2": "0.011", "accuracy": "0.3304", "wps": "3912.7", "ups": "2.19", "wpb": "1790", "bsz": "5", "num_updates": "35800", "lr": "0.000494837", "gnorm": "0.506", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "16624"}
[2022-01-03 16:46:46,876][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:46:47,284][valid][INFO] - {"epoch": 895, "valid_loss": "3.401", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "127.682", "valid_code_perplexity": "124.259", "valid_temp": "1.672", "valid_loss_0": "3.275", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.36207", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "35800", "valid_best_loss": "3.221"}
[2022-01-03 16:46:47,287][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 895 @ 35800 updates
[2022-01-03 16:46:47,287][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:46:51,203][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:46:51,222][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 895 @ 35800 updates, score 3.401) (writing took 3.9352698931470513 seconds)
[2022-01-03 16:46:51,222][fairseq_cli.train][INFO] - end of epoch 895 (average epoch stats below)
[2022-01-03 16:46:51,235][train][INFO] - {"epoch": 895, "train_loss": "3.635", "train_ntokens": "1786.42", "train_nsentences": "4.95", "train_prob_perplexity": "131.829", "train_code_perplexity": "129.505", "train_temp": "1.672", "train_loss_0": "3.509", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.33203", "train_wps": "3915.6", "train_ups": "2.19", "train_wpb": "1786.4", "train_bsz": "5", "train_num_updates": "35800", "train_lr": "0.000494837", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16629"}
[2022-01-03 16:46:51,281][fairseq.trainer][INFO] - begin training epoch 896
[2022-01-03 16:46:51,282][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:47:05,134][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:47:05,541][valid][INFO] - {"epoch": 896, "valid_loss": "3.226", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "129.706", "valid_code_perplexity": "126.15", "valid_temp": "1.672", "valid_loss_0": "3.102", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.41713", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "35840", "valid_best_loss": "3.221"}
[2022-01-03 16:47:05,544][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 896 @ 35840 updates
[2022-01-03 16:47:05,545][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:47:09,460][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:47:09,486][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 896 @ 35840 updates, score 3.226) (writing took 3.9417369309812784 seconds)
[2022-01-03 16:47:09,486][fairseq_cli.train][INFO] - end of epoch 896 (average epoch stats below)
[2022-01-03 16:47:09,499][train][INFO] - {"epoch": 896, "train_loss": "3.661", "train_ntokens": "1789.42", "train_nsentences": "4.95", "train_prob_perplexity": "131.888", "train_code_perplexity": "129.555", "train_temp": "1.672", "train_loss_0": "3.536", "train_loss_1": "0.115", "train_loss_2": "0.011", "train_accuracy": "0.32612", "train_wps": "3921.8", "train_ups": "2.19", "train_wpb": "1789.4", "train_bsz": "5", "train_num_updates": "35840", "train_lr": "0.000494783", "train_gnorm": "0.524", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16647"}
[2022-01-03 16:47:09,570][fairseq.trainer][INFO] - begin training epoch 897
[2022-01-03 16:47:09,571][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:47:23,545][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:47:23,962][valid][INFO] - {"epoch": 897, "valid_loss": "3.435", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "127.956", "valid_code_perplexity": "123.611", "valid_temp": "1.672", "valid_loss_0": "3.308", "valid_loss_1": "0.115", "valid_loss_2": "0.011", "valid_accuracy": "0.38363", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "35880", "valid_best_loss": "3.221"}
[2022-01-03 16:47:23,967][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 897 @ 35880 updates
[2022-01-03 16:47:23,968][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:47:27,697][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:47:27,727][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 897 @ 35880 updates, score 3.435) (writing took 3.7599147763103247 seconds)
[2022-01-03 16:47:27,727][fairseq_cli.train][INFO] - end of epoch 897 (average epoch stats below)
[2022-01-03 16:47:27,740][train][INFO] - {"epoch": 897, "train_loss": "3.617", "train_ntokens": "1802.95", "train_nsentences": "4.95", "train_prob_perplexity": "132.952", "train_code_perplexity": "130.762", "train_temp": "1.672", "train_loss_0": "3.492", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33196", "train_wps": "3956.3", "train_ups": "2.19", "train_wpb": "1803", "train_bsz": "5", "train_num_updates": "35880", "train_lr": "0.000494728", "train_gnorm": "0.513", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.4", "train_wall": "16665"}
[2022-01-03 16:47:27,819][fairseq.trainer][INFO] - begin training epoch 898
[2022-01-03 16:47:27,819][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:47:41,709][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:47:42,131][valid][INFO] - {"epoch": 898, "valid_loss": "3.861", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "127.939", "valid_code_perplexity": "123.854", "valid_temp": "1.671", "valid_loss_0": "3.735", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.31627", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "35920", "valid_best_loss": "3.221"}
[2022-01-03 16:47:42,135][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 898 @ 35920 updates
[2022-01-03 16:47:42,136][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:47:46,053][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:47:46,080][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 898 @ 35920 updates, score 3.861) (writing took 3.9455027524381876 seconds)
[2022-01-03 16:47:46,081][fairseq_cli.train][INFO] - end of epoch 898 (average epoch stats below)
[2022-01-03 16:47:46,094][train][INFO] - {"epoch": 898, "train_loss": "3.621", "train_ntokens": "1795.78", "train_nsentences": "4.95", "train_prob_perplexity": "132.786", "train_code_perplexity": "130.456", "train_temp": "1.671", "train_loss_0": "3.495", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33465", "train_wps": "3916.5", "train_ups": "2.18", "train_wpb": "1795.8", "train_bsz": "5", "train_num_updates": "35920", "train_lr": "0.000494674", "train_gnorm": "0.505", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16683"}
[2022-01-03 16:47:46,167][fairseq.trainer][INFO] - begin training epoch 899
[2022-01-03 16:47:46,168][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:47:59,895][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:48:00,300][valid][INFO] - {"epoch": 899, "valid_loss": "3.302", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "129.814", "valid_code_perplexity": "125.964", "valid_temp": "1.671", "valid_loss_0": "3.177", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.39867", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "35960", "valid_best_loss": "3.221"}
[2022-01-03 16:48:00,303][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 899 @ 35960 updates
[2022-01-03 16:48:00,304][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:48:04,222][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:48:04,248][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 899 @ 35960 updates, score 3.302) (writing took 3.9443649351596832 seconds)
[2022-01-03 16:48:04,248][fairseq_cli.train][INFO] - end of epoch 899 (average epoch stats below)
[2022-01-03 16:48:04,261][train][INFO] - {"epoch": 899, "train_loss": "3.64", "train_ntokens": "1785.42", "train_nsentences": "4.95", "train_prob_perplexity": "133.218", "train_code_perplexity": "130.878", "train_temp": "1.671", "train_loss_0": "3.515", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.32744", "train_wps": "3933.9", "train_ups": "2.2", "train_wpb": "1785.4", "train_bsz": "5", "train_num_updates": "35960", "train_lr": "0.00049462", "train_gnorm": "0.511", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "16702"}
[2022-01-03 16:48:04,330][fairseq.trainer][INFO] - begin training epoch 900
[2022-01-03 16:48:04,331][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:48:18,354][train_inner][INFO] - {"epoch": 900, "update": 900.0, "loss": "3.639", "ntokens": "1794.01", "nsentences": "4.95", "prob_perplexity": "132.947", "code_perplexity": "130.638", "temp": "1.671", "loss_0": "3.514", "loss_1": "0.114", "loss_2": "0.011", "accuracy": "0.32952", "wps": "3922.7", "ups": "2.19", "wpb": "1794", "bsz": "5", "num_updates": "36000", "lr": "0.000494565", "gnorm": "0.51", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "16716"}
[2022-01-03 16:48:18,355][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:48:18,778][valid][INFO] - {"epoch": 900, "valid_loss": "3.409", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "130.411", "valid_code_perplexity": "125.228", "valid_temp": "1.671", "valid_loss_0": "3.284", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.35286", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "36000", "valid_best_loss": "3.221"}
[2022-01-03 16:48:18,783][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 900 @ 36000 updates
[2022-01-03 16:48:18,784][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:48:22,503][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:48:22,531][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 900 @ 36000 updates, score 3.409) (writing took 3.7483568005263805 seconds)
[2022-01-03 16:48:22,531][fairseq_cli.train][INFO] - end of epoch 900 (average epoch stats below)
[2022-01-03 16:48:22,544][train][INFO] - {"epoch": 900, "train_loss": "3.655", "train_ntokens": "1796.45", "train_nsentences": "4.95", "train_prob_perplexity": "133.89", "train_code_perplexity": "131.541", "train_temp": "1.671", "train_loss_0": "3.53", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.32738", "train_wps": "3933", "train_ups": "2.19", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "36000", "train_lr": "0.000494565", "train_gnorm": "0.495", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16720"}
[2022-01-03 16:48:22,619][fairseq.trainer][INFO] - begin training epoch 901
[2022-01-03 16:48:22,620][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:48:36,438][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:48:36,922][valid][INFO] - {"epoch": 901, "valid_loss": "3.468", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "128.976", "valid_code_perplexity": "125.22", "valid_temp": "1.67", "valid_loss_0": "3.344", "valid_loss_1": "0.115", "valid_loss_2": "0.009", "valid_accuracy": "0.36732", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "36040", "valid_best_loss": "3.221"}
[2022-01-03 16:48:36,924][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 901 @ 36040 updates
[2022-01-03 16:48:36,925][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:48:40,851][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:48:40,879][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 901 @ 36040 updates, score 3.468) (writing took 3.95465306378901 seconds)
[2022-01-03 16:48:40,879][fairseq_cli.train][INFO] - end of epoch 901 (average epoch stats below)
[2022-01-03 16:48:40,892][train][INFO] - {"epoch": 901, "train_loss": "3.651", "train_ntokens": "1789.45", "train_nsentences": "4.95", "train_prob_perplexity": "132.658", "train_code_perplexity": "130.29", "train_temp": "1.67", "train_loss_0": "3.525", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.32862", "train_wps": "3903.8", "train_ups": "2.18", "train_wpb": "1789.5", "train_bsz": "5", "train_num_updates": "36040", "train_lr": "0.000494511", "train_gnorm": "0.515", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "16738"}
[2022-01-03 16:48:40,939][fairseq.trainer][INFO] - begin training epoch 902
[2022-01-03 16:48:40,940][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:48:54,856][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:48:55,413][valid][INFO] - {"epoch": 902, "valid_loss": "3.496", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "120.327", "valid_code_perplexity": "115.004", "valid_temp": "1.67", "valid_loss_0": "3.368", "valid_loss_1": "0.117", "valid_loss_2": "0.011", "valid_accuracy": "0.35438", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "36080", "valid_best_loss": "3.221"}
[2022-01-03 16:48:55,417][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 902 @ 36080 updates
[2022-01-03 16:48:55,418][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:48:59,161][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:48:59,190][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 902 @ 36080 updates, score 3.496) (writing took 3.773103181272745 seconds)
[2022-01-03 16:48:59,191][fairseq_cli.train][INFO] - end of epoch 902 (average epoch stats below)
[2022-01-03 16:48:59,204][train][INFO] - {"epoch": 902, "train_loss": "3.645", "train_ntokens": "1780", "train_nsentences": "4.95", "train_prob_perplexity": "133.362", "train_code_perplexity": "130.837", "train_temp": "1.67", "train_loss_0": "3.519", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.32934", "train_wps": "3891.1", "train_ups": "2.19", "train_wpb": "1780", "train_bsz": "5", "train_num_updates": "36080", "train_lr": "0.000494457", "train_gnorm": "0.511", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "16757"}
[2022-01-03 16:48:59,280][fairseq.trainer][INFO] - begin training epoch 903
[2022-01-03 16:48:59,281][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:49:13,273][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:49:13,721][valid][INFO] - {"epoch": 903, "valid_loss": "3.324", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "120.972", "valid_code_perplexity": "115.57", "valid_temp": "1.67", "valid_loss_0": "3.197", "valid_loss_1": "0.117", "valid_loss_2": "0.01", "valid_accuracy": "0.3836", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "36120", "valid_best_loss": "3.221"}
[2022-01-03 16:49:13,726][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 903 @ 36120 updates
[2022-01-03 16:49:13,727][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:49:17,411][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:49:17,435][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 903 @ 36120 updates, score 3.324) (writing took 3.709138583391905 seconds)
[2022-01-03 16:49:17,436][fairseq_cli.train][INFO] - end of epoch 903 (average epoch stats below)
[2022-01-03 16:49:17,449][train][INFO] - {"epoch": 903, "train_loss": "3.616", "train_ntokens": "1785.97", "train_nsentences": "4.95", "train_prob_perplexity": "132.695", "train_code_perplexity": "130.379", "train_temp": "1.67", "train_loss_0": "3.49", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.3329", "train_wps": "3918.4", "train_ups": "2.19", "train_wpb": "1786", "train_bsz": "5", "train_num_updates": "36120", "train_lr": "0.000494402", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "16775"}
[2022-01-03 16:49:17,519][fairseq.trainer][INFO] - begin training epoch 904
[2022-01-03 16:49:17,520][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:49:31,459][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:49:31,873][valid][INFO] - {"epoch": 904, "valid_loss": "3.431", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "115.292", "valid_code_perplexity": "110.759", "valid_temp": "1.669", "valid_loss_0": "3.301", "valid_loss_1": "0.118", "valid_loss_2": "0.012", "valid_accuracy": "0.39286", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "36160", "valid_best_loss": "3.221"}
[2022-01-03 16:49:31,876][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 904 @ 36160 updates
[2022-01-03 16:49:31,877][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:49:35,644][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:49:35,673][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 904 @ 36160 updates, score 3.431) (writing took 3.796271724626422 seconds)
[2022-01-03 16:49:35,673][fairseq_cli.train][INFO] - end of epoch 904 (average epoch stats below)
[2022-01-03 16:49:35,686][train][INFO] - {"epoch": 904, "train_loss": "3.623", "train_ntokens": "1798.3", "train_nsentences": "4.95", "train_prob_perplexity": "133.624", "train_code_perplexity": "131.263", "train_temp": "1.669", "train_loss_0": "3.497", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33119", "train_wps": "3947.1", "train_ups": "2.19", "train_wpb": "1798.3", "train_bsz": "5", "train_num_updates": "36160", "train_lr": "0.000494348", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "16793"}
[2022-01-03 16:49:35,751][fairseq.trainer][INFO] - begin training epoch 905
[2022-01-03 16:49:35,752][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:49:49,616][train_inner][INFO] - {"epoch": 905, "update": 905.0, "loss": "3.634", "ntokens": "1787.88", "nsentences": "4.95", "prob_perplexity": "133.274", "code_perplexity": "130.892", "temp": "1.67", "loss_0": "3.509", "loss_1": "0.114", "loss_2": "0.011", "accuracy": "0.33053", "wps": "3918.6", "ups": "2.19", "wpb": "1787.9", "bsz": "5", "num_updates": "36200", "lr": "0.000494293", "gnorm": "0.514", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "16807"}
[2022-01-03 16:49:49,617][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:49:50,048][valid][INFO] - {"epoch": 905, "valid_loss": "3.726", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "130.264", "valid_code_perplexity": "125.174", "valid_temp": "1.669", "valid_loss_0": "3.6", "valid_loss_1": "0.115", "valid_loss_2": "0.011", "valid_accuracy": "0.31855", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "36200", "valid_best_loss": "3.221"}
[2022-01-03 16:49:50,052][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 905 @ 36200 updates
[2022-01-03 16:49:50,053][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:49:53,989][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:49:54,016][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 905 @ 36200 updates, score 3.726) (writing took 3.9640718726441264 seconds)
[2022-01-03 16:49:54,016][fairseq_cli.train][INFO] - end of epoch 905 (average epoch stats below)
[2022-01-03 16:49:54,029][train][INFO] - {"epoch": 905, "train_loss": "3.638", "train_ntokens": "1785.65", "train_nsentences": "4.95", "train_prob_perplexity": "134.03", "train_code_perplexity": "131.691", "train_temp": "1.669", "train_loss_0": "3.513", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33061", "train_wps": "3896.6", "train_ups": "2.18", "train_wpb": "1785.7", "train_bsz": "5", "train_num_updates": "36200", "train_lr": "0.000494293", "train_gnorm": "0.517", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16811"}
[2022-01-03 16:49:54,099][fairseq.trainer][INFO] - begin training epoch 906
[2022-01-03 16:49:54,099][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:50:08,058][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:50:08,470][valid][INFO] - {"epoch": 906, "valid_loss": "3.383", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "134.152", "valid_code_perplexity": "130.139", "valid_temp": "1.669", "valid_loss_0": "3.26", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.36979", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "36240", "valid_best_loss": "3.221"}
[2022-01-03 16:50:08,472][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 906 @ 36240 updates
[2022-01-03 16:50:08,473][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:50:12,199][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:50:12,226][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 906 @ 36240 updates, score 3.383) (writing took 3.7540592467412353 seconds)
[2022-01-03 16:50:12,227][fairseq_cli.train][INFO] - end of epoch 906 (average epoch stats below)
[2022-01-03 16:50:12,239][train][INFO] - {"epoch": 906, "train_loss": "3.664", "train_ntokens": "1787.12", "train_nsentences": "4.95", "train_prob_perplexity": "134.11", "train_code_perplexity": "131.712", "train_temp": "1.669", "train_loss_0": "3.539", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.32639", "train_wps": "3928.2", "train_ups": "2.2", "train_wpb": "1787.1", "train_bsz": "5", "train_num_updates": "36240", "train_lr": "0.000494239", "train_gnorm": "0.515", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "16830"}
[2022-01-03 16:50:12,318][fairseq.trainer][INFO] - begin training epoch 907
[2022-01-03 16:50:12,319][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:50:26,235][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:50:26,649][valid][INFO] - {"epoch": 907, "valid_loss": "3.518", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "130.333", "valid_code_perplexity": "126.73", "valid_temp": "1.668", "valid_loss_0": "3.393", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.37265", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "36280", "valid_best_loss": "3.221"}
[2022-01-03 16:50:26,652][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 907 @ 36280 updates
[2022-01-03 16:50:26,653][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:50:30,445][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:50:30,472][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 907 @ 36280 updates, score 3.518) (writing took 3.819874440319836 seconds)
[2022-01-03 16:50:30,473][fairseq_cli.train][INFO] - end of epoch 907 (average epoch stats below)
[2022-01-03 16:50:30,485][train][INFO] - {"epoch": 907, "train_loss": "3.64", "train_ntokens": "1784.03", "train_nsentences": "4.95", "train_prob_perplexity": "133.79", "train_code_perplexity": "131.511", "train_temp": "1.668", "train_loss_0": "3.515", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33359", "train_wps": "3913.8", "train_ups": "2.19", "train_wpb": "1784", "train_bsz": "5", "train_num_updates": "36280", "train_lr": "0.000494185", "train_gnorm": "0.513", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "16848"}
[2022-01-03 16:50:30,560][fairseq.trainer][INFO] - begin training epoch 908
[2022-01-03 16:50:30,561][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:50:44,433][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:50:44,867][valid][INFO] - {"epoch": 908, "valid_loss": "3.449", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "130.639", "valid_code_perplexity": "125.536", "valid_temp": "1.668", "valid_loss_0": "3.324", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.35974", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "36320", "valid_best_loss": "3.221"}
[2022-01-03 16:50:44,871][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 908 @ 36320 updates
[2022-01-03 16:50:44,871][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:50:48,893][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:50:48,917][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 908 @ 36320 updates, score 3.449) (writing took 4.046621687710285 seconds)
[2022-01-03 16:50:48,918][fairseq_cli.train][INFO] - end of epoch 908 (average epoch stats below)
[2022-01-03 16:50:48,930][train][INFO] - {"epoch": 908, "train_loss": "3.662", "train_ntokens": "1804.53", "train_nsentences": "4.95", "train_prob_perplexity": "134.454", "train_code_perplexity": "132.181", "train_temp": "1.668", "train_loss_0": "3.537", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.3269", "train_wps": "3916", "train_ups": "2.17", "train_wpb": "1804.5", "train_bsz": "5", "train_num_updates": "36320", "train_lr": "0.00049413", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "16866"}
[2022-01-03 16:50:49,001][fairseq.trainer][INFO] - begin training epoch 909
[2022-01-03 16:50:49,001][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:51:02,844][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:51:03,246][valid][INFO] - {"epoch": 909, "valid_loss": "3.664", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "128.807", "valid_code_perplexity": "125.214", "valid_temp": "1.668", "valid_loss_0": "3.54", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.35135", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "36360", "valid_best_loss": "3.221"}
[2022-01-03 16:51:03,249][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 909 @ 36360 updates
[2022-01-03 16:51:03,250][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:51:06,959][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:51:06,984][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 909 @ 36360 updates, score 3.664) (writing took 3.7347021931782365 seconds)
[2022-01-03 16:51:06,985][fairseq_cli.train][INFO] - end of epoch 909 (average epoch stats below)
[2022-01-03 16:51:06,997][train][INFO] - {"epoch": 909, "train_loss": "3.631", "train_ntokens": "1790.6", "train_nsentences": "4.95", "train_prob_perplexity": "134.684", "train_code_perplexity": "132.251", "train_temp": "1.668", "train_loss_0": "3.506", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.3337", "train_wps": "3967.2", "train_ups": "2.22", "train_wpb": "1790.6", "train_bsz": "5", "train_num_updates": "36360", "train_lr": "0.000494076", "train_gnorm": "0.519", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.7", "train_wall": "16884"}
[2022-01-03 16:51:07,068][fairseq.trainer][INFO] - begin training epoch 910
[2022-01-03 16:51:07,069][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:51:20,896][train_inner][INFO] - {"epoch": 910, "update": 910.0, "loss": "3.645", "ntokens": "1791.35", "nsentences": "4.95", "prob_perplexity": "134.218", "code_perplexity": "131.871", "temp": "1.668", "loss_0": "3.52", "loss_1": "0.114", "loss_2": "0.011", "accuracy": "0.33087", "wps": "3925.5", "ups": "2.19", "wpb": "1791.3", "bsz": "5", "num_updates": "36400", "lr": "0.000494022", "gnorm": "0.515", "clip": "0", "train_wall": "67", "gb_free": "5.4", "wall": "16898"}
[2022-01-03 16:51:20,897][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:51:21,303][valid][INFO] - {"epoch": 910, "valid_loss": "3.863", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "129.519", "valid_code_perplexity": "126.43", "valid_temp": "1.667", "valid_loss_0": "3.737", "valid_loss_1": "0.115", "valid_loss_2": "0.012", "valid_accuracy": "0.31085", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "36400", "valid_best_loss": "3.221"}
[2022-01-03 16:51:21,306][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 910 @ 36400 updates
[2022-01-03 16:51:21,306][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:51:25,233][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:51:25,247][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 910 @ 36400 updates, score 3.863) (writing took 3.940838811919093 seconds)
[2022-01-03 16:51:25,247][fairseq_cli.train][INFO] - end of epoch 910 (average epoch stats below)
[2022-01-03 16:51:25,260][train][INFO] - {"epoch": 910, "train_loss": "3.628", "train_ntokens": "1790.45", "train_nsentences": "4.95", "train_prob_perplexity": "134.05", "train_code_perplexity": "131.701", "train_temp": "1.667", "train_loss_0": "3.503", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33378", "train_wps": "3924.3", "train_ups": "2.19", "train_wpb": "1790.5", "train_bsz": "5", "train_num_updates": "36400", "train_lr": "0.000494022", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "16903"}
[2022-01-03 16:51:25,333][fairseq.trainer][INFO] - begin training epoch 911
[2022-01-03 16:51:25,334][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:51:39,231][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:51:39,631][valid][INFO] - {"epoch": 911, "valid_loss": "3.619", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "124.834", "valid_code_perplexity": "120.939", "valid_temp": "1.667", "valid_loss_0": "3.492", "valid_loss_1": "0.116", "valid_loss_2": "0.011", "valid_accuracy": "0.33562", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "36440", "valid_best_loss": "3.221"}
[2022-01-03 16:51:39,634][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 911 @ 36440 updates
[2022-01-03 16:51:39,635][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:51:43,450][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:51:43,478][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 911 @ 36440 updates, score 3.619) (writing took 3.8437660057097673 seconds)
[2022-01-03 16:51:43,479][fairseq_cli.train][INFO] - end of epoch 911 (average epoch stats below)
[2022-01-03 16:51:43,492][train][INFO] - {"epoch": 911, "train_loss": "3.614", "train_ntokens": "1775.6", "train_nsentences": "4.95", "train_prob_perplexity": "133.25", "train_code_perplexity": "130.612", "train_temp": "1.667", "train_loss_0": "3.489", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33254", "train_wps": "3898.4", "train_ups": "2.2", "train_wpb": "1775.6", "train_bsz": "5", "train_num_updates": "36440", "train_lr": "0.000493967", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "16921"}
[2022-01-03 16:51:43,571][fairseq.trainer][INFO] - begin training epoch 912
[2022-01-03 16:51:43,571][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:51:57,493][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:51:57,916][valid][INFO] - {"epoch": 912, "valid_loss": "3.605", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "129.723", "valid_code_perplexity": "125.733", "valid_temp": "1.667", "valid_loss_0": "3.479", "valid_loss_1": "0.115", "valid_loss_2": "0.011", "valid_accuracy": "0.32687", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "36480", "valid_best_loss": "3.221"}
[2022-01-03 16:51:57,919][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 912 @ 36480 updates
[2022-01-03 16:51:57,920][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:52:01,682][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:52:01,710][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 912 @ 36480 updates, score 3.605) (writing took 3.791145375929773 seconds)
[2022-01-03 16:52:01,712][fairseq_cli.train][INFO] - end of epoch 912 (average epoch stats below)
[2022-01-03 16:52:01,725][train][INFO] - {"epoch": 912, "train_loss": "3.631", "train_ntokens": "1795.65", "train_nsentences": "4.95", "train_prob_perplexity": "133.907", "train_code_perplexity": "131.468", "train_temp": "1.667", "train_loss_0": "3.505", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33028", "train_wps": "3942.2", "train_ups": "2.2", "train_wpb": "1795.7", "train_bsz": "5", "train_num_updates": "36480", "train_lr": "0.000493913", "train_gnorm": "0.536", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "16939"}
[2022-01-03 16:52:01,779][fairseq.trainer][INFO] - begin training epoch 913
[2022-01-03 16:52:01,780][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:52:15,801][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:52:16,205][valid][INFO] - {"epoch": 913, "valid_loss": "3.569", "valid_ntokens": "704", "valid_nsentences": "2", "valid_prob_perplexity": "131.961", "valid_code_perplexity": "128.095", "valid_temp": "1.666", "valid_loss_0": "3.444", "valid_loss_1": "0.115", "valid_loss_2": "0.011", "valid_accuracy": "0.33665", "valid_wps": "0", "valid_wpb": "704", "valid_bsz": "2", "valid_num_updates": "36520", "valid_best_loss": "3.221"}
[2022-01-03 16:52:16,208][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 913 @ 36520 updates
[2022-01-03 16:52:16,208][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:52:20,167][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:52:20,196][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 913 @ 36520 updates, score 3.569) (writing took 3.9879169072955847 seconds)
[2022-01-03 16:52:20,196][fairseq_cli.train][INFO] - end of epoch 913 (average epoch stats below)
[2022-01-03 16:52:20,209][train][INFO] - {"epoch": 913, "train_loss": "3.624", "train_ntokens": "1801.95", "train_nsentences": "4.95", "train_prob_perplexity": "133.218", "train_code_perplexity": "130.879", "train_temp": "1.666", "train_loss_0": "3.499", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33088", "train_wps": "3902.1", "train_ups": "2.17", "train_wpb": "1802", "train_bsz": "5", "train_num_updates": "36520", "train_lr": "0.000493859", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "16958"}
[2022-01-03 16:52:20,287][fairseq.trainer][INFO] - begin training epoch 914
[2022-01-03 16:52:20,287][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:52:34,173][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:52:34,593][valid][INFO] - {"epoch": 914, "valid_loss": "3.404", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "133.12", "valid_code_perplexity": "129.57", "valid_temp": "1.666", "valid_loss_0": "3.28", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.38342", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "36560", "valid_best_loss": "3.221"}
[2022-01-03 16:52:34,596][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 914 @ 36560 updates
[2022-01-03 16:52:34,597][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:52:38,425][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:52:38,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 914 @ 36560 updates, score 3.404) (writing took 3.856921998783946 seconds)
[2022-01-03 16:52:38,453][fairseq_cli.train][INFO] - end of epoch 914 (average epoch stats below)
[2022-01-03 16:52:38,466][train][INFO] - {"epoch": 914, "train_loss": "3.631", "train_ntokens": "1809.4", "train_nsentences": "4.95", "train_prob_perplexity": "135.21", "train_code_perplexity": "132.901", "train_temp": "1.666", "train_loss_0": "3.507", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.32911", "train_wps": "3967.1", "train_ups": "2.19", "train_wpb": "1809.4", "train_bsz": "5", "train_num_updates": "36560", "train_lr": "0.000493804", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "16976"}
[2022-01-03 16:52:38,541][fairseq.trainer][INFO] - begin training epoch 915
[2022-01-03 16:52:38,541][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:52:52,529][train_inner][INFO] - {"epoch": 915, "update": 915.0, "loss": "3.624", "ntokens": "1791.42", "nsentences": "4.95", "prob_perplexity": "134.118", "code_perplexity": "131.719", "temp": "1.666", "loss_0": "3.499", "loss_1": "0.114", "loss_2": "0.011", "accuracy": "0.33128", "wps": "3910.5", "ups": "2.18", "wpb": "1791.4", "bsz": "5", "num_updates": "36600", "lr": "0.00049375", "gnorm": "0.513", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "16990"}
[2022-01-03 16:52:52,530][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:52:52,965][valid][INFO] - {"epoch": 915, "valid_loss": "3.312", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "129.366", "valid_code_perplexity": "124.725", "valid_temp": "1.666", "valid_loss_0": "3.185", "valid_loss_1": "0.115", "valid_loss_2": "0.012", "valid_accuracy": "0.38919", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "36600", "valid_best_loss": "3.221"}
[2022-01-03 16:52:52,967][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 915 @ 36600 updates
[2022-01-03 16:52:52,968][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:52:56,667][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:52:56,694][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 915 @ 36600 updates, score 3.312) (writing took 3.7265281016007066 seconds)
[2022-01-03 16:52:56,695][fairseq_cli.train][INFO] - end of epoch 915 (average epoch stats below)
[2022-01-03 16:52:56,708][train][INFO] - {"epoch": 915, "train_loss": "3.619", "train_ntokens": "1774.53", "train_nsentences": "4.95", "train_prob_perplexity": "135.007", "train_code_perplexity": "132.737", "train_temp": "1.666", "train_loss_0": "3.494", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33364", "train_wps": "3893.9", "train_ups": "2.19", "train_wpb": "1774.5", "train_bsz": "5", "train_num_updates": "36600", "train_lr": "0.00049375", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.6", "train_wall": "16994"}
[2022-01-03 16:52:56,780][fairseq.trainer][INFO] - begin training epoch 916
[2022-01-03 16:52:56,781][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:53:10,744][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:53:11,234][valid][INFO] - {"epoch": 916, "valid_loss": "3.508", "valid_ntokens": "700", "valid_nsentences": "2", "valid_prob_perplexity": "129.471", "valid_code_perplexity": "126.329", "valid_temp": "1.665", "valid_loss_0": "3.382", "valid_loss_1": "0.115", "valid_loss_2": "0.011", "valid_accuracy": "0.35857", "valid_wps": "0", "valid_wpb": "700", "valid_bsz": "2", "valid_num_updates": "36640", "valid_best_loss": "3.221"}
[2022-01-03 16:53:11,236][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 916 @ 36640 updates
[2022-01-03 16:53:11,237][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:53:14,913][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:53:14,942][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 916 @ 36640 updates, score 3.508) (writing took 3.7052744198590517 seconds)
[2022-01-03 16:53:14,942][fairseq_cli.train][INFO] - end of epoch 916 (average epoch stats below)
[2022-01-03 16:53:14,956][train][INFO] - {"epoch": 916, "train_loss": "3.651", "train_ntokens": "1804.03", "train_nsentences": "4.95", "train_prob_perplexity": "134.808", "train_code_perplexity": "132.326", "train_temp": "1.665", "train_loss_0": "3.526", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.32644", "train_wps": "3957.5", "train_ups": "2.19", "train_wpb": "1804", "train_bsz": "5", "train_num_updates": "36640", "train_lr": "0.000493696", "train_gnorm": "0.517", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.4", "train_wall": "17012"}
[2022-01-03 16:53:15,032][fairseq.trainer][INFO] - begin training epoch 917
[2022-01-03 16:53:15,033][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:53:28,958][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:53:29,495][valid][INFO] - {"epoch": 917, "valid_loss": "3.288", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "131.88", "valid_code_perplexity": "127.576", "valid_temp": "1.665", "valid_loss_0": "3.163", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.3601", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "36680", "valid_best_loss": "3.221"}
[2022-01-03 16:53:29,497][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 917 @ 36680 updates
[2022-01-03 16:53:29,497][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:53:33,179][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:53:33,208][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 917 @ 36680 updates, score 3.288) (writing took 3.710975483059883 seconds)
[2022-01-03 16:53:33,208][fairseq_cli.train][INFO] - end of epoch 917 (average epoch stats below)
[2022-01-03 16:53:33,221][train][INFO] - {"epoch": 917, "train_loss": "3.637", "train_ntokens": "1800.92", "train_nsentences": "4.95", "train_prob_perplexity": "135.388", "train_code_perplexity": "133.136", "train_temp": "1.665", "train_loss_0": "3.513", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33057", "train_wps": "3946.7", "train_ups": "2.19", "train_wpb": "1800.9", "train_bsz": "5", "train_num_updates": "36680", "train_lr": "0.000493641", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "17031"}
[2022-01-03 16:53:33,301][fairseq.trainer][INFO] - begin training epoch 918
[2022-01-03 16:53:33,302][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:53:47,193][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:53:47,696][valid][INFO] - {"epoch": 918, "valid_loss": "3.525", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "122.039", "valid_code_perplexity": "117.755", "valid_temp": "1.665", "valid_loss_0": "3.399", "valid_loss_1": "0.117", "valid_loss_2": "0.01", "valid_accuracy": "0.34271", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "36720", "valid_best_loss": "3.221"}
[2022-01-03 16:53:47,698][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 918 @ 36720 updates
[2022-01-03 16:53:47,698][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:53:51,397][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:53:51,424][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 918 @ 36720 updates, score 3.525) (writing took 3.7258509434759617 seconds)
[2022-01-03 16:53:51,424][fairseq_cli.train][INFO] - end of epoch 918 (average epoch stats below)
[2022-01-03 16:53:51,437][train][INFO] - {"epoch": 918, "train_loss": "3.59", "train_ntokens": "1758.47", "train_nsentences": "4.95", "train_prob_perplexity": "135.281", "train_code_perplexity": "132.791", "train_temp": "1.665", "train_loss_0": "3.466", "train_loss_1": "0.114", "train_loss_2": "0.01", "train_accuracy": "0.33755", "train_wps": "3864.2", "train_ups": "2.2", "train_wpb": "1758.5", "train_bsz": "5", "train_num_updates": "36720", "train_lr": "0.000493587", "train_gnorm": "0.521", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "17049"}
[2022-01-03 16:53:51,509][fairseq.trainer][INFO] - begin training epoch 919
[2022-01-03 16:53:51,510][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:54:05,445][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:54:05,881][valid][INFO] - {"epoch": 919, "valid_loss": "3.715", "valid_ntokens": "766", "valid_nsentences": "2", "valid_prob_perplexity": "133.514", "valid_code_perplexity": "128.762", "valid_temp": "1.664", "valid_loss_0": "3.59", "valid_loss_1": "0.114", "valid_loss_2": "0.011", "valid_accuracy": "0.3329", "valid_wps": "0", "valid_wpb": "766", "valid_bsz": "2", "valid_num_updates": "36760", "valid_best_loss": "3.221"}
[2022-01-03 16:54:05,885][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 919 @ 36760 updates
[2022-01-03 16:54:05,887][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:54:09,652][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:54:09,681][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 919 @ 36760 updates, score 3.715) (writing took 3.795514683239162 seconds)
[2022-01-03 16:54:09,681][fairseq_cli.train][INFO] - end of epoch 919 (average epoch stats below)
[2022-01-03 16:54:09,694][train][INFO] - {"epoch": 919, "train_loss": "3.643", "train_ntokens": "1794.05", "train_nsentences": "4.95", "train_prob_perplexity": "136.037", "train_code_perplexity": "133.475", "train_temp": "1.664", "train_loss_0": "3.519", "train_loss_1": "0.114", "train_loss_2": "0.01", "train_accuracy": "0.32861", "train_wps": "3933.4", "train_ups": "2.19", "train_wpb": "1794", "train_bsz": "5", "train_num_updates": "36760", "train_lr": "0.000493533", "train_gnorm": "0.505", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17067"}
[2022-01-03 16:54:09,772][fairseq.trainer][INFO] - begin training epoch 920
[2022-01-03 16:54:09,772][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:54:23,852][train_inner][INFO] - {"epoch": 920, "update": 920.0, "loss": "3.629", "ntokens": "1790.65", "nsentences": "4.95", "prob_perplexity": "135.481", "code_perplexity": "133.05", "temp": "1.665", "loss_0": "3.505", "loss_1": "0.114", "loss_2": "0.011", "accuracy": "0.33147", "wps": "3922.1", "ups": "2.19", "wpb": "1790.7", "bsz": "5", "num_updates": "36800", "lr": "0.000493478", "gnorm": "0.511", "clip": "0", "train_wall": "68", "gb_free": "5.5", "wall": "17081"}
[2022-01-03 16:54:23,853][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:54:24,264][valid][INFO] - {"epoch": 920, "valid_loss": "3.543", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "130.383", "valid_code_perplexity": "125.3", "valid_temp": "1.664", "valid_loss_0": "3.417", "valid_loss_1": "0.115", "valid_loss_2": "0.011", "valid_accuracy": "0.36792", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "36800", "valid_best_loss": "3.221"}
[2022-01-03 16:54:24,269][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 920 @ 36800 updates
[2022-01-03 16:54:24,270][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:54:27,908][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:54:27,938][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 920 @ 36800 updates, score 3.543) (writing took 3.668805291876197 seconds)
[2022-01-03 16:54:27,938][fairseq_cli.train][INFO] - end of epoch 920 (average epoch stats below)
[2022-01-03 16:54:27,951][train][INFO] - {"epoch": 920, "train_loss": "3.623", "train_ntokens": "1795.78", "train_nsentences": "4.95", "train_prob_perplexity": "135.889", "train_code_perplexity": "133.524", "train_temp": "1.664", "train_loss_0": "3.498", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33434", "train_wps": "3937.2", "train_ups": "2.19", "train_wpb": "1795.8", "train_bsz": "5", "train_num_updates": "36800", "train_lr": "0.000493478", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "17085"}
[2022-01-03 16:54:28,004][fairseq.trainer][INFO] - begin training epoch 921
[2022-01-03 16:54:28,005][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:54:41,841][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:54:42,260][valid][INFO] - {"epoch": 921, "valid_loss": "3.324", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "113.748", "valid_code_perplexity": "107.719", "valid_temp": "1.664", "valid_loss_0": "3.195", "valid_loss_1": "0.119", "valid_loss_2": "0.01", "valid_accuracy": "0.39689", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "36840", "valid_best_loss": "3.221"}
[2022-01-03 16:54:42,263][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 921 @ 36840 updates
[2022-01-03 16:54:42,264][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:54:46,217][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:54:46,245][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 921 @ 36840 updates, score 3.324) (writing took 3.982146106660366 seconds)
[2022-01-03 16:54:46,246][fairseq_cli.train][INFO] - end of epoch 921 (average epoch stats below)
[2022-01-03 16:54:46,259][train][INFO] - {"epoch": 921, "train_loss": "3.672", "train_ntokens": "1784.28", "train_nsentences": "4.95", "train_prob_perplexity": "135.878", "train_code_perplexity": "133.509", "train_temp": "1.664", "train_loss_0": "3.548", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.32424", "train_wps": "3901.2", "train_ups": "2.19", "train_wpb": "1784.3", "train_bsz": "5", "train_num_updates": "36840", "train_lr": "0.000493424", "train_gnorm": "0.52", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17104"}
[2022-01-03 16:54:46,310][fairseq.trainer][INFO] - begin training epoch 922
[2022-01-03 16:54:46,311][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:55:00,254][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:55:00,679][valid][INFO] - {"epoch": 922, "valid_loss": "3.06", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "133.255", "valid_code_perplexity": "130.112", "valid_temp": "1.663", "valid_loss_0": "2.936", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.42016", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "36880", "valid_best_loss": "3.06"}
[2022-01-03 16:55:00,682][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 922 @ 36880 updates
[2022-01-03 16:55:00,683][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 16:55:04,451][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 16:55:12,491][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 922 @ 36880 updates, score 3.06) (writing took 11.80854357406497 seconds)
[2022-01-03 16:55:12,491][fairseq_cli.train][INFO] - end of epoch 922 (average epoch stats below)
[2022-01-03 16:55:12,504][train][INFO] - {"epoch": 922, "train_loss": "3.667", "train_ntokens": "1795.55", "train_nsentences": "4.95", "train_prob_perplexity": "136.493", "train_code_perplexity": "133.978", "train_temp": "1.663", "train_loss_0": "3.542", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.32572", "train_wps": "2737.9", "train_ups": "1.52", "train_wpb": "1795.5", "train_bsz": "5", "train_num_updates": "36880", "train_lr": "0.00049337", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "17130"}
[2022-01-03 16:55:12,595][fairseq.trainer][INFO] - begin training epoch 923
[2022-01-03 16:55:12,596][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:55:26,360][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:55:26,772][valid][INFO] - {"epoch": 923, "valid_loss": "3.537", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "123.336", "valid_code_perplexity": "118.558", "valid_temp": "1.663", "valid_loss_0": "3.408", "valid_loss_1": "0.116", "valid_loss_2": "0.013", "valid_accuracy": "0.35881", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "36920", "valid_best_loss": "3.06"}
[2022-01-03 16:55:26,775][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 923 @ 36920 updates
[2022-01-03 16:55:26,776][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:55:30,753][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:55:30,779][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 923 @ 36920 updates, score 3.537) (writing took 4.003991877660155 seconds)
[2022-01-03 16:55:30,779][fairseq_cli.train][INFO] - end of epoch 923 (average epoch stats below)
[2022-01-03 16:55:30,792][train][INFO] - {"epoch": 923, "train_loss": "3.643", "train_ntokens": "1802.42", "train_nsentences": "4.95", "train_prob_perplexity": "136.832", "train_code_perplexity": "134.369", "train_temp": "1.663", "train_loss_0": "3.519", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.3313", "train_wps": "3945", "train_ups": "2.19", "train_wpb": "1802.4", "train_bsz": "5", "train_num_updates": "36920", "train_lr": "0.000493315", "train_gnorm": "0.511", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "17148"}
[2022-01-03 16:55:30,867][fairseq.trainer][INFO] - begin training epoch 924
[2022-01-03 16:55:30,868][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:55:44,680][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:55:45,083][valid][INFO] - {"epoch": 924, "valid_loss": "3.426", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "134.396", "valid_code_perplexity": "130.812", "valid_temp": "1.663", "valid_loss_0": "3.302", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.36243", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "36960", "valid_best_loss": "3.06"}
[2022-01-03 16:55:45,085][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 924 @ 36960 updates
[2022-01-03 16:55:45,086][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:55:49,029][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:55:49,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 924 @ 36960 updates, score 3.426) (writing took 3.9723887657746673 seconds)
[2022-01-03 16:55:49,058][fairseq_cli.train][INFO] - end of epoch 924 (average epoch stats below)
[2022-01-03 16:55:49,071][train][INFO] - {"epoch": 924, "train_loss": "3.605", "train_ntokens": "1779.08", "train_nsentences": "4.95", "train_prob_perplexity": "136.055", "train_code_perplexity": "133.66", "train_temp": "1.663", "train_loss_0": "3.481", "train_loss_1": "0.114", "train_loss_2": "0.011", "train_accuracy": "0.33638", "train_wps": "3896", "train_ups": "2.19", "train_wpb": "1779.1", "train_bsz": "5", "train_num_updates": "36960", "train_lr": "0.000493261", "train_gnorm": "0.495", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "17166"}
[2022-01-03 16:55:49,149][fairseq.trainer][INFO] - begin training epoch 925
[2022-01-03 16:55:49,149][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:56:03,036][train_inner][INFO] - {"epoch": 925, "update": 925.0, "loss": "3.645", "ntokens": "1791.44", "nsentences": "4.95", "prob_perplexity": "136.28", "code_perplexity": "133.865", "temp": "1.663", "loss_0": "3.52", "loss_1": "0.114", "loss_2": "0.011", "accuracy": "0.3298", "wps": "3612.9", "ups": "2.02", "wpb": "1791.4", "bsz": "5", "num_updates": "37000", "lr": "0.000493207", "gnorm": "0.507", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "17180"}
[2022-01-03 16:56:03,036][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:56:03,461][valid][INFO] - {"epoch": 925, "valid_loss": "3.26", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "135.762", "valid_code_perplexity": "130.943", "valid_temp": "1.662", "valid_loss_0": "3.134", "valid_loss_1": "0.114", "valid_loss_2": "0.012", "valid_accuracy": "0.37838", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "37000", "valid_best_loss": "3.06"}
[2022-01-03 16:56:03,465][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 925 @ 37000 updates
[2022-01-03 16:56:03,466][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:56:07,272][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:56:07,299][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 925 @ 37000 updates, score 3.26) (writing took 3.83413430955261 seconds)
[2022-01-03 16:56:07,299][fairseq_cli.train][INFO] - end of epoch 925 (average epoch stats below)
[2022-01-03 16:56:07,312][train][INFO] - {"epoch": 925, "train_loss": "3.636", "train_ntokens": "1795.9", "train_nsentences": "4.95", "train_prob_perplexity": "136.14", "train_code_perplexity": "133.808", "train_temp": "1.662", "train_loss_0": "3.512", "train_loss_1": "0.114", "train_loss_2": "0.01", "train_accuracy": "0.33135", "train_wps": "3940.9", "train_ups": "2.19", "train_wpb": "1795.9", "train_bsz": "5", "train_num_updates": "37000", "train_lr": "0.000493207", "train_gnorm": "0.498", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17185"}
[2022-01-03 16:56:07,391][fairseq.trainer][INFO] - begin training epoch 926
[2022-01-03 16:56:07,392][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:56:21,220][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:56:21,635][valid][INFO] - {"epoch": 926, "valid_loss": "3.513", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "134.929", "valid_code_perplexity": "130.155", "valid_temp": "1.662", "valid_loss_0": "3.389", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.33162", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "37040", "valid_best_loss": "3.06"}
[2022-01-03 16:56:21,639][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 926 @ 37040 updates
[2022-01-03 16:56:21,639][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:56:25,615][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:56:25,643][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 926 @ 37040 updates, score 3.513) (writing took 4.004450062289834 seconds)
[2022-01-03 16:56:25,644][fairseq_cli.train][INFO] - end of epoch 926 (average epoch stats below)
[2022-01-03 16:56:25,656][train][INFO] - {"epoch": 926, "train_loss": "3.625", "train_ntokens": "1787.53", "train_nsentences": "4.95", "train_prob_perplexity": "136.792", "train_code_perplexity": "134.263", "train_temp": "1.662", "train_loss_0": "3.501", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33228", "train_wps": "3900.5", "train_ups": "2.18", "train_wpb": "1787.5", "train_bsz": "5", "train_num_updates": "37040", "train_lr": "0.000493152", "train_gnorm": "0.522", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "17203"}
[2022-01-03 16:56:25,726][fairseq.trainer][INFO] - begin training epoch 927
[2022-01-03 16:56:25,727][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:56:39,645][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:56:40,041][valid][INFO] - {"epoch": 927, "valid_loss": "3.546", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "137.07", "valid_code_perplexity": "132.497", "valid_temp": "1.662", "valid_loss_0": "3.423", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.35656", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "37080", "valid_best_loss": "3.06"}
[2022-01-03 16:56:40,044][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 927 @ 37080 updates
[2022-01-03 16:56:40,045][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:56:43,816][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:56:43,843][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 927 @ 37080 updates, score 3.546) (writing took 3.799510659649968 seconds)
[2022-01-03 16:56:43,844][fairseq_cli.train][INFO] - end of epoch 927 (average epoch stats below)
[2022-01-03 16:56:43,856][train][INFO] - {"epoch": 927, "train_loss": "3.623", "train_ntokens": "1801.53", "train_nsentences": "4.95", "train_prob_perplexity": "137.07", "train_code_perplexity": "134.733", "train_temp": "1.662", "train_loss_0": "3.498", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.3349", "train_wps": "3962", "train_ups": "2.2", "train_wpb": "1801.5", "train_bsz": "5", "train_num_updates": "37080", "train_lr": "0.000493098", "train_gnorm": "0.505", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "17221"}
[2022-01-03 16:56:43,911][fairseq.trainer][INFO] - begin training epoch 928
[2022-01-03 16:56:43,912][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:56:57,732][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:56:58,148][valid][INFO] - {"epoch": 928, "valid_loss": "3.447", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "132.949", "valid_code_perplexity": "127.659", "valid_temp": "1.661", "valid_loss_0": "3.323", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.35054", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "37120", "valid_best_loss": "3.06"}
[2022-01-03 16:56:58,152][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 928 @ 37120 updates
[2022-01-03 16:56:58,154][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:57:02,129][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:57:02,144][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 928 @ 37120 updates, score 3.447) (writing took 3.9915213538333774 seconds)
[2022-01-03 16:57:02,144][fairseq_cli.train][INFO] - end of epoch 928 (average epoch stats below)
[2022-01-03 16:57:02,157][train][INFO] - {"epoch": 928, "train_loss": "3.67", "train_ntokens": "1803.2", "train_nsentences": "4.95", "train_prob_perplexity": "136.985", "train_code_perplexity": "134.442", "train_temp": "1.661", "train_loss_0": "3.546", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.32446", "train_wps": "3944", "train_ups": "2.19", "train_wpb": "1803.2", "train_bsz": "5", "train_num_updates": "37120", "train_lr": "0.000493043", "train_gnorm": "0.5", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "17240"}
[2022-01-03 16:57:02,212][fairseq.trainer][INFO] - begin training epoch 929
[2022-01-03 16:57:02,213][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:57:16,064][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:57:16,484][valid][INFO] - {"epoch": 929, "valid_loss": "3.808", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "132.035", "valid_code_perplexity": "127.44", "valid_temp": "1.661", "valid_loss_0": "3.683", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.32821", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "37160", "valid_best_loss": "3.06"}
[2022-01-03 16:57:16,488][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 929 @ 37160 updates
[2022-01-03 16:57:16,489][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:57:20,401][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:57:20,412][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 929 @ 37160 updates, score 3.808) (writing took 3.923665914684534 seconds)
[2022-01-03 16:57:20,412][fairseq_cli.train][INFO] - end of epoch 929 (average epoch stats below)
[2022-01-03 16:57:20,426][train][INFO] - {"epoch": 929, "train_loss": "3.634", "train_ntokens": "1785.83", "train_nsentences": "4.95", "train_prob_perplexity": "136.743", "train_code_perplexity": "134.39", "train_temp": "1.661", "train_loss_0": "3.511", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33018", "train_wps": "3913", "train_ups": "2.19", "train_wpb": "1785.8", "train_bsz": "5", "train_num_updates": "37160", "train_lr": "0.000492989", "train_gnorm": "0.508", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "17258"}
[2022-01-03 16:57:20,491][fairseq.trainer][INFO] - begin training epoch 930
[2022-01-03 16:57:20,492][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:57:34,236][train_inner][INFO] - {"epoch": 930, "update": 930.0, "loss": "3.64", "ntokens": "1795.49", "nsentences": "4.95", "prob_perplexity": "137.049", "code_perplexity": "134.622", "temp": "1.661", "loss_0": "3.516", "loss_1": "0.113", "loss_2": "0.011", "accuracy": "0.33022", "wps": "3938", "ups": "2.19", "wpb": "1795.5", "bsz": "5", "num_updates": "37200", "lr": "0.000492935", "gnorm": "0.508", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "17272"}
[2022-01-03 16:57:34,237][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:57:34,654][valid][INFO] - {"epoch": 930, "valid_loss": "3.898", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "130.651", "valid_code_perplexity": "126.309", "valid_temp": "1.661", "valid_loss_0": "3.771", "valid_loss_1": "0.115", "valid_loss_2": "0.012", "valid_accuracy": "0.31472", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "37200", "valid_best_loss": "3.06"}
[2022-01-03 16:57:34,657][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 930 @ 37200 updates
[2022-01-03 16:57:34,658][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:57:38,590][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:57:38,606][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 930 @ 37200 updates, score 3.898) (writing took 3.9483502684161067 seconds)
[2022-01-03 16:57:38,606][fairseq_cli.train][INFO] - end of epoch 930 (average epoch stats below)
[2022-01-03 16:57:38,619][train][INFO] - {"epoch": 930, "train_loss": "3.647", "train_ntokens": "1799.38", "train_nsentences": "4.95", "train_prob_perplexity": "137.655", "train_code_perplexity": "135.281", "train_temp": "1.661", "train_loss_0": "3.523", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.32932", "train_wps": "3959.1", "train_ups": "2.2", "train_wpb": "1799.4", "train_bsz": "5", "train_num_updates": "37200", "train_lr": "0.000492935", "train_gnorm": "0.503", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17276"}
[2022-01-03 16:57:38,665][fairseq.trainer][INFO] - begin training epoch 931
[2022-01-03 16:57:38,666][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:57:52,569][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:57:52,987][valid][INFO] - {"epoch": 931, "valid_loss": "3.736", "valid_ntokens": "792", "valid_nsentences": "2", "valid_prob_perplexity": "135.231", "valid_code_perplexity": "130.304", "valid_temp": "1.66", "valid_loss_0": "3.61", "valid_loss_1": "0.114", "valid_loss_2": "0.012", "valid_accuracy": "0.31313", "valid_wps": "0", "valid_wpb": "792", "valid_bsz": "2", "valid_num_updates": "37240", "valid_best_loss": "3.06"}
[2022-01-03 16:57:52,990][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 931 @ 37240 updates
[2022-01-03 16:57:52,990][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:57:56,921][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:57:56,948][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 931 @ 37240 updates, score 3.736) (writing took 3.9583730893209577 seconds)
[2022-01-03 16:57:56,948][fairseq_cli.train][INFO] - end of epoch 931 (average epoch stats below)
[2022-01-03 16:57:56,961][train][INFO] - {"epoch": 931, "train_loss": "3.612", "train_ntokens": "1799.3", "train_nsentences": "4.95", "train_prob_perplexity": "137.048", "train_code_perplexity": "134.433", "train_temp": "1.66", "train_loss_0": "3.488", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.33098", "train_wps": "3926.5", "train_ups": "2.18", "train_wpb": "1799.3", "train_bsz": "5", "train_num_updates": "37240", "train_lr": "0.00049288", "train_gnorm": "0.495", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17294"}
[2022-01-03 16:57:57,032][fairseq.trainer][INFO] - begin training epoch 932
[2022-01-03 16:57:57,033][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:58:10,924][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:58:11,335][valid][INFO] - {"epoch": 932, "valid_loss": "3.606", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "123.996", "valid_code_perplexity": "120.127", "valid_temp": "1.66", "valid_loss_0": "3.478", "valid_loss_1": "0.116", "valid_loss_2": "0.012", "valid_accuracy": "0.36179", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "37280", "valid_best_loss": "3.06"}
[2022-01-03 16:58:11,340][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 932 @ 37280 updates
[2022-01-03 16:58:11,341][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:58:15,118][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:58:15,144][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 932 @ 37280 updates, score 3.606) (writing took 3.804420132189989 seconds)
[2022-01-03 16:58:15,145][fairseq_cli.train][INFO] - end of epoch 932 (average epoch stats below)
[2022-01-03 16:58:15,157][train][INFO] - {"epoch": 932, "train_loss": "3.641", "train_ntokens": "1800.33", "train_nsentences": "4.95", "train_prob_perplexity": "136.529", "train_code_perplexity": "134.048", "train_temp": "1.66", "train_loss_0": "3.517", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.33019", "train_wps": "3960.4", "train_ups": "2.2", "train_wpb": "1800.3", "train_bsz": "5", "train_num_updates": "37280", "train_lr": "0.000492826", "train_gnorm": "0.519", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17313"}
[2022-01-03 16:58:15,231][fairseq.trainer][INFO] - begin training epoch 933
[2022-01-03 16:58:15,231][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:58:29,344][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:58:29,757][valid][INFO] - {"epoch": 933, "valid_loss": "3.575", "valid_ntokens": "678", "valid_nsentences": "2", "valid_prob_perplexity": "133.532", "valid_code_perplexity": "129.355", "valid_temp": "1.66", "valid_loss_0": "3.452", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.36283", "valid_wps": "0", "valid_wpb": "678", "valid_bsz": "2", "valid_num_updates": "37320", "valid_best_loss": "3.06"}
[2022-01-03 16:58:29,760][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 933 @ 37320 updates
[2022-01-03 16:58:29,761][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:58:33,391][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:58:33,419][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 933 @ 37320 updates, score 3.575) (writing took 3.6593605391681194 seconds)
[2022-01-03 16:58:33,420][fairseq_cli.train][INFO] - end of epoch 933 (average epoch stats below)
[2022-01-03 16:58:33,433][train][INFO] - {"epoch": 933, "train_loss": "3.608", "train_ntokens": "1793.15", "train_nsentences": "4.95", "train_prob_perplexity": "137.556", "train_code_perplexity": "135.17", "train_temp": "1.66", "train_loss_0": "3.484", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33291", "train_wps": "3927.5", "train_ups": "2.19", "train_wpb": "1793.2", "train_bsz": "5", "train_num_updates": "37320", "train_lr": "0.000492772", "train_gnorm": "0.498", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.5", "train_wall": "17331"}
[2022-01-03 16:58:33,497][fairseq.trainer][INFO] - begin training epoch 934
[2022-01-03 16:58:33,497][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:58:47,298][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:58:47,708][valid][INFO] - {"epoch": 934, "valid_loss": "3.459", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "137.063", "valid_code_perplexity": "132.042", "valid_temp": "1.659", "valid_loss_0": "3.335", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.38442", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "37360", "valid_best_loss": "3.06"}
[2022-01-03 16:58:47,710][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 934 @ 37360 updates
[2022-01-03 16:58:47,711][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:58:51,668][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:58:51,698][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 934 @ 37360 updates, score 3.459) (writing took 3.98716470785439 seconds)
[2022-01-03 16:58:51,698][fairseq_cli.train][INFO] - end of epoch 934 (average epoch stats below)
[2022-01-03 16:58:51,711][train][INFO] - {"epoch": 934, "train_loss": "3.607", "train_ntokens": "1794.12", "train_nsentences": "4.95", "train_prob_perplexity": "137.386", "train_code_perplexity": "134.752", "train_temp": "1.659", "train_loss_0": "3.484", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.3348", "train_wps": "3929.1", "train_ups": "2.19", "train_wpb": "1794.1", "train_bsz": "5", "train_num_updates": "37360", "train_lr": "0.000492717", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "17349"}
[2022-01-03 16:58:51,792][fairseq.trainer][INFO] - begin training epoch 935
[2022-01-03 16:58:51,792][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:59:05,673][train_inner][INFO] - {"epoch": 935, "update": 935.0, "loss": "3.621", "ntokens": "1796.01", "nsentences": "4.95", "prob_perplexity": "137.217", "code_perplexity": "134.708", "temp": "1.66", "loss_0": "3.497", "loss_1": "0.113", "loss_2": "0.01", "accuracy": "0.33151", "wps": "3929", "ups": "2.19", "wpb": "1796", "bsz": "5", "num_updates": "37400", "lr": "0.000492663", "gnorm": "0.507", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "17363"}
[2022-01-03 16:59:05,674][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:59:06,076][valid][INFO] - {"epoch": 935, "valid_loss": "3.326", "valid_ntokens": "654", "valid_nsentences": "2", "valid_prob_perplexity": "118.012", "valid_code_perplexity": "115.018", "valid_temp": "1.659", "valid_loss_0": "3.197", "valid_loss_1": "0.118", "valid_loss_2": "0.011", "valid_accuracy": "0.40673", "valid_wps": "0", "valid_wpb": "654", "valid_bsz": "2", "valid_num_updates": "37400", "valid_best_loss": "3.06"}
[2022-01-03 16:59:06,078][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 935 @ 37400 updates
[2022-01-03 16:59:06,079][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:59:09,903][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:59:09,930][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 935 @ 37400 updates, score 3.326) (writing took 3.851942900568247 seconds)
[2022-01-03 16:59:09,931][fairseq_cli.train][INFO] - end of epoch 935 (average epoch stats below)
[2022-01-03 16:59:09,944][train][INFO] - {"epoch": 935, "train_loss": "3.638", "train_ntokens": "1793.12", "train_nsentences": "4.95", "train_prob_perplexity": "137.564", "train_code_perplexity": "135.137", "train_temp": "1.659", "train_loss_0": "3.514", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.3287", "train_wps": "3936.7", "train_ups": "2.2", "train_wpb": "1793.1", "train_bsz": "5", "train_num_updates": "37400", "train_lr": "0.000492663", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17367"}
[2022-01-03 16:59:09,995][fairseq.trainer][INFO] - begin training epoch 936
[2022-01-03 16:59:09,996][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:59:23,779][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:59:24,269][valid][INFO] - {"epoch": 936, "valid_loss": "3.205", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "132.718", "valid_code_perplexity": "127.701", "valid_temp": "1.659", "valid_loss_0": "3.082", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.40584", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "37440", "valid_best_loss": "3.06"}
[2022-01-03 16:59:24,271][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 936 @ 37440 updates
[2022-01-03 16:59:24,272][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:59:28,197][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:59:28,227][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 936 @ 37440 updates, score 3.205) (writing took 3.95526310056448 seconds)
[2022-01-03 16:59:28,227][fairseq_cli.train][INFO] - end of epoch 936 (average epoch stats below)
[2022-01-03 16:59:28,240][train][INFO] - {"epoch": 936, "train_loss": "3.63", "train_ntokens": "1796.55", "train_nsentences": "4.95", "train_prob_perplexity": "137.718", "train_code_perplexity": "135.179", "train_temp": "1.659", "train_loss_0": "3.507", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.3291", "train_wps": "3930.4", "train_ups": "2.19", "train_wpb": "1796.5", "train_bsz": "5", "train_num_updates": "37440", "train_lr": "0.000492609", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "17386"}
[2022-01-03 16:59:28,298][fairseq.trainer][INFO] - begin training epoch 937
[2022-01-03 16:59:28,299][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 16:59:42,284][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 16:59:42,782][valid][INFO] - {"epoch": 937, "valid_loss": "3.626", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "133.889", "valid_code_perplexity": "129.092", "valid_temp": "1.658", "valid_loss_0": "3.502", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.34319", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "37480", "valid_best_loss": "3.06"}
[2022-01-03 16:59:42,784][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 937 @ 37480 updates
[2022-01-03 16:59:42,785][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:59:46,479][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 16:59:46,507][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 937 @ 37480 updates, score 3.626) (writing took 3.7226702496409416 seconds)
[2022-01-03 16:59:46,507][fairseq_cli.train][INFO] - end of epoch 937 (average epoch stats below)
[2022-01-03 16:59:46,520][train][INFO] - {"epoch": 937, "train_loss": "3.626", "train_ntokens": "1803.15", "train_nsentences": "4.95", "train_prob_perplexity": "137.578", "train_code_perplexity": "135.132", "train_temp": "1.658", "train_loss_0": "3.502", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33149", "train_wps": "3948.3", "train_ups": "2.19", "train_wpb": "1803.2", "train_bsz": "5", "train_num_updates": "37480", "train_lr": "0.000492554", "train_gnorm": "0.493", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "17404"}
[2022-01-03 16:59:46,571][fairseq.trainer][INFO] - begin training epoch 938
[2022-01-03 16:59:46,571][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:00:00,582][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:00:01,058][valid][INFO] - {"epoch": 938, "valid_loss": "3.701", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "133.235", "valid_code_perplexity": "127.457", "valid_temp": "1.658", "valid_loss_0": "3.577", "valid_loss_1": "0.114", "valid_loss_2": "0.011", "valid_accuracy": "0.33858", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "37520", "valid_best_loss": "3.06"}
[2022-01-03 17:00:01,060][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 938 @ 37520 updates
[2022-01-03 17:00:01,061][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:00:04,726][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:00:04,756][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 938 @ 37520 updates, score 3.701) (writing took 3.695264113135636 seconds)
[2022-01-03 17:00:04,756][fairseq_cli.train][INFO] - end of epoch 938 (average epoch stats below)
[2022-01-03 17:00:04,769][train][INFO] - {"epoch": 938, "train_loss": "3.642", "train_ntokens": "1795.12", "train_nsentences": "4.95", "train_prob_perplexity": "138.145", "train_code_perplexity": "135.734", "train_temp": "1.658", "train_loss_0": "3.518", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.328", "train_wps": "3937.6", "train_ups": "2.19", "train_wpb": "1795.1", "train_bsz": "5", "train_num_updates": "37520", "train_lr": "0.0004925", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "17422"}
[2022-01-03 17:00:04,850][fairseq.trainer][INFO] - begin training epoch 939
[2022-01-03 17:00:04,851][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:00:18,726][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:00:19,137][valid][INFO] - {"epoch": 939, "valid_loss": "3.043", "valid_ntokens": "680", "valid_nsentences": "2", "valid_prob_perplexity": "127.537", "valid_code_perplexity": "122.762", "valid_temp": "1.658", "valid_loss_0": "2.918", "valid_loss_1": "0.116", "valid_loss_2": "0.01", "valid_accuracy": "0.42647", "valid_wps": "0", "valid_wpb": "680", "valid_bsz": "2", "valid_num_updates": "37560", "valid_best_loss": "3.043"}
[2022-01-03 17:00:19,140][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 939 @ 37560 updates
[2022-01-03 17:00:19,141][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 17:00:22,981][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2022-01-03 17:00:31,152][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 939 @ 37560 updates, score 3.043) (writing took 12.01173909381032 seconds)
[2022-01-03 17:00:31,152][fairseq_cli.train][INFO] - end of epoch 939 (average epoch stats below)
[2022-01-03 17:00:31,167][train][INFO] - {"epoch": 939, "train_loss": "3.619", "train_ntokens": "1781.67", "train_nsentences": "4.95", "train_prob_perplexity": "138.292", "train_code_perplexity": "135.895", "train_temp": "1.658", "train_loss_0": "3.496", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.3333", "train_wps": "2701.2", "train_ups": "1.52", "train_wpb": "1781.7", "train_bsz": "5", "train_num_updates": "37560", "train_lr": "0.000492446", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17449"}
[2022-01-03 17:00:31,252][fairseq.trainer][INFO] - begin training epoch 940
[2022-01-03 17:00:31,253][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:00:44,917][train_inner][INFO] - {"epoch": 940, "update": 940.0, "loss": "3.618", "ntokens": "1792.84", "nsentences": "4.95", "prob_perplexity": "137.875", "code_perplexity": "135.41", "temp": "1.658", "loss_0": "3.495", "loss_1": "0.113", "loss_2": "0.01", "accuracy": "0.33236", "wps": "3613.4", "ups": "2.02", "wpb": "1792.8", "bsz": "5", "num_updates": "37600", "lr": "0.000492391", "gnorm": "0.505", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "17462"}
[2022-01-03 17:00:44,918][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:00:45,335][valid][INFO] - {"epoch": 940, "valid_loss": "3.275", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "131.397", "valid_code_perplexity": "127.041", "valid_temp": "1.657", "valid_loss_0": "3.15", "valid_loss_1": "0.115", "valid_loss_2": "0.009", "valid_accuracy": "0.38342", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "37600", "valid_best_loss": "3.043"}
[2022-01-03 17:00:45,339][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 940 @ 37600 updates
[2022-01-03 17:00:45,340][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:00:49,319][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:00:49,328][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 940 @ 37600 updates, score 3.275) (writing took 3.988651568070054 seconds)
[2022-01-03 17:00:49,328][fairseq_cli.train][INFO] - end of epoch 940 (average epoch stats below)
[2022-01-03 17:00:49,341][train][INFO] - {"epoch": 940, "train_loss": "3.576", "train_ntokens": "1787.67", "train_nsentences": "4.95", "train_prob_perplexity": "137.643", "train_code_perplexity": "135.108", "train_temp": "1.657", "train_loss_0": "3.452", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33994", "train_wps": "3937.3", "train_ups": "2.2", "train_wpb": "1787.7", "train_bsz": "5", "train_num_updates": "37600", "train_lr": "0.000492391", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17467"}
[2022-01-03 17:00:49,416][fairseq.trainer][INFO] - begin training epoch 941
[2022-01-03 17:00:49,416][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:01:03,244][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:01:03,661][valid][INFO] - {"epoch": 941, "valid_loss": "3.664", "valid_ntokens": "812", "valid_nsentences": "2", "valid_prob_perplexity": "139.094", "valid_code_perplexity": "136.585", "valid_temp": "1.657", "valid_loss_0": "3.543", "valid_loss_1": "0.113", "valid_loss_2": "0.009", "valid_accuracy": "0.3436", "valid_wps": "0", "valid_wpb": "812", "valid_bsz": "2", "valid_num_updates": "37640", "valid_best_loss": "3.043"}
[2022-01-03 17:01:03,665][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 941 @ 37640 updates
[2022-01-03 17:01:03,667][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:01:07,588][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:01:07,614][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 941 @ 37640 updates, score 3.664) (writing took 3.9483551559969783 seconds)
[2022-01-03 17:01:07,614][fairseq_cli.train][INFO] - end of epoch 941 (average epoch stats below)
[2022-01-03 17:01:07,627][train][INFO] - {"epoch": 941, "train_loss": "3.595", "train_ntokens": "1798.95", "train_nsentences": "4.95", "train_prob_perplexity": "138.492", "train_code_perplexity": "136.065", "train_temp": "1.657", "train_loss_0": "3.472", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33675", "train_wps": "3937.9", "train_ups": "2.19", "train_wpb": "1799", "train_bsz": "5", "train_num_updates": "37640", "train_lr": "0.000492337", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17485"}
[2022-01-03 17:01:07,692][fairseq.trainer][INFO] - begin training epoch 942
[2022-01-03 17:01:07,693][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:01:21,683][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:01:22,111][valid][INFO] - {"epoch": 942, "valid_loss": "3.729", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "133.249", "valid_code_perplexity": "128.707", "valid_temp": "1.657", "valid_loss_0": "3.605", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.32642", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "37680", "valid_best_loss": "3.043"}
[2022-01-03 17:01:22,116][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 942 @ 37680 updates
[2022-01-03 17:01:22,118][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:01:25,808][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:01:25,836][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 942 @ 37680 updates, score 3.729) (writing took 3.719801887869835 seconds)
[2022-01-03 17:01:25,837][fairseq_cli.train][INFO] - end of epoch 942 (average epoch stats below)
[2022-01-03 17:01:25,849][train][INFO] - {"epoch": 942, "train_loss": "3.616", "train_ntokens": "1787.03", "train_nsentences": "4.95", "train_prob_perplexity": "137.606", "train_code_perplexity": "135.132", "train_temp": "1.657", "train_loss_0": "3.493", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33354", "train_wps": "3925.4", "train_ups": "2.2", "train_wpb": "1787", "train_bsz": "5", "train_num_updates": "37680", "train_lr": "0.000492283", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "17503"}
[2022-01-03 17:01:25,928][fairseq.trainer][INFO] - begin training epoch 943
[2022-01-03 17:01:25,928][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:01:39,792][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:01:40,216][valid][INFO] - {"epoch": 943, "valid_loss": "3.638", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "134.488", "valid_code_perplexity": "128.946", "valid_temp": "1.656", "valid_loss_0": "3.515", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.31586", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "37720", "valid_best_loss": "3.043"}
[2022-01-03 17:01:40,220][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 943 @ 37720 updates
[2022-01-03 17:01:40,221][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:01:44,053][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:01:44,083][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 943 @ 37720 updates, score 3.638) (writing took 3.862987936474383 seconds)
[2022-01-03 17:01:44,084][fairseq_cli.train][INFO] - end of epoch 943 (average epoch stats below)
[2022-01-03 17:01:44,096][train][INFO] - {"epoch": 943, "train_loss": "3.623", "train_ntokens": "1800.45", "train_nsentences": "4.95", "train_prob_perplexity": "138.835", "train_code_perplexity": "136.295", "train_temp": "1.656", "train_loss_0": "3.5", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33301", "train_wps": "3949.6", "train_ups": "2.19", "train_wpb": "1800.5", "train_bsz": "5", "train_num_updates": "37720", "train_lr": "0.000492228", "train_gnorm": "0.497", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "17521"}
[2022-01-03 17:01:44,155][fairseq.trainer][INFO] - begin training epoch 944
[2022-01-03 17:01:44,155][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:01:57,951][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:01:58,356][valid][INFO] - {"epoch": 944, "valid_loss": "3.472", "valid_ntokens": "696", "valid_nsentences": "2", "valid_prob_perplexity": "132.071", "valid_code_perplexity": "127.29", "valid_temp": "1.656", "valid_loss_0": "3.349", "valid_loss_1": "0.114", "valid_loss_2": "0.008", "valid_accuracy": "0.35776", "valid_wps": "0", "valid_wpb": "696", "valid_bsz": "2", "valid_num_updates": "37760", "valid_best_loss": "3.043"}
[2022-01-03 17:01:58,359][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 944 @ 37760 updates
[2022-01-03 17:01:58,360][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:02:02,353][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:02:02,379][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 944 @ 37760 updates, score 3.472) (writing took 4.019991028122604 seconds)
[2022-01-03 17:02:02,380][fairseq_cli.train][INFO] - end of epoch 944 (average epoch stats below)
[2022-01-03 17:02:02,392][train][INFO] - {"epoch": 944, "train_loss": "3.617", "train_ntokens": "1806.45", "train_nsentences": "4.95", "train_prob_perplexity": "138.915", "train_code_perplexity": "136.459", "train_temp": "1.656", "train_loss_0": "3.495", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33322", "train_wps": "3952.1", "train_ups": "2.19", "train_wpb": "1806.5", "train_bsz": "5", "train_num_updates": "37760", "train_lr": "0.000492174", "train_gnorm": "0.513", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17540"}
[2022-01-03 17:02:02,455][fairseq.trainer][INFO] - begin training epoch 945
[2022-01-03 17:02:02,455][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:02:16,268][train_inner][INFO] - {"epoch": 945, "update": 945.0, "loss": "3.615", "ntokens": "1796.99", "nsentences": "4.95", "prob_perplexity": "138.523", "code_perplexity": "136.043", "temp": "1.656", "loss_0": "3.492", "loss_1": "0.113", "loss_2": "0.01", "accuracy": "0.33331", "wps": "3934.8", "ups": "2.19", "wpb": "1797", "bsz": "5", "num_updates": "37800", "lr": "0.00049212", "gnorm": "0.505", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "17554"}
[2022-01-03 17:02:16,269][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:02:16,761][valid][INFO] - {"epoch": 945, "valid_loss": "3.444", "valid_ntokens": "682", "valid_nsentences": "2", "valid_prob_perplexity": "135.097", "valid_code_perplexity": "130.994", "valid_temp": "1.656", "valid_loss_0": "3.322", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.37977", "valid_wps": "0", "valid_wpb": "682", "valid_bsz": "2", "valid_num_updates": "37800", "valid_best_loss": "3.043"}
[2022-01-03 17:02:16,763][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 945 @ 37800 updates
[2022-01-03 17:02:16,763][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:02:20,700][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:02:20,728][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 945 @ 37800 updates, score 3.444) (writing took 3.9653452914208174 seconds)
[2022-01-03 17:02:20,729][fairseq_cli.train][INFO] - end of epoch 945 (average epoch stats below)
[2022-01-03 17:02:20,741][train][INFO] - {"epoch": 945, "train_loss": "3.625", "train_ntokens": "1792.1", "train_nsentences": "4.95", "train_prob_perplexity": "138.767", "train_code_perplexity": "136.264", "train_temp": "1.656", "train_loss_0": "3.502", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33003", "train_wps": "3909.4", "train_ups": "2.18", "train_wpb": "1792.1", "train_bsz": "5", "train_num_updates": "37800", "train_lr": "0.00049212", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17558"}
[2022-01-03 17:02:20,817][fairseq.trainer][INFO] - begin training epoch 946
[2022-01-03 17:02:20,817][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:02:34,645][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:02:35,152][valid][INFO] - {"epoch": 946, "valid_loss": "3.745", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "135.675", "valid_code_perplexity": "130.848", "valid_temp": "1.655", "valid_loss_0": "3.622", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.29625", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "37840", "valid_best_loss": "3.043"}
[2022-01-03 17:02:35,154][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 946 @ 37840 updates
[2022-01-03 17:02:35,155][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:02:38,943][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:02:38,971][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 946 @ 37840 updates, score 3.745) (writing took 3.8171794367954135 seconds)
[2022-01-03 17:02:38,972][fairseq_cli.train][INFO] - end of epoch 946 (average epoch stats below)
[2022-01-03 17:02:38,985][train][INFO] - {"epoch": 946, "train_loss": "3.634", "train_ntokens": "1803.62", "train_nsentences": "4.95", "train_prob_perplexity": "138.505", "train_code_perplexity": "136.165", "train_temp": "1.655", "train_loss_0": "3.511", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.32808", "train_wps": "3957.3", "train_ups": "2.19", "train_wpb": "1803.6", "train_bsz": "5", "train_num_updates": "37840", "train_lr": "0.000492065", "train_gnorm": "0.521", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "17576"}
[2022-01-03 17:02:39,064][fairseq.trainer][INFO] - begin training epoch 947
[2022-01-03 17:02:39,064][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:02:53,001][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:02:53,414][valid][INFO] - {"epoch": 947, "valid_loss": "3.546", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "132.368", "valid_code_perplexity": "128.963", "valid_temp": "1.655", "valid_loss_0": "3.423", "valid_loss_1": "0.114", "valid_loss_2": "0.008", "valid_accuracy": "0.33596", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "37880", "valid_best_loss": "3.043"}
[2022-01-03 17:02:53,417][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 947 @ 37880 updates
[2022-01-03 17:02:53,417][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:02:57,194][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:02:57,222][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 947 @ 37880 updates, score 3.546) (writing took 3.8047144524753094 seconds)
[2022-01-03 17:02:57,222][fairseq_cli.train][INFO] - end of epoch 947 (average epoch stats below)
[2022-01-03 17:02:57,235][train][INFO] - {"epoch": 947, "train_loss": "3.615", "train_ntokens": "1788.72", "train_nsentences": "4.95", "train_prob_perplexity": "138.983", "train_code_perplexity": "136.298", "train_temp": "1.655", "train_loss_0": "3.492", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33441", "train_wps": "3923.2", "train_ups": "2.19", "train_wpb": "1788.7", "train_bsz": "5", "train_num_updates": "37880", "train_lr": "0.000492011", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "17595"}
[2022-01-03 17:02:57,295][fairseq.trainer][INFO] - begin training epoch 948
[2022-01-03 17:02:57,296][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:03:11,209][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:03:11,623][valid][INFO] - {"epoch": 948, "valid_loss": "3.422", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "132.457", "valid_code_perplexity": "128.55", "valid_temp": "1.655", "valid_loss_0": "3.297", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.35963", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "37920", "valid_best_loss": "3.043"}
[2022-01-03 17:03:11,626][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 948 @ 37920 updates
[2022-01-03 17:03:11,627][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:03:15,469][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:03:15,495][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 948 @ 37920 updates, score 3.422) (writing took 3.8687690598890185 seconds)
[2022-01-03 17:03:15,496][fairseq_cli.train][INFO] - end of epoch 948 (average epoch stats below)
[2022-01-03 17:03:15,509][train][INFO] - {"epoch": 948, "train_loss": "3.577", "train_ntokens": "1786", "train_nsentences": "4.95", "train_prob_perplexity": "138.783", "train_code_perplexity": "136.25", "train_temp": "1.655", "train_loss_0": "3.454", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33887", "train_wps": "3912.2", "train_ups": "2.19", "train_wpb": "1786", "train_bsz": "5", "train_num_updates": "37920", "train_lr": "0.000491957", "train_gnorm": "0.505", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17613"}
[2022-01-03 17:03:15,583][fairseq.trainer][INFO] - begin training epoch 949
[2022-01-03 17:03:15,584][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:03:29,314][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:03:29,716][valid][INFO] - {"epoch": 949, "valid_loss": "3.332", "valid_ntokens": "780", "valid_nsentences": "2", "valid_prob_perplexity": "132.624", "valid_code_perplexity": "128.125", "valid_temp": "1.654", "valid_loss_0": "3.21", "valid_loss_1": "0.114", "valid_loss_2": "0.008", "valid_accuracy": "0.3859", "valid_wps": "0", "valid_wpb": "780", "valid_bsz": "2", "valid_num_updates": "37960", "valid_best_loss": "3.043"}
[2022-01-03 17:03:29,719][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 949 @ 37960 updates
[2022-01-03 17:03:29,720][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:03:33,617][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:03:33,643][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 949 @ 37960 updates, score 3.332) (writing took 3.923609549179673 seconds)
[2022-01-03 17:03:33,643][fairseq_cli.train][INFO] - end of epoch 949 (average epoch stats below)
[2022-01-03 17:03:33,656][train][INFO] - {"epoch": 949, "train_loss": "3.615", "train_ntokens": "1801.08", "train_nsentences": "4.95", "train_prob_perplexity": "138.965", "train_code_perplexity": "136.379", "train_temp": "1.654", "train_loss_0": "3.491", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.33502", "train_wps": "3972.7", "train_ups": "2.21", "train_wpb": "1801.1", "train_bsz": "5", "train_num_updates": "37960", "train_lr": "0.000491902", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "17631"}
[2022-01-03 17:03:33,702][fairseq.trainer][INFO] - begin training epoch 950
[2022-01-03 17:03:33,703][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:03:47,592][train_inner][INFO] - {"epoch": 950, "update": 950.0, "loss": "3.615", "ntokens": "1794.6", "nsentences": "4.95", "prob_perplexity": "138.811", "code_perplexity": "136.276", "temp": "1.655", "loss_0": "3.491", "loss_1": "0.113", "loss_2": "0.01", "accuracy": "0.33369", "wps": "3930.7", "ups": "2.19", "wpb": "1794.6", "bsz": "5", "num_updates": "38000", "lr": "0.000491848", "gnorm": "0.511", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "17645"}
[2022-01-03 17:03:47,593][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:03:48,000][valid][INFO] - {"epoch": 950, "valid_loss": "3.468", "valid_ntokens": "702", "valid_nsentences": "2", "valid_prob_perplexity": "132.405", "valid_code_perplexity": "127.955", "valid_temp": "1.654", "valid_loss_0": "3.342", "valid_loss_1": "0.114", "valid_loss_2": "0.011", "valid_accuracy": "0.37607", "valid_wps": "0", "valid_wpb": "702", "valid_bsz": "2", "valid_num_updates": "38000", "valid_best_loss": "3.043"}
[2022-01-03 17:03:48,004][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 950 @ 38000 updates
[2022-01-03 17:03:48,005][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:03:51,907][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:03:51,934][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 950 @ 38000 updates, score 3.468) (writing took 3.93016448430717 seconds)
[2022-01-03 17:03:51,935][fairseq_cli.train][INFO] - end of epoch 950 (average epoch stats below)
[2022-01-03 17:03:51,948][train][INFO] - {"epoch": 950, "train_loss": "3.632", "train_ntokens": "1793.55", "train_nsentences": "4.95", "train_prob_perplexity": "138.82", "train_code_perplexity": "136.287", "train_temp": "1.654", "train_loss_0": "3.509", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33211", "train_wps": "3924.8", "train_ups": "2.19", "train_wpb": "1793.5", "train_bsz": "5", "train_num_updates": "38000", "train_lr": "0.000491848", "train_gnorm": "0.516", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "17649"}
[2022-01-03 17:03:52,017][fairseq.trainer][INFO] - begin training epoch 951
[2022-01-03 17:03:52,017][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:04:05,856][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:04:06,251][valid][INFO] - {"epoch": 951, "valid_loss": "3.544", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "135.845", "valid_code_perplexity": "132.024", "valid_temp": "1.654", "valid_loss_0": "3.421", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.35925", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "38040", "valid_best_loss": "3.043"}
[2022-01-03 17:04:06,254][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 951 @ 38040 updates
[2022-01-03 17:04:06,255][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:04:10,210][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:04:10,238][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 951 @ 38040 updates, score 3.544) (writing took 3.984397883526981 seconds)
[2022-01-03 17:04:10,239][fairseq_cli.train][INFO] - end of epoch 951 (average epoch stats below)
[2022-01-03 17:04:10,252][train][INFO] - {"epoch": 951, "train_loss": "3.648", "train_ntokens": "1795.55", "train_nsentences": "4.95", "train_prob_perplexity": "139.376", "train_code_perplexity": "136.906", "train_temp": "1.654", "train_loss_0": "3.524", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.32892", "train_wps": "3926.5", "train_ups": "2.19", "train_wpb": "1795.5", "train_bsz": "5", "train_num_updates": "38040", "train_lr": "0.000491793", "train_gnorm": "0.49", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "17668"}
[2022-01-03 17:04:10,330][fairseq.trainer][INFO] - begin training epoch 952
[2022-01-03 17:04:10,331][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:04:24,215][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:04:24,624][valid][INFO] - {"epoch": 952, "valid_loss": "3.639", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "137.714", "valid_code_perplexity": "134.371", "valid_temp": "1.653", "valid_loss_0": "3.516", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.31545", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "38080", "valid_best_loss": "3.043"}
[2022-01-03 17:04:24,627][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 952 @ 38080 updates
[2022-01-03 17:04:24,628][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:04:28,436][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:04:28,464][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 952 @ 38080 updates, score 3.639) (writing took 3.836334764957428 seconds)
[2022-01-03 17:04:28,465][fairseq_cli.train][INFO] - end of epoch 952 (average epoch stats below)
[2022-01-03 17:04:28,478][train][INFO] - {"epoch": 952, "train_loss": "3.625", "train_ntokens": "1794.2", "train_nsentences": "4.95", "train_prob_perplexity": "139.157", "train_code_perplexity": "136.529", "train_temp": "1.653", "train_loss_0": "3.501", "train_loss_1": "0.113", "train_loss_2": "0.011", "train_accuracy": "0.32988", "train_wps": "3940.5", "train_ups": "2.2", "train_wpb": "1794.2", "train_bsz": "5", "train_num_updates": "38080", "train_lr": "0.000491739", "train_gnorm": "0.497", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17686"}
[2022-01-03 17:04:28,555][fairseq.trainer][INFO] - begin training epoch 953
[2022-01-03 17:04:28,556][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:04:42,411][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:04:42,819][valid][INFO] - {"epoch": 953, "valid_loss": "3.484", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "136.296", "valid_code_perplexity": "130.831", "valid_temp": "1.653", "valid_loss_0": "3.36", "valid_loss_1": "0.114", "valid_loss_2": "0.011", "valid_accuracy": "0.34319", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "38120", "valid_best_loss": "3.043"}
[2022-01-03 17:04:42,822][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 953 @ 38120 updates
[2022-01-03 17:04:42,823][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:04:46,774][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:04:46,801][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 953 @ 38120 updates, score 3.484) (writing took 3.9786836868152022 seconds)
[2022-01-03 17:04:46,802][fairseq_cli.train][INFO] - end of epoch 953 (average epoch stats below)
[2022-01-03 17:04:46,814][train][INFO] - {"epoch": 953, "train_loss": "3.588", "train_ntokens": "1799.53", "train_nsentences": "4.95", "train_prob_perplexity": "139.928", "train_code_perplexity": "137.564", "train_temp": "1.653", "train_loss_0": "3.465", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33689", "train_wps": "3928.4", "train_ups": "2.18", "train_wpb": "1799.5", "train_bsz": "5", "train_num_updates": "38120", "train_lr": "0.000491685", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17704"}
[2022-01-03 17:04:46,865][fairseq.trainer][INFO] - begin training epoch 954
[2022-01-03 17:04:46,866][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:05:00,839][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:05:01,254][valid][INFO] - {"epoch": 954, "valid_loss": "3.449", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "133.034", "valid_code_perplexity": "128.851", "valid_temp": "1.653", "valid_loss_0": "3.325", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.35239", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "38160", "valid_best_loss": "3.043"}
[2022-01-03 17:05:01,258][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 954 @ 38160 updates
[2022-01-03 17:05:01,258][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:05:04,952][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:05:04,970][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 954 @ 38160 updates, score 3.449) (writing took 3.712629735469818 seconds)
[2022-01-03 17:05:04,971][fairseq_cli.train][INFO] - end of epoch 954 (average epoch stats below)
[2022-01-03 17:05:04,984][train][INFO] - {"epoch": 954, "train_loss": "3.616", "train_ntokens": "1773.67", "train_nsentences": "4.95", "train_prob_perplexity": "139.768", "train_code_perplexity": "137.179", "train_temp": "1.653", "train_loss_0": "3.493", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33237", "train_wps": "3907.4", "train_ups": "2.2", "train_wpb": "1773.7", "train_bsz": "5", "train_num_updates": "38160", "train_lr": "0.00049163", "train_gnorm": "0.511", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "17722"}
[2022-01-03 17:05:05,064][fairseq.trainer][INFO] - begin training epoch 955
[2022-01-03 17:05:05,065][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:05:18,961][train_inner][INFO] - {"epoch": 955, "update": 955.0, "loss": "3.622", "ntokens": "1792.57", "nsentences": "4.95", "prob_perplexity": "139.744", "code_perplexity": "137.246", "temp": "1.653", "loss_0": "3.499", "loss_1": "0.113", "loss_2": "0.01", "accuracy": "0.33207", "wps": "3924.4", "ups": "2.19", "wpb": "1792.6", "bsz": "5", "num_updates": "38200", "lr": "0.000491576", "gnorm": "0.504", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "17736"}
[2022-01-03 17:05:18,962][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:05:19,371][valid][INFO] - {"epoch": 955, "valid_loss": "3.416", "valid_ntokens": "710", "valid_nsentences": "2", "valid_prob_perplexity": "138.013", "valid_code_perplexity": "134.812", "valid_temp": "1.652", "valid_loss_0": "3.293", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.4", "valid_wps": "0", "valid_wpb": "710", "valid_bsz": "2", "valid_num_updates": "38200", "valid_best_loss": "3.043"}
[2022-01-03 17:05:19,375][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 955 @ 38200 updates
[2022-01-03 17:05:19,375][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:05:23,289][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:05:23,315][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 955 @ 38200 updates, score 3.416) (writing took 3.9403195874765515 seconds)
[2022-01-03 17:05:23,315][fairseq_cli.train][INFO] - end of epoch 955 (average epoch stats below)
[2022-01-03 17:05:23,328][train][INFO] - {"epoch": 955, "train_loss": "3.632", "train_ntokens": "1799.9", "train_nsentences": "4.95", "train_prob_perplexity": "140.491", "train_code_perplexity": "138.051", "train_temp": "1.652", "train_loss_0": "3.509", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33228", "train_wps": "3927.4", "train_ups": "2.18", "train_wpb": "1799.9", "train_bsz": "5", "train_num_updates": "38200", "train_lr": "0.000491576", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "17741"}
[2022-01-03 17:05:23,400][fairseq.trainer][INFO] - begin training epoch 956
[2022-01-03 17:05:23,401][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:05:37,240][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:05:37,654][valid][INFO] - {"epoch": 956, "valid_loss": "3.415", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "130.9", "valid_code_perplexity": "126.597", "valid_temp": "1.652", "valid_loss_0": "3.29", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.38674", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "38240", "valid_best_loss": "3.043"}
[2022-01-03 17:05:37,657][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 956 @ 38240 updates
[2022-01-03 17:05:37,658][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:05:41,591][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:05:41,620][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 956 @ 38240 updates, score 3.415) (writing took 3.9630615143105388 seconds)
[2022-01-03 17:05:41,621][fairseq_cli.train][INFO] - end of epoch 956 (average epoch stats below)
[2022-01-03 17:05:41,633][train][INFO] - {"epoch": 956, "train_loss": "3.605", "train_ntokens": "1794.15", "train_nsentences": "4.95", "train_prob_perplexity": "139.802", "train_code_perplexity": "137.281", "train_temp": "1.652", "train_loss_0": "3.482", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33616", "train_wps": "3923.3", "train_ups": "2.19", "train_wpb": "1794.2", "train_bsz": "5", "train_num_updates": "38240", "train_lr": "0.000491522", "train_gnorm": "0.514", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17759"}
[2022-01-03 17:05:41,714][fairseq.trainer][INFO] - begin training epoch 957
[2022-01-03 17:05:41,714][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:05:55,673][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:05:56,087][valid][INFO] - {"epoch": 957, "valid_loss": "3.318", "valid_ntokens": "808", "valid_nsentences": "2", "valid_prob_perplexity": "135.798", "valid_code_perplexity": "130.956", "valid_temp": "1.652", "valid_loss_0": "3.195", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.37624", "valid_wps": "0", "valid_wpb": "808", "valid_bsz": "2", "valid_num_updates": "38280", "valid_best_loss": "3.043"}
[2022-01-03 17:05:56,091][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 957 @ 38280 updates
[2022-01-03 17:05:56,092][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:05:59,854][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:05:59,883][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 957 @ 38280 updates, score 3.318) (writing took 3.792255498468876 seconds)
[2022-01-03 17:05:59,883][fairseq_cli.train][INFO] - end of epoch 957 (average epoch stats below)
[2022-01-03 17:05:59,896][train][INFO] - {"epoch": 957, "train_loss": "3.584", "train_ntokens": "1810.92", "train_nsentences": "4.95", "train_prob_perplexity": "140.247", "train_code_perplexity": "137.694", "train_temp": "1.652", "train_loss_0": "3.462", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33983", "train_wps": "3969.1", "train_ups": "2.19", "train_wpb": "1810.9", "train_bsz": "5", "train_num_updates": "38280", "train_lr": "0.000491467", "train_gnorm": "0.495", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17777"}
[2022-01-03 17:05:59,975][fairseq.trainer][INFO] - begin training epoch 958
[2022-01-03 17:05:59,975][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:06:13,907][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:06:14,315][valid][INFO] - {"epoch": 958, "valid_loss": "3.263", "valid_ntokens": "736", "valid_nsentences": "2", "valid_prob_perplexity": "129.397", "valid_code_perplexity": "125.646", "valid_temp": "1.651", "valid_loss_0": "3.138", "valid_loss_1": "0.115", "valid_loss_2": "0.009", "valid_accuracy": "0.375", "valid_wps": "0", "valid_wpb": "736", "valid_bsz": "2", "valid_num_updates": "38320", "valid_best_loss": "3.043"}
[2022-01-03 17:06:14,318][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 958 @ 38320 updates
[2022-01-03 17:06:14,319][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:06:18,103][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:06:18,130][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 958 @ 38320 updates, score 3.263) (writing took 3.8119610836729407 seconds)
[2022-01-03 17:06:18,130][fairseq_cli.train][INFO] - end of epoch 958 (average epoch stats below)
[2022-01-03 17:06:18,143][train][INFO] - {"epoch": 958, "train_loss": "3.624", "train_ntokens": "1800.08", "train_nsentences": "4.95", "train_prob_perplexity": "140.512", "train_code_perplexity": "137.88", "train_temp": "1.651", "train_loss_0": "3.501", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33269", "train_wps": "3948.8", "train_ups": "2.19", "train_wpb": "1800.1", "train_bsz": "5", "train_num_updates": "38320", "train_lr": "0.000491413", "train_gnorm": "0.497", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17796"}
[2022-01-03 17:06:18,219][fairseq.trainer][INFO] - begin training epoch 959
[2022-01-03 17:06:18,220][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:06:32,174][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:06:32,590][valid][INFO] - {"epoch": 959, "valid_loss": "3.631", "valid_ntokens": "686", "valid_nsentences": "2", "valid_prob_perplexity": "137.769", "valid_code_perplexity": "133.997", "valid_temp": "1.651", "valid_loss_0": "3.508", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.3207", "valid_wps": "0", "valid_wpb": "686", "valid_bsz": "2", "valid_num_updates": "38360", "valid_best_loss": "3.043"}
[2022-01-03 17:06:32,594][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 959 @ 38360 updates
[2022-01-03 17:06:32,594][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:06:36,367][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:06:36,392][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 959 @ 38360 updates, score 3.631) (writing took 3.7983568608760834 seconds)
[2022-01-03 17:06:36,392][fairseq_cli.train][INFO] - end of epoch 959 (average epoch stats below)
[2022-01-03 17:06:36,405][train][INFO] - {"epoch": 959, "train_loss": "3.569", "train_ntokens": "1792.83", "train_nsentences": "4.95", "train_prob_perplexity": "139.953", "train_code_perplexity": "137.368", "train_temp": "1.651", "train_loss_0": "3.446", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.34026", "train_wps": "3929.6", "train_ups": "2.19", "train_wpb": "1792.8", "train_bsz": "5", "train_num_updates": "38360", "train_lr": "0.000491359", "train_gnorm": "0.496", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "17814"}
[2022-01-03 17:06:36,480][fairseq.trainer][INFO] - begin training epoch 960
[2022-01-03 17:06:36,481][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:06:50,366][train_inner][INFO] - {"epoch": 960, "update": 960.0, "loss": "3.594", "ntokens": "1798.72", "nsentences": "4.95", "prob_perplexity": "140.149", "code_perplexity": "137.577", "temp": "1.651", "loss_0": "3.471", "loss_1": "0.113", "loss_2": "0.01", "accuracy": "0.33697", "wps": "3936.3", "ups": "2.19", "wpb": "1798.7", "bsz": "5", "num_updates": "38400", "lr": "0.000491304", "gnorm": "0.507", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "17828"}
[2022-01-03 17:06:50,367][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:06:50,772][valid][INFO] - {"epoch": 960, "valid_loss": "3.441", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "123.712", "valid_code_perplexity": "119.05", "valid_temp": "1.651", "valid_loss_0": "3.314", "valid_loss_1": "0.116", "valid_loss_2": "0.01", "valid_accuracy": "0.38154", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "38400", "valid_best_loss": "3.043"}
[2022-01-03 17:06:50,776][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 960 @ 38400 updates
[2022-01-03 17:06:50,777][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:06:54,588][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:06:54,614][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 960 @ 38400 updates, score 3.441) (writing took 3.838313969783485 seconds)
[2022-01-03 17:06:54,614][fairseq_cli.train][INFO] - end of epoch 960 (average epoch stats below)
[2022-01-03 17:06:54,627][train][INFO] - {"epoch": 960, "train_loss": "3.588", "train_ntokens": "1795.62", "train_nsentences": "4.95", "train_prob_perplexity": "140.231", "train_code_perplexity": "137.663", "train_temp": "1.651", "train_loss_0": "3.465", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.3359", "train_wps": "3944.4", "train_ups": "2.2", "train_wpb": "1795.6", "train_bsz": "5", "train_num_updates": "38400", "train_lr": "0.000491304", "train_gnorm": "0.534", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17832"}
[2022-01-03 17:06:54,686][fairseq.trainer][INFO] - begin training epoch 961
[2022-01-03 17:06:54,686][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:07:08,559][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:07:08,993][valid][INFO] - {"epoch": 961, "valid_loss": "3.229", "valid_ntokens": "800", "valid_nsentences": "2", "valid_prob_perplexity": "133.753", "valid_code_perplexity": "129.243", "valid_temp": "1.65", "valid_loss_0": "3.107", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.38875", "valid_wps": "0", "valid_wpb": "800", "valid_bsz": "2", "valid_num_updates": "38440", "valid_best_loss": "3.043"}
[2022-01-03 17:07:08,996][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 961 @ 38440 updates
[2022-01-03 17:07:08,997][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:07:12,944][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:07:12,971][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 961 @ 38440 updates, score 3.229) (writing took 3.9746868228539824 seconds)
[2022-01-03 17:07:12,971][fairseq_cli.train][INFO] - end of epoch 961 (average epoch stats below)
[2022-01-03 17:07:12,984][train][INFO] - {"epoch": 961, "train_loss": "3.602", "train_ntokens": "1778.7", "train_nsentences": "4.95", "train_prob_perplexity": "140.979", "train_code_perplexity": "138.275", "train_temp": "1.65", "train_loss_0": "3.479", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33591", "train_wps": "3878.6", "train_ups": "2.18", "train_wpb": "1778.7", "train_bsz": "5", "train_num_updates": "38440", "train_lr": "0.00049125", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17850"}
[2022-01-03 17:07:13,057][fairseq.trainer][INFO] - begin training epoch 962
[2022-01-03 17:07:13,058][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:07:26,855][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:07:27,240][valid][INFO] - {"epoch": 962, "valid_loss": "3.771", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "138.442", "valid_code_perplexity": "133.368", "valid_temp": "1.65", "valid_loss_0": "3.647", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.34921", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "38480", "valid_best_loss": "3.043"}
[2022-01-03 17:07:27,243][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 962 @ 38480 updates
[2022-01-03 17:07:27,244][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:07:31,185][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:07:31,213][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 962 @ 38480 updates, score 3.771) (writing took 3.9692754494026303 seconds)
[2022-01-03 17:07:31,213][fairseq_cli.train][INFO] - end of epoch 962 (average epoch stats below)
[2022-01-03 17:07:31,225][train][INFO] - {"epoch": 962, "train_loss": "3.608", "train_ntokens": "1793.38", "train_nsentences": "4.95", "train_prob_perplexity": "140.244", "train_code_perplexity": "137.559", "train_temp": "1.65", "train_loss_0": "3.485", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33229", "train_wps": "3935.3", "train_ups": "2.19", "train_wpb": "1793.4", "train_bsz": "5", "train_num_updates": "38480", "train_lr": "0.000491196", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "17869"}
[2022-01-03 17:07:31,298][fairseq.trainer][INFO] - begin training epoch 963
[2022-01-03 17:07:31,298][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:07:45,299][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:07:45,687][valid][INFO] - {"epoch": 963, "valid_loss": "3.472", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "136.623", "valid_code_perplexity": "132.036", "valid_temp": "1.65", "valid_loss_0": "3.351", "valid_loss_1": "0.113", "valid_loss_2": "0.008", "valid_accuracy": "0.33957", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "38520", "valid_best_loss": "3.043"}
[2022-01-03 17:07:45,692][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 963 @ 38520 updates
[2022-01-03 17:07:45,693][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:07:49,390][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:07:49,420][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 963 @ 38520 updates, score 3.472) (writing took 3.728649193421006 seconds)
[2022-01-03 17:07:49,421][fairseq_cli.train][INFO] - end of epoch 963 (average epoch stats below)
[2022-01-03 17:07:49,433][train][INFO] - {"epoch": 963, "train_loss": "3.572", "train_ntokens": "1780.35", "train_nsentences": "4.95", "train_prob_perplexity": "141.054", "train_code_perplexity": "138.519", "train_temp": "1.65", "train_loss_0": "3.45", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33933", "train_wps": "3913.9", "train_ups": "2.2", "train_wpb": "1780.3", "train_bsz": "5", "train_num_updates": "38520", "train_lr": "0.000491141", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "17887"}
[2022-01-03 17:07:49,508][fairseq.trainer][INFO] - begin training epoch 964
[2022-01-03 17:07:49,509][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:08:03,419][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:08:03,855][valid][INFO] - {"epoch": 964, "valid_loss": "3.67", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "133.093", "valid_code_perplexity": "128.469", "valid_temp": "1.649", "valid_loss_0": "3.545", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.32061", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "38560", "valid_best_loss": "3.043"}
[2022-01-03 17:08:03,859][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 964 @ 38560 updates
[2022-01-03 17:08:03,860][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:08:07,598][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:08:07,623][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 964 @ 38560 updates, score 3.67) (writing took 3.7641463046893477 seconds)
[2022-01-03 17:08:07,623][fairseq_cli.train][INFO] - end of epoch 964 (average epoch stats below)
[2022-01-03 17:08:07,636][train][INFO] - {"epoch": 964, "train_loss": "3.589", "train_ntokens": "1794.08", "train_nsentences": "4.95", "train_prob_perplexity": "140.735", "train_code_perplexity": "138.172", "train_temp": "1.649", "train_loss_0": "3.466", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.33984", "train_wps": "3945.1", "train_ups": "2.2", "train_wpb": "1794.1", "train_bsz": "5", "train_num_updates": "38560", "train_lr": "0.000491087", "train_gnorm": "0.506", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17905"}
[2022-01-03 17:08:07,691][fairseq.trainer][INFO] - begin training epoch 965
[2022-01-03 17:08:07,692][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:08:21,673][train_inner][INFO] - {"epoch": 965, "update": 965.0, "loss": "3.6", "ntokens": "1786.44", "nsentences": "4.95", "prob_perplexity": "140.868", "code_perplexity": "138.249", "temp": "1.65", "loss_0": "3.477", "loss_1": "0.113", "loss_2": "0.01", "accuracy": "0.33582", "wps": "3913.6", "ups": "2.19", "wpb": "1786.4", "bsz": "5", "num_updates": "38600", "lr": "0.000491033", "gnorm": "0.512", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "17919"}
[2022-01-03 17:08:21,674][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:08:22,084][valid][INFO] - {"epoch": 965, "valid_loss": "3.529", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "139.116", "valid_code_perplexity": "135.129", "valid_temp": "1.649", "valid_loss_0": "3.407", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.34286", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "38600", "valid_best_loss": "3.043"}
[2022-01-03 17:08:22,087][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 965 @ 38600 updates
[2022-01-03 17:08:22,088][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:08:25,871][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:08:25,900][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 965 @ 38600 updates, score 3.529) (writing took 3.8133186753839254 seconds)
[2022-01-03 17:08:25,901][fairseq_cli.train][INFO] - end of epoch 965 (average epoch stats below)
[2022-01-03 17:08:25,914][train][INFO] - {"epoch": 965, "train_loss": "3.629", "train_ntokens": "1785.7", "train_nsentences": "4.95", "train_prob_perplexity": "141.329", "train_code_perplexity": "138.719", "train_temp": "1.649", "train_loss_0": "3.506", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33173", "train_wps": "3910.7", "train_ups": "2.19", "train_wpb": "1785.7", "train_bsz": "5", "train_num_updates": "38600", "train_lr": "0.000491033", "train_gnorm": "0.521", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "17923"}
[2022-01-03 17:08:25,988][fairseq.trainer][INFO] - begin training epoch 966
[2022-01-03 17:08:25,988][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:08:39,945][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:08:40,351][valid][INFO] - {"epoch": 966, "valid_loss": "3.818", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "138.694", "valid_code_perplexity": "135.259", "valid_temp": "1.649", "valid_loss_0": "3.695", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.32105", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "38640", "valid_best_loss": "3.043"}
[2022-01-03 17:08:40,355][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 966 @ 38640 updates
[2022-01-03 17:08:40,356][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:08:44,134][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:08:44,162][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 966 @ 38640 updates, score 3.818) (writing took 3.807023188099265 seconds)
[2022-01-03 17:08:44,162][fairseq_cli.train][INFO] - end of epoch 966 (average epoch stats below)
[2022-01-03 17:08:44,175][train][INFO] - {"epoch": 966, "train_loss": "3.6", "train_ntokens": "1800.3", "train_nsentences": "4.95", "train_prob_perplexity": "140.543", "train_code_perplexity": "137.84", "train_temp": "1.649", "train_loss_0": "3.477", "train_loss_1": "0.113", "train_loss_2": "0.01", "train_accuracy": "0.3355", "train_wps": "3946.2", "train_ups": "2.19", "train_wpb": "1800.3", "train_bsz": "5", "train_num_updates": "38640", "train_lr": "0.000490978", "train_gnorm": "0.497", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "17942"}
[2022-01-03 17:08:44,233][fairseq.trainer][INFO] - begin training epoch 967
[2022-01-03 17:08:44,233][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:08:58,116][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:08:58,541][valid][INFO] - {"epoch": 967, "valid_loss": "3.486", "valid_ntokens": "706", "valid_nsentences": "2", "valid_prob_perplexity": "135.732", "valid_code_perplexity": "130.902", "valid_temp": "1.648", "valid_loss_0": "3.363", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.36827", "valid_wps": "0", "valid_wpb": "706", "valid_bsz": "2", "valid_num_updates": "38680", "valid_best_loss": "3.043"}
[2022-01-03 17:08:58,544][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 967 @ 38680 updates
[2022-01-03 17:08:58,545][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:09:02,464][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:09:02,492][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 967 @ 38680 updates, score 3.486) (writing took 3.9479752043262124 seconds)
[2022-01-03 17:09:02,493][fairseq_cli.train][INFO] - end of epoch 967 (average epoch stats below)
[2022-01-03 17:09:02,506][train][INFO] - {"epoch": 967, "train_loss": "3.59", "train_ntokens": "1788.17", "train_nsentences": "4.95", "train_prob_perplexity": "142.247", "train_code_perplexity": "139.532", "train_temp": "1.648", "train_loss_0": "3.467", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33537", "train_wps": "3904.7", "train_ups": "2.18", "train_wpb": "1788.2", "train_bsz": "5", "train_num_updates": "38680", "train_lr": "0.000490924", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "17960"}
[2022-01-03 17:09:02,577][fairseq.trainer][INFO] - begin training epoch 968
[2022-01-03 17:09:02,578][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:09:16,391][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:09:16,806][valid][INFO] - {"epoch": 968, "valid_loss": "3.218", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "137.635", "valid_code_perplexity": "131.052", "valid_temp": "1.648", "valid_loss_0": "3.095", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.40028", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "38720", "valid_best_loss": "3.043"}
[2022-01-03 17:09:16,809][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 968 @ 38720 updates
[2022-01-03 17:09:16,809][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:09:20,823][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:09:20,824][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 968 @ 38720 updates, score 3.218) (writing took 4.014892818406224 seconds)
[2022-01-03 17:09:20,824][fairseq_cli.train][INFO] - end of epoch 968 (average epoch stats below)
[2022-01-03 17:09:20,838][train][INFO] - {"epoch": 968, "train_loss": "3.622", "train_ntokens": "1806.7", "train_nsentences": "4.95", "train_prob_perplexity": "141.501", "train_code_perplexity": "138.765", "train_temp": "1.648", "train_loss_0": "3.499", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33251", "train_wps": "3945", "train_ups": "2.18", "train_wpb": "1806.7", "train_bsz": "5", "train_num_updates": "38720", "train_lr": "0.00049087", "train_gnorm": "0.513", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "17978"}
[2022-01-03 17:09:20,912][fairseq.trainer][INFO] - begin training epoch 969
[2022-01-03 17:09:20,913][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:09:34,839][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:09:35,243][valid][INFO] - {"epoch": 969, "valid_loss": "3.638", "valid_ntokens": "724", "valid_nsentences": "2", "valid_prob_perplexity": "137.363", "valid_code_perplexity": "132.181", "valid_temp": "1.648", "valid_loss_0": "3.516", "valid_loss_1": "0.113", "valid_loss_2": "0.009", "valid_accuracy": "0.35912", "valid_wps": "0", "valid_wpb": "724", "valid_bsz": "2", "valid_num_updates": "38760", "valid_best_loss": "3.043"}
[2022-01-03 17:09:35,245][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 969 @ 38760 updates
[2022-01-03 17:09:35,246][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:09:39,102][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:09:39,131][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 969 @ 38760 updates, score 3.638) (writing took 3.886015363968909 seconds)
[2022-01-03 17:09:39,132][fairseq_cli.train][INFO] - end of epoch 969 (average epoch stats below)
[2022-01-03 17:09:39,146][train][INFO] - {"epoch": 969, "train_loss": "3.561", "train_ntokens": "1792.55", "train_nsentences": "4.95", "train_prob_perplexity": "142.668", "train_code_perplexity": "139.987", "train_temp": "1.648", "train_loss_0": "3.438", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.34198", "train_wps": "3919.5", "train_ups": "2.19", "train_wpb": "1792.5", "train_bsz": "5", "train_num_updates": "38760", "train_lr": "0.000490815", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "17997"}
[2022-01-03 17:09:39,226][fairseq.trainer][INFO] - begin training epoch 970
[2022-01-03 17:09:39,227][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:09:53,112][train_inner][INFO] - {"epoch": 970, "update": 970.0, "loss": "3.597", "ntokens": "1796.31", "nsentences": "4.95", "prob_perplexity": "141.853", "code_perplexity": "139.141", "temp": "1.648", "loss_0": "3.474", "loss_1": "0.112", "loss_2": "0.01", "accuracy": "0.33562", "wps": "3929.5", "ups": "2.19", "wpb": "1796.3", "bsz": "5", "num_updates": "38800", "lr": "0.000490761", "gnorm": "0.507", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "18011"}
[2022-01-03 17:09:53,113][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:09:53,490][valid][INFO] - {"epoch": 970, "valid_loss": "3.577", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "141.079", "valid_code_perplexity": "135.662", "valid_temp": "1.647", "valid_loss_0": "3.453", "valid_loss_1": "0.112", "valid_loss_2": "0.011", "valid_accuracy": "0.35622", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "38800", "valid_best_loss": "3.043"}
[2022-01-03 17:09:53,494][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 970 @ 38800 updates
[2022-01-03 17:09:53,495][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:09:57,511][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:09:57,538][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 970 @ 38800 updates, score 3.577) (writing took 4.043642411008477 seconds)
[2022-01-03 17:09:57,538][fairseq_cli.train][INFO] - end of epoch 970 (average epoch stats below)
[2022-01-03 17:09:57,551][train][INFO] - {"epoch": 970, "train_loss": "3.612", "train_ntokens": "1793.8", "train_nsentences": "4.95", "train_prob_perplexity": "142.307", "train_code_perplexity": "139.582", "train_temp": "1.647", "train_loss_0": "3.49", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33274", "train_wps": "3901.2", "train_ups": "2.17", "train_wpb": "1793.8", "train_bsz": "5", "train_num_updates": "38800", "train_lr": "0.000490761", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "18015"}
[2022-01-03 17:09:57,590][fairseq.trainer][INFO] - begin training epoch 971
[2022-01-03 17:09:57,590][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:10:11,345][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:10:11,746][valid][INFO] - {"epoch": 971, "valid_loss": "3.707", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "136.15", "valid_code_perplexity": "131.856", "valid_temp": "1.647", "valid_loss_0": "3.584", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.34079", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "38840", "valid_best_loss": "3.043"}
[2022-01-03 17:10:11,750][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 971 @ 38840 updates
[2022-01-03 17:10:11,751][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:10:15,823][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:10:15,852][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 971 @ 38840 updates, score 3.707) (writing took 4.101671632379293 seconds)
[2022-01-03 17:10:15,852][fairseq_cli.train][INFO] - end of epoch 971 (average epoch stats below)
[2022-01-03 17:10:15,865][train][INFO] - {"epoch": 971, "train_loss": "3.582", "train_ntokens": "1786.28", "train_nsentences": "4.95", "train_prob_perplexity": "142.367", "train_code_perplexity": "139.974", "train_temp": "1.647", "train_loss_0": "3.459", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33949", "train_wps": "3904.1", "train_ups": "2.19", "train_wpb": "1786.3", "train_bsz": "5", "train_num_updates": "38840", "train_lr": "0.000490707", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "18033"}
[2022-01-03 17:10:15,946][fairseq.trainer][INFO] - begin training epoch 972
[2022-01-03 17:10:15,947][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:10:29,913][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:10:30,287][valid][INFO] - {"epoch": 972, "valid_loss": "3.248", "valid_ntokens": "768", "valid_nsentences": "2", "valid_prob_perplexity": "135.303", "valid_code_perplexity": "129.035", "valid_temp": "1.647", "valid_loss_0": "3.125", "valid_loss_1": "0.114", "valid_loss_2": "0.009", "valid_accuracy": "0.38672", "valid_wps": "0", "valid_wpb": "768", "valid_bsz": "2", "valid_num_updates": "38880", "valid_best_loss": "3.043"}
[2022-01-03 17:10:30,290][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 972 @ 38880 updates
[2022-01-03 17:10:30,291][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:10:34,028][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:10:34,057][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 972 @ 38880 updates, score 3.248) (writing took 3.7665274124592543 seconds)
[2022-01-03 17:10:34,057][fairseq_cli.train][INFO] - end of epoch 972 (average epoch stats below)
[2022-01-03 17:10:34,070][train][INFO] - {"epoch": 972, "train_loss": "3.606", "train_ntokens": "1775.7", "train_nsentences": "4.95", "train_prob_perplexity": "142.048", "train_code_perplexity": "139.286", "train_temp": "1.647", "train_loss_0": "3.484", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33704", "train_wps": "3904.3", "train_ups": "2.2", "train_wpb": "1775.7", "train_bsz": "5", "train_num_updates": "38880", "train_lr": "0.000490652", "train_gnorm": "0.493", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "18051"}
[2022-01-03 17:10:34,144][fairseq.trainer][INFO] - begin training epoch 973
[2022-01-03 17:10:34,145][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:10:48,010][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:10:48,499][valid][INFO] - {"epoch": 973, "valid_loss": "3.417", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "121.375", "valid_code_perplexity": "116.554", "valid_temp": "1.646", "valid_loss_0": "3.29", "valid_loss_1": "0.117", "valid_loss_2": "0.009", "valid_accuracy": "0.37805", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "38920", "valid_best_loss": "3.043"}
[2022-01-03 17:10:48,501][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 973 @ 38920 updates
[2022-01-03 17:10:48,502][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:10:52,287][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:10:52,314][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 973 @ 38920 updates, score 3.417) (writing took 3.812855397351086 seconds)
[2022-01-03 17:10:52,315][fairseq_cli.train][INFO] - end of epoch 973 (average epoch stats below)
[2022-01-03 17:10:52,327][train][INFO] - {"epoch": 973, "train_loss": "3.634", "train_ntokens": "1801.03", "train_nsentences": "4.95", "train_prob_perplexity": "142.617", "train_code_perplexity": "139.904", "train_temp": "1.646", "train_loss_0": "3.512", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33287", "train_wps": "3948.6", "train_ups": "2.19", "train_wpb": "1801", "train_bsz": "5", "train_num_updates": "38920", "train_lr": "0.000490598", "train_gnorm": "0.491", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "18070"}
[2022-01-03 17:10:52,383][fairseq.trainer][INFO] - begin training epoch 974
[2022-01-03 17:10:52,384][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:11:06,100][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:11:06,523][valid][INFO] - {"epoch": 974, "valid_loss": "3.354", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "140.861", "valid_code_perplexity": "134.644", "valid_temp": "1.646", "valid_loss_0": "3.233", "valid_loss_1": "0.113", "valid_loss_2": "0.009", "valid_accuracy": "0.3509", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "38960", "valid_best_loss": "3.043"}
[2022-01-03 17:11:06,527][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 974 @ 38960 updates
[2022-01-03 17:11:06,527][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:11:10,430][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:11:10,456][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 974 @ 38960 updates, score 3.354) (writing took 3.9295029109343886 seconds)
[2022-01-03 17:11:10,457][fairseq_cli.train][INFO] - end of epoch 974 (average epoch stats below)
[2022-01-03 17:11:10,470][train][INFO] - {"epoch": 974, "train_loss": "3.627", "train_ntokens": "1794.83", "train_nsentences": "4.95", "train_prob_perplexity": "142.908", "train_code_perplexity": "140.098", "train_temp": "1.646", "train_loss_0": "3.506", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33085", "train_wps": "3960.1", "train_ups": "2.21", "train_wpb": "1794.8", "train_bsz": "5", "train_num_updates": "38960", "train_lr": "0.000490543", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18088"}
[2022-01-03 17:11:10,543][fairseq.trainer][INFO] - begin training epoch 975
[2022-01-03 17:11:10,544][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:11:24,406][train_inner][INFO] - {"epoch": 975, "update": 975.0, "loss": "3.608", "ntokens": "1788.67", "nsentences": "4.95", "prob_perplexity": "142.475", "code_perplexity": "139.809", "temp": "1.646", "loss_0": "3.486", "loss_1": "0.112", "loss_2": "0.01", "accuracy": "0.33538", "wps": "3919", "ups": "2.19", "wpb": "1788.7", "bsz": "5", "num_updates": "39000", "lr": "0.000490489", "gnorm": "0.502", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "18102"}
[2022-01-03 17:11:24,407][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:11:24,818][valid][INFO] - {"epoch": 975, "valid_loss": "3.488", "valid_ntokens": "782", "valid_nsentences": "2", "valid_prob_perplexity": "129.025", "valid_code_perplexity": "123.915", "valid_temp": "1.646", "valid_loss_0": "3.363", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.3798", "valid_wps": "0", "valid_wpb": "782", "valid_bsz": "2", "valid_num_updates": "39000", "valid_best_loss": "3.043"}
[2022-01-03 17:11:24,821][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 975 @ 39000 updates
[2022-01-03 17:11:24,822][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:11:28,648][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:11:28,675][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 975 @ 39000 updates, score 3.488) (writing took 3.8537683468312025 seconds)
[2022-01-03 17:11:28,675][fairseq_cli.train][INFO] - end of epoch 975 (average epoch stats below)
[2022-01-03 17:11:28,688][train][INFO] - {"epoch": 975, "train_loss": "3.591", "train_ntokens": "1785.55", "train_nsentences": "4.95", "train_prob_perplexity": "142.436", "train_code_perplexity": "139.784", "train_temp": "1.646", "train_loss_0": "3.469", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33669", "train_wps": "3923.2", "train_ups": "2.2", "train_wpb": "1785.5", "train_bsz": "5", "train_num_updates": "39000", "train_lr": "0.000490489", "train_gnorm": "0.516", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "18106"}
[2022-01-03 17:11:28,759][fairseq.trainer][INFO] - begin training epoch 976
[2022-01-03 17:11:28,760][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:11:42,668][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:11:43,080][valid][INFO] - {"epoch": 976, "valid_loss": "3.707", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "140.364", "valid_code_perplexity": "135.779", "valid_temp": "1.645", "valid_loss_0": "3.586", "valid_loss_1": "0.113", "valid_loss_2": "0.008", "valid_accuracy": "0.3445", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "39040", "valid_best_loss": "3.043"}
[2022-01-03 17:11:43,084][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 976 @ 39040 updates
[2022-01-03 17:11:43,085][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:11:46,873][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:11:46,900][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 976 @ 39040 updates, score 3.707) (writing took 3.8159703593701124 seconds)
[2022-01-03 17:11:46,900][fairseq_cli.train][INFO] - end of epoch 976 (average epoch stats below)
[2022-01-03 17:11:46,913][train][INFO] - {"epoch": 976, "train_loss": "3.582", "train_ntokens": "1786.67", "train_nsentences": "4.95", "train_prob_perplexity": "142.558", "train_code_perplexity": "139.8", "train_temp": "1.646", "train_loss_0": "3.46", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33979", "train_wps": "3924.1", "train_ups": "2.2", "train_wpb": "1786.7", "train_bsz": "5", "train_num_updates": "39040", "train_lr": "0.000490435", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18124"}
[2022-01-03 17:11:46,975][fairseq.trainer][INFO] - begin training epoch 977
[2022-01-03 17:11:46,976][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:12:00,880][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:12:01,369][valid][INFO] - {"epoch": 977, "valid_loss": "3.861", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "138.644", "valid_code_perplexity": "131.928", "valid_temp": "1.645", "valid_loss_0": "3.738", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.30194", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "39080", "valid_best_loss": "3.043"}
[2022-01-03 17:12:01,371][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 977 @ 39080 updates
[2022-01-03 17:12:01,371][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:12:05,196][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:12:05,223][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 977 @ 39080 updates, score 3.861) (writing took 3.8520751167088747 seconds)
[2022-01-03 17:12:05,223][fairseq_cli.train][INFO] - end of epoch 977 (average epoch stats below)
[2022-01-03 17:12:05,236][train][INFO] - {"epoch": 977, "train_loss": "3.57", "train_ntokens": "1794.95", "train_nsentences": "4.95", "train_prob_perplexity": "143.355", "train_code_perplexity": "140.455", "train_temp": "1.645", "train_loss_0": "3.449", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.34065", "train_wps": "3921.2", "train_ups": "2.18", "train_wpb": "1795", "train_bsz": "5", "train_num_updates": "39080", "train_lr": "0.00049038", "train_gnorm": "0.488", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "18143"}
[2022-01-03 17:12:05,291][fairseq.trainer][INFO] - begin training epoch 978
[2022-01-03 17:12:05,292][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:12:19,238][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:12:19,646][valid][INFO] - {"epoch": 978, "valid_loss": "3.669", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "143.518", "valid_code_perplexity": "139.059", "valid_temp": "1.645", "valid_loss_0": "3.548", "valid_loss_1": "0.112", "valid_loss_2": "0.009", "valid_accuracy": "0.32718", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "39120", "valid_best_loss": "3.043"}
[2022-01-03 17:12:19,649][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 978 @ 39120 updates
[2022-01-03 17:12:19,650][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:12:23,441][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:12:23,469][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 978 @ 39120 updates, score 3.669) (writing took 3.819673783145845 seconds)
[2022-01-03 17:12:23,469][fairseq_cli.train][INFO] - end of epoch 978 (average epoch stats below)
[2022-01-03 17:12:23,482][train][INFO] - {"epoch": 978, "train_loss": "3.603", "train_ntokens": "1812.03", "train_nsentences": "4.95", "train_prob_perplexity": "143.232", "train_code_perplexity": "140.165", "train_temp": "1.645", "train_loss_0": "3.482", "train_loss_1": "0.112", "train_loss_2": "0.009", "train_accuracy": "0.33715", "train_wps": "3975.2", "train_ups": "2.19", "train_wpb": "1812", "train_bsz": "5", "train_num_updates": "39120", "train_lr": "0.000490326", "train_gnorm": "0.499", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "18161"}
[2022-01-03 17:12:23,560][fairseq.trainer][INFO] - begin training epoch 979
[2022-01-03 17:12:23,561][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:12:37,401][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:12:37,812][valid][INFO] - {"epoch": 979, "valid_loss": "3.518", "valid_ntokens": "738", "valid_nsentences": "2", "valid_prob_perplexity": "140.859", "valid_code_perplexity": "136.557", "valid_temp": "1.644", "valid_loss_0": "3.397", "valid_loss_1": "0.113", "valid_loss_2": "0.009", "valid_accuracy": "0.35908", "valid_wps": "0", "valid_wpb": "738", "valid_bsz": "2", "valid_num_updates": "39160", "valid_best_loss": "3.043"}
[2022-01-03 17:12:37,815][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 979 @ 39160 updates
[2022-01-03 17:12:37,816][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:12:41,777][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:12:41,804][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 979 @ 39160 updates, score 3.518) (writing took 3.989003569819033 seconds)
[2022-01-03 17:12:41,805][fairseq_cli.train][INFO] - end of epoch 979 (average epoch stats below)
[2022-01-03 17:12:41,818][train][INFO] - {"epoch": 979, "train_loss": "3.609", "train_ntokens": "1805.47", "train_nsentences": "4.95", "train_prob_perplexity": "143.509", "train_code_perplexity": "140.637", "train_temp": "1.645", "train_loss_0": "3.487", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33411", "train_wps": "3941.5", "train_ups": "2.18", "train_wpb": "1805.5", "train_bsz": "5", "train_num_updates": "39160", "train_lr": "0.000490272", "train_gnorm": "0.505", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "18179"}
[2022-01-03 17:12:41,893][fairseq.trainer][INFO] - begin training epoch 980
[2022-01-03 17:12:41,894][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:12:55,781][train_inner][INFO] - {"epoch": 980, "update": 980.0, "loss": "3.588", "ntokens": "1797.42", "nsentences": "4.95", "prob_perplexity": "143.071", "code_perplexity": "140.184", "temp": "1.645", "loss_0": "3.466", "loss_1": "0.112", "loss_2": "0.01", "accuracy": "0.33839", "wps": "3934.7", "ups": "2.19", "wpb": "1797.4", "bsz": "5", "num_updates": "39200", "lr": "0.000490217", "gnorm": "0.502", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "18193"}
[2022-01-03 17:12:55,782][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:12:56,169][valid][INFO] - {"epoch": 980, "valid_loss": "3.502", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "142.161", "valid_code_perplexity": "136.781", "valid_temp": "1.644", "valid_loss_0": "3.38", "valid_loss_1": "0.112", "valid_loss_2": "0.01", "valid_accuracy": "0.34582", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "39200", "valid_best_loss": "3.043"}
[2022-01-03 17:12:56,174][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 980 @ 39200 updates
[2022-01-03 17:12:56,176][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:13:00,143][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:13:00,172][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 980 @ 39200 updates, score 3.502) (writing took 3.9977817060425878 seconds)
[2022-01-03 17:13:00,173][fairseq_cli.train][INFO] - end of epoch 980 (average epoch stats below)
[2022-01-03 17:13:00,185][train][INFO] - {"epoch": 980, "train_loss": "3.574", "train_ntokens": "1788", "train_nsentences": "4.95", "train_prob_perplexity": "142.701", "train_code_perplexity": "139.864", "train_temp": "1.644", "train_loss_0": "3.452", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.3403", "train_wps": "3896.5", "train_ups": "2.18", "train_wpb": "1788", "train_bsz": "5", "train_num_updates": "39200", "train_lr": "0.000490217", "train_gnorm": "0.515", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18198"}
[2022-01-03 17:13:00,263][fairseq.trainer][INFO] - begin training epoch 981
[2022-01-03 17:13:00,264][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:13:14,153][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:13:14,680][valid][INFO] - {"epoch": 981, "valid_loss": "3.485", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "142.722", "valid_code_perplexity": "135.566", "valid_temp": "1.644", "valid_loss_0": "3.363", "valid_loss_1": "0.112", "valid_loss_2": "0.009", "valid_accuracy": "0.34908", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "39240", "valid_best_loss": "3.043"}
[2022-01-03 17:13:14,683][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 981 @ 39240 updates
[2022-01-03 17:13:14,684][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:13:18,349][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:13:18,378][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 981 @ 39240 updates, score 3.485) (writing took 3.695582065731287 seconds)
[2022-01-03 17:13:18,379][fairseq_cli.train][INFO] - end of epoch 981 (average epoch stats below)
[2022-01-03 17:13:18,392][train][INFO] - {"epoch": 981, "train_loss": "3.53", "train_ntokens": "1782.42", "train_nsentences": "4.95", "train_prob_perplexity": "144.265", "train_code_perplexity": "141.355", "train_temp": "1.644", "train_loss_0": "3.408", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.34634", "train_wps": "3918.8", "train_ups": "2.2", "train_wpb": "1782.4", "train_bsz": "5", "train_num_updates": "39240", "train_lr": "0.000490163", "train_gnorm": "0.493", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18216"}
[2022-01-03 17:13:18,480][fairseq.trainer][INFO] - begin training epoch 982
[2022-01-03 17:13:18,481][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:13:32,462][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:13:32,899][valid][INFO] - {"epoch": 982, "valid_loss": "3.423", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "129.718", "valid_code_perplexity": "124.812", "valid_temp": "1.643", "valid_loss_0": "3.298", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.34615", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "39280", "valid_best_loss": "3.043"}
[2022-01-03 17:13:32,903][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 982 @ 39280 updates
[2022-01-03 17:13:32,904][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:13:36,564][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:13:36,588][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 982 @ 39280 updates, score 3.423) (writing took 3.6846163542941213 seconds)
[2022-01-03 17:13:36,588][fairseq_cli.train][INFO] - end of epoch 982 (average epoch stats below)
[2022-01-03 17:13:36,603][train][INFO] - {"epoch": 982, "train_loss": "3.546", "train_ntokens": "1780.35", "train_nsentences": "4.95", "train_prob_perplexity": "144.094", "train_code_perplexity": "141.32", "train_temp": "1.644", "train_loss_0": "3.424", "train_loss_1": "0.112", "train_loss_2": "0.009", "train_accuracy": "0.34472", "train_wps": "3913.8", "train_ups": "2.2", "train_wpb": "1780.3", "train_bsz": "5", "train_num_updates": "39280", "train_lr": "0.000490109", "train_gnorm": "0.505", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "18234"}
[2022-01-03 17:13:36,671][fairseq.trainer][INFO] - begin training epoch 983
[2022-01-03 17:13:36,671][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:13:50,602][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:13:51,029][valid][INFO] - {"epoch": 983, "valid_loss": "3.581", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "141.783", "valid_code_perplexity": "136.475", "valid_temp": "1.643", "valid_loss_0": "3.459", "valid_loss_1": "0.112", "valid_loss_2": "0.01", "valid_accuracy": "0.33699", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "39320", "valid_best_loss": "3.043"}
[2022-01-03 17:13:51,033][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 983 @ 39320 updates
[2022-01-03 17:13:51,034][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:13:54,773][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:13:54,801][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 983 @ 39320 updates, score 3.581) (writing took 3.7678651800379157 seconds)
[2022-01-03 17:13:54,801][fairseq_cli.train][INFO] - end of epoch 983 (average epoch stats below)
[2022-01-03 17:13:54,814][train][INFO] - {"epoch": 983, "train_loss": "3.612", "train_ntokens": "1788.67", "train_nsentences": "4.95", "train_prob_perplexity": "144.56", "train_code_perplexity": "141.663", "train_temp": "1.643", "train_loss_0": "3.491", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33201", "train_wps": "3931.4", "train_ups": "2.2", "train_wpb": "1788.7", "train_bsz": "5", "train_num_updates": "39320", "train_lr": "0.000490054", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "18252"}
[2022-01-03 17:13:54,892][fairseq.trainer][INFO] - begin training epoch 984
[2022-01-03 17:13:54,893][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:14:08,676][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:14:09,091][valid][INFO] - {"epoch": 984, "valid_loss": "3.204", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "121.259", "valid_code_perplexity": "116.729", "valid_temp": "1.643", "valid_loss_0": "3.078", "valid_loss_1": "0.117", "valid_loss_2": "0.009", "valid_accuracy": "0.41029", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "39360", "valid_best_loss": "3.043"}
[2022-01-03 17:14:09,094][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 984 @ 39360 updates
[2022-01-03 17:14:09,095][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:14:13,016][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:14:13,043][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 984 @ 39360 updates, score 3.204) (writing took 3.9494654703885317 seconds)
[2022-01-03 17:14:13,044][fairseq_cli.train][INFO] - end of epoch 984 (average epoch stats below)
[2022-01-03 17:14:13,056][train][INFO] - {"epoch": 984, "train_loss": "3.607", "train_ntokens": "1798.2", "train_nsentences": "4.95", "train_prob_perplexity": "144.414", "train_code_perplexity": "141.494", "train_temp": "1.643", "train_loss_0": "3.485", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33344", "train_wps": "3945.7", "train_ups": "2.19", "train_wpb": "1798.2", "train_bsz": "5", "train_num_updates": "39360", "train_lr": "0.00049", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18270"}
[2022-01-03 17:14:13,131][fairseq.trainer][INFO] - begin training epoch 985
[2022-01-03 17:14:13,132][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:14:27,040][train_inner][INFO] - {"epoch": 985, "update": 985.0, "loss": "3.575", "ntokens": "1785.61", "nsentences": "4.95", "prob_perplexity": "144.51", "code_perplexity": "141.636", "temp": "1.643", "loss_0": "3.454", "loss_1": "0.112", "loss_2": "0.01", "accuracy": "0.3391", "wps": "3913.9", "ups": "2.19", "wpb": "1785.6", "bsz": "5", "num_updates": "39400", "lr": "0.000489946", "gnorm": "0.503", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "18284"}
[2022-01-03 17:14:27,040][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:14:27,458][valid][INFO] - {"epoch": 985, "valid_loss": "3.343", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "138.592", "valid_code_perplexity": "134.529", "valid_temp": "1.642", "valid_loss_0": "3.222", "valid_loss_1": "0.113", "valid_loss_2": "0.007", "valid_accuracy": "0.38175", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "39400", "valid_best_loss": "3.043"}
[2022-01-03 17:14:27,462][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 985 @ 39400 updates
[2022-01-03 17:14:27,463][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:14:31,216][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:14:31,223][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 985 @ 39400 updates, score 3.343) (writing took 3.760398980230093 seconds)
[2022-01-03 17:14:31,223][fairseq_cli.train][INFO] - end of epoch 985 (average epoch stats below)
[2022-01-03 17:14:31,236][train][INFO] - {"epoch": 985, "train_loss": "3.58", "train_ntokens": "1778.4", "train_nsentences": "4.95", "train_prob_perplexity": "145.219", "train_code_perplexity": "142.346", "train_temp": "1.643", "train_loss_0": "3.459", "train_loss_1": "0.112", "train_loss_2": "0.009", "train_accuracy": "0.33908", "train_wps": "3915.7", "train_ups": "2.2", "train_wpb": "1778.4", "train_bsz": "5", "train_num_updates": "39400", "train_lr": "0.000489946", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18289"}
[2022-01-03 17:14:31,298][fairseq.trainer][INFO] - begin training epoch 986
[2022-01-03 17:14:31,299][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:14:45,258][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:14:45,668][valid][INFO] - {"epoch": 986, "valid_loss": "3.536", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "141.856", "valid_code_perplexity": "137.467", "valid_temp": "1.642", "valid_loss_0": "3.415", "valid_loss_1": "0.112", "valid_loss_2": "0.008", "valid_accuracy": "0.36074", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "39440", "valid_best_loss": "3.043"}
[2022-01-03 17:14:45,671][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 986 @ 39440 updates
[2022-01-03 17:14:45,672][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:14:49,484][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:14:49,512][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 986 @ 39440 updates, score 3.536) (writing took 3.8408457916229963 seconds)
[2022-01-03 17:14:49,512][fairseq_cli.train][INFO] - end of epoch 986 (average epoch stats below)
[2022-01-03 17:14:49,525][train][INFO] - {"epoch": 986, "train_loss": "3.592", "train_ntokens": "1800.2", "train_nsentences": "4.95", "train_prob_perplexity": "145.65", "train_code_perplexity": "142.907", "train_temp": "1.642", "train_loss_0": "3.471", "train_loss_1": "0.111", "train_loss_2": "0.01", "train_accuracy": "0.33702", "train_wps": "3940.1", "train_ups": "2.19", "train_wpb": "1800.2", "train_bsz": "5", "train_num_updates": "39440", "train_lr": "0.000489891", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.4", "train_wall": "18307"}
[2022-01-03 17:14:49,606][fairseq.trainer][INFO] - begin training epoch 987
[2022-01-03 17:14:49,607][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:15:03,541][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:15:03,970][valid][INFO] - {"epoch": 987, "valid_loss": "3.337", "valid_ntokens": "748", "valid_nsentences": "2", "valid_prob_perplexity": "141.457", "valid_code_perplexity": "137.908", "valid_temp": "1.642", "valid_loss_0": "3.215", "valid_loss_1": "0.112", "valid_loss_2": "0.01", "valid_accuracy": "0.36765", "valid_wps": "0", "valid_wpb": "748", "valid_bsz": "2", "valid_num_updates": "39480", "valid_best_loss": "3.043"}
[2022-01-03 17:15:03,974][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 987 @ 39480 updates
[2022-01-03 17:15:03,975][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:15:07,705][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:15:07,734][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 987 @ 39480 updates, score 3.337) (writing took 3.759768237359822 seconds)
[2022-01-03 17:15:07,734][fairseq_cli.train][INFO] - end of epoch 987 (average epoch stats below)
[2022-01-03 17:15:07,748][train][INFO] - {"epoch": 987, "train_loss": "3.57", "train_ntokens": "1773.3", "train_nsentences": "4.95", "train_prob_perplexity": "144.947", "train_code_perplexity": "142.135", "train_temp": "1.642", "train_loss_0": "3.449", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33956", "train_wps": "3895.4", "train_ups": "2.2", "train_wpb": "1773.3", "train_bsz": "5", "train_num_updates": "39480", "train_lr": "0.000489837", "train_gnorm": "0.493", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.4", "train_wall": "18325"}
[2022-01-03 17:15:07,829][fairseq.trainer][INFO] - begin training epoch 988
[2022-01-03 17:15:07,829][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:15:21,754][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:15:22,169][valid][INFO] - {"epoch": 988, "valid_loss": "3.504", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "138.923", "valid_code_perplexity": "132.429", "valid_temp": "1.641", "valid_loss_0": "3.382", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.3719", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "39520", "valid_best_loss": "3.043"}
[2022-01-03 17:15:22,172][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 988 @ 39520 updates
[2022-01-03 17:15:22,173][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:15:25,926][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:15:25,954][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 988 @ 39520 updates, score 3.504) (writing took 3.781446694396436 seconds)
[2022-01-03 17:15:25,954][fairseq_cli.train][INFO] - end of epoch 988 (average epoch stats below)
[2022-01-03 17:15:25,967][train][INFO] - {"epoch": 988, "train_loss": "3.587", "train_ntokens": "1790.55", "train_nsentences": "4.95", "train_prob_perplexity": "145.362", "train_code_perplexity": "142.653", "train_temp": "1.642", "train_loss_0": "3.466", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33812", "train_wps": "3933.9", "train_ups": "2.2", "train_wpb": "1790.5", "train_bsz": "5", "train_num_updates": "39520", "train_lr": "0.000489783", "train_gnorm": "0.517", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18343"}
[2022-01-03 17:15:26,022][fairseq.trainer][INFO] - begin training epoch 989
[2022-01-03 17:15:26,023][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:15:39,877][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:15:40,291][valid][INFO] - {"epoch": 989, "valid_loss": "3.22", "valid_ntokens": "700", "valid_nsentences": "2", "valid_prob_perplexity": "140.313", "valid_code_perplexity": "134.859", "valid_temp": "1.641", "valid_loss_0": "3.098", "valid_loss_1": "0.113", "valid_loss_2": "0.009", "valid_accuracy": "0.38714", "valid_wps": "0", "valid_wpb": "700", "valid_bsz": "2", "valid_num_updates": "39560", "valid_best_loss": "3.043"}
[2022-01-03 17:15:40,295][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 989 @ 39560 updates
[2022-01-03 17:15:40,295][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:15:44,281][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:15:44,309][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 989 @ 39560 updates, score 3.22) (writing took 4.014620425179601 seconds)
[2022-01-03 17:15:44,310][fairseq_cli.train][INFO] - end of epoch 989 (average epoch stats below)
[2022-01-03 17:15:44,323][train][INFO] - {"epoch": 989, "train_loss": "3.592", "train_ntokens": "1789.4", "train_nsentences": "4.95", "train_prob_perplexity": "145.101", "train_code_perplexity": "142.313", "train_temp": "1.641", "train_loss_0": "3.47", "train_loss_1": "0.112", "train_loss_2": "0.01", "train_accuracy": "0.33666", "train_wps": "3902", "train_ups": "2.18", "train_wpb": "1789.4", "train_bsz": "5", "train_num_updates": "39560", "train_lr": "0.000489728", "train_gnorm": "0.511", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18362"}
[2022-01-03 17:15:44,396][fairseq.trainer][INFO] - begin training epoch 990
[2022-01-03 17:15:44,397][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:15:58,224][train_inner][INFO] - {"epoch": 990, "update": 990.0, "loss": "3.584", "ntokens": "1789.56", "nsentences": "4.95", "prob_perplexity": "145.515", "code_perplexity": "142.757", "temp": "1.642", "loss_0": "3.463", "loss_1": "0.111", "loss_2": "0.01", "accuracy": "0.33745", "wps": "3925.7", "ups": "2.19", "wpb": "1789.6", "bsz": "5", "num_updates": "39600", "lr": "0.000489674", "gnorm": "0.505", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "18376"}
[2022-01-03 17:15:58,225][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:15:58,633][valid][INFO] - {"epoch": 990, "valid_loss": "3.485", "valid_ntokens": "730", "valid_nsentences": "2", "valid_prob_perplexity": "144.105", "valid_code_perplexity": "138.064", "valid_temp": "1.641", "valid_loss_0": "3.365", "valid_loss_1": "0.112", "valid_loss_2": "0.009", "valid_accuracy": "0.36027", "valid_wps": "0", "valid_wpb": "730", "valid_bsz": "2", "valid_num_updates": "39600", "valid_best_loss": "3.043"}
[2022-01-03 17:15:58,635][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 990 @ 39600 updates
[2022-01-03 17:15:58,636][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:16:02,613][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:16:02,642][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 990 @ 39600 updates, score 3.485) (writing took 4.006367106921971 seconds)
[2022-01-03 17:16:02,642][fairseq_cli.train][INFO] - end of epoch 990 (average epoch stats below)
[2022-01-03 17:16:02,654][train][INFO] - {"epoch": 990, "train_loss": "3.58", "train_ntokens": "1794.35", "train_nsentences": "4.95", "train_prob_perplexity": "146.515", "train_code_perplexity": "143.776", "train_temp": "1.641", "train_loss_0": "3.459", "train_loss_1": "0.111", "train_loss_2": "0.01", "train_accuracy": "0.3359", "train_wps": "3918", "train_ups": "2.18", "train_wpb": "1794.3", "train_bsz": "5", "train_num_updates": "39600", "train_lr": "0.000489674", "train_gnorm": "0.505", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "18380"}
[2022-01-03 17:16:02,714][fairseq.trainer][INFO] - begin training epoch 991
[2022-01-03 17:16:02,715][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:16:16,570][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:16:17,048][valid][INFO] - {"epoch": 991, "valid_loss": "3.586", "valid_ntokens": "734", "valid_nsentences": "2", "valid_prob_perplexity": "140.529", "valid_code_perplexity": "134.872", "valid_temp": "1.64", "valid_loss_0": "3.465", "valid_loss_1": "0.113", "valid_loss_2": "0.008", "valid_accuracy": "0.35831", "valid_wps": "0", "valid_wpb": "734", "valid_bsz": "2", "valid_num_updates": "39640", "valid_best_loss": "3.043"}
[2022-01-03 17:16:17,050][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 991 @ 39640 updates
[2022-01-03 17:16:17,050][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:16:20,963][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:16:20,989][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 991 @ 39640 updates, score 3.586) (writing took 3.9395365696400404 seconds)
[2022-01-03 17:16:20,990][fairseq_cli.train][INFO] - end of epoch 991 (average epoch stats below)
[2022-01-03 17:16:21,003][train][INFO] - {"epoch": 991, "train_loss": "3.574", "train_ntokens": "1800.33", "train_nsentences": "4.95", "train_prob_perplexity": "146.531", "train_code_perplexity": "143.77", "train_temp": "1.641", "train_loss_0": "3.454", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33924", "train_wps": "3927.5", "train_ups": "2.18", "train_wpb": "1800.3", "train_bsz": "5", "train_num_updates": "39640", "train_lr": "0.00048962", "train_gnorm": "0.492", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18398"}
[2022-01-03 17:16:21,042][fairseq.trainer][INFO] - begin training epoch 992
[2022-01-03 17:16:21,043][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:16:34,953][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:16:35,378][valid][INFO] - {"epoch": 992, "valid_loss": "3.212", "valid_ntokens": "692", "valid_nsentences": "2", "valid_prob_perplexity": "127.804", "valid_code_perplexity": "121.078", "valid_temp": "1.64", "valid_loss_0": "3.087", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.40462", "valid_wps": "0", "valid_wpb": "692", "valid_bsz": "2", "valid_num_updates": "39680", "valid_best_loss": "3.043"}
[2022-01-03 17:16:35,382][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 992 @ 39680 updates
[2022-01-03 17:16:35,383][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:16:39,148][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:16:39,175][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 992 @ 39680 updates, score 3.212) (writing took 3.7932859556749463 seconds)
[2022-01-03 17:16:39,176][fairseq_cli.train][INFO] - end of epoch 992 (average epoch stats below)
[2022-01-03 17:16:39,189][train][INFO] - {"epoch": 992, "train_loss": "3.576", "train_ntokens": "1795.7", "train_nsentences": "4.95", "train_prob_perplexity": "146.791", "train_code_perplexity": "143.993", "train_temp": "1.64", "train_loss_0": "3.455", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34056", "train_wps": "3952.5", "train_ups": "2.2", "train_wpb": "1795.7", "train_bsz": "5", "train_num_updates": "39680", "train_lr": "0.000489565", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18417"}
[2022-01-03 17:16:39,271][fairseq.trainer][INFO] - begin training epoch 993
[2022-01-03 17:16:39,272][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:16:53,174][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:16:53,677][valid][INFO] - {"epoch": 993, "valid_loss": "3.608", "valid_ntokens": "770", "valid_nsentences": "2", "valid_prob_perplexity": "144.441", "valid_code_perplexity": "139.769", "valid_temp": "1.64", "valid_loss_0": "3.486", "valid_loss_1": "0.112", "valid_loss_2": "0.01", "valid_accuracy": "0.32338", "valid_wps": "0", "valid_wpb": "770", "valid_bsz": "2", "valid_num_updates": "39720", "valid_best_loss": "3.043"}
[2022-01-03 17:16:53,679][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 993 @ 39720 updates
[2022-01-03 17:16:53,680][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:16:57,442][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:16:57,469][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 993 @ 39720 updates, score 3.608) (writing took 3.790507957339287 seconds)
[2022-01-03 17:16:57,470][fairseq_cli.train][INFO] - end of epoch 993 (average epoch stats below)
[2022-01-03 17:16:57,483][train][INFO] - {"epoch": 993, "train_loss": "3.58", "train_ntokens": "1781.3", "train_nsentences": "4.95", "train_prob_perplexity": "146.044", "train_code_perplexity": "143.083", "train_temp": "1.64", "train_loss_0": "3.459", "train_loss_1": "0.111", "train_loss_2": "0.01", "train_accuracy": "0.33954", "train_wps": "3897.5", "train_ups": "2.19", "train_wpb": "1781.3", "train_bsz": "5", "train_num_updates": "39720", "train_lr": "0.000489511", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18435"}
[2022-01-03 17:16:57,554][fairseq.trainer][INFO] - begin training epoch 994
[2022-01-03 17:16:57,555][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:17:11,412][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:17:11,844][valid][INFO] - {"epoch": 994, "valid_loss": "3.43", "valid_ntokens": "754", "valid_nsentences": "2", "valid_prob_perplexity": "126.05", "valid_code_perplexity": "119.629", "valid_temp": "1.639", "valid_loss_0": "3.305", "valid_loss_1": "0.116", "valid_loss_2": "0.01", "valid_accuracy": "0.35809", "valid_wps": "0", "valid_wpb": "754", "valid_bsz": "2", "valid_num_updates": "39760", "valid_best_loss": "3.043"}
[2022-01-03 17:17:11,847][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 994 @ 39760 updates
[2022-01-03 17:17:11,848][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:17:15,793][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:17:15,816][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 994 @ 39760 updates, score 3.43) (writing took 3.9691934203729033 seconds)
[2022-01-03 17:17:15,817][fairseq_cli.train][INFO] - end of epoch 994 (average epoch stats below)
[2022-01-03 17:17:15,830][train][INFO] - {"epoch": 994, "train_loss": "3.601", "train_ntokens": "1804.7", "train_nsentences": "4.95", "train_prob_perplexity": "146.136", "train_code_perplexity": "143.472", "train_temp": "1.64", "train_loss_0": "3.48", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33461", "train_wps": "3937.3", "train_ups": "2.18", "train_wpb": "1804.7", "train_bsz": "5", "train_num_updates": "39760", "train_lr": "0.000489457", "train_gnorm": "0.49", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "18453"}
[2022-01-03 17:17:15,901][fairseq.trainer][INFO] - begin training epoch 995
[2022-01-03 17:17:15,902][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:17:29,917][train_inner][INFO] - {"epoch": 995, "update": 995.0, "loss": "3.575", "ntokens": "1792.72", "nsentences": "4.95", "prob_perplexity": "146.396", "code_perplexity": "143.61", "temp": "1.64", "loss_0": "3.454", "loss_1": "0.111", "loss_2": "0.009", "accuracy": "0.33942", "wps": "3910.8", "ups": "2.18", "wpb": "1792.7", "bsz": "5", "num_updates": "39800", "lr": "0.000489402", "gnorm": "0.5", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "18467"}
[2022-01-03 17:17:29,917][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:17:30,326][valid][INFO] - {"epoch": 995, "valid_loss": "3.364", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "145.174", "valid_code_perplexity": "141.739", "valid_temp": "1.639", "valid_loss_0": "3.244", "valid_loss_1": "0.112", "valid_loss_2": "0.009", "valid_accuracy": "0.38168", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "39800", "valid_best_loss": "3.043"}
[2022-01-03 17:17:30,329][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 995 @ 39800 updates
[2022-01-03 17:17:30,330][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:17:33,986][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:17:34,014][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 995 @ 39800 updates, score 3.364) (writing took 3.6846256349235773 seconds)
[2022-01-03 17:17:34,014][fairseq_cli.train][INFO] - end of epoch 995 (average epoch stats below)
[2022-01-03 17:17:34,027][train][INFO] - {"epoch": 995, "train_loss": "3.543", "train_ntokens": "1781.58", "train_nsentences": "4.95", "train_prob_perplexity": "146.476", "train_code_perplexity": "143.729", "train_temp": "1.639", "train_loss_0": "3.422", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34318", "train_wps": "3918.9", "train_ups": "2.2", "train_wpb": "1781.6", "train_bsz": "5", "train_num_updates": "39800", "train_lr": "0.000489402", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "18471"}
[2022-01-03 17:17:34,101][fairseq.trainer][INFO] - begin training epoch 996
[2022-01-03 17:17:34,102][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:17:47,982][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:17:48,390][valid][INFO] - {"epoch": 996, "valid_loss": "3.3", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "137.407", "valid_code_perplexity": "131.728", "valid_temp": "1.639", "valid_loss_0": "3.178", "valid_loss_1": "0.113", "valid_loss_2": "0.008", "valid_accuracy": "0.40503", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "39840", "valid_best_loss": "3.043"}
[2022-01-03 17:17:48,393][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 996 @ 39840 updates
[2022-01-03 17:17:48,394][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:17:52,221][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:17:52,249][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 996 @ 39840 updates, score 3.3) (writing took 3.855727380141616 seconds)
[2022-01-03 17:17:52,249][fairseq_cli.train][INFO] - end of epoch 996 (average epoch stats below)
[2022-01-03 17:17:52,262][train][INFO] - {"epoch": 996, "train_loss": "3.566", "train_ntokens": "1796.22", "train_nsentences": "4.95", "train_prob_perplexity": "146.546", "train_code_perplexity": "143.701", "train_temp": "1.639", "train_loss_0": "3.445", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33943", "train_wps": "3943", "train_ups": "2.2", "train_wpb": "1796.2", "train_bsz": "5", "train_num_updates": "39840", "train_lr": "0.000489348", "train_gnorm": "0.5", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18490"}
[2022-01-03 17:17:52,316][fairseq.trainer][INFO] - begin training epoch 997
[2022-01-03 17:17:52,316][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:18:06,188][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:18:06,618][valid][INFO] - {"epoch": 997, "valid_loss": "3.279", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "147.234", "valid_code_perplexity": "142.911", "valid_temp": "1.638", "valid_loss_0": "3.159", "valid_loss_1": "0.111", "valid_loss_2": "0.009", "valid_accuracy": "0.3899", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "39880", "valid_best_loss": "3.043"}
[2022-01-03 17:18:06,623][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 997 @ 39880 updates
[2022-01-03 17:18:06,624][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:18:10,435][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:18:10,443][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 997 @ 39880 updates, score 3.279) (writing took 3.8202991103753448 seconds)
[2022-01-03 17:18:10,444][fairseq_cli.train][INFO] - end of epoch 997 (average epoch stats below)
[2022-01-03 17:18:10,457][train][INFO] - {"epoch": 997, "train_loss": "3.587", "train_ntokens": "1815.75", "train_nsentences": "4.95", "train_prob_perplexity": "146.44", "train_code_perplexity": "143.759", "train_temp": "1.639", "train_loss_0": "3.467", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33632", "train_wps": "3994.7", "train_ups": "2.2", "train_wpb": "1815.8", "train_bsz": "5", "train_num_updates": "39880", "train_lr": "0.000489293", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18508"}
[2022-01-03 17:18:10,549][fairseq.trainer][INFO] - begin training epoch 998
[2022-01-03 17:18:10,550][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:18:24,502][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:18:24,906][valid][INFO] - {"epoch": 998, "valid_loss": "3.304", "valid_ntokens": "722", "valid_nsentences": "2", "valid_prob_perplexity": "133.916", "valid_code_perplexity": "127.299", "valid_temp": "1.638", "valid_loss_0": "3.181", "valid_loss_1": "0.114", "valid_loss_2": "0.008", "valid_accuracy": "0.38643", "valid_wps": "0", "valid_wpb": "722", "valid_bsz": "2", "valid_num_updates": "39920", "valid_best_loss": "3.043"}
[2022-01-03 17:18:24,909][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 998 @ 39920 updates
[2022-01-03 17:18:24,909][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:18:28,678][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:18:28,706][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 998 @ 39920 updates, score 3.304) (writing took 3.7977035297080874 seconds)
[2022-01-03 17:18:28,707][fairseq_cli.train][INFO] - end of epoch 998 (average epoch stats below)
[2022-01-03 17:18:28,720][train][INFO] - {"epoch": 998, "train_loss": "3.556", "train_ntokens": "1795.92", "train_nsentences": "4.95", "train_prob_perplexity": "147.327", "train_code_perplexity": "144.59", "train_temp": "1.638", "train_loss_0": "3.436", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34314", "train_wps": "3936.4", "train_ups": "2.19", "train_wpb": "1795.9", "train_bsz": "5", "train_num_updates": "39920", "train_lr": "0.000489239", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "18526"}
[2022-01-03 17:18:28,801][fairseq.trainer][INFO] - begin training epoch 999
[2022-01-03 17:18:28,802][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:18:42,634][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:18:43,044][valid][INFO] - {"epoch": 999, "valid_loss": "3.668", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "142.608", "valid_code_perplexity": "138.687", "valid_temp": "1.638", "valid_loss_0": "3.546", "valid_loss_1": "0.112", "valid_loss_2": "0.01", "valid_accuracy": "0.37399", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "39960", "valid_best_loss": "3.043"}
[2022-01-03 17:18:43,048][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 999 @ 39960 updates
[2022-01-03 17:18:43,048][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:18:46,999][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:18:47,027][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 999 @ 39960 updates, score 3.668) (writing took 3.9796198401600122 seconds)
[2022-01-03 17:18:47,028][fairseq_cli.train][INFO] - end of epoch 999 (average epoch stats below)
[2022-01-03 17:18:47,041][train][INFO] - {"epoch": 999, "train_loss": "3.566", "train_ntokens": "1765.53", "train_nsentences": "4.95", "train_prob_perplexity": "147.309", "train_code_perplexity": "144.584", "train_temp": "1.638", "train_loss_0": "3.446", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.3433", "train_wps": "3857.5", "train_ups": "2.18", "train_wpb": "1765.5", "train_bsz": "5", "train_num_updates": "39960", "train_lr": "0.000489185", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.4", "train_wall": "18544"}
[2022-01-03 17:18:47,120][fairseq.trainer][INFO] - begin training epoch 1000
[2022-01-03 17:18:47,121][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:19:01,225][train_inner][INFO] - {"epoch": 1000, "update": 1000.0, "loss": "3.572", "ntokens": "1791.59", "nsentences": "4.95", "prob_perplexity": "147.001", "code_perplexity": "144.252", "temp": "1.638", "loss_0": "3.452", "loss_1": "0.111", "loss_2": "0.009", "accuracy": "0.3398", "wps": "3924.8", "ups": "2.19", "wpb": "1791.6", "bsz": "5", "num_updates": "40000", "lr": "0.00048913", "gnorm": "0.503", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "18559"}
[2022-01-03 17:19:01,226][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:19:01,725][valid][INFO] - {"epoch": 1000, "valid_loss": "3.669", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "140.71", "valid_code_perplexity": "133.1", "valid_temp": "1.637", "valid_loss_0": "3.547", "valid_loss_1": "0.113", "valid_loss_2": "0.009", "valid_accuracy": "0.31746", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "40000", "valid_best_loss": "3.043"}
[2022-01-03 17:19:01,727][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1000 @ 40000 updates
[2022-01-03 17:19:01,728][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:19:05,616][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:19:05,641][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1000 @ 40000 updates, score 3.669) (writing took 3.9137894455343485 seconds)
[2022-01-03 17:19:05,641][fairseq_cli.train][INFO] - end of epoch 1000 (average epoch stats below)
[2022-01-03 17:19:05,654][train][INFO] - {"epoch": 1000, "train_loss": "3.585", "train_ntokens": "1784.53", "train_nsentences": "4.95", "train_prob_perplexity": "147.382", "train_code_perplexity": "144.625", "train_temp": "1.638", "train_loss_0": "3.465", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33687", "train_wps": "3837.6", "train_ups": "2.15", "train_wpb": "1784.5", "train_bsz": "5", "train_num_updates": "40000", "train_lr": "0.00048913", "train_gnorm": "0.497", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "18563"}
[2022-01-03 17:19:05,702][fairseq.trainer][INFO] - begin training epoch 1001
[2022-01-03 17:19:05,703][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:19:19,555][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:19:20,050][valid][INFO] - {"epoch": 1001, "valid_loss": "3.367", "valid_ntokens": "684", "valid_nsentences": "2", "valid_prob_perplexity": "138.753", "valid_code_perplexity": "135.048", "valid_temp": "1.637", "valid_loss_0": "3.244", "valid_loss_1": "0.113", "valid_loss_2": "0.01", "valid_accuracy": "0.39035", "valid_wps": "0", "valid_wpb": "684", "valid_bsz": "2", "valid_num_updates": "40040", "valid_best_loss": "3.043"}
[2022-01-03 17:19:20,052][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1001 @ 40040 updates
[2022-01-03 17:19:20,052][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:19:23,920][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:19:23,946][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1001 @ 40040 updates, score 3.367) (writing took 3.894085959531367 seconds)
[2022-01-03 17:19:23,946][fairseq_cli.train][INFO] - end of epoch 1001 (average epoch stats below)
[2022-01-03 17:19:23,959][train][INFO] - {"epoch": 1001, "train_loss": "3.562", "train_ntokens": "1790.62", "train_nsentences": "4.95", "train_prob_perplexity": "146.42", "train_code_perplexity": "143.73", "train_temp": "1.637", "train_loss_0": "3.442", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34138", "train_wps": "3915.6", "train_ups": "2.19", "train_wpb": "1790.6", "train_bsz": "5", "train_num_updates": "40040", "train_lr": "0.000489076", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.8", "train_wall": "18581"}
[2022-01-03 17:19:24,015][fairseq.trainer][INFO] - begin training epoch 1002
[2022-01-03 17:19:24,016][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:19:37,748][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:19:38,161][valid][INFO] - {"epoch": 1002, "valid_loss": "3.491", "valid_ntokens": "744", "valid_nsentences": "2", "valid_prob_perplexity": "139.6", "valid_code_perplexity": "134.769", "valid_temp": "1.637", "valid_loss_0": "3.369", "valid_loss_1": "0.113", "valid_loss_2": "0.009", "valid_accuracy": "0.35753", "valid_wps": "0", "valid_wpb": "744", "valid_bsz": "2", "valid_num_updates": "40080", "valid_best_loss": "3.043"}
[2022-01-03 17:19:38,163][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1002 @ 40080 updates
[2022-01-03 17:19:38,164][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:19:42,069][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:19:42,097][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1002 @ 40080 updates, score 3.491) (writing took 3.9338336503133178 seconds)
[2022-01-03 17:19:42,097][fairseq_cli.train][INFO] - end of epoch 1002 (average epoch stats below)
[2022-01-03 17:19:42,110][train][INFO] - {"epoch": 1002, "train_loss": "3.579", "train_ntokens": "1799.05", "train_nsentences": "4.95", "train_prob_perplexity": "147.793", "train_code_perplexity": "145.069", "train_temp": "1.637", "train_loss_0": "3.459", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33853", "train_wps": "3967.4", "train_ups": "2.21", "train_wpb": "1799", "train_bsz": "5", "train_num_updates": "40080", "train_lr": "0.000489022", "train_gnorm": "0.495", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18600"}
[2022-01-03 17:19:42,163][fairseq.trainer][INFO] - begin training epoch 1003
[2022-01-03 17:19:42,164][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:19:55,995][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:19:56,419][valid][INFO] - {"epoch": 1003, "valid_loss": "3.598", "valid_ntokens": "740", "valid_nsentences": "2", "valid_prob_perplexity": "144.081", "valid_code_perplexity": "136.485", "valid_temp": "1.636", "valid_loss_0": "3.477", "valid_loss_1": "0.112", "valid_loss_2": "0.009", "valid_accuracy": "0.36081", "valid_wps": "0", "valid_wpb": "740", "valid_bsz": "2", "valid_num_updates": "40120", "valid_best_loss": "3.043"}
[2022-01-03 17:19:56,421][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1003 @ 40120 updates
[2022-01-03 17:19:56,422][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:20:00,353][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:20:00,380][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1003 @ 40120 updates, score 3.598) (writing took 3.959220113232732 seconds)
[2022-01-03 17:20:00,381][fairseq_cli.train][INFO] - end of epoch 1003 (average epoch stats below)
[2022-01-03 17:20:00,394][train][INFO] - {"epoch": 1003, "train_loss": "3.548", "train_ntokens": "1789.83", "train_nsentences": "4.95", "train_prob_perplexity": "147.663", "train_code_perplexity": "144.831", "train_temp": "1.637", "train_loss_0": "3.428", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.3428", "train_wps": "3918.3", "train_ups": "2.19", "train_wpb": "1789.8", "train_bsz": "5", "train_num_updates": "40120", "train_lr": "0.000488967", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "18618"}
[2022-01-03 17:20:00,448][fairseq.trainer][INFO] - begin training epoch 1004
[2022-01-03 17:20:00,449][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:20:14,311][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:20:14,729][valid][INFO] - {"epoch": 1004, "valid_loss": "3.086", "valid_ntokens": "682", "valid_nsentences": "2", "valid_prob_perplexity": "143.081", "valid_code_perplexity": "134.374", "valid_temp": "1.636", "valid_loss_0": "2.966", "valid_loss_1": "0.112", "valid_loss_2": "0.008", "valid_accuracy": "0.42229", "valid_wps": "0", "valid_wpb": "682", "valid_bsz": "2", "valid_num_updates": "40160", "valid_best_loss": "3.043"}
[2022-01-03 17:20:14,731][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1004 @ 40160 updates
[2022-01-03 17:20:14,732][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:20:18,661][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:20:18,691][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1004 @ 40160 updates, score 3.086) (writing took 3.959540388546884 seconds)
[2022-01-03 17:20:18,691][fairseq_cli.train][INFO] - end of epoch 1004 (average epoch stats below)
[2022-01-03 17:20:18,705][train][INFO] - {"epoch": 1004, "train_loss": "3.589", "train_ntokens": "1793.83", "train_nsentences": "4.95", "train_prob_perplexity": "147.89", "train_code_perplexity": "144.986", "train_temp": "1.636", "train_loss_0": "3.468", "train_loss_1": "0.111", "train_loss_2": "0.01", "train_accuracy": "0.3366", "train_wps": "3921.4", "train_ups": "2.19", "train_wpb": "1793.8", "train_bsz": "5", "train_num_updates": "40160", "train_lr": "0.000488913", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "18636"}
[2022-01-03 17:20:18,779][fairseq.trainer][INFO] - begin training epoch 1005
[2022-01-03 17:20:18,780][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:20:32,792][train_inner][INFO] - {"epoch": 1005, "update": 1005.0, "loss": "3.563", "ntokens": "1793.05", "nsentences": "4.95", "prob_perplexity": "147.527", "code_perplexity": "144.776", "temp": "1.637", "loss_0": "3.443", "loss_1": "0.111", "loss_2": "0.009", "accuracy": "0.34066", "wps": "3916.9", "ups": "2.18", "wpb": "1793", "bsz": "5", "num_updates": "40200", "lr": "0.000488859", "gnorm": "0.506", "clip": "0", "train_wall": "67", "gb_free": "6.1", "wall": "18650"}
[2022-01-03 17:20:32,793][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:20:33,206][valid][INFO] - {"epoch": 1005, "valid_loss": "3.509", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "123.853", "valid_code_perplexity": "116.224", "valid_temp": "1.636", "valid_loss_0": "3.383", "valid_loss_1": "0.116", "valid_loss_2": "0.009", "valid_accuracy": "0.35109", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "40200", "valid_best_loss": "3.043"}
[2022-01-03 17:20:33,210][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1005 @ 40200 updates
[2022-01-03 17:20:33,212][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:20:36,877][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:20:36,905][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1005 @ 40200 updates, score 3.509) (writing took 3.6952808490023017 seconds)
[2022-01-03 17:20:36,906][fairseq_cli.train][INFO] - end of epoch 1005 (average epoch stats below)
[2022-01-03 17:20:36,919][train][INFO] - {"epoch": 1005, "train_loss": "3.539", "train_ntokens": "1791.92", "train_nsentences": "4.95", "train_prob_perplexity": "147.867", "train_code_perplexity": "145.263", "train_temp": "1.636", "train_loss_0": "3.418", "train_loss_1": "0.111", "train_loss_2": "0.01", "train_accuracy": "0.344", "train_wps": "3938", "train_ups": "2.2", "train_wpb": "1791.9", "train_bsz": "5", "train_num_updates": "40200", "train_lr": "0.000488859", "train_gnorm": "0.512", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6.1", "train_wall": "18654"}
[2022-01-03 17:20:36,999][fairseq.trainer][INFO] - begin training epoch 1006
[2022-01-03 17:20:37,000][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:20:50,865][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:20:51,286][valid][INFO] - {"epoch": 1006, "valid_loss": "3.71", "valid_ntokens": "714", "valid_nsentences": "2", "valid_prob_perplexity": "145.704", "valid_code_perplexity": "140.55", "valid_temp": "1.636", "valid_loss_0": "3.59", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.33754", "valid_wps": "0", "valid_wpb": "714", "valid_bsz": "2", "valid_num_updates": "40240", "valid_best_loss": "3.043"}
[2022-01-03 17:20:51,290][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1006 @ 40240 updates
[2022-01-03 17:20:51,291][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:20:55,121][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:20:55,149][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1006 @ 40240 updates, score 3.71) (writing took 3.8587748827412724 seconds)
[2022-01-03 17:20:55,149][fairseq_cli.train][INFO] - end of epoch 1006 (average epoch stats below)
[2022-01-03 17:20:55,162][train][INFO] - {"epoch": 1006, "train_loss": "3.573", "train_ntokens": "1800.7", "train_nsentences": "4.95", "train_prob_perplexity": "147.545", "train_code_perplexity": "144.748", "train_temp": "1.636", "train_loss_0": "3.453", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33894", "train_wps": "3951", "train_ups": "2.19", "train_wpb": "1800.7", "train_bsz": "5", "train_num_updates": "40240", "train_lr": "0.000488804", "train_gnorm": "0.493", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18673"}
[2022-01-03 17:20:55,226][fairseq.trainer][INFO] - begin training epoch 1007
[2022-01-03 17:20:55,227][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:21:08,969][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:21:09,379][valid][INFO] - {"epoch": 1007, "valid_loss": "3.317", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "145.84", "valid_code_perplexity": "140.672", "valid_temp": "1.635", "valid_loss_0": "3.196", "valid_loss_1": "0.111", "valid_loss_2": "0.01", "valid_accuracy": "0.39594", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "40280", "valid_best_loss": "3.043"}
[2022-01-03 17:21:09,381][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1007 @ 40280 updates
[2022-01-03 17:21:09,382][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:21:13,346][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:21:13,370][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1007 @ 40280 updates, score 3.317) (writing took 3.9890664387494326 seconds)
[2022-01-03 17:21:13,371][fairseq_cli.train][INFO] - end of epoch 1007 (average epoch stats below)
[2022-01-03 17:21:13,384][train][INFO] - {"epoch": 1007, "train_loss": "3.604", "train_ntokens": "1801.58", "train_nsentences": "4.95", "train_prob_perplexity": "147.822", "train_code_perplexity": "144.893", "train_temp": "1.635", "train_loss_0": "3.483", "train_loss_1": "0.111", "train_loss_2": "0.01", "train_accuracy": "0.33263", "train_wps": "3957.5", "train_ups": "2.2", "train_wpb": "1801.6", "train_bsz": "5", "train_num_updates": "40280", "train_lr": "0.00048875", "train_gnorm": "0.503", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18691"}
[2022-01-03 17:21:13,444][fairseq.trainer][INFO] - begin training epoch 1008
[2022-01-03 17:21:13,445][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:21:27,443][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:21:27,935][valid][INFO] - {"epoch": 1008, "valid_loss": "3.41", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "125.521", "valid_code_perplexity": "119.248", "valid_temp": "1.635", "valid_loss_0": "3.285", "valid_loss_1": "0.116", "valid_loss_2": "0.01", "valid_accuracy": "0.37601", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "40320", "valid_best_loss": "3.043"}
[2022-01-03 17:21:27,937][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1008 @ 40320 updates
[2022-01-03 17:21:27,937][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:21:31,578][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:21:31,606][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1008 @ 40320 updates, score 3.41) (writing took 3.669827787205577 seconds)
[2022-01-03 17:21:31,607][fairseq_cli.train][INFO] - end of epoch 1008 (average epoch stats below)
[2022-01-03 17:21:31,620][train][INFO] - {"epoch": 1008, "train_loss": "3.523", "train_ntokens": "1779.83", "train_nsentences": "4.95", "train_prob_perplexity": "148.138", "train_code_perplexity": "145.51", "train_temp": "1.635", "train_loss_0": "3.403", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34885", "train_wps": "3906.7", "train_ups": "2.19", "train_wpb": "1779.8", "train_bsz": "5", "train_num_updates": "40320", "train_lr": "0.000488696", "train_gnorm": "0.5", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "18709"}
[2022-01-03 17:21:31,689][fairseq.trainer][INFO] - begin training epoch 1009
[2022-01-03 17:21:31,690][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:21:45,652][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:21:46,144][valid][INFO] - {"epoch": 1009, "valid_loss": "3.799", "valid_ntokens": "774", "valid_nsentences": "2", "valid_prob_perplexity": "146.581", "valid_code_perplexity": "142.12", "valid_temp": "1.635", "valid_loss_0": "3.679", "valid_loss_1": "0.111", "valid_loss_2": "0.009", "valid_accuracy": "0.30749", "valid_wps": "0", "valid_wpb": "774", "valid_bsz": "2", "valid_num_updates": "40360", "valid_best_loss": "3.043"}
[2022-01-03 17:21:46,146][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1009 @ 40360 updates
[2022-01-03 17:21:46,146][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:21:49,813][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:21:49,839][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1009 @ 40360 updates, score 3.799) (writing took 3.693648741580546 seconds)
[2022-01-03 17:21:49,840][fairseq_cli.train][INFO] - end of epoch 1009 (average epoch stats below)
[2022-01-03 17:21:49,853][train][INFO] - {"epoch": 1009, "train_loss": "3.555", "train_ntokens": "1781.7", "train_nsentences": "4.95", "train_prob_perplexity": "148.455", "train_code_perplexity": "145.51", "train_temp": "1.635", "train_loss_0": "3.435", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34038", "train_wps": "3911.6", "train_ups": "2.2", "train_wpb": "1781.7", "train_bsz": "5", "train_num_updates": "40360", "train_lr": "0.000488641", "train_gnorm": "0.49", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "18727"}
[2022-01-03 17:21:49,932][fairseq.trainer][INFO] - begin training epoch 1010
[2022-01-03 17:21:49,932][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:22:03,751][train_inner][INFO] - {"epoch": 1010, "update": 1010.0, "loss": "3.564", "ntokens": "1792.67", "nsentences": "4.95", "prob_perplexity": "148.039", "code_perplexity": "145.245", "temp": "1.635", "loss_0": "3.444", "loss_1": "0.111", "loss_2": "0.009", "accuracy": "0.34", "wps": "3942.2", "ups": "2.2", "wpb": "1792.7", "bsz": "5", "num_updates": "40400", "lr": "0.000488587", "gnorm": "0.498", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "18741"}
[2022-01-03 17:22:03,752][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:22:04,180][valid][INFO] - {"epoch": 1010, "valid_loss": "3.314", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "145.07", "valid_code_perplexity": "139.433", "valid_temp": "1.634", "valid_loss_0": "3.193", "valid_loss_1": "0.112", "valid_loss_2": "0.009", "valid_accuracy": "0.37912", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "40400", "valid_best_loss": "3.043"}
[2022-01-03 17:22:04,184][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1010 @ 40400 updates
[2022-01-03 17:22:04,186][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:22:08,137][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:22:08,166][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1010 @ 40400 updates, score 3.314) (writing took 3.981412176042795 seconds)
[2022-01-03 17:22:08,166][fairseq_cli.train][INFO] - end of epoch 1010 (average epoch stats below)
[2022-01-03 17:22:08,179][train][INFO] - {"epoch": 1010, "train_loss": "3.566", "train_ntokens": "1799.58", "train_nsentences": "4.95", "train_prob_perplexity": "148.233", "train_code_perplexity": "145.564", "train_temp": "1.634", "train_loss_0": "3.445", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.3393", "train_wps": "3930.6", "train_ups": "2.18", "train_wpb": "1799.6", "train_bsz": "5", "train_num_updates": "40400", "train_lr": "0.000488587", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18746"}
[2022-01-03 17:22:08,230][fairseq.trainer][INFO] - begin training epoch 1011
[2022-01-03 17:22:08,230][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:22:22,098][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:22:22,514][valid][INFO] - {"epoch": 1011, "valid_loss": "3.575", "valid_ntokens": "720", "valid_nsentences": "2", "valid_prob_perplexity": "127.922", "valid_code_perplexity": "123.171", "valid_temp": "1.634", "valid_loss_0": "3.45", "valid_loss_1": "0.115", "valid_loss_2": "0.01", "valid_accuracy": "0.35833", "valid_wps": "0", "valid_wpb": "720", "valid_bsz": "2", "valid_num_updates": "40440", "valid_best_loss": "3.043"}
[2022-01-03 17:22:22,517][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1011 @ 40440 updates
[2022-01-03 17:22:22,517][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:22:26,481][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:22:26,511][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1011 @ 40440 updates, score 3.575) (writing took 3.993929374963045 seconds)
[2022-01-03 17:22:26,511][fairseq_cli.train][INFO] - end of epoch 1011 (average epoch stats below)
[2022-01-03 17:22:26,524][train][INFO] - {"epoch": 1011, "train_loss": "3.559", "train_ntokens": "1794.35", "train_nsentences": "4.95", "train_prob_perplexity": "148.848", "train_code_perplexity": "146.104", "train_temp": "1.634", "train_loss_0": "3.439", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34223", "train_wps": "3915.1", "train_ups": "2.18", "train_wpb": "1794.3", "train_bsz": "5", "train_num_updates": "40440", "train_lr": "0.000488533", "train_gnorm": "0.497", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "18764"}
[2022-01-03 17:22:26,601][fairseq.trainer][INFO] - begin training epoch 1012
[2022-01-03 17:22:26,602][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:22:40,486][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:22:40,891][valid][INFO] - {"epoch": 1012, "valid_loss": "3.473", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "145.128", "valid_code_perplexity": "138.779", "valid_temp": "1.634", "valid_loss_0": "3.353", "valid_loss_1": "0.112", "valid_loss_2": "0.008", "valid_accuracy": "0.34853", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "40480", "valid_best_loss": "3.043"}
[2022-01-03 17:22:40,894][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1012 @ 40480 updates
[2022-01-03 17:22:40,895][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:22:44,723][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:22:44,729][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1012 @ 40480 updates, score 3.473) (writing took 3.835122543387115 seconds)
[2022-01-03 17:22:44,730][fairseq_cli.train][INFO] - end of epoch 1012 (average epoch stats below)
[2022-01-03 17:22:44,743][train][INFO] - {"epoch": 1012, "train_loss": "3.559", "train_ntokens": "1775.12", "train_nsentences": "4.95", "train_prob_perplexity": "149.027", "train_code_perplexity": "146.246", "train_temp": "1.634", "train_loss_0": "3.439", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33815", "train_wps": "3900.2", "train_ups": "2.2", "train_wpb": "1775.1", "train_bsz": "5", "train_num_updates": "40480", "train_lr": "0.000488478", "train_gnorm": "0.506", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18782"}
[2022-01-03 17:22:44,792][fairseq.trainer][INFO] - begin training epoch 1013
[2022-01-03 17:22:44,793][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:22:58,699][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:22:59,107][valid][INFO] - {"epoch": 1013, "valid_loss": "3.332", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "129.975", "valid_code_perplexity": "125.494", "valid_temp": "1.633", "valid_loss_0": "3.208", "valid_loss_1": "0.115", "valid_loss_2": "0.009", "valid_accuracy": "0.39394", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "40520", "valid_best_loss": "3.043"}
[2022-01-03 17:22:59,111][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1013 @ 40520 updates
[2022-01-03 17:22:59,112][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:23:02,998][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:23:03,027][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1013 @ 40520 updates, score 3.332) (writing took 3.916177469305694 seconds)
[2022-01-03 17:23:03,028][fairseq_cli.train][INFO] - end of epoch 1013 (average epoch stats below)
[2022-01-03 17:23:03,040][train][INFO] - {"epoch": 1013, "train_loss": "3.565", "train_ntokens": "1785.33", "train_nsentences": "4.95", "train_prob_perplexity": "148.032", "train_code_perplexity": "145.147", "train_temp": "1.633", "train_loss_0": "3.445", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34026", "train_wps": "3905.6", "train_ups": "2.19", "train_wpb": "1785.3", "train_bsz": "5", "train_num_updates": "40520", "train_lr": "0.000488424", "train_gnorm": "0.511", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18800"}
[2022-01-03 17:23:03,123][fairseq.trainer][INFO] - begin training epoch 1014
[2022-01-03 17:23:03,124][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:23:16,997][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:23:17,416][valid][INFO] - {"epoch": 1014, "valid_loss": "3.4", "valid_ntokens": "712", "valid_nsentences": "2", "valid_prob_perplexity": "142.432", "valid_code_perplexity": "135.323", "valid_temp": "1.633", "valid_loss_0": "3.279", "valid_loss_1": "0.112", "valid_loss_2": "0.009", "valid_accuracy": "0.375", "valid_wps": "0", "valid_wpb": "712", "valid_bsz": "2", "valid_num_updates": "40560", "valid_best_loss": "3.043"}
[2022-01-03 17:23:17,419][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1014 @ 40560 updates
[2022-01-03 17:23:17,420][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:23:21,177][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:23:21,202][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1014 @ 40560 updates, score 3.4) (writing took 3.7823668709024787 seconds)
[2022-01-03 17:23:21,202][fairseq_cli.train][INFO] - end of epoch 1014 (average epoch stats below)
[2022-01-03 17:23:21,215][train][INFO] - {"epoch": 1014, "train_loss": "3.571", "train_ntokens": "1789.72", "train_nsentences": "4.95", "train_prob_perplexity": "148.81", "train_code_perplexity": "145.96", "train_temp": "1.633", "train_loss_0": "3.451", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34035", "train_wps": "3941.7", "train_ups": "2.2", "train_wpb": "1789.7", "train_bsz": "5", "train_num_updates": "40560", "train_lr": "0.00048837", "train_gnorm": "0.498", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "18819"}
[2022-01-03 17:23:21,264][fairseq.trainer][INFO] - begin training epoch 1015
[2022-01-03 17:23:21,265][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:23:35,293][train_inner][INFO] - {"epoch": 1015, "update": 1015.0, "loss": "3.558", "ntokens": "1787.2", "nsentences": "4.95", "prob_perplexity": "148.632", "code_perplexity": "145.796", "temp": "1.633", "loss_0": "3.438", "loss_1": "0.111", "loss_2": "0.009", "accuracy": "0.3416", "wps": "3905.2", "ups": "2.19", "wpb": "1787.2", "bsz": "5", "num_updates": "40600", "lr": "0.000488315", "gnorm": "0.504", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "18833"}
[2022-01-03 17:23:35,293][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:23:35,701][valid][INFO] - {"epoch": 1015, "valid_loss": "3.519", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "132.172", "valid_code_perplexity": "127.111", "valid_temp": "1.633", "valid_loss_0": "3.395", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.35604", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "40600", "valid_best_loss": "3.043"}
[2022-01-03 17:23:35,705][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1015 @ 40600 updates
[2022-01-03 17:23:35,706][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:23:39,438][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:23:39,466][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1015 @ 40600 updates, score 3.519) (writing took 3.7615369791164994 seconds)
[2022-01-03 17:23:39,467][fairseq_cli.train][INFO] - end of epoch 1015 (average epoch stats below)
[2022-01-03 17:23:39,479][train][INFO] - {"epoch": 1015, "train_loss": "3.535", "train_ntokens": "1791.47", "train_nsentences": "4.95", "train_prob_perplexity": "148.446", "train_code_perplexity": "145.52", "train_temp": "1.633", "train_loss_0": "3.415", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34699", "train_wps": "3926.3", "train_ups": "2.19", "train_wpb": "1791.5", "train_bsz": "5", "train_num_updates": "40600", "train_lr": "0.000488315", "train_gnorm": "0.508", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "18837"}
[2022-01-03 17:23:39,557][fairseq.trainer][INFO] - begin training epoch 1016
[2022-01-03 17:23:39,557][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:23:53,533][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:23:53,950][valid][INFO] - {"epoch": 1016, "valid_loss": "3.834", "valid_ntokens": "808", "valid_nsentences": "2", "valid_prob_perplexity": "147.572", "valid_code_perplexity": "142.833", "valid_temp": "1.632", "valid_loss_0": "3.712", "valid_loss_1": "0.111", "valid_loss_2": "0.011", "valid_accuracy": "0.32302", "valid_wps": "0", "valid_wpb": "808", "valid_bsz": "2", "valid_num_updates": "40640", "valid_best_loss": "3.043"}
[2022-01-03 17:23:53,953][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1016 @ 40640 updates
[2022-01-03 17:23:53,954][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:23:57,670][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:23:57,697][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1016 @ 40640 updates, score 3.834) (writing took 3.7438592119142413 seconds)
[2022-01-03 17:23:57,698][fairseq_cli.train][INFO] - end of epoch 1016 (average epoch stats below)
[2022-01-03 17:23:57,711][train][INFO] - {"epoch": 1016, "train_loss": "3.547", "train_ntokens": "1802.9", "train_nsentences": "4.95", "train_prob_perplexity": "148.961", "train_code_perplexity": "146.169", "train_temp": "1.632", "train_loss_0": "3.427", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34268", "train_wps": "3958.4", "train_ups": "2.2", "train_wpb": "1802.9", "train_bsz": "5", "train_num_updates": "40640", "train_lr": "0.000488261", "train_gnorm": "0.493", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.4", "train_wall": "18855"}
[2022-01-03 17:23:57,773][fairseq.trainer][INFO] - begin training epoch 1017
[2022-01-03 17:23:57,774][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:24:11,570][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:24:12,006][valid][INFO] - {"epoch": 1017, "valid_loss": "3.346", "valid_ntokens": "698", "valid_nsentences": "2", "valid_prob_perplexity": "144.686", "valid_code_perplexity": "139.354", "valid_temp": "1.632", "valid_loss_0": "3.227", "valid_loss_1": "0.112", "valid_loss_2": "0.007", "valid_accuracy": "0.3553", "valid_wps": "0", "valid_wpb": "698", "valid_bsz": "2", "valid_num_updates": "40680", "valid_best_loss": "3.043"}
[2022-01-03 17:24:12,009][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1017 @ 40680 updates
[2022-01-03 17:24:12,009][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:24:15,914][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:24:15,937][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1017 @ 40680 updates, score 3.346) (writing took 3.928919612430036 seconds)
[2022-01-03 17:24:15,938][fairseq_cli.train][INFO] - end of epoch 1017 (average epoch stats below)
[2022-01-03 17:24:15,950][train][INFO] - {"epoch": 1017, "train_loss": "3.545", "train_ntokens": "1779.45", "train_nsentences": "4.95", "train_prob_perplexity": "148.857", "train_code_perplexity": "146.179", "train_temp": "1.632", "train_loss_0": "3.425", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34346", "train_wps": "3905.1", "train_ups": "2.19", "train_wpb": "1779.5", "train_bsz": "5", "train_num_updates": "40680", "train_lr": "0.000488207", "train_gnorm": "0.514", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18873"}
[2022-01-03 17:24:16,002][fairseq.trainer][INFO] - begin training epoch 1018
[2022-01-03 17:24:16,003][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:24:29,890][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:24:30,320][valid][INFO] - {"epoch": 1018, "valid_loss": "3.264", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "141.957", "valid_code_perplexity": "137.757", "valid_temp": "1.632", "valid_loss_0": "3.143", "valid_loss_1": "0.112", "valid_loss_2": "0.009", "valid_accuracy": "0.40945", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "40720", "valid_best_loss": "3.043"}
[2022-01-03 17:24:30,323][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1018 @ 40720 updates
[2022-01-03 17:24:30,324][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:24:34,122][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:24:34,149][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1018 @ 40720 updates, score 3.264) (writing took 3.8256359668448567 seconds)
[2022-01-03 17:24:34,149][fairseq_cli.train][INFO] - end of epoch 1018 (average epoch stats below)
[2022-01-03 17:24:34,162][train][INFO] - {"epoch": 1018, "train_loss": "3.566", "train_ntokens": "1775.85", "train_nsentences": "4.95", "train_prob_perplexity": "148.999", "train_code_perplexity": "146.205", "train_temp": "1.632", "train_loss_0": "3.446", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34067", "train_wps": "3903.1", "train_ups": "2.2", "train_wpb": "1775.8", "train_bsz": "5", "train_num_updates": "40720", "train_lr": "0.000488152", "train_gnorm": "0.506", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18892"}
[2022-01-03 17:24:34,234][fairseq.trainer][INFO] - begin training epoch 1019
[2022-01-03 17:24:34,235][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:24:48,164][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:24:48,573][valid][INFO] - {"epoch": 1019, "valid_loss": "3.532", "valid_ntokens": "694", "valid_nsentences": "2", "valid_prob_perplexity": "147.199", "valid_code_perplexity": "142.624", "valid_temp": "1.631", "valid_loss_0": "3.412", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.35447", "valid_wps": "0", "valid_wpb": "694", "valid_bsz": "2", "valid_num_updates": "40760", "valid_best_loss": "3.043"}
[2022-01-03 17:24:48,576][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1019 @ 40760 updates
[2022-01-03 17:24:48,577][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:24:52,410][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:24:52,439][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1019 @ 40760 updates, score 3.532) (writing took 3.862574715167284 seconds)
[2022-01-03 17:24:52,440][fairseq_cli.train][INFO] - end of epoch 1019 (average epoch stats below)
[2022-01-03 17:24:52,452][train][INFO] - {"epoch": 1019, "train_loss": "3.568", "train_ntokens": "1797.53", "train_nsentences": "4.95", "train_prob_perplexity": "149.106", "train_code_perplexity": "146.307", "train_temp": "1.631", "train_loss_0": "3.448", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34137", "train_wps": "3933.9", "train_ups": "2.19", "train_wpb": "1797.5", "train_bsz": "5", "train_num_updates": "40760", "train_lr": "0.000488098", "train_gnorm": "0.503", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.4", "train_wall": "18910"}
[2022-01-03 17:24:52,532][fairseq.trainer][INFO] - begin training epoch 1020
[2022-01-03 17:24:52,532][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:25:06,496][train_inner][INFO] - {"epoch": 1020, "update": 1020.0, "loss": "3.549", "ntokens": "1786.22", "nsentences": "4.95", "prob_perplexity": "148.99", "code_perplexity": "146.203", "temp": "1.632", "loss_0": "3.429", "loss_1": "0.111", "loss_2": "0.009", "accuracy": "0.34305", "wps": "3917.6", "ups": "2.19", "wpb": "1786.2", "bsz": "5", "num_updates": "40800", "lr": "0.000488043", "gnorm": "0.501", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "18924"}
[2022-01-03 17:25:06,496][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:25:06,966][valid][INFO] - {"epoch": 1020, "valid_loss": "3.401", "valid_ntokens": "758", "valid_nsentences": "2", "valid_prob_perplexity": "133.588", "valid_code_perplexity": "129.45", "valid_temp": "1.631", "valid_loss_0": "3.277", "valid_loss_1": "0.114", "valid_loss_2": "0.01", "valid_accuracy": "0.3496", "valid_wps": "0", "valid_wpb": "758", "valid_bsz": "2", "valid_num_updates": "40800", "valid_best_loss": "3.043"}
[2022-01-03 17:25:06,969][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1020 @ 40800 updates
[2022-01-03 17:25:06,970][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:25:10,615][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:25:10,632][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1020 @ 40800 updates, score 3.401) (writing took 3.6627711970359087 seconds)
[2022-01-03 17:25:10,632][fairseq_cli.train][INFO] - end of epoch 1020 (average epoch stats below)
[2022-01-03 17:25:10,645][train][INFO] - {"epoch": 1020, "train_loss": "3.518", "train_ntokens": "1775.38", "train_nsentences": "4.95", "train_prob_perplexity": "149.028", "train_code_perplexity": "146.154", "train_temp": "1.631", "train_loss_0": "3.398", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34708", "train_wps": "3906.3", "train_ups": "2.2", "train_wpb": "1775.4", "train_bsz": "5", "train_num_updates": "40800", "train_lr": "0.000488043", "train_gnorm": "0.49", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "18928"}
[2022-01-03 17:25:10,698][fairseq.trainer][INFO] - begin training epoch 1021
[2022-01-03 17:25:10,698][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:25:24,548][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:25:24,972][valid][INFO] - {"epoch": 1021, "valid_loss": "3.302", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "144.83", "valid_code_perplexity": "139.046", "valid_temp": "1.631", "valid_loss_0": "3.182", "valid_loss_1": "0.112", "valid_loss_2": "0.008", "valid_accuracy": "0.38624", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "40840", "valid_best_loss": "3.043"}
[2022-01-03 17:25:24,974][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1021 @ 40840 updates
[2022-01-03 17:25:24,975][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:25:28,860][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:25:28,879][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1021 @ 40840 updates, score 3.302) (writing took 3.9048884958028793 seconds)
[2022-01-03 17:25:28,880][fairseq_cli.train][INFO] - end of epoch 1021 (average epoch stats below)
[2022-01-03 17:25:28,893][train][INFO] - {"epoch": 1021, "train_loss": "3.575", "train_ntokens": "1795.35", "train_nsentences": "4.95", "train_prob_perplexity": "150.32", "train_code_perplexity": "147.676", "train_temp": "1.631", "train_loss_0": "3.455", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.33935", "train_wps": "3938.2", "train_ups": "2.19", "train_wpb": "1795.3", "train_bsz": "5", "train_num_updates": "40840", "train_lr": "0.000487989", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18946"}
[2022-01-03 17:25:28,969][fairseq.trainer][INFO] - begin training epoch 1022
[2022-01-03 17:25:28,970][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:25:42,761][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:25:43,184][valid][INFO] - {"epoch": 1022, "valid_loss": "3.558", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "145.999", "valid_code_perplexity": "141.111", "valid_temp": "1.63", "valid_loss_0": "3.439", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.332", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "40880", "valid_best_loss": "3.043"}
[2022-01-03 17:25:43,188][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1022 @ 40880 updates
[2022-01-03 17:25:43,190][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:25:47,138][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:25:47,167][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1022 @ 40880 updates, score 3.558) (writing took 3.9785748925060034 seconds)
[2022-01-03 17:25:47,168][fairseq_cli.train][INFO] - end of epoch 1022 (average epoch stats below)
[2022-01-03 17:25:47,181][train][INFO] - {"epoch": 1022, "train_loss": "3.578", "train_ntokens": "1802.5", "train_nsentences": "4.95", "train_prob_perplexity": "149.831", "train_code_perplexity": "147.178", "train_temp": "1.63", "train_loss_0": "3.458", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.33854", "train_wps": "3945.3", "train_ups": "2.19", "train_wpb": "1802.5", "train_bsz": "5", "train_num_updates": "40880", "train_lr": "0.000487935", "train_gnorm": "0.493", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "18965"}
[2022-01-03 17:25:47,263][fairseq.trainer][INFO] - begin training epoch 1023
[2022-01-03 17:25:47,264][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:26:01,155][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:26:01,621][valid][INFO] - {"epoch": 1023, "valid_loss": "3.472", "valid_ntokens": "756", "valid_nsentences": "2", "valid_prob_perplexity": "149.096", "valid_code_perplexity": "144.778", "valid_temp": "1.63", "valid_loss_0": "3.352", "valid_loss_1": "0.111", "valid_loss_2": "0.009", "valid_accuracy": "0.35185", "valid_wps": "0", "valid_wpb": "756", "valid_bsz": "2", "valid_num_updates": "40920", "valid_best_loss": "3.043"}
[2022-01-03 17:26:01,623][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1023 @ 40920 updates
[2022-01-03 17:26:01,624][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:26:05,374][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:26:05,401][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1023 @ 40920 updates, score 3.472) (writing took 3.7779525090008974 seconds)
[2022-01-03 17:26:05,402][fairseq_cli.train][INFO] - end of epoch 1023 (average epoch stats below)
[2022-01-03 17:26:05,415][train][INFO] - {"epoch": 1023, "train_loss": "3.555", "train_ntokens": "1801.08", "train_nsentences": "4.95", "train_prob_perplexity": "149.29", "train_code_perplexity": "146.599", "train_temp": "1.63", "train_loss_0": "3.436", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34266", "train_wps": "3953.9", "train_ups": "2.2", "train_wpb": "1801.1", "train_bsz": "5", "train_num_updates": "40920", "train_lr": "0.00048788", "train_gnorm": "0.521", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "18983"}
[2022-01-03 17:26:05,468][fairseq.trainer][INFO] - begin training epoch 1024
[2022-01-03 17:26:05,468][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:26:19,331][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:26:19,737][valid][INFO] - {"epoch": 1024, "valid_loss": "3.374", "valid_ntokens": "788", "valid_nsentences": "2", "valid_prob_perplexity": "147.41", "valid_code_perplexity": "142.963", "valid_temp": "1.63", "valid_loss_0": "3.255", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.3769", "valid_wps": "0", "valid_wpb": "788", "valid_bsz": "2", "valid_num_updates": "40960", "valid_best_loss": "3.043"}
[2022-01-03 17:26:19,740][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1024 @ 40960 updates
[2022-01-03 17:26:19,741][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:26:23,649][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:26:23,677][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1024 @ 40960 updates, score 3.374) (writing took 3.9373129289597273 seconds)
[2022-01-03 17:26:23,678][fairseq_cli.train][INFO] - end of epoch 1024 (average epoch stats below)
[2022-01-03 17:26:23,690][train][INFO] - {"epoch": 1024, "train_loss": "3.531", "train_ntokens": "1783.08", "train_nsentences": "4.95", "train_prob_perplexity": "149.683", "train_code_perplexity": "146.924", "train_temp": "1.63", "train_loss_0": "3.411", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.349", "train_wps": "3905.3", "train_ups": "2.19", "train_wpb": "1783.1", "train_bsz": "5", "train_num_updates": "40960", "train_lr": "0.000487826", "train_gnorm": "0.518", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "19001"}
[2022-01-03 17:26:23,751][fairseq.trainer][INFO] - begin training epoch 1025
[2022-01-03 17:26:23,752][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:26:37,730][train_inner][INFO] - {"epoch": 1025, "update": 1025.0, "loss": "3.557", "ntokens": "1793.78", "nsentences": "4.95", "prob_perplexity": "149.724", "code_perplexity": "146.998", "temp": "1.63", "loss_0": "3.438", "loss_1": "0.111", "loss_2": "0.009", "accuracy": "0.34255", "wps": "3932.8", "ups": "2.19", "wpb": "1793.8", "bsz": "5", "num_updates": "41000", "lr": "0.000487772", "gnorm": "0.509", "clip": "0", "train_wall": "67", "gb_free": "6", "wall": "19015"}
[2022-01-03 17:26:37,732][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:26:38,138][valid][INFO] - {"epoch": 1025, "valid_loss": "3.377", "valid_ntokens": "728", "valid_nsentences": "2", "valid_prob_perplexity": "123.391", "valid_code_perplexity": "118.639", "valid_temp": "1.629", "valid_loss_0": "3.252", "valid_loss_1": "0.116", "valid_loss_2": "0.009", "valid_accuracy": "0.36538", "valid_wps": "0", "valid_wpb": "728", "valid_bsz": "2", "valid_num_updates": "41000", "valid_best_loss": "3.043"}
[2022-01-03 17:26:38,142][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1025 @ 41000 updates
[2022-01-03 17:26:38,143][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:26:41,823][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:26:41,850][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1025 @ 41000 updates, score 3.377) (writing took 3.708266976289451 seconds)
[2022-01-03 17:26:41,851][fairseq_cli.train][INFO] - end of epoch 1025 (average epoch stats below)
[2022-01-03 17:26:41,863][train][INFO] - {"epoch": 1025, "train_loss": "3.547", "train_ntokens": "1786.88", "train_nsentences": "4.95", "train_prob_perplexity": "149.496", "train_code_perplexity": "146.615", "train_temp": "1.629", "train_loss_0": "3.428", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34325", "train_wps": "3935.7", "train_ups": "2.2", "train_wpb": "1786.9", "train_bsz": "5", "train_num_updates": "41000", "train_lr": "0.000487772", "train_gnorm": "0.503", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "19019"}
[2022-01-03 17:26:41,941][fairseq.trainer][INFO] - begin training epoch 1026
[2022-01-03 17:26:41,942][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:26:55,862][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:26:56,333][valid][INFO] - {"epoch": 1026, "valid_loss": "3.469", "valid_ntokens": "818", "valid_nsentences": "2", "valid_prob_perplexity": "149.449", "valid_code_perplexity": "143.715", "valid_temp": "1.629", "valid_loss_0": "3.351", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.37042", "valid_wps": "0", "valid_wpb": "818", "valid_bsz": "2", "valid_num_updates": "41040", "valid_best_loss": "3.043"}
[2022-01-03 17:26:56,335][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1026 @ 41040 updates
[2022-01-03 17:26:56,336][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:27:00,118][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:27:00,145][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1026 @ 41040 updates, score 3.469) (writing took 3.81012662127614 seconds)
[2022-01-03 17:27:00,146][fairseq_cli.train][INFO] - end of epoch 1026 (average epoch stats below)
[2022-01-03 17:27:00,159][train][INFO] - {"epoch": 1026, "train_loss": "3.539", "train_ntokens": "1782.92", "train_nsentences": "4.95", "train_prob_perplexity": "148.629", "train_code_perplexity": "145.676", "train_temp": "1.629", "train_loss_0": "3.419", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34436", "train_wps": "3900.9", "train_ups": "2.19", "train_wpb": "1782.9", "train_bsz": "5", "train_num_updates": "41040", "train_lr": "0.000487717", "train_gnorm": "0.51", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "19038"}
[2022-01-03 17:27:00,208][fairseq.trainer][INFO] - begin training epoch 1027
[2022-01-03 17:27:00,209][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:27:14,068][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:27:14,486][valid][INFO] - {"epoch": 1027, "valid_loss": "3.257", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "145.353", "valid_code_perplexity": "142.401", "valid_temp": "1.629", "valid_loss_0": "3.138", "valid_loss_1": "0.112", "valid_loss_2": "0.008", "valid_accuracy": "0.4036", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "41080", "valid_best_loss": "3.043"}
[2022-01-03 17:27:14,490][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1027 @ 41080 updates
[2022-01-03 17:27:14,491][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:27:18,502][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:27:18,531][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1027 @ 41080 updates, score 3.257) (writing took 4.041478427127004 seconds)
[2022-01-03 17:27:18,532][fairseq_cli.train][INFO] - end of epoch 1027 (average epoch stats below)
[2022-01-03 17:27:18,544][train][INFO] - {"epoch": 1027, "train_loss": "3.585", "train_ntokens": "1800", "train_nsentences": "4.95", "train_prob_perplexity": "149.605", "train_code_perplexity": "146.609", "train_temp": "1.629", "train_loss_0": "3.466", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.33719", "train_wps": "3918.8", "train_ups": "2.18", "train_wpb": "1800", "train_bsz": "5", "train_num_updates": "41080", "train_lr": "0.000487663", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "9.4", "train_wall": "19056"}
[2022-01-03 17:27:18,606][fairseq.trainer][INFO] - begin training epoch 1028
[2022-01-03 17:27:18,607][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:27:32,469][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:27:32,880][valid][INFO] - {"epoch": 1028, "valid_loss": "3.237", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "146.899", "valid_code_perplexity": "142.034", "valid_temp": "1.628", "valid_loss_0": "3.118", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.40933", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "41120", "valid_best_loss": "3.043"}
[2022-01-03 17:27:32,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1028 @ 41120 updates
[2022-01-03 17:27:32,885][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:27:36,955][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:27:36,982][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1028 @ 41120 updates, score 3.237) (writing took 4.0986538249999285 seconds)
[2022-01-03 17:27:36,983][fairseq_cli.train][INFO] - end of epoch 1028 (average epoch stats below)
[2022-01-03 17:27:36,996][train][INFO] - {"epoch": 1028, "train_loss": "3.545", "train_ntokens": "1789.35", "train_nsentences": "4.95", "train_prob_perplexity": "149.656", "train_code_perplexity": "146.94", "train_temp": "1.628", "train_loss_0": "3.426", "train_loss_1": "0.111", "train_loss_2": "0.009", "train_accuracy": "0.34146", "train_wps": "3881.7", "train_ups": "2.17", "train_wpb": "1789.3", "train_bsz": "5", "train_num_updates": "41120", "train_lr": "0.000487609", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "19074"}
[2022-01-03 17:27:37,074][fairseq.trainer][INFO] - begin training epoch 1029
[2022-01-03 17:27:37,075][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:27:50,903][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:27:51,316][valid][INFO] - {"epoch": 1029, "valid_loss": "3.368", "valid_ntokens": "762", "valid_nsentences": "2", "valid_prob_perplexity": "145.39", "valid_code_perplexity": "138.935", "valid_temp": "1.628", "valid_loss_0": "3.249", "valid_loss_1": "0.111", "valid_loss_2": "0.007", "valid_accuracy": "0.38058", "valid_wps": "0", "valid_wpb": "762", "valid_bsz": "2", "valid_num_updates": "41160", "valid_best_loss": "3.043"}
[2022-01-03 17:27:51,319][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1029 @ 41160 updates
[2022-01-03 17:27:51,320][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:27:55,248][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:27:55,266][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1029 @ 41160 updates, score 3.368) (writing took 3.9473577765747905 seconds)
[2022-01-03 17:27:55,267][fairseq_cli.train][INFO] - end of epoch 1029 (average epoch stats below)
[2022-01-03 17:27:55,280][train][INFO] - {"epoch": 1029, "train_loss": "3.552", "train_ntokens": "1801.92", "train_nsentences": "4.95", "train_prob_perplexity": "150.25", "train_code_perplexity": "147.704", "train_temp": "1.628", "train_loss_0": "3.433", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34337", "train_wps": "3944.9", "train_ups": "2.19", "train_wpb": "1801.9", "train_bsz": "5", "train_num_updates": "41160", "train_lr": "0.000487554", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "19093"}
[2022-01-03 17:27:55,341][fairseq.trainer][INFO] - begin training epoch 1030
[2022-01-03 17:27:55,342][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:28:09,227][train_inner][INFO] - {"epoch": 1030, "update": 1030.0, "loss": "3.547", "ntokens": "1793.21", "nsentences": "4.95", "prob_perplexity": "149.614", "code_perplexity": "146.794", "temp": "1.628", "loss_0": "3.428", "loss_1": "0.111", "loss_2": "0.009", "accuracy": "0.34309", "wps": "3920.3", "ups": "2.19", "wpb": "1793.2", "bsz": "5", "num_updates": "41200", "lr": "0.0004875", "gnorm": "0.504", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "19107"}
[2022-01-03 17:28:09,228][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:28:09,644][valid][INFO] - {"epoch": 1030, "valid_loss": "3.379", "valid_ntokens": "726", "valid_nsentences": "2", "valid_prob_perplexity": "123.11", "valid_code_perplexity": "118.009", "valid_temp": "1.628", "valid_loss_0": "3.253", "valid_loss_1": "0.117", "valid_loss_2": "0.009", "valid_accuracy": "0.37466", "valid_wps": "0", "valid_wpb": "726", "valid_bsz": "2", "valid_num_updates": "41200", "valid_best_loss": "3.043"}
[2022-01-03 17:28:09,649][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1030 @ 41200 updates
[2022-01-03 17:28:09,650][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:28:13,554][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:28:13,582][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1030 @ 41200 updates, score 3.379) (writing took 3.9324138024821877 seconds)
[2022-01-03 17:28:13,582][fairseq_cli.train][INFO] - end of epoch 1030 (average epoch stats below)
[2022-01-03 17:28:13,595][train][INFO] - {"epoch": 1030, "train_loss": "3.515", "train_ntokens": "1791.88", "train_nsentences": "4.95", "train_prob_perplexity": "149.932", "train_code_perplexity": "147.04", "train_temp": "1.628", "train_loss_0": "3.396", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.3491", "train_wps": "3916.1", "train_ups": "2.19", "train_wpb": "1791.9", "train_bsz": "5", "train_num_updates": "41200", "train_lr": "0.0004875", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "19111"}
[2022-01-03 17:28:13,676][fairseq.trainer][INFO] - begin training epoch 1031
[2022-01-03 17:28:13,677][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:28:27,459][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:28:27,874][valid][INFO] - {"epoch": 1031, "valid_loss": "3.296", "valid_ntokens": "784", "valid_nsentences": "2", "valid_prob_perplexity": "142.731", "valid_code_perplexity": "137.15", "valid_temp": "1.627", "valid_loss_0": "3.175", "valid_loss_1": "0.112", "valid_loss_2": "0.008", "valid_accuracy": "0.37372", "valid_wps": "0", "valid_wpb": "784", "valid_bsz": "2", "valid_num_updates": "41240", "valid_best_loss": "3.043"}
[2022-01-03 17:28:27,877][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1031 @ 41240 updates
[2022-01-03 17:28:27,878][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:28:31,808][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:28:31,836][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1031 @ 41240 updates, score 3.296) (writing took 3.959236202761531 seconds)
[2022-01-03 17:28:31,837][fairseq_cli.train][INFO] - end of epoch 1031 (average epoch stats below)
[2022-01-03 17:28:31,850][train][INFO] - {"epoch": 1031, "train_loss": "3.514", "train_ntokens": "1761.4", "train_nsentences": "4.95", "train_prob_perplexity": "149.814", "train_code_perplexity": "146.948", "train_temp": "1.628", "train_loss_0": "3.395", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.35233", "train_wps": "3862.4", "train_ups": "2.19", "train_wpb": "1761.4", "train_bsz": "5", "train_num_updates": "41240", "train_lr": "0.000487446", "train_gnorm": "0.508", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.1", "train_wall": "19129"}
[2022-01-03 17:28:31,927][fairseq.trainer][INFO] - begin training epoch 1032
[2022-01-03 17:28:31,928][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:28:45,783][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:28:46,213][valid][INFO] - {"epoch": 1032, "valid_loss": "3.611", "valid_ntokens": "746", "valid_nsentences": "2", "valid_prob_perplexity": "131.654", "valid_code_perplexity": "125.635", "valid_temp": "1.627", "valid_loss_0": "3.487", "valid_loss_1": "0.115", "valid_loss_2": "0.009", "valid_accuracy": "0.34316", "valid_wps": "0", "valid_wpb": "746", "valid_bsz": "2", "valid_num_updates": "41280", "valid_best_loss": "3.043"}
[2022-01-03 17:28:46,217][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1032 @ 41280 updates
[2022-01-03 17:28:46,219][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:28:49,994][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:28:50,022][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1032 @ 41280 updates, score 3.611) (writing took 3.805035197176039 seconds)
[2022-01-03 17:28:50,023][fairseq_cli.train][INFO] - end of epoch 1032 (average epoch stats below)
[2022-01-03 17:28:50,036][train][INFO] - {"epoch": 1032, "train_loss": "3.536", "train_ntokens": "1799.15", "train_nsentences": "4.95", "train_prob_perplexity": "150.342", "train_code_perplexity": "147.497", "train_temp": "1.627", "train_loss_0": "3.417", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34612", "train_wps": "3960", "train_ups": "2.2", "train_wpb": "1799.2", "train_bsz": "5", "train_num_updates": "41280", "train_lr": "0.000487391", "train_gnorm": "0.498", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "19147"}
[2022-01-03 17:28:50,107][fairseq.trainer][INFO] - begin training epoch 1033
[2022-01-03 17:28:50,108][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:29:04,026][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:29:04,438][valid][INFO] - {"epoch": 1033, "valid_loss": "3.538", "valid_ntokens": "764", "valid_nsentences": "2", "valid_prob_perplexity": "150.056", "valid_code_perplexity": "147.652", "valid_temp": "1.627", "valid_loss_0": "3.418", "valid_loss_1": "0.11", "valid_loss_2": "0.009", "valid_accuracy": "0.3233", "valid_wps": "0", "valid_wpb": "764", "valid_bsz": "2", "valid_num_updates": "41320", "valid_best_loss": "3.043"}
[2022-01-03 17:29:04,442][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1033 @ 41320 updates
[2022-01-03 17:29:04,443][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:29:08,259][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:29:08,288][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1033 @ 41320 updates, score 3.538) (writing took 3.8456610506400466 seconds)
[2022-01-03 17:29:08,288][fairseq_cli.train][INFO] - end of epoch 1033 (average epoch stats below)
[2022-01-03 17:29:08,301][train][INFO] - {"epoch": 1033, "train_loss": "3.55", "train_ntokens": "1788", "train_nsentences": "4.95", "train_prob_perplexity": "149.949", "train_code_perplexity": "147.1", "train_temp": "1.627", "train_loss_0": "3.43", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34413", "train_wps": "3918.4", "train_ups": "2.19", "train_wpb": "1788", "train_bsz": "5", "train_num_updates": "41320", "train_lr": "0.000487337", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "7.2", "train_wall": "19166"}
[2022-01-03 17:29:08,378][fairseq.trainer][INFO] - begin training epoch 1034
[2022-01-03 17:29:08,379][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:29:22,204][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:29:22,628][valid][INFO] - {"epoch": 1034, "valid_loss": "3.28", "valid_ntokens": "776", "valid_nsentences": "2", "valid_prob_perplexity": "147.539", "valid_code_perplexity": "142.313", "valid_temp": "1.626", "valid_loss_0": "3.162", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.38144", "valid_wps": "0", "valid_wpb": "776", "valid_bsz": "2", "valid_num_updates": "41360", "valid_best_loss": "3.043"}
[2022-01-03 17:29:22,631][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1034 @ 41360 updates
[2022-01-03 17:29:22,632][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:29:26,562][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:29:26,590][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1034 @ 41360 updates, score 3.28) (writing took 3.95933208335191 seconds)
[2022-01-03 17:29:26,591][fairseq_cli.train][INFO] - end of epoch 1034 (average epoch stats below)
[2022-01-03 17:29:26,603][train][INFO] - {"epoch": 1034, "train_loss": "3.537", "train_ntokens": "1794.22", "train_nsentences": "4.95", "train_prob_perplexity": "149.938", "train_code_perplexity": "147.197", "train_temp": "1.627", "train_loss_0": "3.418", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34534", "train_wps": "3924", "train_ups": "2.19", "train_wpb": "1794.2", "train_bsz": "5", "train_num_updates": "41360", "train_lr": "0.000487283", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "19184"}
[2022-01-03 17:29:26,656][fairseq.trainer][INFO] - begin training epoch 1035
[2022-01-03 17:29:26,656][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:29:40,464][train_inner][INFO] - {"epoch": 1035, "update": 1035.0, "loss": "3.536", "ntokens": "1788.37", "nsentences": "4.95", "prob_perplexity": "150.042", "code_perplexity": "147.234", "temp": "1.627", "loss_0": "3.417", "loss_1": "0.11", "loss_2": "0.009", "accuracy": "0.34629", "wps": "3920.8", "ups": "2.19", "wpb": "1788.4", "bsz": "5", "num_updates": "41400", "lr": "0.000487228", "gnorm": "0.505", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "19198"}
[2022-01-03 17:29:40,465][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:29:40,946][valid][INFO] - {"epoch": 1035, "valid_loss": "3.43", "valid_ntokens": "752", "valid_nsentences": "2", "valid_prob_perplexity": "148.405", "valid_code_perplexity": "142.314", "valid_temp": "1.626", "valid_loss_0": "3.31", "valid_loss_1": "0.111", "valid_loss_2": "0.009", "valid_accuracy": "0.35771", "valid_wps": "0", "valid_wpb": "752", "valid_bsz": "2", "valid_num_updates": "41400", "valid_best_loss": "3.043"}
[2022-01-03 17:29:40,947][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1035 @ 41400 updates
[2022-01-03 17:29:40,948][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:29:44,876][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:29:44,904][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1035 @ 41400 updates, score 3.43) (writing took 3.9570420645177364 seconds)
[2022-01-03 17:29:44,905][fairseq_cli.train][INFO] - end of epoch 1035 (average epoch stats below)
[2022-01-03 17:29:44,918][train][INFO] - {"epoch": 1035, "train_loss": "3.544", "train_ntokens": "1799.08", "train_nsentences": "4.95", "train_prob_perplexity": "150.164", "train_code_perplexity": "147.427", "train_temp": "1.626", "train_loss_0": "3.424", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34363", "train_wps": "3932.1", "train_ups": "2.19", "train_wpb": "1799.1", "train_bsz": "5", "train_num_updates": "41400", "train_lr": "0.000487228", "train_gnorm": "0.509", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "19202"}
[2022-01-03 17:29:44,993][fairseq.trainer][INFO] - begin training epoch 1036
[2022-01-03 17:29:44,994][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:29:58,954][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:29:59,448][valid][INFO] - {"epoch": 1036, "valid_loss": "3.476", "valid_ntokens": "786", "valid_nsentences": "2", "valid_prob_perplexity": "146.853", "valid_code_perplexity": "141.844", "valid_temp": "1.626", "valid_loss_0": "3.356", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.38041", "valid_wps": "0", "valid_wpb": "786", "valid_bsz": "2", "valid_num_updates": "41440", "valid_best_loss": "3.043"}
[2022-01-03 17:29:59,449][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1036 @ 41440 updates
[2022-01-03 17:29:59,450][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:30:03,111][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:30:03,140][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1036 @ 41440 updates, score 3.476) (writing took 3.6906379889696836 seconds)
[2022-01-03 17:30:03,141][fairseq_cli.train][INFO] - end of epoch 1036 (average epoch stats below)
[2022-01-03 17:30:03,155][train][INFO] - {"epoch": 1036, "train_loss": "3.58", "train_ntokens": "1797.05", "train_nsentences": "4.95", "train_prob_perplexity": "150.866", "train_code_perplexity": "148.055", "train_temp": "1.626", "train_loss_0": "3.46", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.33701", "train_wps": "3944.4", "train_ups": "2.19", "train_wpb": "1797", "train_bsz": "5", "train_num_updates": "41440", "train_lr": "0.000487174", "train_gnorm": "0.504", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "19221"}
[2022-01-03 17:30:03,228][fairseq.trainer][INFO] - begin training epoch 1037
[2022-01-03 17:30:03,229][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:30:17,256][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:30:17,683][valid][INFO] - {"epoch": 1037, "valid_loss": "3.254", "valid_ntokens": "716", "valid_nsentences": "2", "valid_prob_perplexity": "137.934", "valid_code_perplexity": "133.207", "valid_temp": "1.625", "valid_loss_0": "3.132", "valid_loss_1": "0.113", "valid_loss_2": "0.008", "valid_accuracy": "0.39804", "valid_wps": "0", "valid_wpb": "716", "valid_bsz": "2", "valid_num_updates": "41480", "valid_best_loss": "3.043"}
[2022-01-03 17:30:17,687][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1037 @ 41480 updates
[2022-01-03 17:30:17,687][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:30:21,380][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:30:21,410][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1037 @ 41480 updates, score 3.254) (writing took 3.7230703327804804 seconds)
[2022-01-03 17:30:21,410][fairseq_cli.train][INFO] - end of epoch 1037 (average epoch stats below)
[2022-01-03 17:30:21,422][train][INFO] - {"epoch": 1037, "train_loss": "3.544", "train_ntokens": "1794.55", "train_nsentences": "4.95", "train_prob_perplexity": "150.996", "train_code_perplexity": "148.161", "train_temp": "1.626", "train_loss_0": "3.424", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34445", "train_wps": "3932.1", "train_ups": "2.19", "train_wpb": "1794.5", "train_bsz": "5", "train_num_updates": "41480", "train_lr": "0.00048712", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "5.5", "train_wall": "19239"}
[2022-01-03 17:30:21,480][fairseq.trainer][INFO] - begin training epoch 1038
[2022-01-03 17:30:21,481][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:30:35,437][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:30:35,863][valid][INFO] - {"epoch": 1038, "valid_loss": "3.946", "valid_ntokens": "772", "valid_nsentences": "2", "valid_prob_perplexity": "148.249", "valid_code_perplexity": "142.519", "valid_temp": "1.625", "valid_loss_0": "3.826", "valid_loss_1": "0.111", "valid_loss_2": "0.009", "valid_accuracy": "0.28627", "valid_wps": "0", "valid_wpb": "772", "valid_bsz": "2", "valid_num_updates": "41520", "valid_best_loss": "3.043"}
[2022-01-03 17:30:35,866][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1038 @ 41520 updates
[2022-01-03 17:30:35,866][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:30:39,627][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:30:39,653][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1038 @ 41520 updates, score 3.946) (writing took 3.787646295502782 seconds)
[2022-01-03 17:30:39,654][fairseq_cli.train][INFO] - end of epoch 1038 (average epoch stats below)
[2022-01-03 17:30:39,668][train][INFO] - {"epoch": 1038, "train_loss": "3.559", "train_ntokens": "1784.67", "train_nsentences": "4.95", "train_prob_perplexity": "150.171", "train_code_perplexity": "147.271", "train_temp": "1.625", "train_loss_0": "3.439", "train_loss_1": "0.11", "train_loss_2": "0.01", "train_accuracy": "0.34281", "train_wps": "3915.6", "train_ups": "2.19", "train_wpb": "1784.7", "train_bsz": "5", "train_num_updates": "41520", "train_lr": "0.000487065", "train_gnorm": "0.492", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "6", "train_wall": "19257"}
[2022-01-03 17:30:39,725][fairseq.trainer][INFO] - begin training epoch 1039
[2022-01-03 17:30:39,726][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:30:53,521][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:30:53,935][valid][INFO] - {"epoch": 1039, "valid_loss": "3.798", "valid_ntokens": "760", "valid_nsentences": "2", "valid_prob_perplexity": "124.818", "valid_code_perplexity": "121.681", "valid_temp": "1.625", "valid_loss_0": "3.673", "valid_loss_1": "0.116", "valid_loss_2": "0.009", "valid_accuracy": "0.32105", "valid_wps": "0", "valid_wpb": "760", "valid_bsz": "2", "valid_num_updates": "41560", "valid_best_loss": "3.043"}
[2022-01-03 17:30:53,937][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1039 @ 41560 updates
[2022-01-03 17:30:53,938][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:30:57,865][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:30:57,894][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1039 @ 41560 updates, score 3.798) (writing took 3.9567700549960136 seconds)
[2022-01-03 17:30:57,895][fairseq_cli.train][INFO] - end of epoch 1039 (average epoch stats below)
[2022-01-03 17:30:57,907][train][INFO] - {"epoch": 1039, "train_loss": "3.55", "train_ntokens": "1790.12", "train_nsentences": "4.95", "train_prob_perplexity": "150.816", "train_code_perplexity": "148.121", "train_temp": "1.625", "train_loss_0": "3.431", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34422", "train_wps": "3928.7", "train_ups": "2.19", "train_wpb": "1790.1", "train_bsz": "5", "train_num_updates": "41560", "train_lr": "0.000487011", "train_gnorm": "0.495", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "19275"}
[2022-01-03 17:30:57,989][fairseq.trainer][INFO] - begin training epoch 1040
[2022-01-03 17:30:57,990][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:31:11,824][train_inner][INFO] - {"epoch": 1040, "update": 1040.0, "loss": "3.557", "ntokens": "1794.48", "nsentences": "4.95", "prob_perplexity": "150.895", "code_perplexity": "148.106", "temp": "1.625", "loss_0": "3.437", "loss_1": "0.11", "loss_2": "0.009", "accuracy": "0.34258", "wps": "3928.9", "ups": "2.19", "wpb": "1794.5", "bsz": "5", "num_updates": "41600", "lr": "0.000486957", "gnorm": "0.499", "clip": "0", "train_wall": "67", "gb_free": "5.5", "wall": "19289"}
[2022-01-03 17:31:11,825][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:31:12,229][valid][INFO] - {"epoch": 1040, "valid_loss": "3.368", "valid_ntokens": "750", "valid_nsentences": "2", "valid_prob_perplexity": "147.341", "valid_code_perplexity": "142.681", "valid_temp": "1.624", "valid_loss_0": "3.249", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.36267", "valid_wps": "0", "valid_wpb": "750", "valid_bsz": "2", "valid_num_updates": "41600", "valid_best_loss": "3.043"}
[2022-01-03 17:31:12,233][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1040 @ 41600 updates
[2022-01-03 17:31:12,233][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:31:16,156][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:31:16,184][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1040 @ 41600 updates, score 3.368) (writing took 3.9516602158546448 seconds)
[2022-01-03 17:31:16,185][fairseq_cli.train][INFO] - end of epoch 1040 (average epoch stats below)
[2022-01-03 17:31:16,198][train][INFO] - {"epoch": 1040, "train_loss": "3.552", "train_ntokens": "1806", "train_nsentences": "4.95", "train_prob_perplexity": "151.623", "train_code_perplexity": "148.925", "train_temp": "1.625", "train_loss_0": "3.433", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34444", "train_wps": "3952.4", "train_ups": "2.19", "train_wpb": "1806", "train_bsz": "5", "train_num_updates": "41600", "train_lr": "0.000486957", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "19294"}
[2022-01-03 17:31:16,271][fairseq.trainer][INFO] - begin training epoch 1041
[2022-01-03 17:31:16,272][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:31:30,210][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:31:30,687][valid][INFO] - {"epoch": 1041, "valid_loss": "3.249", "valid_ntokens": "742", "valid_nsentences": "2", "valid_prob_perplexity": "138.569", "valid_code_perplexity": "132.663", "valid_temp": "1.624", "valid_loss_0": "3.127", "valid_loss_1": "0.113", "valid_loss_2": "0.009", "valid_accuracy": "0.41644", "valid_wps": "0", "valid_wpb": "742", "valid_bsz": "2", "valid_num_updates": "41640", "valid_best_loss": "3.043"}
[2022-01-03 17:31:30,688][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1041 @ 41640 updates
[2022-01-03 17:31:30,689][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:31:34,353][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:31:34,369][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1041 @ 41640 updates, score 3.249) (writing took 3.6802899902686477 seconds)
[2022-01-03 17:31:34,369][fairseq_cli.train][INFO] - end of epoch 1041 (average epoch stats below)
[2022-01-03 17:31:34,382][train][INFO] - {"epoch": 1041, "train_loss": "3.551", "train_ntokens": "1804.33", "train_nsentences": "4.95", "train_prob_perplexity": "150.839", "train_code_perplexity": "148.161", "train_temp": "1.624", "train_loss_0": "3.432", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34365", "train_wps": "3971.8", "train_ups": "2.2", "train_wpb": "1804.3", "train_bsz": "5", "train_num_updates": "41640", "train_lr": "0.000486902", "train_gnorm": "0.502", "train_clip": "0", "train_train_wall": "14", "train_gb_free": "9.4", "train_wall": "19312"}
[2022-01-03 17:31:34,454][fairseq.trainer][INFO] - begin training epoch 1042
[2022-01-03 17:31:34,455][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:31:48,368][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:31:48,841][valid][INFO] - {"epoch": 1042, "valid_loss": "3.267", "valid_ntokens": "778", "valid_nsentences": "2", "valid_prob_perplexity": "142.973", "valid_code_perplexity": "137.192", "valid_temp": "1.624", "valid_loss_0": "3.145", "valid_loss_1": "0.112", "valid_loss_2": "0.01", "valid_accuracy": "0.39332", "valid_wps": "0", "valid_wpb": "778", "valid_bsz": "2", "valid_num_updates": "41680", "valid_best_loss": "3.043"}
[2022-01-03 17:31:48,843][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1042 @ 41680 updates
[2022-01-03 17:31:48,843][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:31:52,562][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:31:52,589][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1042 @ 41680 updates, score 3.267) (writing took 3.746411698870361 seconds)
[2022-01-03 17:31:52,590][fairseq_cli.train][INFO] - end of epoch 1042 (average epoch stats below)
[2022-01-03 17:31:52,603][train][INFO] - {"epoch": 1042, "train_loss": "3.543", "train_ntokens": "1795.2", "train_nsentences": "4.95", "train_prob_perplexity": "151.234", "train_code_perplexity": "148.704", "train_temp": "1.624", "train_loss_0": "3.424", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.343", "train_wps": "3943.8", "train_ups": "2.2", "train_wpb": "1795.2", "train_bsz": "5", "train_num_updates": "41680", "train_lr": "0.000486848", "train_gnorm": "0.5", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "5.5", "train_wall": "19330"}
[2022-01-03 17:31:52,668][fairseq.trainer][INFO] - begin training epoch 1043
[2022-01-03 17:31:52,669][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:32:06,597][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:32:07,096][valid][INFO] - {"epoch": 1043, "valid_loss": "3.258", "valid_ntokens": "732", "valid_nsentences": "2", "valid_prob_perplexity": "140.469", "valid_code_perplexity": "135.623", "valid_temp": "1.623", "valid_loss_0": "3.138", "valid_loss_1": "0.113", "valid_loss_2": "0.007", "valid_accuracy": "0.39891", "valid_wps": "0", "valid_wpb": "732", "valid_bsz": "2", "valid_num_updates": "41720", "valid_best_loss": "3.043"}
[2022-01-03 17:32:07,098][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1043 @ 41720 updates
[2022-01-03 17:32:07,099][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:32:10,820][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:32:10,846][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1043 @ 41720 updates, score 3.258) (writing took 3.7474547550082207 seconds)
[2022-01-03 17:32:10,846][fairseq_cli.train][INFO] - end of epoch 1043 (average epoch stats below)
[2022-01-03 17:32:10,859][train][INFO] - {"epoch": 1043, "train_loss": "3.576", "train_ntokens": "1791.92", "train_nsentences": "4.95", "train_prob_perplexity": "151.357", "train_code_perplexity": "148.46", "train_temp": "1.624", "train_loss_0": "3.457", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34051", "train_wps": "3928.9", "train_ups": "2.19", "train_wpb": "1791.9", "train_bsz": "5", "train_num_updates": "41720", "train_lr": "0.000486793", "train_gnorm": "0.501", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "19348"}
[2022-01-03 17:32:10,927][fairseq.trainer][INFO] - begin training epoch 1044
[2022-01-03 17:32:10,928][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:32:24,770][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:32:25,175][valid][INFO] - {"epoch": 1044, "valid_loss": "3.342", "valid_ntokens": "708", "valid_nsentences": "2", "valid_prob_perplexity": "149.019", "valid_code_perplexity": "144.711", "valid_temp": "1.623", "valid_loss_0": "3.224", "valid_loss_1": "0.111", "valid_loss_2": "0.008", "valid_accuracy": "0.37429", "valid_wps": "0", "valid_wpb": "708", "valid_bsz": "2", "valid_num_updates": "41760", "valid_best_loss": "3.043"}
[2022-01-03 17:32:25,178][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1044 @ 41760 updates
[2022-01-03 17:32:25,179][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:32:29,073][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:32:29,097][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1044 @ 41760 updates, score 3.342) (writing took 3.918853825889528 seconds)
[2022-01-03 17:32:29,097][fairseq_cli.train][INFO] - end of epoch 1044 (average epoch stats below)
[2022-01-03 17:32:29,111][train][INFO] - {"epoch": 1044, "train_loss": "3.557", "train_ntokens": "1780.9", "train_nsentences": "4.95", "train_prob_perplexity": "151.414", "train_code_perplexity": "148.686", "train_temp": "1.623", "train_loss_0": "3.438", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.34262", "train_wps": "3905.7", "train_ups": "2.19", "train_wpb": "1780.9", "train_bsz": "5", "train_num_updates": "41760", "train_lr": "0.000486739", "train_gnorm": "0.5", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6", "train_wall": "19367"}
[2022-01-03 17:32:29,158][fairseq.trainer][INFO] - begin training epoch 1045
[2022-01-03 17:32:29,158][fairseq_cli.train][INFO] - Start iterating over samples
[2022-01-03 17:32:42,913][train_inner][INFO] - {"epoch": 1045, "update": 1045.0, "loss": "3.56", "ntokens": "1795.71", "nsentences": "4.95", "prob_perplexity": "151.249", "code_perplexity": "148.535", "temp": "1.624", "loss_0": "3.441", "loss_1": "0.11", "loss_2": "0.009", "accuracy": "0.34181", "wps": "3943.3", "ups": "2.2", "wpb": "1795.7", "bsz": "5", "num_updates": "41800", "lr": "0.000486685", "gnorm": "0.502", "clip": "0", "train_wall": "67", "gb_free": "6.6", "wall": "19380"}
[2022-01-03 17:32:42,914][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2022-01-03 17:32:43,329][valid][INFO] - {"epoch": 1045, "valid_loss": "3.751", "valid_ntokens": "696", "valid_nsentences": "2", "valid_prob_perplexity": "149.611", "valid_code_perplexity": "144.089", "valid_temp": "1.623", "valid_loss_0": "3.632", "valid_loss_1": "0.111", "valid_loss_2": "0.009", "valid_accuracy": "0.32759", "valid_wps": "0", "valid_wpb": "696", "valid_bsz": "2", "valid_num_updates": "41800", "valid_best_loss": "3.043"}
[2022-01-03 17:32:43,333][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1045 @ 41800 updates
[2022-01-03 17:32:43,334][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:32:47,298][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2022-01-03 17:32:47,312][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 1045 @ 41800 updates, score 3.751) (writing took 3.979905535466969 seconds)
[2022-01-03 17:32:47,313][fairseq_cli.train][INFO] - end of epoch 1045 (average epoch stats below)
[2022-01-03 17:32:47,326][train][INFO] - {"epoch": 1045, "train_loss": "3.573", "train_ntokens": "1806.22", "train_nsentences": "4.95", "train_prob_perplexity": "151.4", "train_code_perplexity": "148.662", "train_temp": "1.623", "train_loss_0": "3.454", "train_loss_1": "0.11", "train_loss_2": "0.009", "train_accuracy": "0.33926", "train_wps": "3969.2", "train_ups": "2.2", "train_wpb": "1806.2", "train_bsz": "5", "train_num_updates": "41800", "train_lr": "0.000486685", "train_gnorm": "0.507", "train_clip": "0", "train_train_wall": "13", "train_gb_free": "6.6", "train_wall": "19385"}
[2022-01-03 17:32:47,398][fairseq.trainer][INFO] - begin training epoch 1046
[2022-01-03 17:32:47,399][fairseq_cli.train][INFO] - Start iterating over samples
